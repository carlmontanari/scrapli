{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"scrapli \u00b6 scrapli -- scrap(e c)li -- is a python library focused on connecting to devices, specifically network devices (routers/switches/firewalls/etc.) via SSH or Telnet. The name scrapli -- is just \"scrape cli\" (as in screen scrape) squished together! scrapli's goal is to be as fast and flexible as possible, while providing a thoroughly tested, well typed, well documented, simple API that supports both synchronous and asynchronous usage. Feel free to join the very awesome networktocode slack workspace here , where you will find a scrapli channel where you can discuss anything about scrapli, as well as tons of other channels covering all sorts of network/network-automation topics!","title":"Scrapli"},{"location":"#scrapli","text":"scrapli -- scrap(e c)li -- is a python library focused on connecting to devices, specifically network devices (routers/switches/firewalls/etc.) via SSH or Telnet. The name scrapli -- is just \"scrape cli\" (as in screen scrape) squished together! scrapli's goal is to be as fast and flexible as possible, while providing a thoroughly tested, well typed, well documented, simple API that supports both synchronous and asynchronous usage. Feel free to join the very awesome networktocode slack workspace here , where you will find a scrapli channel where you can discuss anything about scrapli, as well as tons of other channels covering all sorts of network/network-automation topics!","title":"scrapli"},{"location":"changelog/","text":"Changelog \u00b6 2022.07.30.post1 \u00b6 Big thanks once again to @haccht (and to @egreenspan2 for raising an issue on this as well) for fixing up some broken telnet control character handling, and for porting that to async side of things as well! 2022.07.30 \u00b6 Added MANIFEST.in to make sure requirements files are in source distribution see #216 Move weekly build to develop branch so weekly build doesn't fail for \"stale\" main branch reasons textfsm_parse now supports passing in a file or URL to load as the template file -- thank you to @haccht for this one -- see #215 Fixed some mypy/typing challenges around the scrapli \"factory\" context manager -- thank you to @erwinkinn for working on this With lots of help from @netixx tracked down some silliness with timeout decorators not behaving how they should -- check out #233 for details on this Overhauled the functional testing to align more closely with scrapligo and to remove all the old unnecessary dockerfile bits, replacing that completely with containerlab 2022.01.30.post1 \u00b6 Remove newline anchor in in-channel auth password pattern. Felt like a good/smart idea but Cisco in their infinite wisdom have some awful banner on IOL (CML/VIRL) things that doesn't end with a newline and too many people will hit that. Move decorators back to function style -- fixes possible timeout issues as seen in #233 Modified escalate_priv methods to check for password prompt and desired prompt patterns and the current prompt pattern. There was an issue in scrapligo/containerlab where a cEOS device would not let you auth past enable until it is done \"booting\" up, and scrapli would just simply timeout as it didn't expect to see the exec prompt again. Thanks to @hellt for helping track this one down! Replaced standard library telnetlib transport with custom telnet transport (still no external requirements) in very early preparation for telnetlib's deprecation. 2022.01.30 \u00b6 Removed deprecated comms_ansi argument Improved error handling/error message for insufficient permissions when opening ssh config/known hosts file (system transport) Added support for hashed entries in known hosts file thanks to @kangtastic work in #174 Improved \"in channel\" SSH and Telnet authentication handling; better consistency between sync and async, patterns are now compiled only if/when needed Added option to enable echo in PTYProcess (was originally removed from vendor'd code) -- should only be useful/necessary with netconf #165 Allow users to build their own open_cmd for system transport -- users can override this to do things like kubectl exec -it args args args or docker exec -it args args args to connect to containers in k8s/docker #166 Updated/fixed(?) Juniper shell patterns for \"normal\" and root shells #170 Support transport options being passed to asyncssh transport thanks to @cuong-nguyenduy work in #178 and #183 A handful of nice readability/simplicity improvements throughout the codebase thanks to @yezz123 in #188 Fix (add) missing kwarg for channel_log_mode in the driver layers \"above\" base driver Update NXOS config pattern to include \"+\" to not break when entering TACACS config mode Added support for encrypted SSH keys with ssh2 transport in #192 thanks to @shnurty Fix/improve in channel SSH auth password prompt pattern to match scrapligo (which handles user @host password: strings) Update ssh2-python requirements now that 3.10/Darwin release is available Better exception/exception message for auth failures escalating privilege (network drivers) Added a global Settings object -- for now only has an attribute for \"SUPPRESS_USER_WARNINGS\" to... suppress user warnings Added read_callback method to GenericDriver / AsyncGenericDriver -- basically this is a fancier version of send interactive that lets you assign callbacks to things that scrapli reads rather than having to follow prompts in a linear fashion. Dropped Python3.6 support as it is now EOL! Of course, scrapli probably still works just fine with 3.6 (if you install the old 3.6 requirements), but we won't test/support it anymore. Added enable_rsa2 setting to paramiko transport options -- basically 2.9.0+ paramiko enables rsa2 support by default which causes key auth to fail on the test network devices, so we disable that by default, but exposet his flag so users can enable it if desired! 2021.07.30 \u00b6 Added \"% Unavailable command\" to EOS failed_when_contains Moved core platform failed_when_contains to base to not have to duplicate them in sync and async platforms Add file_mode to the enable_basic_logging function, can now choose \"append\" or \"write\" for logfile Add channel_log_mode to the base driver arguments; you can now choose \"append\" or \"write\" for this as well! Improve reading until prompt methods; no longer use re.search on the entire received byte string, now only checks for prompt on the last N chars where N is governed by the base channel args comms_prompt_search_depth attribute.. . this fixes an issue where scrapli could be wayyyyyy slow for very very large outputs (like full tables show bgp) Fix bug (or just terrible initial idea!?) in asynctelnet that reset a timer back to a very small value that was used for testing; most people shouldn't have noticed an issue here, but if you had slow devices this could cause issues that \"looked\" like an authentication issue due to scrapli not having responded to all telnet control characters before punting to auth Added commandeer to driver object; this is used to \"commandeer\" an existing connection but treat it like the new connection object (prompt patterns, methods, etc.) -- generally this would be used for using GenericDriver to connect to a console server, then \"commandeering\" that connection and turning it into an IOSXR/IOSXE/etc. connection object so you have all the \"normal\" behavior of scrapli Add missing timeout on the asynctelnet open method Add py.typed to hopefully do typing more correctly :P BUGFIX: network drivers aborted configuration sessions if responses were failed even if the stop_on_failed arg was set to False; this has been fixed now so that sessions are only aborted if the response is failed and Improved typing for send_interactive Remove napalm dev requirement -- switch to scrapli-cfg for dev environment config management; something something eating dog food or whatever. Deprecate comms_ansi -- if there is an ANSI escape sequence we will now just strip it out automagically; this is not currently a breaking change, but will be -- there is a deprecation warning now and comms_ansi will be fully removed in the 2022.01.30 release (and pre-releases). Removed a sleep that was in the default on_open for IOSXR devices... this has been there a while and I think it was just a hold over from early early versions of scrapli that perhaps had a less robust in channel authentication handler. 1 second faster IOSXR for free! Yay! Fixed an issue with system transport where the transport would get closed twice causing an unhandled exception -- thank you to Alex Lardschneider for finding this! Added an example for the enable_basic_logging function as well as the commandeer method Improved priv level handling -- if you try to acquire \"parallel\" privileges (ex. configuration and configuration exclusive in IOSXR) previously we would say things worked, but we would just stay in configuration mode. This has been fixed (hopefully)! Move ansi escape pattern to compile globally, so it only compiles once (why it was never like that before... who knows) Simplify the collect bits for integration tests... this is still not used heavily but hopefully will be soon! Replace vrnetlab creds in examples with scrapli (felt confusing to have vrnetlab creds everywhere, plus functional testing is moving away from (but still supporting) vrnetlab test environment) Crank up the rows/cols for system transport -> 80 rows, 256 cols -- this to align with scrapligo and to make it less common that users need to modify these values. BUGFIX: fixed blocking read in async channel telnet authentication (thank you Dmitry Figol!) Added not_contains field to privilege levels... this will help greatly simplify the necessary regex patterns, as well as allow us to ditch look arounds which go does not support... step one to a standardized community platform that works with python -or- go! Simplified (at least a little... more would be good) patterns for privilege levels for core platforms. Added _generic_driver_mode to the NetworkDriver classes -- this is a private mode as it should probably be used cautiously -- the idea here is that you can send any strings you want and scrapli will not care about privilege levels at all. See the discussion about this here . BUGFIX: fixed asynctelnet issue with control character handling, thank you to @davaeron -- see #147 BREAKING CHANGE removed the transport.username_prompt and transport.password_prompt attributes of the telnet transports. All authentication has been moved into the channel, so it made no sense to leave these attributes on the transports. This may cause an issue for users that had explicitly set their prompts to something non-standard. Finally added logic to auto set port to 23 for telnet :) BUGFIX: fixed a rare issue where decoding bytes received from the channel (in the response object) would raise a UnicodedecodEerror ; we now catch this exception and decode with ISO-8859-1 encoding which seems to be much less picky about what it decodes. Thanks to Alex Lardschneider for yet another good catch and fix! Added interaction_complete_patterns to all \"interactive\" methods -- this argument accepts a list of strings/patterns; will be re-escape'd if each string does not start with and end with \"^\" and \"$\" (line anchors), otherwise will be compiled with the standard scrapli case-insensitive and multiline flags. If the interactive event finds any of these pattenrs during the course of the interacting it will terminate the interactive session. Note that this is entirely optional and is a keyword only argument so no changes are necessary to any existing scrapli programs. 2021.01.30 \u00b6 BREAKING CHANGE PrivilegeLevel import location changed -- this will break things! timeout_exit deprecated; will always close connection on timeout now All exceptions rationalized/changed -- all exceptions now rooted in ScrapliException and scrapli should not raise any exception that is not rooted in this! It is of course possible that non-scrapli exceptions will get raised at some point, but all \"common\" exceptions will now follow this pattern. Added opinionated logging option -- should be used only for debugging/testing, otherwise use your own logging setup! Moved \"in channel\" auth into channel (for telnet/system ssh authentication) Added channel_lock option, defaults to false Added channel_log option Decorators got reswizzled a little, no more requires open as the transports handle this. There is now a dedicated ChannelTimeout and TransportTimeout to keep things simpler. All transport plugins are now in scrapli \"core\" All (ok, most...) channel and transport args are now properties of the driver class -- this should remove confusion about where to update what timeout/value Response._record_response is now public but only for linting reasons, people generally should ignore this anyway! Python 3.6 will now require dataclasses backport All driver methods now have only the \"main\" argument as an allowable positional argument, the rest of the arguments are keyword-only! For example, send_command you can pass a positional argument for command , but strip_prompt and any additional arguments must be keyword arguments! BREAKING CHANGE Scrape / AsyncScrape renamed --> Driver / AsyncDriver -- given most folks should not be using these directly there will be no alias for this, just a hard change! More improvements to IOSXE tclsh pattern handling; handles tclsh in exec or privilege exec mode now read_until_prompt_or_time now supports regex patterns in the channel_outputs list (pass as a string, will be compiled for you) Big improvements to Factory for users of IDEs -- factories now have proper typing data so you will have nice auto completion things there/typing will be much happier 2020.12.31 \u00b6 Make log messages for textfsm and genie parsers failing to parse consistent as log.warning Add factory example Add \"root\" priv level to junos driver -- probably should be considered experimental for now :) Fix issue where send_config unified result did not have finish time set POSSIBLY BREAKING CHANGE: logger names have changed to be easier to get/make more sense -- the logger for each instance used to look like: \"scrapli-channel-{{ HOST }}\" which kinda was not really smart :). Loggers now look like: \"scrapli.{{ HOST }}:{{ PORT }}.channel\" -- can be channel|driver|transport! Changes to test environment: ~~Support running devices on localhost w/ nat'd management ports -- in \"vrouter\" mode (poorly named) -- this is enabled with the SCRAPLI_VROUTER environment variable set to on/true/something~~ Update 2022.01.30 - renamed to SCRAPLI_BOXEN but does the same thing! Added bootvar into nxos base config -- when missing causes qemu nxosv to boot into loader prompt so thats no good Replace resource settings in vdc in nxos to account for nxos instances with differing resources (memory/cpu) Got rid of static license udi in iosxe config, replaced more certificate stuff so show run comparisons are easier on iosxe NEW TRANSPORT asynctelnet transport is built using standard library asyncio, as such it is part of scrapli core Should be considered beta for a while :) Added a bunch of tests mocking streamreader/writer to ensure that this driver is well tested Added asynctelnet support in nxos and juniper drivers (to change prompt for those platforms) Support asynctelnet in base driver auth_bypass for both telnet drivers completely bypasses not only auth (as it did previously) but also the auth validation where we confirm we got logged in successfully -- reason being is that for console servers and such you may not care about that, you may just want to log in and read data. Removed unnecessary re-checking/verifying of ssh config file in system transport (was basically duplicated from base transport, so was pointless!) Bumped all the default timeout values up as they were probably a bit on the aggressive side Added eager argument to send commands/commands from file and config/configs/configs from file methods -- basically this eager mode will not look for a prompt between lines of commands/configs. This means that things have a tiny potential to get out of whack because we will just send things as fast as possible. In order to not totally break things we will (whether you like it or not!) wait and find the prompt on the last command/config in the list though -- that way we dont get too out of whack. This now means we can use eager to configure banners and macros and things and we no longer need to do the dirty send interactive workaround. Added ScrapliConnectionLost exception and raise it if we get EOF in system transport -- with a message that is more clear than just \"EOF\" and some obscure line in ptyprocess! Added tclsh privilege level for IOSXE Fixed a bug that would prevent going to \"parallel\" privilege levels -- i.e. going from tclsh to configuration or visa versa in IOSXE or from configuration to configuration_exclusive in IOSXR If no failed_when_contains is passed to send_interactive network drivers will now use the network drivers failed_when_contains attribute to bring it inline with the normal command/config methods Added timeout_ops to send_interactive and wrap those methods with the TimeoutModifier decorator Add logic to properly fetch socket address family type so we can handle IPv6 hosts (w/ scrapli-ssh2/scrapli-paramiko) Added tclsh privilege level for NXOS, didn't even know that existed before! 2020.11.15 \u00b6 Fix a regex that sometimes caused a failed functional IOSXR test Add ptyprocess transport options for system transport -- sounds like this may be needed for huawei community platform to be able to set the pty process terminal size -- also added some basic testing for this Update scrapli-ssh2 pin to latest version -- now supports keyboard interactive auth; also un-skipped all related EOS tests now that this works Fix missing acquire priv in default on_open methods for nxos and eos async version Fix incorrect textfsm_platform for iosxr (was cisco_iosxr, now is cisco_xr) Remove unnecessary decorator on write operations for systemssh and telnet -- this operation shouldn't block so this was unnecessary; any issue here should raise some exception from the lower level library. Playing around w/ adding coverage reports with Codecov 2020.10.10 \u00b6 Improve logging in helper functions - especially around resolving ssh config/known hosts Add ttp_parse_output method to Response object; add ttp_parse function in helper Load requirements from requirements files and parse them for setup.py -- stop me from forgetting to update in one place or another! Slacken the IOSXE configuration prompt pattern -- hostname(ipsec-profile) was not being caught by the pattern as it was expecting the part in parenthesis to start with \"conf\" - thank you Talha Javaid for bringing this up on ntc slack, and Alex Lardschneider for confirming the \"fix\" should be good to go! Add community pip extra to install scrapli community Minor README house keeping! Made transport set_timeout saner -- I genuinely don't know what I was doing with that before... this included the base class as well as updating telnet and systemssh... in theory this could be a breaking change if you were just calling set_timeout for some reason without passing an argument... you probably weren't doing that... because why would you? There was some precedent for doing it like this before but it isn't worth caring about now :) Did smarter things with imports in helper, added tests to make sure the warnings are correct Dramatically simplified session locking... this had just gotten out of hand over time... now only the channel locks . This means that basically all inputs/outputs should go through the channel and/or you should acquire the lock yourself if you wish to read/write directly to the transport. Critically this means that all the external transport plugins AND scrapli-netconf need to be updated as well -- this means that you must update all of these if you are using this release! (requirements are of course pinned to make sure this is the case) BREAKING CHANGE: removed ALL keepalive stuff... for now. This will probably get added back, but AFAIK nobody uses it right now and the implementation of it is frankly not very good... keeping it around right now added complexity for little gain. Keepalives will be back and improved hopefully in the next release. If you need them, please just pin to 2020.09.26! 2020.09.26 \u00b6 Improved error handling/exceptions for scrapli Factory Fixed issue where system transport did not properly close/kill SSH connections Added 3.9-dev testing to GitHub Actions Added initial testing/support of on_init callable to base driver -- the idea for on_init is mostly to allow scrapli_community platform creators to be able to add an additional callable to be executed after initialization of the scrapli object, but before any open method is called Added initial testing/support of scrapli_community driver classes -- this would allow scrapli_community platform creators to create driver classes so that they can implement custom methods for each platform type if desired Minor improvements to telnet transport to improve logging as well as authentication validation (are we authenticated); this also makes telnet look/feel a lot more like system which is nice for consistency reasons Fix regression that caused scrapli to spam a bajillion log entries -- now a filter gets applied in both Channel and Transport base classes to snag the filter from the root scrapli logger and apply it to the base/channel loggers Fully give into the warm embrace of dependabot and pin all the dev requirements to specific versions... dependabot can keep us up to date and this lets us not worry about builds failing because of dev requirements getting changed around Fix ptyprocess file object closing issue 2020.08.28 \u00b6 Added Packet Pushers scrapli episode to the README!! Added NXOS and Junos mock ssh servers and created tests for open/close methods (silly tests but just ensures we send what we think we should be sending) Created a property timeout_ops on the driver class -- this property will also set the timeout_ops value of the channel as well, this is just to make it so users don't have to do conn.channel.timeout_ops to set the timeout value... that was not super intuitive! Update dev/test requirements to finally have pylama 2.6! This means that isort can be unpinned and free to update! Add send_and_read method to GenericDriver -- this method allows you to send an input (at the current priv level ) and wait for a prompt, an expected output, or a duration. Add eager flag to the channel send_input method -- this probably should not be used by many folks, but can be used to not read until the prompt pattern is seen. In other words, this will send an input, read the input off the channel and then return. All exceptions that are raised due to catching an internal exception should now be raising \"from\" the caught exception -- mostly this is to appease Pylama, but may end up being nicer on the eyes/easier to see whats going on in some scenarios. IOSXE now catches \"Enable password:\" for an escalation pattern from exec to privilege exec -- fixes #45 The \"requires open\" decorator has been updated/fixed to play nice with asyncio timeout_ops has been converted from an int to a float to allow for more granular timeout control (the other timeouts remain as integers) Few minor docstring fixes from copypasta issues :) Update black pin/re-run black 2020.07.26 \u00b6 Fixed the same get_prompt issue from the last release, but this time managed to actually fix it in async version! Better handling of read_until_input -- stripping some characters out that may get inserted (backspace char), and compares a normalized whitespace version of the read output to the a normalized whitespace version of the input , fixes #36 . Improved system transport ssh error handling -- catch cipher/kex errors better, catch bad configuration messages. Now raise an exception if trying to use an invalid transport class for the base driver type -- i.e. if using asyncssh transport plugin with the \"normal\" sync driver class. Added links to the other projects in the scrapli \"family\" to the readme. Created first draft of the scrapli \"factory\" -- this will allow users to provide the platform name as a string to a single Scrapli or AsyncScrapli class and it will automagically get the right platform driver selected and such . This is also the first support for scrapli_community , which will allow users to contribute non \"core\" platforms and have them be usable in scrapli just like \"normal\". Overhaul decorators for timeouts into a single class (for sync and async), prefer to use signals timeout method where possible, fall back to multiprocessing timeout where required (multiprocessing is slower/more cpu intensive so dont use it if we dont have to). 2020.07.12 \u00b6 Fixed a silly issue where get_prompt was setting the transport timeout to 10s causing user defined timeouts to be effectively ignored. Improved telnet authentication handling -- previously if a return character was needed to get the auth prompts to kick into gear this could break auth. Added \"auth_bypass\" to telnet transport. Probably BUGFIX -- async functions were being decorated by the \"normal\" operation_timeout decorator -- created a mostly duplicated async version of the timeout decorator to wrap the AsyncChannel methods. Fixed a maybe regression that caused drivers to try to authenticate (via interactive methods) even if a auth_secondary is not set. Added tests to make sure that we raise a warning if there is no secondary password set , but try to increase privilege without authentication, and of course if there is an auth secondary set, we obviously try to auth in the normal fashion. Started thinning down the PtyProcess stuff to simplify and and remove all unnecessary parts, as well as add typing and docstrings... not done yet, but some progress! Added additional asyncio example Added blurb about versioning in README Fixed a few README issues (incorrect methods/typos) Updated notes about auth_bypass to include telnet support Added SSHNotFound exception for system SSH/PtyProcess if ssh binary can't be found 2020.07.04 \u00b6 Updated IOSXE base config to include netconf setup for consistency w/ scrapli_netconf Removed \"pipes\" authentication for system ssh -- this is mostly an internal change that simplifies the way that system transport authenticates. We lose the ability to very easily read out of stderr what is going on so even if we auth with a key now we have to \"confirm\" that we are authenticated, but this removes a fair bit of code and unifies things as well as allows for the next line item... Added support for auth_private_key_passphrase to system transport -- allows for entering ssh key passphrase to decrypt ssh keys Added an example on how to deal with \"weird\" things like banners and macros -- these types of things change how the ssh channel works in that they are pseudo \"interactive\" -- meaning the prompt is modified/removed so scrapli can't ever \"know\" when a command is done inserting. It would be possible to support these types of config items more \"natively\" but doing so would lose some of the smarts about how scrapli enters/confirms inputs sent, so for now (and probably for forever) these will need to be configured in a \"special\" fashion Updated IOSXE for functional tests to use 16.12.03 -- this includes updates to the base config/expected configs ... AFAIK there is some better netconf/restconf support in this version which may be handy for tests for scrapli-netconf Update channel/drivers to never decode bytes -- this now only happens in the response object; primary motivation for this is to not have to decode/re-encode in general, and in scrapli-netconf in particular 2020.06.06 \u00b6 Converted all priv levels to be kwargs instead of just args for setup -- simple thing but makes it more readable IMO. Added to the Juniper prompt pattern to include matching the RE prompt that is on the line \"above\" the \"normal \" prompt as this was getting included in command output instead of being seen as part of the prompt by scrapli. Convert driver privilege escalation prompts to use regex to match upper and lower case \"P\" in password prompt Fix core drivers to actually allow for users to pass failed_when_contains , textfsm_platform , genie_platform , and default_desired_privilege_level Add better exception/message for attempting to send command/config to a connection object that has not been opened Add testing for on open/close methods of core drivers Add send_config method to send a single configuration string -- this will automagically handle sending a full configuration, breaking it into a list of configs, sending that list with send_configs and then joining the responses into a single Response object... or of course you can just send a single config line with it too! Add better handling/logging for SystemSSH transport when key exchange cannot be negotiated Convert the _failed() method of MultiResponse to be a property so users can check .failed on a MultiResponse object more intuitively/sanely ASYNC ALL THE THINGS... basically only an internal change, but hugely modified the guts of scrapli to try to be able to best support asyncio while still having the same api for sync and async. Again, if you dont care about aysncio this probably doesnt matter at all as all the \"public\" stuff has not changed for sync versions of things. Completely overhaul unit tests -- unit tests now spin up an SSH server using asyncssh, this server is a very basic implementation of an IOSXE device. This fake IOSXE device allows for connecting/sending commands/handling log on stuff like disabling paging all in as close to the real thing as possible while being completely self contained and completely in python. Additionally since there was a lot of changes to break things out to be more granular with the async implementation the testing has evolved to support this. Increased all hostname patterns to match up to 63 characters -- this is the hostname length limit for Cisco IOSXE at least and should be a reasonable value that hopefully doesnt really ever need to be changed/expanded now Changing logging to create a logger associated with each object instance and include the name/ip of the host in the log name -- should make things a lot nicer with threads/asyncio/etc. Moved from tox to using nox for handling tests/linting; originally this was because of some of the unit testing failing when ran via tox (now I believe this was because there was no TERM env var set in tox), but at this point nox is quite nice so we'll stick with it! Added exception to be raised when users try to use system transport on Windows BUGFIX: Added underscores to hostname patterns for IOSXE, IOSXR, NXOS, and Junos (not valid in EOS at least in my testing) No more Windows testing, not worth the effort BUGFIX: Added functionality to merge less specific (but matching) host entry data for ssh config file hosts -- meaning that we can now merge attributes from a \"*\" entry into a more specific host entry (see #21 ) Add dependabot to see how we like having that friend around... 2020.05.09 \u00b6 Add underscores to EOS config prompt matching Actually fixed on_close methods that I could have sworn were fixed.... gremlins ! (was sending prompt pattern instead of a return char... for copypasta reasons probably) No longer \"exit\" config mode... given that send_command like methods already check to ensure they are in the right priv level there is no reason to exit config mode... just leave it when you need to. Should be a minor speed up if using send_configs more than once in a row, and otherwise should be basically exactly the same. For NetworkDrivers we no longer set the channel prompt pattern depending on the priv level -- it is now *always the combined pattern that matches all priv levels... this should make doing manual things where you change privileges and don't use scrapli's built in methods a little easier. Scrapli still checks that the current prompt matches where it thinks it should be (i.e. config mode vs privileged exec) though, so nothing should change from a user perspective. Improve (fix?) the abort config setup for IOSXR/Junos Add more helpful exception if ssh key permissions are too open Convert PrivilegeLevel from a namedtuple to a class with slots... better for typing and is also mutable so users can more easily update the pattern for a given privilege level if so desired Minor clean up stuff for all the core platforms and network driver, all internal, mostly just about organization! Add \"configuration_exclusive\" privilege level for IOSXRDriver, add \"configuration_private\" and \"configuration_exclusive\" for JunosDriver, modify some of the privilege handling to support these modes -- these can be accessed by simply passing privilege_level=\"configuration_exclusive\" when using send_configs method Add support for configuration sessions for EOS/NXOS. At this time sessions need to be \"registered\" as a privilege level, and then are requestable like any other privilege level, and can be used when sending configs by passing the name of your session as the privilege level argument for send config methods Add a space to EOS prompts -- it seems its very easy to add one to the prompts and scrapli did not enjoy that previously! Give users the option to pass in their own privilege levels for network drivers, and also throw a warning if users try to pass comms_prompt_pattern when using network drivers (as this should all be handled by priv levels) Created MultiResponse object to use instead of a generic list for grouping multiple Response objects Added raise_for_status methods to Response and MultiResponse -- copying the requests style method here to raise an exception if any elements were failed BUGFIX: fixed an issue with IOSXEDriver not matching the config mode pattern for ssh pub key entries. 2020.04.30 \u00b6 Continued improvement around SystemSSHTransport connection/auth failure logging Fix for very intermittent issue where pty fd is not available for reading on SystemSSH/Telnet connections, now we loop over the select statement checking the fd instead of failing if it isn't immediately readable Implement atexit function if keepalives are enabled -- this originally just lived in the ssh2 transport, but needs to be here in the base Transport class as the issue affected all transport types Added send_commands_from_file method... does what it sounds like it does... Added send_configs_from_file method ( NetworkDriver and sub-classes)... also does what it sounds like it does Simplified privilege levels and overhauled how auth escalation/deescalation works. Its still probably a bit more complex than it should be, but its a bit more efficient and at least a little simpler/more flexible. Removed comms_prompt_pattern from Network drivers and now build this as a big pattern matching all of the priv levels for that device type. This is used only for initial connection/finding prompt then scrapli still sets the explicit prompt for the particular privilege level. Implemented lru_cache on some places where we have repetitive tasks... probably unmeasurable difference, but in theory its a little faster now in some places Moved some Network driver things into the base NetworkDriver class to clean things up a bit. Added an _abort_config method to abort configurations for IOSXR/Juniper, this is ignored on the other core platforms BREAKING CHANGE : (minor) Removed now unneeded exception CouldNotAcquirePrivLevel Made the get_prompt_pattern helper a little worse... should revisit to improve/make its use more clear Fixed a screw up that had ridiculous transport timeouts -- at one point timeouts were in seconds, then milliseconds ... went back to seconds, but left things setting millisecond values... fixed :D Added transport_options to base Scrape class -- this is a dict of arguments that can be passed down to your selected transport class... for now this is very limited and is just for passing additional \"open_cmd\" arguments to SystemSSHTransport . The current use case is adding args such as ciphers/kex to your ssh command so you don't need to rely on having this in an ssh config file. 2020.04.19 \u00b6 Increase character count for base prompt pattern for Scrape , GenericDriver , and core drivers. Example: r\"^[a-z0-9.\\-@()/:]{1,32}[#>$]$\" for the base IOSXEDriver comms_prompt_pattern has been increased to: r\"^[a-z0-9.\\-@()/:]{1,48}[#>$]$\" Improve the logging for SystemSSHTransport authentication Fixed an issue where SystemSSHTransport auth would fail due to a login banner having the word password in the banner/text Significantly increase the base timeout_ops value -- as this is not a timer that is going to cause things to block, it may as well be much higher for the default value to help prevent issues Fixed an issue w/ ssh config file not parsing the last host entry Added super basic tests for most of the examples -- just making sure they don't blow up... in general that should keep them in decent shape! Removed cssh2 and miko transports from scrapli core. These have been migrated to their own repositories. From a users perspective nothing really should change -- you can still pip install scrapli[paramiko] to install the paramiko transport and the requirements (paramiko), and the actual usage (setting \"transport\" = \"paramiko \" ) remains the same! This is mostly about keeping the core of scrapli as simple as possible, and also will hopefully help to illustrate that SystemSSH is the development priority for scrapli. Convert many function calls to use keyword args for better readability throughout Add a comms_auto_expand argument to the Channel ; for now this is mostly not used, but may be useful in the future. The purpose of this is to handle devices that auto expand input commands to their full canonical name. Hopefully(?) fixed a bit of an idiosyncrasy where the timeout_transport was being used to decorate read/write operations for telnet/system transports. This is no longer the case, the read/write methods are NOT decorated now , instead we rely on the timeout_ops to time these operations out OR the timeout_transport being set to the timeout value (telnet) or ServerAliveInterval value for system ssh. 2020.04.11 \u00b6 BREAKING CHANGE : modify send_interact to just make more sense in general... now it supports 1->N \"events\" to interact with -- see the \"handling prompts\" section of README for updated example Moved record_response of Response object to be a private method, shouldn't really be needed publicly Moved authenticate and isauthenticated methods of ssh2/paramiko transports to private methods Add auth_bypass option to ignore ssh auth for weird devices such as Cisco WLC -- currently only supported on system transport. Bump timeout_transport up to 10 seconds after finding some issues for some users. Add example for \"non-standard\" device type (Cisco WLC) demo-ing the auth_bypass, custom on_open method, custom comms_prompt_pattern and just general non-standard device stuff. Add option (and make it the default) to have textfsm data returned in list of dict form with the headers being the keys and of course the row values as the values, should be much nicer on the eyes this way! Added terminal width settings for the core drivers to set things as wide as possible so long commands don't have issues Teeny tiny improvements that may make things a tick faster in Channel by using str methods instead of re Create a draft of public api status doc -- this should be useful on a quick glance to see if/when any public methods change, obviously as development simmers down things should be stable but inevitably stuff will change , so the goal here is to just document when methods were introduced and the last time they were changed Move some imports around so that scrapli works on windows (with paramiko/ssh2 transports) 2020.03.29 \u00b6 Add support for parse_genie to Response object; obviously really only for Cisco devices at this point unless there are parsers floating around out there for other platforms I don't know about! Add an atexit function for the ssh2 transport which forcibly closes the connection. This fixes a bug where if a user did not manually close the connection (or use a context manager for the connection) the script would hang open until an interrupt. Added a GenericDriver for those with non-core platforms. The GenericDriver has a really broad prompt pattern match, doesn't know about privilege levels or any other device specific stuff, but does provide the send_command , send_commands , send_interact , and get_prompt methods just like the \"core\" drivers do. This should be a decent starting point for anyone working on non-core platforms! Minor unit test improvement to cover send_commands (plural) and to cover the new GenericDriver Improved auth failure handling for systemssh using pty auth (username/pass auth) Add \"failed_when\" strings to the core drivers; these are used in the response object to help indicate if the channel input failed or succeeded. For scrapli not super super helpful, but nornir_scrapli will benefit from this as well! Modify NetworkDriver to inherit from GenericDriver -- this allowed for some clean up of how/where Response objects get created/returned from. Channel now is much more de-coupled from whatever sits on top of it (this will be important for some netconf testing happening soon!). Minor test de-duplication around ssh config/known hosts file gathering. Added a few simple examples for structured data (textfsm/genie) and updated existing examples a bit.","title":"Changelog"},{"location":"changelog/#changelog","text":"","title":"Changelog"},{"location":"changelog/#20220730post1","text":"Big thanks once again to @haccht (and to @egreenspan2 for raising an issue on this as well) for fixing up some broken telnet control character handling, and for porting that to async side of things as well!","title":"2022.07.30.post1"},{"location":"changelog/#20220730","text":"Added MANIFEST.in to make sure requirements files are in source distribution see #216 Move weekly build to develop branch so weekly build doesn't fail for \"stale\" main branch reasons textfsm_parse now supports passing in a file or URL to load as the template file -- thank you to @haccht for this one -- see #215 Fixed some mypy/typing challenges around the scrapli \"factory\" context manager -- thank you to @erwinkinn for working on this With lots of help from @netixx tracked down some silliness with timeout decorators not behaving how they should -- check out #233 for details on this Overhauled the functional testing to align more closely with scrapligo and to remove all the old unnecessary dockerfile bits, replacing that completely with containerlab","title":"2022.07.30"},{"location":"changelog/#20220130post1","text":"Remove newline anchor in in-channel auth password pattern. Felt like a good/smart idea but Cisco in their infinite wisdom have some awful banner on IOL (CML/VIRL) things that doesn't end with a newline and too many people will hit that. Move decorators back to function style -- fixes possible timeout issues as seen in #233 Modified escalate_priv methods to check for password prompt and desired prompt patterns and the current prompt pattern. There was an issue in scrapligo/containerlab where a cEOS device would not let you auth past enable until it is done \"booting\" up, and scrapli would just simply timeout as it didn't expect to see the exec prompt again. Thanks to @hellt for helping track this one down! Replaced standard library telnetlib transport with custom telnet transport (still no external requirements) in very early preparation for telnetlib's deprecation.","title":"2022.01.30.post1"},{"location":"changelog/#20220130","text":"Removed deprecated comms_ansi argument Improved error handling/error message for insufficient permissions when opening ssh config/known hosts file (system transport) Added support for hashed entries in known hosts file thanks to @kangtastic work in #174 Improved \"in channel\" SSH and Telnet authentication handling; better consistency between sync and async, patterns are now compiled only if/when needed Added option to enable echo in PTYProcess (was originally removed from vendor'd code) -- should only be useful/necessary with netconf #165 Allow users to build their own open_cmd for system transport -- users can override this to do things like kubectl exec -it args args args or docker exec -it args args args to connect to containers in k8s/docker #166 Updated/fixed(?) Juniper shell patterns for \"normal\" and root shells #170 Support transport options being passed to asyncssh transport thanks to @cuong-nguyenduy work in #178 and #183 A handful of nice readability/simplicity improvements throughout the codebase thanks to @yezz123 in #188 Fix (add) missing kwarg for channel_log_mode in the driver layers \"above\" base driver Update NXOS config pattern to include \"+\" to not break when entering TACACS config mode Added support for encrypted SSH keys with ssh2 transport in #192 thanks to @shnurty Fix/improve in channel SSH auth password prompt pattern to match scrapligo (which handles user @host password: strings) Update ssh2-python requirements now that 3.10/Darwin release is available Better exception/exception message for auth failures escalating privilege (network drivers) Added a global Settings object -- for now only has an attribute for \"SUPPRESS_USER_WARNINGS\" to... suppress user warnings Added read_callback method to GenericDriver / AsyncGenericDriver -- basically this is a fancier version of send interactive that lets you assign callbacks to things that scrapli reads rather than having to follow prompts in a linear fashion. Dropped Python3.6 support as it is now EOL! Of course, scrapli probably still works just fine with 3.6 (if you install the old 3.6 requirements), but we won't test/support it anymore. Added enable_rsa2 setting to paramiko transport options -- basically 2.9.0+ paramiko enables rsa2 support by default which causes key auth to fail on the test network devices, so we disable that by default, but exposet his flag so users can enable it if desired!","title":"2022.01.30"},{"location":"changelog/#20210730","text":"Added \"% Unavailable command\" to EOS failed_when_contains Moved core platform failed_when_contains to base to not have to duplicate them in sync and async platforms Add file_mode to the enable_basic_logging function, can now choose \"append\" or \"write\" for logfile Add channel_log_mode to the base driver arguments; you can now choose \"append\" or \"write\" for this as well! Improve reading until prompt methods; no longer use re.search on the entire received byte string, now only checks for prompt on the last N chars where N is governed by the base channel args comms_prompt_search_depth attribute.. . this fixes an issue where scrapli could be wayyyyyy slow for very very large outputs (like full tables show bgp) Fix bug (or just terrible initial idea!?) in asynctelnet that reset a timer back to a very small value that was used for testing; most people shouldn't have noticed an issue here, but if you had slow devices this could cause issues that \"looked\" like an authentication issue due to scrapli not having responded to all telnet control characters before punting to auth Added commandeer to driver object; this is used to \"commandeer\" an existing connection but treat it like the new connection object (prompt patterns, methods, etc.) -- generally this would be used for using GenericDriver to connect to a console server, then \"commandeering\" that connection and turning it into an IOSXR/IOSXE/etc. connection object so you have all the \"normal\" behavior of scrapli Add missing timeout on the asynctelnet open method Add py.typed to hopefully do typing more correctly :P BUGFIX: network drivers aborted configuration sessions if responses were failed even if the stop_on_failed arg was set to False; this has been fixed now so that sessions are only aborted if the response is failed and Improved typing for send_interactive Remove napalm dev requirement -- switch to scrapli-cfg for dev environment config management; something something eating dog food or whatever. Deprecate comms_ansi -- if there is an ANSI escape sequence we will now just strip it out automagically; this is not currently a breaking change, but will be -- there is a deprecation warning now and comms_ansi will be fully removed in the 2022.01.30 release (and pre-releases). Removed a sleep that was in the default on_open for IOSXR devices... this has been there a while and I think it was just a hold over from early early versions of scrapli that perhaps had a less robust in channel authentication handler. 1 second faster IOSXR for free! Yay! Fixed an issue with system transport where the transport would get closed twice causing an unhandled exception -- thank you to Alex Lardschneider for finding this! Added an example for the enable_basic_logging function as well as the commandeer method Improved priv level handling -- if you try to acquire \"parallel\" privileges (ex. configuration and configuration exclusive in IOSXR) previously we would say things worked, but we would just stay in configuration mode. This has been fixed (hopefully)! Move ansi escape pattern to compile globally, so it only compiles once (why it was never like that before... who knows) Simplify the collect bits for integration tests... this is still not used heavily but hopefully will be soon! Replace vrnetlab creds in examples with scrapli (felt confusing to have vrnetlab creds everywhere, plus functional testing is moving away from (but still supporting) vrnetlab test environment) Crank up the rows/cols for system transport -> 80 rows, 256 cols -- this to align with scrapligo and to make it less common that users need to modify these values. BUGFIX: fixed blocking read in async channel telnet authentication (thank you Dmitry Figol!) Added not_contains field to privilege levels... this will help greatly simplify the necessary regex patterns, as well as allow us to ditch look arounds which go does not support... step one to a standardized community platform that works with python -or- go! Simplified (at least a little... more would be good) patterns for privilege levels for core platforms. Added _generic_driver_mode to the NetworkDriver classes -- this is a private mode as it should probably be used cautiously -- the idea here is that you can send any strings you want and scrapli will not care about privilege levels at all. See the discussion about this here . BUGFIX: fixed asynctelnet issue with control character handling, thank you to @davaeron -- see #147 BREAKING CHANGE removed the transport.username_prompt and transport.password_prompt attributes of the telnet transports. All authentication has been moved into the channel, so it made no sense to leave these attributes on the transports. This may cause an issue for users that had explicitly set their prompts to something non-standard. Finally added logic to auto set port to 23 for telnet :) BUGFIX: fixed a rare issue where decoding bytes received from the channel (in the response object) would raise a UnicodedecodEerror ; we now catch this exception and decode with ISO-8859-1 encoding which seems to be much less picky about what it decodes. Thanks to Alex Lardschneider for yet another good catch and fix! Added interaction_complete_patterns to all \"interactive\" methods -- this argument accepts a list of strings/patterns; will be re-escape'd if each string does not start with and end with \"^\" and \"$\" (line anchors), otherwise will be compiled with the standard scrapli case-insensitive and multiline flags. If the interactive event finds any of these pattenrs during the course of the interacting it will terminate the interactive session. Note that this is entirely optional and is a keyword only argument so no changes are necessary to any existing scrapli programs.","title":"2021.07.30"},{"location":"changelog/#20210130","text":"BREAKING CHANGE PrivilegeLevel import location changed -- this will break things! timeout_exit deprecated; will always close connection on timeout now All exceptions rationalized/changed -- all exceptions now rooted in ScrapliException and scrapli should not raise any exception that is not rooted in this! It is of course possible that non-scrapli exceptions will get raised at some point, but all \"common\" exceptions will now follow this pattern. Added opinionated logging option -- should be used only for debugging/testing, otherwise use your own logging setup! Moved \"in channel\" auth into channel (for telnet/system ssh authentication) Added channel_lock option, defaults to false Added channel_log option Decorators got reswizzled a little, no more requires open as the transports handle this. There is now a dedicated ChannelTimeout and TransportTimeout to keep things simpler. All transport plugins are now in scrapli \"core\" All (ok, most...) channel and transport args are now properties of the driver class -- this should remove confusion about where to update what timeout/value Response._record_response is now public but only for linting reasons, people generally should ignore this anyway! Python 3.6 will now require dataclasses backport All driver methods now have only the \"main\" argument as an allowable positional argument, the rest of the arguments are keyword-only! For example, send_command you can pass a positional argument for command , but strip_prompt and any additional arguments must be keyword arguments! BREAKING CHANGE Scrape / AsyncScrape renamed --> Driver / AsyncDriver -- given most folks should not be using these directly there will be no alias for this, just a hard change! More improvements to IOSXE tclsh pattern handling; handles tclsh in exec or privilege exec mode now read_until_prompt_or_time now supports regex patterns in the channel_outputs list (pass as a string, will be compiled for you) Big improvements to Factory for users of IDEs -- factories now have proper typing data so you will have nice auto completion things there/typing will be much happier","title":"2021.01.30"},{"location":"changelog/#20201231","text":"Make log messages for textfsm and genie parsers failing to parse consistent as log.warning Add factory example Add \"root\" priv level to junos driver -- probably should be considered experimental for now :) Fix issue where send_config unified result did not have finish time set POSSIBLY BREAKING CHANGE: logger names have changed to be easier to get/make more sense -- the logger for each instance used to look like: \"scrapli-channel-{{ HOST }}\" which kinda was not really smart :). Loggers now look like: \"scrapli.{{ HOST }}:{{ PORT }}.channel\" -- can be channel|driver|transport! Changes to test environment: ~~Support running devices on localhost w/ nat'd management ports -- in \"vrouter\" mode (poorly named) -- this is enabled with the SCRAPLI_VROUTER environment variable set to on/true/something~~ Update 2022.01.30 - renamed to SCRAPLI_BOXEN but does the same thing! Added bootvar into nxos base config -- when missing causes qemu nxosv to boot into loader prompt so thats no good Replace resource settings in vdc in nxos to account for nxos instances with differing resources (memory/cpu) Got rid of static license udi in iosxe config, replaced more certificate stuff so show run comparisons are easier on iosxe NEW TRANSPORT asynctelnet transport is built using standard library asyncio, as such it is part of scrapli core Should be considered beta for a while :) Added a bunch of tests mocking streamreader/writer to ensure that this driver is well tested Added asynctelnet support in nxos and juniper drivers (to change prompt for those platforms) Support asynctelnet in base driver auth_bypass for both telnet drivers completely bypasses not only auth (as it did previously) but also the auth validation where we confirm we got logged in successfully -- reason being is that for console servers and such you may not care about that, you may just want to log in and read data. Removed unnecessary re-checking/verifying of ssh config file in system transport (was basically duplicated from base transport, so was pointless!) Bumped all the default timeout values up as they were probably a bit on the aggressive side Added eager argument to send commands/commands from file and config/configs/configs from file methods -- basically this eager mode will not look for a prompt between lines of commands/configs. This means that things have a tiny potential to get out of whack because we will just send things as fast as possible. In order to not totally break things we will (whether you like it or not!) wait and find the prompt on the last command/config in the list though -- that way we dont get too out of whack. This now means we can use eager to configure banners and macros and things and we no longer need to do the dirty send interactive workaround. Added ScrapliConnectionLost exception and raise it if we get EOF in system transport -- with a message that is more clear than just \"EOF\" and some obscure line in ptyprocess! Added tclsh privilege level for IOSXE Fixed a bug that would prevent going to \"parallel\" privilege levels -- i.e. going from tclsh to configuration or visa versa in IOSXE or from configuration to configuration_exclusive in IOSXR If no failed_when_contains is passed to send_interactive network drivers will now use the network drivers failed_when_contains attribute to bring it inline with the normal command/config methods Added timeout_ops to send_interactive and wrap those methods with the TimeoutModifier decorator Add logic to properly fetch socket address family type so we can handle IPv6 hosts (w/ scrapli-ssh2/scrapli-paramiko) Added tclsh privilege level for NXOS, didn't even know that existed before!","title":"2020.12.31"},{"location":"changelog/#20201115","text":"Fix a regex that sometimes caused a failed functional IOSXR test Add ptyprocess transport options for system transport -- sounds like this may be needed for huawei community platform to be able to set the pty process terminal size -- also added some basic testing for this Update scrapli-ssh2 pin to latest version -- now supports keyboard interactive auth; also un-skipped all related EOS tests now that this works Fix missing acquire priv in default on_open methods for nxos and eos async version Fix incorrect textfsm_platform for iosxr (was cisco_iosxr, now is cisco_xr) Remove unnecessary decorator on write operations for systemssh and telnet -- this operation shouldn't block so this was unnecessary; any issue here should raise some exception from the lower level library. Playing around w/ adding coverage reports with Codecov","title":"2020.11.15"},{"location":"changelog/#20201010","text":"Improve logging in helper functions - especially around resolving ssh config/known hosts Add ttp_parse_output method to Response object; add ttp_parse function in helper Load requirements from requirements files and parse them for setup.py -- stop me from forgetting to update in one place or another! Slacken the IOSXE configuration prompt pattern -- hostname(ipsec-profile) was not being caught by the pattern as it was expecting the part in parenthesis to start with \"conf\" - thank you Talha Javaid for bringing this up on ntc slack, and Alex Lardschneider for confirming the \"fix\" should be good to go! Add community pip extra to install scrapli community Minor README house keeping! Made transport set_timeout saner -- I genuinely don't know what I was doing with that before... this included the base class as well as updating telnet and systemssh... in theory this could be a breaking change if you were just calling set_timeout for some reason without passing an argument... you probably weren't doing that... because why would you? There was some precedent for doing it like this before but it isn't worth caring about now :) Did smarter things with imports in helper, added tests to make sure the warnings are correct Dramatically simplified session locking... this had just gotten out of hand over time... now only the channel locks . This means that basically all inputs/outputs should go through the channel and/or you should acquire the lock yourself if you wish to read/write directly to the transport. Critically this means that all the external transport plugins AND scrapli-netconf need to be updated as well -- this means that you must update all of these if you are using this release! (requirements are of course pinned to make sure this is the case) BREAKING CHANGE: removed ALL keepalive stuff... for now. This will probably get added back, but AFAIK nobody uses it right now and the implementation of it is frankly not very good... keeping it around right now added complexity for little gain. Keepalives will be back and improved hopefully in the next release. If you need them, please just pin to 2020.09.26!","title":"2020.10.10"},{"location":"changelog/#20200926","text":"Improved error handling/exceptions for scrapli Factory Fixed issue where system transport did not properly close/kill SSH connections Added 3.9-dev testing to GitHub Actions Added initial testing/support of on_init callable to base driver -- the idea for on_init is mostly to allow scrapli_community platform creators to be able to add an additional callable to be executed after initialization of the scrapli object, but before any open method is called Added initial testing/support of scrapli_community driver classes -- this would allow scrapli_community platform creators to create driver classes so that they can implement custom methods for each platform type if desired Minor improvements to telnet transport to improve logging as well as authentication validation (are we authenticated); this also makes telnet look/feel a lot more like system which is nice for consistency reasons Fix regression that caused scrapli to spam a bajillion log entries -- now a filter gets applied in both Channel and Transport base classes to snag the filter from the root scrapli logger and apply it to the base/channel loggers Fully give into the warm embrace of dependabot and pin all the dev requirements to specific versions... dependabot can keep us up to date and this lets us not worry about builds failing because of dev requirements getting changed around Fix ptyprocess file object closing issue","title":"2020.09.26"},{"location":"changelog/#20200828","text":"Added Packet Pushers scrapli episode to the README!! Added NXOS and Junos mock ssh servers and created tests for open/close methods (silly tests but just ensures we send what we think we should be sending) Created a property timeout_ops on the driver class -- this property will also set the timeout_ops value of the channel as well, this is just to make it so users don't have to do conn.channel.timeout_ops to set the timeout value... that was not super intuitive! Update dev/test requirements to finally have pylama 2.6! This means that isort can be unpinned and free to update! Add send_and_read method to GenericDriver -- this method allows you to send an input (at the current priv level ) and wait for a prompt, an expected output, or a duration. Add eager flag to the channel send_input method -- this probably should not be used by many folks, but can be used to not read until the prompt pattern is seen. In other words, this will send an input, read the input off the channel and then return. All exceptions that are raised due to catching an internal exception should now be raising \"from\" the caught exception -- mostly this is to appease Pylama, but may end up being nicer on the eyes/easier to see whats going on in some scenarios. IOSXE now catches \"Enable password:\" for an escalation pattern from exec to privilege exec -- fixes #45 The \"requires open\" decorator has been updated/fixed to play nice with asyncio timeout_ops has been converted from an int to a float to allow for more granular timeout control (the other timeouts remain as integers) Few minor docstring fixes from copypasta issues :) Update black pin/re-run black","title":"2020.08.28"},{"location":"changelog/#20200726","text":"Fixed the same get_prompt issue from the last release, but this time managed to actually fix it in async version! Better handling of read_until_input -- stripping some characters out that may get inserted (backspace char), and compares a normalized whitespace version of the read output to the a normalized whitespace version of the input , fixes #36 . Improved system transport ssh error handling -- catch cipher/kex errors better, catch bad configuration messages. Now raise an exception if trying to use an invalid transport class for the base driver type -- i.e. if using asyncssh transport plugin with the \"normal\" sync driver class. Added links to the other projects in the scrapli \"family\" to the readme. Created first draft of the scrapli \"factory\" -- this will allow users to provide the platform name as a string to a single Scrapli or AsyncScrapli class and it will automagically get the right platform driver selected and such . This is also the first support for scrapli_community , which will allow users to contribute non \"core\" platforms and have them be usable in scrapli just like \"normal\". Overhaul decorators for timeouts into a single class (for sync and async), prefer to use signals timeout method where possible, fall back to multiprocessing timeout where required (multiprocessing is slower/more cpu intensive so dont use it if we dont have to).","title":"2020.07.26"},{"location":"changelog/#20200712","text":"Fixed a silly issue where get_prompt was setting the transport timeout to 10s causing user defined timeouts to be effectively ignored. Improved telnet authentication handling -- previously if a return character was needed to get the auth prompts to kick into gear this could break auth. Added \"auth_bypass\" to telnet transport. Probably BUGFIX -- async functions were being decorated by the \"normal\" operation_timeout decorator -- created a mostly duplicated async version of the timeout decorator to wrap the AsyncChannel methods. Fixed a maybe regression that caused drivers to try to authenticate (via interactive methods) even if a auth_secondary is not set. Added tests to make sure that we raise a warning if there is no secondary password set , but try to increase privilege without authentication, and of course if there is an auth secondary set, we obviously try to auth in the normal fashion. Started thinning down the PtyProcess stuff to simplify and and remove all unnecessary parts, as well as add typing and docstrings... not done yet, but some progress! Added additional asyncio example Added blurb about versioning in README Fixed a few README issues (incorrect methods/typos) Updated notes about auth_bypass to include telnet support Added SSHNotFound exception for system SSH/PtyProcess if ssh binary can't be found","title":"2020.07.12"},{"location":"changelog/#20200704","text":"Updated IOSXE base config to include netconf setup for consistency w/ scrapli_netconf Removed \"pipes\" authentication for system ssh -- this is mostly an internal change that simplifies the way that system transport authenticates. We lose the ability to very easily read out of stderr what is going on so even if we auth with a key now we have to \"confirm\" that we are authenticated, but this removes a fair bit of code and unifies things as well as allows for the next line item... Added support for auth_private_key_passphrase to system transport -- allows for entering ssh key passphrase to decrypt ssh keys Added an example on how to deal with \"weird\" things like banners and macros -- these types of things change how the ssh channel works in that they are pseudo \"interactive\" -- meaning the prompt is modified/removed so scrapli can't ever \"know\" when a command is done inserting. It would be possible to support these types of config items more \"natively\" but doing so would lose some of the smarts about how scrapli enters/confirms inputs sent, so for now (and probably for forever) these will need to be configured in a \"special\" fashion Updated IOSXE for functional tests to use 16.12.03 -- this includes updates to the base config/expected configs ... AFAIK there is some better netconf/restconf support in this version which may be handy for tests for scrapli-netconf Update channel/drivers to never decode bytes -- this now only happens in the response object; primary motivation for this is to not have to decode/re-encode in general, and in scrapli-netconf in particular","title":"2020.07.04"},{"location":"changelog/#20200606","text":"Converted all priv levels to be kwargs instead of just args for setup -- simple thing but makes it more readable IMO. Added to the Juniper prompt pattern to include matching the RE prompt that is on the line \"above\" the \"normal \" prompt as this was getting included in command output instead of being seen as part of the prompt by scrapli. Convert driver privilege escalation prompts to use regex to match upper and lower case \"P\" in password prompt Fix core drivers to actually allow for users to pass failed_when_contains , textfsm_platform , genie_platform , and default_desired_privilege_level Add better exception/message for attempting to send command/config to a connection object that has not been opened Add testing for on open/close methods of core drivers Add send_config method to send a single configuration string -- this will automagically handle sending a full configuration, breaking it into a list of configs, sending that list with send_configs and then joining the responses into a single Response object... or of course you can just send a single config line with it too! Add better handling/logging for SystemSSH transport when key exchange cannot be negotiated Convert the _failed() method of MultiResponse to be a property so users can check .failed on a MultiResponse object more intuitively/sanely ASYNC ALL THE THINGS... basically only an internal change, but hugely modified the guts of scrapli to try to be able to best support asyncio while still having the same api for sync and async. Again, if you dont care about aysncio this probably doesnt matter at all as all the \"public\" stuff has not changed for sync versions of things. Completely overhaul unit tests -- unit tests now spin up an SSH server using asyncssh, this server is a very basic implementation of an IOSXE device. This fake IOSXE device allows for connecting/sending commands/handling log on stuff like disabling paging all in as close to the real thing as possible while being completely self contained and completely in python. Additionally since there was a lot of changes to break things out to be more granular with the async implementation the testing has evolved to support this. Increased all hostname patterns to match up to 63 characters -- this is the hostname length limit for Cisco IOSXE at least and should be a reasonable value that hopefully doesnt really ever need to be changed/expanded now Changing logging to create a logger associated with each object instance and include the name/ip of the host in the log name -- should make things a lot nicer with threads/asyncio/etc. Moved from tox to using nox for handling tests/linting; originally this was because of some of the unit testing failing when ran via tox (now I believe this was because there was no TERM env var set in tox), but at this point nox is quite nice so we'll stick with it! Added exception to be raised when users try to use system transport on Windows BUGFIX: Added underscores to hostname patterns for IOSXE, IOSXR, NXOS, and Junos (not valid in EOS at least in my testing) No more Windows testing, not worth the effort BUGFIX: Added functionality to merge less specific (but matching) host entry data for ssh config file hosts -- meaning that we can now merge attributes from a \"*\" entry into a more specific host entry (see #21 ) Add dependabot to see how we like having that friend around...","title":"2020.06.06"},{"location":"changelog/#20200509","text":"Add underscores to EOS config prompt matching Actually fixed on_close methods that I could have sworn were fixed.... gremlins ! (was sending prompt pattern instead of a return char... for copypasta reasons probably) No longer \"exit\" config mode... given that send_command like methods already check to ensure they are in the right priv level there is no reason to exit config mode... just leave it when you need to. Should be a minor speed up if using send_configs more than once in a row, and otherwise should be basically exactly the same. For NetworkDrivers we no longer set the channel prompt pattern depending on the priv level -- it is now *always the combined pattern that matches all priv levels... this should make doing manual things where you change privileges and don't use scrapli's built in methods a little easier. Scrapli still checks that the current prompt matches where it thinks it should be (i.e. config mode vs privileged exec) though, so nothing should change from a user perspective. Improve (fix?) the abort config setup for IOSXR/Junos Add more helpful exception if ssh key permissions are too open Convert PrivilegeLevel from a namedtuple to a class with slots... better for typing and is also mutable so users can more easily update the pattern for a given privilege level if so desired Minor clean up stuff for all the core platforms and network driver, all internal, mostly just about organization! Add \"configuration_exclusive\" privilege level for IOSXRDriver, add \"configuration_private\" and \"configuration_exclusive\" for JunosDriver, modify some of the privilege handling to support these modes -- these can be accessed by simply passing privilege_level=\"configuration_exclusive\" when using send_configs method Add support for configuration sessions for EOS/NXOS. At this time sessions need to be \"registered\" as a privilege level, and then are requestable like any other privilege level, and can be used when sending configs by passing the name of your session as the privilege level argument for send config methods Add a space to EOS prompts -- it seems its very easy to add one to the prompts and scrapli did not enjoy that previously! Give users the option to pass in their own privilege levels for network drivers, and also throw a warning if users try to pass comms_prompt_pattern when using network drivers (as this should all be handled by priv levels) Created MultiResponse object to use instead of a generic list for grouping multiple Response objects Added raise_for_status methods to Response and MultiResponse -- copying the requests style method here to raise an exception if any elements were failed BUGFIX: fixed an issue with IOSXEDriver not matching the config mode pattern for ssh pub key entries.","title":"2020.05.09"},{"location":"changelog/#20200430","text":"Continued improvement around SystemSSHTransport connection/auth failure logging Fix for very intermittent issue where pty fd is not available for reading on SystemSSH/Telnet connections, now we loop over the select statement checking the fd instead of failing if it isn't immediately readable Implement atexit function if keepalives are enabled -- this originally just lived in the ssh2 transport, but needs to be here in the base Transport class as the issue affected all transport types Added send_commands_from_file method... does what it sounds like it does... Added send_configs_from_file method ( NetworkDriver and sub-classes)... also does what it sounds like it does Simplified privilege levels and overhauled how auth escalation/deescalation works. Its still probably a bit more complex than it should be, but its a bit more efficient and at least a little simpler/more flexible. Removed comms_prompt_pattern from Network drivers and now build this as a big pattern matching all of the priv levels for that device type. This is used only for initial connection/finding prompt then scrapli still sets the explicit prompt for the particular privilege level. Implemented lru_cache on some places where we have repetitive tasks... probably unmeasurable difference, but in theory its a little faster now in some places Moved some Network driver things into the base NetworkDriver class to clean things up a bit. Added an _abort_config method to abort configurations for IOSXR/Juniper, this is ignored on the other core platforms BREAKING CHANGE : (minor) Removed now unneeded exception CouldNotAcquirePrivLevel Made the get_prompt_pattern helper a little worse... should revisit to improve/make its use more clear Fixed a screw up that had ridiculous transport timeouts -- at one point timeouts were in seconds, then milliseconds ... went back to seconds, but left things setting millisecond values... fixed :D Added transport_options to base Scrape class -- this is a dict of arguments that can be passed down to your selected transport class... for now this is very limited and is just for passing additional \"open_cmd\" arguments to SystemSSHTransport . The current use case is adding args such as ciphers/kex to your ssh command so you don't need to rely on having this in an ssh config file.","title":"2020.04.30"},{"location":"changelog/#20200419","text":"Increase character count for base prompt pattern for Scrape , GenericDriver , and core drivers. Example: r\"^[a-z0-9.\\-@()/:]{1,32}[#>$]$\" for the base IOSXEDriver comms_prompt_pattern has been increased to: r\"^[a-z0-9.\\-@()/:]{1,48}[#>$]$\" Improve the logging for SystemSSHTransport authentication Fixed an issue where SystemSSHTransport auth would fail due to a login banner having the word password in the banner/text Significantly increase the base timeout_ops value -- as this is not a timer that is going to cause things to block, it may as well be much higher for the default value to help prevent issues Fixed an issue w/ ssh config file not parsing the last host entry Added super basic tests for most of the examples -- just making sure they don't blow up... in general that should keep them in decent shape! Removed cssh2 and miko transports from scrapli core. These have been migrated to their own repositories. From a users perspective nothing really should change -- you can still pip install scrapli[paramiko] to install the paramiko transport and the requirements (paramiko), and the actual usage (setting \"transport\" = \"paramiko \" ) remains the same! This is mostly about keeping the core of scrapli as simple as possible, and also will hopefully help to illustrate that SystemSSH is the development priority for scrapli. Convert many function calls to use keyword args for better readability throughout Add a comms_auto_expand argument to the Channel ; for now this is mostly not used, but may be useful in the future. The purpose of this is to handle devices that auto expand input commands to their full canonical name. Hopefully(?) fixed a bit of an idiosyncrasy where the timeout_transport was being used to decorate read/write operations for telnet/system transports. This is no longer the case, the read/write methods are NOT decorated now , instead we rely on the timeout_ops to time these operations out OR the timeout_transport being set to the timeout value (telnet) or ServerAliveInterval value for system ssh.","title":"2020.04.19"},{"location":"changelog/#20200411","text":"BREAKING CHANGE : modify send_interact to just make more sense in general... now it supports 1->N \"events\" to interact with -- see the \"handling prompts\" section of README for updated example Moved record_response of Response object to be a private method, shouldn't really be needed publicly Moved authenticate and isauthenticated methods of ssh2/paramiko transports to private methods Add auth_bypass option to ignore ssh auth for weird devices such as Cisco WLC -- currently only supported on system transport. Bump timeout_transport up to 10 seconds after finding some issues for some users. Add example for \"non-standard\" device type (Cisco WLC) demo-ing the auth_bypass, custom on_open method, custom comms_prompt_pattern and just general non-standard device stuff. Add option (and make it the default) to have textfsm data returned in list of dict form with the headers being the keys and of course the row values as the values, should be much nicer on the eyes this way! Added terminal width settings for the core drivers to set things as wide as possible so long commands don't have issues Teeny tiny improvements that may make things a tick faster in Channel by using str methods instead of re Create a draft of public api status doc -- this should be useful on a quick glance to see if/when any public methods change, obviously as development simmers down things should be stable but inevitably stuff will change , so the goal here is to just document when methods were introduced and the last time they were changed Move some imports around so that scrapli works on windows (with paramiko/ssh2 transports)","title":"2020.04.11"},{"location":"changelog/#20200329","text":"Add support for parse_genie to Response object; obviously really only for Cisco devices at this point unless there are parsers floating around out there for other platforms I don't know about! Add an atexit function for the ssh2 transport which forcibly closes the connection. This fixes a bug where if a user did not manually close the connection (or use a context manager for the connection) the script would hang open until an interrupt. Added a GenericDriver for those with non-core platforms. The GenericDriver has a really broad prompt pattern match, doesn't know about privilege levels or any other device specific stuff, but does provide the send_command , send_commands , send_interact , and get_prompt methods just like the \"core\" drivers do. This should be a decent starting point for anyone working on non-core platforms! Minor unit test improvement to cover send_commands (plural) and to cover the new GenericDriver Improved auth failure handling for systemssh using pty auth (username/pass auth) Add \"failed_when\" strings to the core drivers; these are used in the response object to help indicate if the channel input failed or succeeded. For scrapli not super super helpful, but nornir_scrapli will benefit from this as well! Modify NetworkDriver to inherit from GenericDriver -- this allowed for some clean up of how/where Response objects get created/returned from. Channel now is much more de-coupled from whatever sits on top of it (this will be important for some netconf testing happening soon!). Minor test de-duplication around ssh config/known hosts file gathering. Added a few simple examples for structured data (textfsm/genie) and updated existing examples a bit.","title":"2020.03.29"},{"location":"public_api_status/","text":"Public API Status \u00b6 Note that all public methods, unless otherwise noted, are available in sync and async form depending on the driver you have selected. Drivers \u00b6 Driver \u00b6 Method Implemented Last Change Notes open 2020.03.29 close 2020.03.29 isalive 2020.03.29 AsyncDriver \u00b6 Method Implemented Last Change Notes open 2020.06.06 close 2020.06.06 isalive 2020.06.06 GenericDriver (and NetworkDriver sub-classes unless overridden) \u00b6 Method Implemented Last Change Notes get_prompt 2020.03.29 send_command 2020.03.29 2020.08.09 added timeout_ops keyword argument to modify timeout send_commands 2020.03.29 2020.12.31 added eager keyword argument send_commands_from_file 2020.04.30 2020.12.31 added eager keyword argument send_interactive 2020.03.29 2021.01.30 added interaction_complete_patterns keyword argument send_and_read 2020.08.28 send_callback 2022.01.30 AsyncGenericDriver (and NetworkDriver sub-classes unless overridden) \u00b6 Method Implemented Last Change Notes get_prompt 2020.06.06 send_command 2020.06.06 2020.08.09 added timeout_ops keyword argument to modify timeout send_commands 2020.06.06 2020.12.31 added eager keyword argument send_commands_from_file 2020.06.06 2020.12.31 added eager keyword argument send_interactive 2020.06.06 2021.01.30 added interaction_complete_patterns keyword argument send_and_read 2020.08.28 send_callback 2022.01.30 NetworkDriver (and Platform driver sub-classes unless overridden) \u00b6 Method Implemented Last Change Notes update_privilege_levels 2020.05.09 update priv map/all prompt pattern if adding/modifying privs acquire_priv 2020.03.29 register_configuration_session 2020.05.09 register a config session so the priv level can be tracked send_config 2020.05.09 2020.12.31 added eager keyword argument send_configs 2020.03.29 2020.12.31 added eager keyword argument send_configs_from_file 2020.04.30 2020.12.31 added eager keyword argument send_interactive 2020.03.29 2021.01.30 added interaction_complete_patterns keyword argument AsyncNetworkDriver (and Platform driver sub-classes unless overridden) \u00b6 Method Implemented Last Change Notes update_privilege_levels 2020.06.06 acquire_priv 2020.06.06 register_configuration_session 2020.06.06 send_config 2020.06.06 2020.12.31 added eager keyword argument send_configs 2020.06.06 2020.12.31 added eager keyword argument send_configs_from_file 2020.06.06 2020.12.31 added eager keyword argument send_interactive 2020.06.06 2021.01.30 added interaction_complete_patterns keyword argument Channel \u00b6 Method Implemented Last Change Notes get_prompt 2020.03.29 send_input 2020.03.29 2020.12.31 added eager keyword argument send_inputs_interact 2020.03.29 2020.04.11 changed to support list of \"events\" to interact with send_input_and_read 2020.08.28 AsyncChannel \u00b6 Method Implemented Last Change Notes get_prompt 2020.06.06 send_input 2020.06.06 2020.12.31 added eager keyword argument send_inputs_interact 2020.06.06 send_input_and_read 2020.08.28 Transport \u00b6 Transport ABC (and Transport sub-classes unless overridden) \u00b6 Method Implemented Last Change Notes open 2020.03.29 close 2020.03.29 isalive 2020.03.29 read 2020.03.29 write 2020.03.29 set_timeout 2020.03.29 AsyncTransport ABC (and Transport sub-classes unless overridden) \u00b6 Method Implemented Last Change Notes open 2020.06.06 close 2020.06.06 isalive 2020.06.06 read 2020.06.06 write 2020.06.06 set_timeout 2020.06.06 Response \u00b6 Method Implemented Last Change Notes genie_parse_output 2020.03.29 textfsm_parse_output 2020.03.29 ttp_parse_output 2020.10.10 Unlike other parse methods, requires a template argument raise_for_status 2020.05.09 MultiResponse \u00b6 Method Implemented Last Change Notes raise_for_status 2020.05.09 SSHConfig \u00b6 Method Implemented Last Change Notes lookup 2020.03.29","title":"Public API Status"},{"location":"public_api_status/#public-api-status","text":"Note that all public methods, unless otherwise noted, are available in sync and async form depending on the driver you have selected.","title":"Public API Status"},{"location":"public_api_status/#drivers","text":"","title":"Drivers"},{"location":"public_api_status/#driver","text":"Method Implemented Last Change Notes open 2020.03.29 close 2020.03.29 isalive 2020.03.29","title":"Driver"},{"location":"public_api_status/#asyncdriver","text":"Method Implemented Last Change Notes open 2020.06.06 close 2020.06.06 isalive 2020.06.06","title":"AsyncDriver"},{"location":"public_api_status/#genericdriver-and-networkdriver-sub-classes-unless-overridden","text":"Method Implemented Last Change Notes get_prompt 2020.03.29 send_command 2020.03.29 2020.08.09 added timeout_ops keyword argument to modify timeout send_commands 2020.03.29 2020.12.31 added eager keyword argument send_commands_from_file 2020.04.30 2020.12.31 added eager keyword argument send_interactive 2020.03.29 2021.01.30 added interaction_complete_patterns keyword argument send_and_read 2020.08.28 send_callback 2022.01.30","title":"GenericDriver (and NetworkDriver sub-classes unless overridden)"},{"location":"public_api_status/#asyncgenericdriver-and-networkdriver-sub-classes-unless-overridden","text":"Method Implemented Last Change Notes get_prompt 2020.06.06 send_command 2020.06.06 2020.08.09 added timeout_ops keyword argument to modify timeout send_commands 2020.06.06 2020.12.31 added eager keyword argument send_commands_from_file 2020.06.06 2020.12.31 added eager keyword argument send_interactive 2020.06.06 2021.01.30 added interaction_complete_patterns keyword argument send_and_read 2020.08.28 send_callback 2022.01.30","title":"AsyncGenericDriver (and NetworkDriver sub-classes unless overridden)"},{"location":"public_api_status/#networkdriver-and-platform-driver-sub-classes-unless-overridden","text":"Method Implemented Last Change Notes update_privilege_levels 2020.05.09 update priv map/all prompt pattern if adding/modifying privs acquire_priv 2020.03.29 register_configuration_session 2020.05.09 register a config session so the priv level can be tracked send_config 2020.05.09 2020.12.31 added eager keyword argument send_configs 2020.03.29 2020.12.31 added eager keyword argument send_configs_from_file 2020.04.30 2020.12.31 added eager keyword argument send_interactive 2020.03.29 2021.01.30 added interaction_complete_patterns keyword argument","title":"NetworkDriver (and Platform driver sub-classes unless overridden)"},{"location":"public_api_status/#asyncnetworkdriver-and-platform-driver-sub-classes-unless-overridden","text":"Method Implemented Last Change Notes update_privilege_levels 2020.06.06 acquire_priv 2020.06.06 register_configuration_session 2020.06.06 send_config 2020.06.06 2020.12.31 added eager keyword argument send_configs 2020.06.06 2020.12.31 added eager keyword argument send_configs_from_file 2020.06.06 2020.12.31 added eager keyword argument send_interactive 2020.06.06 2021.01.30 added interaction_complete_patterns keyword argument","title":"AsyncNetworkDriver (and Platform driver sub-classes unless overridden)"},{"location":"public_api_status/#channel","text":"Method Implemented Last Change Notes get_prompt 2020.03.29 send_input 2020.03.29 2020.12.31 added eager keyword argument send_inputs_interact 2020.03.29 2020.04.11 changed to support list of \"events\" to interact with send_input_and_read 2020.08.28","title":"Channel"},{"location":"public_api_status/#asyncchannel","text":"Method Implemented Last Change Notes get_prompt 2020.06.06 send_input 2020.06.06 2020.12.31 added eager keyword argument send_inputs_interact 2020.06.06 send_input_and_read 2020.08.28","title":"AsyncChannel"},{"location":"public_api_status/#transport","text":"","title":"Transport"},{"location":"public_api_status/#transport-abc-and-transport-sub-classes-unless-overridden","text":"Method Implemented Last Change Notes open 2020.03.29 close 2020.03.29 isalive 2020.03.29 read 2020.03.29 write 2020.03.29 set_timeout 2020.03.29","title":"Transport ABC (and Transport sub-classes unless overridden)"},{"location":"public_api_status/#asynctransport-abc-and-transport-sub-classes-unless-overridden","text":"Method Implemented Last Change Notes open 2020.06.06 close 2020.06.06 isalive 2020.06.06 read 2020.06.06 write 2020.06.06 set_timeout 2020.06.06","title":"AsyncTransport ABC (and Transport sub-classes unless overridden)"},{"location":"public_api_status/#response","text":"Method Implemented Last Change Notes genie_parse_output 2020.03.29 textfsm_parse_output 2020.03.29 ttp_parse_output 2020.10.10 Unlike other parse methods, requires a template argument raise_for_status 2020.05.09","title":"Response"},{"location":"public_api_status/#multiresponse","text":"Method Implemented Last Change Notes raise_for_status 2020.05.09","title":"MultiResponse"},{"location":"public_api_status/#sshconfig","text":"Method Implemented Last Change Notes lookup 2020.03.29","title":"SSHConfig"},{"location":"about/code_of_conduct/","text":"Code of Conduct \u00b6 Be excellent to each other!","title":"Code of Conduct"},{"location":"about/code_of_conduct/#code-of-conduct","text":"Be excellent to each other!","title":"Code of Conduct"},{"location":"about/contributing/","text":"Contributing \u00b6 Thanks for thinking about contributing! Contributions are not expected, but are quite welcome. Contributions of all kinds are welcomed -- typos, doc updates, adding examples, bug fixes, and feature adds. Some notes on contributing: Please open a GitHub discussion topic for any potential feature adds/changes to discuss them prior to opening a PR, this way everyone has a chance to chime in and make sure we're all on the same page! Please open an issue to discuss any bugs/bug fixes prior to opening a PR. Once we all have discussed any adds/changes, pull requests are very much welcome and appreciated! All PRs should pass tests/CI linting -- checkout the Makefile for some shortcuts for linting and testing. Please include tests! Even simple/basic tests are better than nothing -- it helps make sure changes in the future don't break functionality or make things act in unexpected ways!","title":"Contributing"},{"location":"about/contributing/#contributing","text":"Thanks for thinking about contributing! Contributions are not expected, but are quite welcome. Contributions of all kinds are welcomed -- typos, doc updates, adding examples, bug fixes, and feature adds. Some notes on contributing: Please open a GitHub discussion topic for any potential feature adds/changes to discuss them prior to opening a PR, this way everyone has a chance to chime in and make sure we're all on the same page! Please open an issue to discuss any bugs/bug fixes prior to opening a PR. Once we all have discussed any adds/changes, pull requests are very much welcome and appreciated! All PRs should pass tests/CI linting -- checkout the Makefile for some shortcuts for linting and testing. Please include tests! Even simple/basic tests are better than nothing -- it helps make sure changes in the future don't break functionality or make things act in unexpected ways!","title":"Contributing"},{"location":"about/thank_you/","text":"Thank You! \u00b6 Thank you to the following people who have made contributions other than (and maybe in addition to) code that have helped make scrapli what it is! Kevin Landreth for helping with the vision for the system transport driver , and putting up with lots of annoying Slack messages while troubleshooting things Dmitry Figol for really helpful guidance on how best to build the API/overall structure of things very early on, and continued support/guidance Javin Craig for very early testing help and extra eyes on loads of readme/docs John (IPvZero) McGovern for loads of testing, encouraging the nornir plugin along, and lots of great discussions Ryan Bradshaw for early testing and discussions on disabling paging, dealing with interactive inputs, and making the paramiko/ssh2-python transports plugins Eric Tedor for some interesting and challenging use cases that helped to improve some of the prompt matching decisions Ron Frederick for building the very awesome asyncssh library! Brett Canter for building the very first scrapli_community platform! (ruckus_fastiron) Alex Lardschneider for great conversation, many contributions to scrapli_community , and helping to improve various pieces of scrapli with great testing and troubleshooting! Marion for loads of testing hard to track down issues with the async transports! Roman Dodin for inspiration to make the docs much better and for adding the doc testing to keep them looking good! netixx for helping unravel some particularly fun decorator timeout shenanigans! The following people have helped identify and report bugs in scrapli, thank you all! Kirill Pletnev IOSXEDriver configuration mode prompt pattern missed pub key config mode Michal D SSH Config not Merging Attributes artyomovs Prompt patterns not matching \"tacacs+\" get_prompt Resetting timeout_ops inadvertently telnet authentication when requiring a return char/telnet auth bypass Dave P Additional enable password prompt format IOSXE Natasha Samoylenko Missing open timeout on asynctelnet transport This list has not been kept up as well as it should, apologies for that! Thank you to everyone else who has contributed in any way to scrapli! Last, but very much not least, a huge shoutout to JetBrains for building awesome tools and providing licenses for their pro tools to open source developers (like me)! If you would like to use JetBrains awesome products, check out their open source support page here for me info.","title":"Thank Yous"},{"location":"about/thank_you/#thank-you","text":"Thank you to the following people who have made contributions other than (and maybe in addition to) code that have helped make scrapli what it is! Kevin Landreth for helping with the vision for the system transport driver , and putting up with lots of annoying Slack messages while troubleshooting things Dmitry Figol for really helpful guidance on how best to build the API/overall structure of things very early on, and continued support/guidance Javin Craig for very early testing help and extra eyes on loads of readme/docs John (IPvZero) McGovern for loads of testing, encouraging the nornir plugin along, and lots of great discussions Ryan Bradshaw for early testing and discussions on disabling paging, dealing with interactive inputs, and making the paramiko/ssh2-python transports plugins Eric Tedor for some interesting and challenging use cases that helped to improve some of the prompt matching decisions Ron Frederick for building the very awesome asyncssh library! Brett Canter for building the very first scrapli_community platform! (ruckus_fastiron) Alex Lardschneider for great conversation, many contributions to scrapli_community , and helping to improve various pieces of scrapli with great testing and troubleshooting! Marion for loads of testing hard to track down issues with the async transports! Roman Dodin for inspiration to make the docs much better and for adding the doc testing to keep them looking good! netixx for helping unravel some particularly fun decorator timeout shenanigans! The following people have helped identify and report bugs in scrapli, thank you all! Kirill Pletnev IOSXEDriver configuration mode prompt pattern missed pub key config mode Michal D SSH Config not Merging Attributes artyomovs Prompt patterns not matching \"tacacs+\" get_prompt Resetting timeout_ops inadvertently telnet authentication when requiring a return char/telnet auth bypass Dave P Additional enable password prompt format IOSXE Natasha Samoylenko Missing open timeout on asynctelnet transport This list has not been kept up as well as it should, apologies for that! Thank you to everyone else who has contributed in any way to scrapli! Last, but very much not least, a huge shoutout to JetBrains for building awesome tools and providing licenses for their pro tools to open source developers (like me)! If you would like to use JetBrains awesome products, check out their open source support page here for me info.","title":"Thank You!"},{"location":"api_docs/decorators/","text":"window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting()) Module scrapli.decorators \u00b6 scrapli.decorators Expand source code \"\"\"scrapli.decorators\"\"\" import asyncio import signal import sys import threading from concurrent.futures import ThreadPoolExecutor, wait from functools import partial, update_wrapper from logging import Logger, LoggerAdapter from typing import TYPE_CHECKING, Any, Callable, Tuple from scrapli.exceptions import ScrapliTimeout if TYPE_CHECKING: from scrapli.driver import AsyncGenericDriver, GenericDriver # pragma: no cover from scrapli.transport.base.base_transport import BaseTransport # pragma: no cover if TYPE_CHECKING: LoggerAdapterT = LoggerAdapter[Logger] # pragma: no cover # pylint:disable=E1136 else: LoggerAdapterT = LoggerAdapter _IS_WINDOWS = sys.platform.startswith(\"win\") FUNC_TIMEOUT_MESSAGE_MAP = { \"channel_authenticate_ssh\": \"timed out during in channel ssh authentication\", \"channel_authenticate_telnet\": \"timed out during in channel telnet authentication\", \"get_prompt\": \"timed out getting prompt\", \"send_input\": \"timed out sending input to device\", \"send_input_and_read\": \"timed out sending input to device\", \"send_inputs_interact\": \"timed out sending interactive input to device\", \"read\": \"timed out reading from transport\", } def _get_timeout_message(func_name: str) -> str: \"\"\" Return appropriate timeout message for the given function name Args: func_name: name of function to fetch timeout message for Returns: str: timeout message Raises: N/A \"\"\" return FUNC_TIMEOUT_MESSAGE_MAP.get(func_name, \"unspecified timeout occurred\") def _signal_raise_exception( signum: Any, frame: Any, transport: \"BaseTransport\", logger: LoggerAdapterT, message: str ) -> None: \"\"\" Signal method exception handler Args: signum: singum from the singal handler, unused here frame: frame from the signal handler, unused here transport: transport to close logger: logger to write closing messages to message: exception message Returns: None Raises: N/A \"\"\" _, _ = signum, frame return _handle_timeout(transport=transport, logger=logger, message=message) def _multiprocessing_timeout( transport: \"BaseTransport\", logger: LoggerAdapterT, timeout: float, wrapped_func: Callable[..., Any], args: Any, kwargs: Any, ) -> Any: \"\"\" Return appropriate timeout message for the given function name Args: transport: transport to close (if timeout occurs) logger: logger to write closing message to timeout: timeout in seconds wrapped_func: function being decorated args: function args kwargs: function kwargs Returns: Any: result of the wrapped function Raises: N/A \"\"\" with ThreadPoolExecutor(max_workers=1) as pool: future = pool.submit(wrapped_func, *args, **kwargs) wait([future], timeout=timeout) if not future.done(): return _handle_timeout( transport=transport, logger=logger, message=_get_timeout_message(func_name=wrapped_func.__name__), ) return future.result() def _handle_timeout(transport: \"BaseTransport\", logger: LoggerAdapterT, message: str) -> None: \"\"\" Timeout handler method to close connections and raise ScrapliTimeout Args: transport: transport to close logger: logger to write closing message to message: message to pass to ScrapliTimeout exception Returns: None Raises: ScrapliTimeout: always, if we hit this method we have already timed out! \"\"\" logger.critical(\"operation timed out, closing connection\") transport.close() raise ScrapliTimeout(message) def _get_transport_logger_timeout( cls: Any, ) -> Tuple[\"BaseTransport\", LoggerAdapterT, float]: \"\"\" Fetch the transport, logger and timeout from the channel or transport object Args: cls: Channel or Transport object (self from wrapped function) to grab transport/logger and timeout values from Returns: Tuple: transport, logger, and timeout value Raises: N/A \"\"\" if hasattr(cls, \"transport\"): return ( cls.transport, cls.logger, cls._base_channel_args.timeout_ops, # pylint: disable=W0212 ) return ( cls, cls.logger, cls._base_transport_args.timeout_transport, # pylint: disable=W0212 ) def timeout_wrapper(wrapped_func: Callable[..., Any]) -> Callable[..., Any]: \"\"\" Timeout wrapper for transports Args: wrapped_func: function being wrapped -- must be a method of Channel or Transport Returns: Any: result of wrapped function Raises: N/A \"\"\" if asyncio.iscoroutinefunction(wrapped_func): async def decorate(*args: Any, **kwargs: Any) -> Any: transport, logger, timeout = _get_transport_logger_timeout(cls=args[0]) if not timeout: return await wrapped_func(*args, **kwargs) try: return await asyncio.wait_for(wrapped_func(*args, **kwargs), timeout=timeout) except asyncio.TimeoutError: _handle_timeout( transport=transport, logger=logger, message=_get_timeout_message(func_name=wrapped_func.__name__), ) else: # ignoring type error: # \"All conditional function variants must have identical signatures\" # one is sync one is async so never going to be identical here! def decorate(*args: Any, **kwargs: Any) -> Any: # type: ignore transport, logger, timeout = _get_transport_logger_timeout(cls=args[0]) if not timeout: return wrapped_func(*args, **kwargs) cls_name = transport.__class__.__name__ if ( cls_name in (\"SystemTransport\", \"TelnetTransport\") or _IS_WINDOWS or threading.current_thread() is not threading.main_thread() ): return _multiprocessing_timeout( transport=transport, logger=logger, timeout=timeout, wrapped_func=wrapped_func, args=args, kwargs=kwargs, ) callback = partial( _signal_raise_exception, transport=transport, logger=logger, message=_get_timeout_message(wrapped_func.__name__), ) old = signal.signal(signal.SIGALRM, callback) signal.setitimer(signal.ITIMER_REAL, timeout) try: return wrapped_func(*args, **kwargs) finally: if timeout: signal.setitimer(signal.ITIMER_REAL, 0) signal.signal(signal.SIGALRM, old) # ensures that the wrapped function is updated w/ the original functions docs/etc. -- # necessary for introspection for the auto gen docs to work! update_wrapper(wrapper=decorate, wrapped=wrapped_func) return decorate def timeout_modifier(wrapped_func: Callable[..., Any]) -> Callable[..., Any]: \"\"\" Decorate an \"operation\" to modify the timeout_ops value for duration of that operation This decorator wraps send command/config ops and is used to allow users to set a `timeout_ops` value for the duration of a single method call -- this makes it so users don't need to manually set/reset the value Args: wrapped_func: function being decorated Returns: decorate: decorated func Raises: N/A \"\"\" if asyncio.iscoroutinefunction(wrapped_func): async def decorate(*args: Any, **kwargs: Any) -> Any: driver_instance: \"AsyncGenericDriver\" = args[0] driver_logger = driver_instance.logger timeout_ops_kwarg = kwargs.get(\"timeout_ops\", None) if timeout_ops_kwarg is None or timeout_ops_kwarg == driver_instance.timeout_ops: result = await wrapped_func(*args, **kwargs) else: driver_logger.info( \"modifying driver timeout for current operation, temporary timeout_ops \" f\"value: '{timeout_ops_kwarg}'\" ) base_timeout_ops = driver_instance.timeout_ops driver_instance.timeout_ops = kwargs[\"timeout_ops\"] result = await wrapped_func(*args, **kwargs) driver_instance.timeout_ops = base_timeout_ops return result else: # ignoring type error: # \"All conditional function variants must have identical signatures\" # one is sync one is async so never going to be identical here! def decorate(*args: Any, **kwargs: Any) -> Any: # type: ignore driver_instance: \"GenericDriver\" = args[0] driver_logger = driver_instance.logger timeout_ops_kwarg = kwargs.get(\"timeout_ops\", None) if timeout_ops_kwarg is None or timeout_ops_kwarg == driver_instance.timeout_ops: result = wrapped_func(*args, **kwargs) else: driver_logger.info( \"modifying driver timeout for current operation, temporary timeout_ops \" f\"value: '{timeout_ops_kwarg}'\" ) base_timeout_ops = driver_instance.timeout_ops driver_instance.timeout_ops = kwargs[\"timeout_ops\"] result = wrapped_func(*args, **kwargs) driver_instance.timeout_ops = base_timeout_ops return result # ensures that the wrapped function is updated w/ the original functions docs/etc. -- # necessary for introspection for the auto gen docs to work! update_wrapper(wrapper=decorate, wrapped=wrapped_func) return decorate Functions \u00b6 timeout_modifier \u00b6 timeout_modifier(wrapped_func: Callable[..., Any]) \u2011> Callable[..., Any] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 Decorate an \"operation\" to modify the timeout_ops value for duration of that operation This decorator wraps send command/config ops and is used to allow users to set a `timeout_ops` value for the duration of a single method call -- this makes it so users don't need to manually set/reset the value Args: wrapped_func: function being decorated Returns: decorate: decorated func Raises: N/A timeout_wrapper \u00b6 timeout_wrapper(wrapped_func: Callable[..., Any]) \u2011> Callable[..., Any] 1 2 3 4 5 6 7 8 9 10 Timeout wrapper for transports Args: wrapped_func: function being wrapped -- must be a method of Channel or Transport Returns: Any: result of wrapped function Raises: N/A","title":"Decorators"},{"location":"api_docs/decorators/#module-scraplidecorators","text":"scrapli.decorators Expand source code \"\"\"scrapli.decorators\"\"\" import asyncio import signal import sys import threading from concurrent.futures import ThreadPoolExecutor, wait from functools import partial, update_wrapper from logging import Logger, LoggerAdapter from typing import TYPE_CHECKING, Any, Callable, Tuple from scrapli.exceptions import ScrapliTimeout if TYPE_CHECKING: from scrapli.driver import AsyncGenericDriver, GenericDriver # pragma: no cover from scrapli.transport.base.base_transport import BaseTransport # pragma: no cover if TYPE_CHECKING: LoggerAdapterT = LoggerAdapter[Logger] # pragma: no cover # pylint:disable=E1136 else: LoggerAdapterT = LoggerAdapter _IS_WINDOWS = sys.platform.startswith(\"win\") FUNC_TIMEOUT_MESSAGE_MAP = { \"channel_authenticate_ssh\": \"timed out during in channel ssh authentication\", \"channel_authenticate_telnet\": \"timed out during in channel telnet authentication\", \"get_prompt\": \"timed out getting prompt\", \"send_input\": \"timed out sending input to device\", \"send_input_and_read\": \"timed out sending input to device\", \"send_inputs_interact\": \"timed out sending interactive input to device\", \"read\": \"timed out reading from transport\", } def _get_timeout_message(func_name: str) -> str: \"\"\" Return appropriate timeout message for the given function name Args: func_name: name of function to fetch timeout message for Returns: str: timeout message Raises: N/A \"\"\" return FUNC_TIMEOUT_MESSAGE_MAP.get(func_name, \"unspecified timeout occurred\") def _signal_raise_exception( signum: Any, frame: Any, transport: \"BaseTransport\", logger: LoggerAdapterT, message: str ) -> None: \"\"\" Signal method exception handler Args: signum: singum from the singal handler, unused here frame: frame from the signal handler, unused here transport: transport to close logger: logger to write closing messages to message: exception message Returns: None Raises: N/A \"\"\" _, _ = signum, frame return _handle_timeout(transport=transport, logger=logger, message=message) def _multiprocessing_timeout( transport: \"BaseTransport\", logger: LoggerAdapterT, timeout: float, wrapped_func: Callable[..., Any], args: Any, kwargs: Any, ) -> Any: \"\"\" Return appropriate timeout message for the given function name Args: transport: transport to close (if timeout occurs) logger: logger to write closing message to timeout: timeout in seconds wrapped_func: function being decorated args: function args kwargs: function kwargs Returns: Any: result of the wrapped function Raises: N/A \"\"\" with ThreadPoolExecutor(max_workers=1) as pool: future = pool.submit(wrapped_func, *args, **kwargs) wait([future], timeout=timeout) if not future.done(): return _handle_timeout( transport=transport, logger=logger, message=_get_timeout_message(func_name=wrapped_func.__name__), ) return future.result() def _handle_timeout(transport: \"BaseTransport\", logger: LoggerAdapterT, message: str) -> None: \"\"\" Timeout handler method to close connections and raise ScrapliTimeout Args: transport: transport to close logger: logger to write closing message to message: message to pass to ScrapliTimeout exception Returns: None Raises: ScrapliTimeout: always, if we hit this method we have already timed out! \"\"\" logger.critical(\"operation timed out, closing connection\") transport.close() raise ScrapliTimeout(message) def _get_transport_logger_timeout( cls: Any, ) -> Tuple[\"BaseTransport\", LoggerAdapterT, float]: \"\"\" Fetch the transport, logger and timeout from the channel or transport object Args: cls: Channel or Transport object (self from wrapped function) to grab transport/logger and timeout values from Returns: Tuple: transport, logger, and timeout value Raises: N/A \"\"\" if hasattr(cls, \"transport\"): return ( cls.transport, cls.logger, cls._base_channel_args.timeout_ops, # pylint: disable=W0212 ) return ( cls, cls.logger, cls._base_transport_args.timeout_transport, # pylint: disable=W0212 ) def timeout_wrapper(wrapped_func: Callable[..., Any]) -> Callable[..., Any]: \"\"\" Timeout wrapper for transports Args: wrapped_func: function being wrapped -- must be a method of Channel or Transport Returns: Any: result of wrapped function Raises: N/A \"\"\" if asyncio.iscoroutinefunction(wrapped_func): async def decorate(*args: Any, **kwargs: Any) -> Any: transport, logger, timeout = _get_transport_logger_timeout(cls=args[0]) if not timeout: return await wrapped_func(*args, **kwargs) try: return await asyncio.wait_for(wrapped_func(*args, **kwargs), timeout=timeout) except asyncio.TimeoutError: _handle_timeout( transport=transport, logger=logger, message=_get_timeout_message(func_name=wrapped_func.__name__), ) else: # ignoring type error: # \"All conditional function variants must have identical signatures\" # one is sync one is async so never going to be identical here! def decorate(*args: Any, **kwargs: Any) -> Any: # type: ignore transport, logger, timeout = _get_transport_logger_timeout(cls=args[0]) if not timeout: return wrapped_func(*args, **kwargs) cls_name = transport.__class__.__name__ if ( cls_name in (\"SystemTransport\", \"TelnetTransport\") or _IS_WINDOWS or threading.current_thread() is not threading.main_thread() ): return _multiprocessing_timeout( transport=transport, logger=logger, timeout=timeout, wrapped_func=wrapped_func, args=args, kwargs=kwargs, ) callback = partial( _signal_raise_exception, transport=transport, logger=logger, message=_get_timeout_message(wrapped_func.__name__), ) old = signal.signal(signal.SIGALRM, callback) signal.setitimer(signal.ITIMER_REAL, timeout) try: return wrapped_func(*args, **kwargs) finally: if timeout: signal.setitimer(signal.ITIMER_REAL, 0) signal.signal(signal.SIGALRM, old) # ensures that the wrapped function is updated w/ the original functions docs/etc. -- # necessary for introspection for the auto gen docs to work! update_wrapper(wrapper=decorate, wrapped=wrapped_func) return decorate def timeout_modifier(wrapped_func: Callable[..., Any]) -> Callable[..., Any]: \"\"\" Decorate an \"operation\" to modify the timeout_ops value for duration of that operation This decorator wraps send command/config ops and is used to allow users to set a `timeout_ops` value for the duration of a single method call -- this makes it so users don't need to manually set/reset the value Args: wrapped_func: function being decorated Returns: decorate: decorated func Raises: N/A \"\"\" if asyncio.iscoroutinefunction(wrapped_func): async def decorate(*args: Any, **kwargs: Any) -> Any: driver_instance: \"AsyncGenericDriver\" = args[0] driver_logger = driver_instance.logger timeout_ops_kwarg = kwargs.get(\"timeout_ops\", None) if timeout_ops_kwarg is None or timeout_ops_kwarg == driver_instance.timeout_ops: result = await wrapped_func(*args, **kwargs) else: driver_logger.info( \"modifying driver timeout for current operation, temporary timeout_ops \" f\"value: '{timeout_ops_kwarg}'\" ) base_timeout_ops = driver_instance.timeout_ops driver_instance.timeout_ops = kwargs[\"timeout_ops\"] result = await wrapped_func(*args, **kwargs) driver_instance.timeout_ops = base_timeout_ops return result else: # ignoring type error: # \"All conditional function variants must have identical signatures\" # one is sync one is async so never going to be identical here! def decorate(*args: Any, **kwargs: Any) -> Any: # type: ignore driver_instance: \"GenericDriver\" = args[0] driver_logger = driver_instance.logger timeout_ops_kwarg = kwargs.get(\"timeout_ops\", None) if timeout_ops_kwarg is None or timeout_ops_kwarg == driver_instance.timeout_ops: result = wrapped_func(*args, **kwargs) else: driver_logger.info( \"modifying driver timeout for current operation, temporary timeout_ops \" f\"value: '{timeout_ops_kwarg}'\" ) base_timeout_ops = driver_instance.timeout_ops driver_instance.timeout_ops = kwargs[\"timeout_ops\"] result = wrapped_func(*args, **kwargs) driver_instance.timeout_ops = base_timeout_ops return result # ensures that the wrapped function is updated w/ the original functions docs/etc. -- # necessary for introspection for the auto gen docs to work! update_wrapper(wrapper=decorate, wrapped=wrapped_func) return decorate","title":"Module scrapli.decorators"},{"location":"api_docs/decorators/#functions","text":"","title":"Functions"},{"location":"api_docs/decorators/#timeout_modifier","text":"timeout_modifier(wrapped_func: Callable[..., Any]) \u2011> Callable[..., Any] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 Decorate an \"operation\" to modify the timeout_ops value for duration of that operation This decorator wraps send command/config ops and is used to allow users to set a `timeout_ops` value for the duration of a single method call -- this makes it so users don't need to manually set/reset the value Args: wrapped_func: function being decorated Returns: decorate: decorated func Raises: N/A","title":"timeout_modifier"},{"location":"api_docs/decorators/#timeout_wrapper","text":"timeout_wrapper(wrapped_func: Callable[..., Any]) \u2011> Callable[..., Any] 1 2 3 4 5 6 7 8 9 10 Timeout wrapper for transports Args: wrapped_func: function being wrapped -- must be a method of Channel or Transport Returns: Any: result of wrapped function Raises: N/A","title":"timeout_wrapper"},{"location":"api_docs/exceptions/","text":"window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting()) Module scrapli.exceptions \u00b6 scrapli.exceptions Expand source code \"\"\"scrapli.exceptions\"\"\" from typing import Optional class ScrapliException(Exception): \"\"\"Base Exception for all scrapli exceptions\"\"\" class ScrapliModuleNotFound(ScrapliException): \"\"\"ModuleNotFound but for scrapli related issues\"\"\" class ScrapliTypeError(ScrapliException): \"\"\"TypeError but for scrapli related typing issues\"\"\" class ScrapliValueError(ScrapliException): \"\"\"ValueError but for scrapli related value issues\"\"\" class ScrapliUnsupportedPlatform(ScrapliException): \"\"\"Exception for unsupported platform; i.e. using system transport on windows\"\"\" class ScrapliTransportPluginError(ScrapliException): \"\"\"Exception for transport plugin issues\"\"\" class ScrapliConnectionNotOpened(ScrapliException): \"\"\"Exception for trying to operate on a transport which has not been opened\"\"\" def __init__( self, message: Optional[str] = None, ) -> None: \"\"\" Scrapli connection not opened exception Args: message: optional message Returns: None Raises: N/A \"\"\" if not message: self.message = ( \"connection not opened, but attempting to call a method that requires an open \" \"connection, do you need to call 'open()'?\" ) else: self.message = message super().__init__(self.message) class ScrapliAuthenticationFailed(ScrapliException): \"\"\"Exception for scrapli authentication issues\"\"\" class ScrapliConnectionError(ScrapliException): \"\"\"Exception for underlying connection issues\"\"\" class ScrapliTimeout(ScrapliException): \"\"\"Exception for any scrapli timeouts\"\"\" class ScrapliCommandFailure(ScrapliException): \"\"\"Exception for scrapli command/config failures\"\"\" class ScrapliPrivilegeError(ScrapliException): \"\"\"Exception for all privilege related scrapli issues\"\"\" Classes \u00b6 ScrapliAuthenticationFailed \u00b6 1 Exception for scrapli authentication issues Expand source code class ScrapliAuthenticationFailed(ScrapliException): \"\"\"Exception for scrapli authentication issues\"\"\" Ancestors (in MRO) \u00b6 scrapli.exceptions.ScrapliException builtins.Exception builtins.BaseException ScrapliCommandFailure \u00b6 1 Exception for scrapli command/config failures Expand source code class ScrapliCommandFailure(ScrapliException): \"\"\"Exception for scrapli command/config failures\"\"\" Ancestors (in MRO) \u00b6 scrapli.exceptions.ScrapliException builtins.Exception builtins.BaseException ScrapliConnectionError \u00b6 1 Exception for underlying connection issues Expand source code class ScrapliConnectionError(ScrapliException): \"\"\"Exception for underlying connection issues\"\"\" Ancestors (in MRO) \u00b6 scrapli.exceptions.ScrapliException builtins.Exception builtins.BaseException ScrapliConnectionNotOpened \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 Exception for trying to operate on a transport which has not been opened Scrapli connection not opened exception Args: message: optional message Returns: None Raises: N/A Expand source code class ScrapliConnectionNotOpened(ScrapliException): \"\"\"Exception for trying to operate on a transport which has not been opened\"\"\" def __init__( self, message: Optional[str] = None, ) -> None: \"\"\" Scrapli connection not opened exception Args: message: optional message Returns: None Raises: N/A \"\"\" if not message: self.message = ( \"connection not opened, but attempting to call a method that requires an open \" \"connection, do you need to call 'open()'?\" ) else: self.message = message super().__init__(self.message) Ancestors (in MRO) \u00b6 scrapli.exceptions.ScrapliException builtins.Exception builtins.BaseException ScrapliException \u00b6 1 Base Exception for all scrapli exceptions Expand source code class ScrapliException(Exception): \"\"\"Base Exception for all scrapli exceptions\"\"\" Ancestors (in MRO) \u00b6 builtins.Exception builtins.BaseException Descendants \u00b6 scrapli.exceptions.ScrapliAuthenticationFailed scrapli.exceptions.ScrapliCommandFailure scrapli.exceptions.ScrapliConnectionError scrapli.exceptions.ScrapliConnectionNotOpened scrapli.exceptions.ScrapliModuleNotFound scrapli.exceptions.ScrapliPrivilegeError scrapli.exceptions.ScrapliTimeout scrapli.exceptions.ScrapliTransportPluginError scrapli.exceptions.ScrapliTypeError scrapli.exceptions.ScrapliUnsupportedPlatform scrapli.exceptions.ScrapliValueError ScrapliModuleNotFound \u00b6 1 ModuleNotFound but for scrapli related issues Expand source code class ScrapliModuleNotFound(ScrapliException): \"\"\"ModuleNotFound but for scrapli related issues\"\"\" Ancestors (in MRO) \u00b6 scrapli.exceptions.ScrapliException builtins.Exception builtins.BaseException ScrapliPrivilegeError \u00b6 1 Exception for all privilege related scrapli issues Expand source code class ScrapliPrivilegeError(ScrapliException): \"\"\"Exception for all privilege related scrapli issues\"\"\" Ancestors (in MRO) \u00b6 scrapli.exceptions.ScrapliException builtins.Exception builtins.BaseException ScrapliTimeout \u00b6 1 Exception for any scrapli timeouts Expand source code class ScrapliTimeout(ScrapliException): \"\"\"Exception for any scrapli timeouts\"\"\" Ancestors (in MRO) \u00b6 scrapli.exceptions.ScrapliException builtins.Exception builtins.BaseException ScrapliTransportPluginError \u00b6 1 Exception for transport plugin issues Expand source code class ScrapliTransportPluginError(ScrapliException): \"\"\"Exception for transport plugin issues\"\"\" Ancestors (in MRO) \u00b6 scrapli.exceptions.ScrapliException builtins.Exception builtins.BaseException ScrapliTypeError \u00b6 1 TypeError but for scrapli related typing issues Expand source code class ScrapliTypeError(ScrapliException): \"\"\"TypeError but for scrapli related typing issues\"\"\" Ancestors (in MRO) \u00b6 scrapli.exceptions.ScrapliException builtins.Exception builtins.BaseException ScrapliUnsupportedPlatform \u00b6 1 Exception for unsupported platform; i.e. using system transport on windows Expand source code class ScrapliUnsupportedPlatform(ScrapliException): \"\"\"Exception for unsupported platform; i.e. using system transport on windows\"\"\" Ancestors (in MRO) \u00b6 scrapli.exceptions.ScrapliException builtins.Exception builtins.BaseException ScrapliValueError \u00b6 1 ValueError but for scrapli related value issues Expand source code class ScrapliValueError(ScrapliException): \"\"\"ValueError but for scrapli related value issues\"\"\" Ancestors (in MRO) \u00b6 scrapli.exceptions.ScrapliException builtins.Exception builtins.BaseException","title":"Exceptions"},{"location":"api_docs/exceptions/#module-scrapliexceptions","text":"scrapli.exceptions Expand source code \"\"\"scrapli.exceptions\"\"\" from typing import Optional class ScrapliException(Exception): \"\"\"Base Exception for all scrapli exceptions\"\"\" class ScrapliModuleNotFound(ScrapliException): \"\"\"ModuleNotFound but for scrapli related issues\"\"\" class ScrapliTypeError(ScrapliException): \"\"\"TypeError but for scrapli related typing issues\"\"\" class ScrapliValueError(ScrapliException): \"\"\"ValueError but for scrapli related value issues\"\"\" class ScrapliUnsupportedPlatform(ScrapliException): \"\"\"Exception for unsupported platform; i.e. using system transport on windows\"\"\" class ScrapliTransportPluginError(ScrapliException): \"\"\"Exception for transport plugin issues\"\"\" class ScrapliConnectionNotOpened(ScrapliException): \"\"\"Exception for trying to operate on a transport which has not been opened\"\"\" def __init__( self, message: Optional[str] = None, ) -> None: \"\"\" Scrapli connection not opened exception Args: message: optional message Returns: None Raises: N/A \"\"\" if not message: self.message = ( \"connection not opened, but attempting to call a method that requires an open \" \"connection, do you need to call 'open()'?\" ) else: self.message = message super().__init__(self.message) class ScrapliAuthenticationFailed(ScrapliException): \"\"\"Exception for scrapli authentication issues\"\"\" class ScrapliConnectionError(ScrapliException): \"\"\"Exception for underlying connection issues\"\"\" class ScrapliTimeout(ScrapliException): \"\"\"Exception for any scrapli timeouts\"\"\" class ScrapliCommandFailure(ScrapliException): \"\"\"Exception for scrapli command/config failures\"\"\" class ScrapliPrivilegeError(ScrapliException): \"\"\"Exception for all privilege related scrapli issues\"\"\"","title":"Module scrapli.exceptions"},{"location":"api_docs/exceptions/#classes","text":"","title":"Classes"},{"location":"api_docs/exceptions/#scrapliauthenticationfailed","text":"1 Exception for scrapli authentication issues Expand source code class ScrapliAuthenticationFailed(ScrapliException): \"\"\"Exception for scrapli authentication issues\"\"\"","title":"ScrapliAuthenticationFailed"},{"location":"api_docs/exceptions/#ancestors-in-mro","text":"scrapli.exceptions.ScrapliException builtins.Exception builtins.BaseException","title":"Ancestors (in MRO)"},{"location":"api_docs/exceptions/#scraplicommandfailure","text":"1 Exception for scrapli command/config failures Expand source code class ScrapliCommandFailure(ScrapliException): \"\"\"Exception for scrapli command/config failures\"\"\"","title":"ScrapliCommandFailure"},{"location":"api_docs/exceptions/#ancestors-in-mro_1","text":"scrapli.exceptions.ScrapliException builtins.Exception builtins.BaseException","title":"Ancestors (in MRO)"},{"location":"api_docs/exceptions/#scrapliconnectionerror","text":"1 Exception for underlying connection issues Expand source code class ScrapliConnectionError(ScrapliException): \"\"\"Exception for underlying connection issues\"\"\"","title":"ScrapliConnectionError"},{"location":"api_docs/exceptions/#ancestors-in-mro_2","text":"scrapli.exceptions.ScrapliException builtins.Exception builtins.BaseException","title":"Ancestors (in MRO)"},{"location":"api_docs/exceptions/#scrapliconnectionnotopened","text":"1 2 3 4 5 6 7 8 9 10 11 12 Exception for trying to operate on a transport which has not been opened Scrapli connection not opened exception Args: message: optional message Returns: None Raises: N/A Expand source code class ScrapliConnectionNotOpened(ScrapliException): \"\"\"Exception for trying to operate on a transport which has not been opened\"\"\" def __init__( self, message: Optional[str] = None, ) -> None: \"\"\" Scrapli connection not opened exception Args: message: optional message Returns: None Raises: N/A \"\"\" if not message: self.message = ( \"connection not opened, but attempting to call a method that requires an open \" \"connection, do you need to call 'open()'?\" ) else: self.message = message super().__init__(self.message)","title":"ScrapliConnectionNotOpened"},{"location":"api_docs/exceptions/#ancestors-in-mro_3","text":"scrapli.exceptions.ScrapliException builtins.Exception builtins.BaseException","title":"Ancestors (in MRO)"},{"location":"api_docs/exceptions/#scrapliexception","text":"1 Base Exception for all scrapli exceptions Expand source code class ScrapliException(Exception): \"\"\"Base Exception for all scrapli exceptions\"\"\"","title":"ScrapliException"},{"location":"api_docs/exceptions/#ancestors-in-mro_4","text":"builtins.Exception builtins.BaseException","title":"Ancestors (in MRO)"},{"location":"api_docs/exceptions/#descendants","text":"scrapli.exceptions.ScrapliAuthenticationFailed scrapli.exceptions.ScrapliCommandFailure scrapli.exceptions.ScrapliConnectionError scrapli.exceptions.ScrapliConnectionNotOpened scrapli.exceptions.ScrapliModuleNotFound scrapli.exceptions.ScrapliPrivilegeError scrapli.exceptions.ScrapliTimeout scrapli.exceptions.ScrapliTransportPluginError scrapli.exceptions.ScrapliTypeError scrapli.exceptions.ScrapliUnsupportedPlatform scrapli.exceptions.ScrapliValueError","title":"Descendants"},{"location":"api_docs/exceptions/#scraplimodulenotfound","text":"1 ModuleNotFound but for scrapli related issues Expand source code class ScrapliModuleNotFound(ScrapliException): \"\"\"ModuleNotFound but for scrapli related issues\"\"\"","title":"ScrapliModuleNotFound"},{"location":"api_docs/exceptions/#ancestors-in-mro_5","text":"scrapli.exceptions.ScrapliException builtins.Exception builtins.BaseException","title":"Ancestors (in MRO)"},{"location":"api_docs/exceptions/#scrapliprivilegeerror","text":"1 Exception for all privilege related scrapli issues Expand source code class ScrapliPrivilegeError(ScrapliException): \"\"\"Exception for all privilege related scrapli issues\"\"\"","title":"ScrapliPrivilegeError"},{"location":"api_docs/exceptions/#ancestors-in-mro_6","text":"scrapli.exceptions.ScrapliException builtins.Exception builtins.BaseException","title":"Ancestors (in MRO)"},{"location":"api_docs/exceptions/#scraplitimeout","text":"1 Exception for any scrapli timeouts Expand source code class ScrapliTimeout(ScrapliException): \"\"\"Exception for any scrapli timeouts\"\"\"","title":"ScrapliTimeout"},{"location":"api_docs/exceptions/#ancestors-in-mro_7","text":"scrapli.exceptions.ScrapliException builtins.Exception builtins.BaseException","title":"Ancestors (in MRO)"},{"location":"api_docs/exceptions/#scraplitransportpluginerror","text":"1 Exception for transport plugin issues Expand source code class ScrapliTransportPluginError(ScrapliException): \"\"\"Exception for transport plugin issues\"\"\"","title":"ScrapliTransportPluginError"},{"location":"api_docs/exceptions/#ancestors-in-mro_8","text":"scrapli.exceptions.ScrapliException builtins.Exception builtins.BaseException","title":"Ancestors (in MRO)"},{"location":"api_docs/exceptions/#scraplitypeerror","text":"1 TypeError but for scrapli related typing issues Expand source code class ScrapliTypeError(ScrapliException): \"\"\"TypeError but for scrapli related typing issues\"\"\"","title":"ScrapliTypeError"},{"location":"api_docs/exceptions/#ancestors-in-mro_9","text":"scrapli.exceptions.ScrapliException builtins.Exception builtins.BaseException","title":"Ancestors (in MRO)"},{"location":"api_docs/exceptions/#scrapliunsupportedplatform","text":"1 Exception for unsupported platform; i.e. using system transport on windows Expand source code class ScrapliUnsupportedPlatform(ScrapliException): \"\"\"Exception for unsupported platform; i.e. using system transport on windows\"\"\"","title":"ScrapliUnsupportedPlatform"},{"location":"api_docs/exceptions/#ancestors-in-mro_10","text":"scrapli.exceptions.ScrapliException builtins.Exception builtins.BaseException","title":"Ancestors (in MRO)"},{"location":"api_docs/exceptions/#scraplivalueerror","text":"1 ValueError but for scrapli related value issues Expand source code class ScrapliValueError(ScrapliException): \"\"\"ValueError but for scrapli related value issues\"\"\"","title":"ScrapliValueError"},{"location":"api_docs/exceptions/#ancestors-in-mro_11","text":"scrapli.exceptions.ScrapliException builtins.Exception builtins.BaseException","title":"Ancestors (in MRO)"},{"location":"api_docs/factory/","text":"window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting()) Module scrapli.factory \u00b6 scrapli.factory Expand source code \"\"\"scrapli.factory\"\"\" import importlib from copy import deepcopy from io import BytesIO from typing import Any, Callable, Dict, List, Optional, Tuple, Type, Union, cast from scrapli.driver import AsyncGenericDriver, AsyncNetworkDriver, GenericDriver, NetworkDriver from scrapli.driver.core import ( AsyncEOSDriver, AsyncIOSXEDriver, AsyncIOSXRDriver, AsyncJunosDriver, AsyncNXOSDriver, EOSDriver, IOSXEDriver, IOSXRDriver, JunosDriver, NXOSDriver, ) from scrapli.driver.network.base_driver import PrivilegeLevel from scrapli.exceptions import ( ScrapliException, ScrapliModuleNotFound, ScrapliTypeError, ScrapliValueError, ) from scrapli.helper import format_user_warning from scrapli.logging import logger from scrapli.transport import ASYNCIO_TRANSPORTS def _build_provided_kwargs_dict( # pylint: disable=R0914 host: str, privilege_levels: Optional[Dict[str, PrivilegeLevel]], default_desired_privilege_level: Optional[str], port: Optional[int], auth_username: Optional[str], auth_password: Optional[str], auth_private_key: Optional[str], auth_private_key_passphrase: Optional[str], auth_strict_key: Optional[bool], auth_bypass: Optional[bool], timeout_socket: Optional[float], timeout_transport: Optional[float], timeout_ops: Optional[float], comms_return_char: Optional[str], ssh_config_file: Optional[Union[str, bool]], ssh_known_hosts_file: Optional[Union[str, bool]], on_init: Optional[Callable[..., Any]], on_open: Optional[Callable[..., Any]], on_close: Optional[Callable[..., Any]], transport: Optional[str], transport_options: Optional[Dict[str, Any]], channel_log: Optional[Union[str, bool, BytesIO]], channel_log_mode: Optional[str], channel_lock: Optional[bool], logging_uid: Optional[str], auth_secondary: Optional[str], failed_when_contains: Optional[List[str]], textfsm_platform: Optional[str], genie_platform: Optional[str], **kwargs: Dict[Any, Any], ) -> Dict[str, Any]: r\"\"\" Build arguments dict based on provided inputs This function builds the dict of keyword args to unpack and send to the driver -- in the factory context this also needs to convert the arguments that have defaults that evaluate to False (i.e ssh_config_file which defaults to False) from None which is their default in the factory, back to their normal default if they are still None -OR- to whatever the user provided. # noqa: DAR101 Args: N/A Returns: dict: dictionary with user args merged with the appropriate default options Raises: N/A \"\"\" # dict of all args coming from the factories _provided_args: Dict[str, Any] = { \"host\": host, \"privilege_levels\": privilege_levels, \"default_desired_privilege_level\": default_desired_privilege_level, \"port\": port, \"auth_username\": auth_username, \"auth_password\": auth_password, \"auth_private_key\": auth_private_key, \"auth_private_key_passphrase\": auth_private_key_passphrase, \"auth_strict_key\": auth_strict_key, \"auth_bypass\": auth_bypass, \"timeout_socket\": timeout_socket, \"timeout_transport\": timeout_transport, \"timeout_ops\": timeout_ops, \"comms_return_char\": comms_return_char, \"ssh_config_file\": ssh_config_file, \"ssh_known_hosts_file\": ssh_known_hosts_file, \"on_init\": on_init, \"on_open\": on_open, \"on_close\": on_close, \"transport\": transport, \"transport_options\": transport_options, \"channel_log\": channel_log, \"channel_log_mode\": channel_log_mode, \"channel_lock\": channel_lock, \"logging_uid\": logging_uid, \"auth_secondary\": auth_secondary, \"failed_when_contains\": failed_when_contains, \"textfsm_platform\": textfsm_platform, \"genie_platform\": genie_platform, } # add back in the None/False args _provided_args = {key: value for key, value in _provided_args.items() if value is not None} # merge in any kwargs that maybe need to get passed down return {**_provided_args, **kwargs} def _get_community_platform_details(community_platform_name: str) -> Dict[str, Any]: \"\"\" Fetch community platform details Args: community_platform_name: name of community Returns: platform_details: dict of details about community platform from scrapli_community library Raises: ScrapliModuleNotFound: if scrapli_community is not importable ScrapliModuleNotFound: if provided community_platform_name package is not importable ScrapliException: if community platform is missing \"SCRAPLI_PLATFORM\" attribute \"\"\" try: importlib.import_module(name=\"scrapli_community\") except ModuleNotFoundError as exc: title = \"Module not found!\" message = ( \"Scrapli Community package is not installed!\\n\" \"To resolve this issue, install the transport plugin. You can do this in one of \" \"the following ways:\\n\" \"1: 'pip install -r requirements-community.txt'\\n\" \"2: 'pip install scrapli[community]'\" ) warning = format_user_warning(title=title, message=message) raise ScrapliModuleNotFound(warning) from exc try: # replace any underscores in platform name with \".\"; should support any future platforms # that dont have \"child\" os types -- i.e. just \"cisco\" instead of \"cisco_iosxe\" scrapli_community_platform = importlib.import_module( name=f\"scrapli_community.{community_platform_name.replace('_', '.')}\" ) except ModuleNotFoundError as exc: title = \"Module not found!\" message = ( f\"Scrapli Community platform '{community_platform_name}` not found!\\n\" \"To resolve this issue, ensure you have the correct platform name, and that a scrapli \" \" community platform of that name exists!\" ) warning = format_user_warning(title=title, message=message) raise ScrapliModuleNotFound(warning) from exc platform_details_original = getattr(scrapli_community_platform, \"SCRAPLI_PLATFORM\", {}) if not platform_details_original: msg = \"Community platform missing required attribute `SCRAPLI_PLATFORM`\" raise ScrapliException(msg) platform_details: Dict[str, Any] = deepcopy(platform_details_original) return platform_details def _get_driver_kwargs( platform_details: Dict[str, Any], variant: Optional[str], _async: bool = False ) -> Dict[str, Any]: \"\"\" Parent get driver method Args: platform_details: dict of details about community platform from scrapli_community library variant: optional name of variant of community platform _async: True/False this is for an asyncio transport driver Returns: final_platform_kwargs: dict of final driver kwargs Raises: N/A \"\"\" platform_kwargs = platform_details[\"defaults\"] if variant: variant_kwargs = platform_details[\"variants\"][variant] final_platform_kwargs = {**platform_kwargs, **variant_kwargs} else: final_platform_kwargs = platform_kwargs if not _async: # remove unnecessary asyncio things final_platform_kwargs.pop(\"async_on_open\") final_platform_kwargs.pop(\"async_on_close\") # rename sync_on_(open|close) keys to just \"on_open\"/\"on_close\" final_platform_kwargs[\"on_open\"] = final_platform_kwargs.pop(\"sync_on_open\") final_platform_kwargs[\"on_close\"] = final_platform_kwargs.pop(\"sync_on_close\") else: # remove unnecessary sync things final_platform_kwargs.pop(\"sync_on_open\") final_platform_kwargs.pop(\"sync_on_close\") # rename sync_on_(open|close) keys to just \"on_open\"/\"on_close\" final_platform_kwargs[\"on_open\"] = final_platform_kwargs.pop(\"async_on_open\") final_platform_kwargs[\"on_close\"] = final_platform_kwargs.pop(\"async_on_close\") return final_platform_kwargs class Scrapli(NetworkDriver): CORE_PLATFORM_MAP = { \"arista_eos\": EOSDriver, \"cisco_iosxe\": IOSXEDriver, \"cisco_iosxr\": IOSXRDriver, \"cisco_nxos\": NXOSDriver, \"juniper_junos\": JunosDriver, } DRIVER_MAP = {\"network\": NetworkDriver, \"generic\": GenericDriver} @classmethod def _get_driver_class( cls, platform_details: Dict[str, Any], variant: Optional[str] ) -> Union[Type[NetworkDriver], Type[GenericDriver]]: \"\"\" Fetch community driver class based on platform details Args: platform_details: dict of details about community platform from scrapli_community library variant: optional name of variant of community platform Returns: NetworkDriver: final driver class Raises: N/A \"\"\" final_driver: Union[ Type[NetworkDriver], Type[GenericDriver], ] if variant and platform_details[\"variants\"][variant].get(\"driver_type\"): variant_driver_data = platform_details[\"variants\"][variant].pop(\"driver_type\") final_driver = variant_driver_data[\"sync\"] return final_driver if isinstance(platform_details[\"driver_type\"], str): driver_type = platform_details[\"driver_type\"] standard_final_driver = cls.DRIVER_MAP.get(driver_type, None) if standard_final_driver: return standard_final_driver final_driver = platform_details[\"driver_type\"][\"sync\"] return final_driver @classmethod def _get_community_driver( cls, community_platform_name: str, variant: Optional[str] ) -> Tuple[Union[Type[NetworkDriver], Type[GenericDriver]], Dict[str, Any]]: \"\"\" Get community driver Args: community_platform_name: name of community variant: optional name of variant of community platform Returns: NetworkDriver: final driver class Raises: N/A \"\"\" platform_details = _get_community_platform_details( community_platform_name=community_platform_name ) final_driver = cls._get_driver_class(platform_details=platform_details, variant=variant) final_platform_kwargs = _get_driver_kwargs( platform_details=platform_details, variant=variant, _async=False ) return final_driver, final_platform_kwargs @classmethod def _get_driver( cls, platform: str, variant: Optional[str] ) -> Tuple[Union[Type[NetworkDriver], Type[GenericDriver]], Dict[str, Any]]: \"\"\" Parent get driver method for sync Scrapli Args: platform: name of target platform; i.e. `cisco_iosxe`, `arista_eos`, etc. variant: name of the target platform variant Returns: NetworkDriver: final driver class; generally NetworkDriver, but for some community platforms could be GenericDriver, also returns any additional kwargs comming from the community platform (if any) Raises: N/A \"\"\" additional_kwargs: Dict[str, Any] = {} final_driver: Union[Type[GenericDriver], Type[NetworkDriver]] if platform in cls.CORE_PLATFORM_MAP: final_driver = cls.CORE_PLATFORM_MAP[platform] msg = f\"Driver '{final_driver}' selected from scrapli core drivers\" else: final_driver, additional_kwargs = cls._get_community_driver( community_platform_name=platform, variant=variant ) msg = ( f\"Driver '{final_driver}' selected from scrapli community platforms, with the \" f\"following platform arguments: '{additional_kwargs}'\" ) logger.info(msg) return final_driver, additional_kwargs def __new__( # pylint: disable=R0914 cls, platform: str, host: str, privilege_levels: Optional[Dict[str, PrivilegeLevel]] = None, default_desired_privilege_level: Optional[str] = None, port: Optional[int] = None, auth_username: Optional[str] = None, auth_password: Optional[str] = None, auth_private_key: Optional[str] = None, auth_private_key_passphrase: Optional[str] = None, auth_strict_key: Optional[bool] = None, auth_bypass: Optional[bool] = None, timeout_socket: Optional[float] = None, timeout_transport: Optional[float] = None, timeout_ops: Optional[float] = None, comms_return_char: Optional[str] = None, ssh_config_file: Optional[Union[str, bool]] = None, ssh_known_hosts_file: Optional[Union[str, bool]] = None, on_init: Optional[Callable[..., Any]] = None, on_open: Optional[Callable[..., Any]] = None, on_close: Optional[Callable[..., Any]] = None, transport: Optional[str] = None, transport_options: Optional[Dict[str, Any]] = None, channel_log: Optional[Union[str, bool, BytesIO]] = None, channel_lock: Optional[bool] = None, channel_log_mode: Optional[str] = None, logging_uid: Optional[str] = None, auth_secondary: Optional[str] = None, failed_when_contains: Optional[List[str]] = None, textfsm_platform: Optional[str] = None, genie_platform: Optional[str] = None, variant: Optional[str] = None, **kwargs: Dict[Any, Any], ) -> \"Scrapli\": r\"\"\" Scrapli Factory method for synchronous drivers Args: platform: name of the scrapli platform to return a connection object for; should be one of the \"core\" platforms or a valid community platform name host: host ip/name to connect to port: port to connect to auth_username: username for authentication auth_private_key: path to private key for authentication auth_private_key_passphrase: passphrase for decrypting ssh key if necessary auth_password: password for authentication auth_strict_key: strict host checking or not auth_bypass: bypass \"in channel\" authentication -- only supported with telnet, asynctelnet, and system transport plugins timeout_socket: timeout for establishing socket/initial connection in seconds timeout_transport: timeout for ssh|telnet transport in seconds timeout_ops: timeout for ssh channel operations comms_return_char: character to use to send returns to host ssh_config_file: string to path for ssh config file, True to use default ssh config file or False to ignore default ssh config file ssh_known_hosts_file: string to path for ssh known hosts file, True to use default known file locations. Only applicable/needed if `auth_strict_key` is set to True on_init: callable that accepts the class instance as its only argument. this callable, if provided, is executed as the last step of object instantiation -- its purpose is primarily to provide a mechanism for scrapli community platforms to have an easy way to modify initialization arguments/object attributes without needing to create a class that extends the driver, instead allowing the community platforms to simply build from the GenericDriver or NetworkDriver classes, and pass this callable to do things such as appending to a username (looking at you RouterOS!!). Note that this is *always* a synchronous function (even for asyncio drivers)! on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar transport: name of the transport plugin to use for the actual telnet/ssh/netconf connection. Available \"core\" transports are: - system - telnet - asynctelnet - ssh2 - paramiko - asyncssh Please see relevant transport plugin section for details. Additionally third party transport plugins may be available. transport_options: dictionary of options to pass to selected transport class; see docs for given transport class for details of what to pass here channel_lock: True/False to lock the channel (threading.Lock/asyncio.Lock) during any channel operations, defaults to False channel_log: True/False or a string path to a file of where to write out channel logs -- these are not \"logs\" in the normal logging module sense, but only the output that is read from the channel. In other words, the output of the channel log should look similar to what you would see as a human connecting to a device channel_log_mode: \"write\"|\"append\", all other values will raise ValueError, does what it sounds like it should by setting the channel log to the provided mode logging_uid: unique identifier (string) to associate to log messages; useful if you have multiple connections to the same device (i.e. one console, one ssh, or one to each supervisor module, etc.) failed_when_contains: list of strings indicating command/config failure textfsm_platform: string to use to fetch ntc-templates templates for textfsm parsing genie_platform: string to use to fetch genie parser templates privilege_levels: optional user provided privilege levels, if left None will default to scrapli standard privilege levels default_desired_privilege_level: string of name of default desired priv, this is the priv level that is generally used to disable paging/set terminal width and things like that upon first login, and is also the priv level scrapli will try to acquire for normal \"command\" operations (`send_command`, `send_commands`) auth_secondary: password to use for secondary authentication (enable) failed_when_contains: List of strings that indicate a command/config has failed variant: name of the community platform variant if desired **kwargs: should be unused, but here to accept any additional kwargs from users Returns: final_driver: synchronous driver class for provided driver Raises: ScrapliValueError: if provided transport is asyncio ScrapliTypeError: if `platform` not in keyword arguments \"\"\" logger.debug(\"Scrapli factory initialized\") if transport in ASYNCIO_TRANSPORTS: raise ScrapliValueError(\"Use 'AsyncScrapli' if using an async transport!\") if not isinstance(platform, str): raise ScrapliTypeError(f\"Argument 'platform' must be 'str' got '{type(platform)}'\") provided_kwargs = _build_provided_kwargs_dict( host=host, port=port, auth_username=auth_username, auth_password=auth_password, auth_private_key=auth_private_key, auth_private_key_passphrase=auth_private_key_passphrase, auth_strict_key=auth_strict_key, auth_bypass=auth_bypass, timeout_socket=timeout_socket, timeout_transport=timeout_transport, timeout_ops=timeout_ops, comms_return_char=comms_return_char, ssh_config_file=ssh_config_file, ssh_known_hosts_file=ssh_known_hosts_file, on_init=on_init, on_open=on_open, on_close=on_close, transport=transport, transport_options=transport_options, channel_log=channel_log, channel_log_mode=channel_log_mode, channel_lock=channel_lock, logging_uid=logging_uid, privilege_levels=privilege_levels, default_desired_privilege_level=default_desired_privilege_level, auth_secondary=auth_secondary, failed_when_contains=failed_when_contains, textfsm_platform=textfsm_platform, genie_platform=genie_platform, **kwargs, ) final_driver, additional_kwargs = cls._get_driver(platform=platform, variant=variant) # at this point will need to merge the additional kwargs in (for community drivers), # ensure that kwargs passed by user supersede the ones coming from community platform if additional_kwargs: final_kwargs = {**additional_kwargs, **provided_kwargs} else: final_kwargs = provided_kwargs final_conn = final_driver(**final_kwargs) # cast the final conn to type Scrapli to appease mypy -- we know it will be a NetworkDriver # or GenericDriver, but thats ok =) final_conn = cast(Scrapli, final_conn) return final_conn class AsyncScrapli(AsyncNetworkDriver): CORE_PLATFORM_MAP = { \"arista_eos\": AsyncEOSDriver, \"cisco_iosxe\": AsyncIOSXEDriver, \"cisco_iosxr\": AsyncIOSXRDriver, \"cisco_nxos\": AsyncNXOSDriver, \"juniper_junos\": AsyncJunosDriver, } DRIVER_MAP = {\"network\": AsyncNetworkDriver, \"generic\": AsyncGenericDriver} @classmethod def _get_driver_class( cls, platform_details: Dict[str, Any], variant: Optional[str] ) -> Union[Type[AsyncNetworkDriver], Type[AsyncGenericDriver]]: \"\"\" Fetch community driver class based on platform details Args: platform_details: dict of details about community platform from scrapli_community library variant: optional name of variant of community platform Returns: NetworkDriver: final driver class Raises: N/A \"\"\" final_driver: Union[ Type[AsyncNetworkDriver], Type[AsyncGenericDriver], ] if variant and platform_details[\"variants\"][variant].get(\"driver_type\"): variant_driver_data = platform_details[\"variants\"][variant].pop(\"driver_type\") final_driver = variant_driver_data[\"async\"] return final_driver if isinstance(platform_details[\"driver_type\"], str): driver_type = platform_details[\"driver_type\"] standard_final_driver = cls.DRIVER_MAP.get(driver_type, None) if standard_final_driver: return standard_final_driver final_driver = platform_details[\"driver_type\"][\"async\"] return final_driver @classmethod def _get_community_driver( cls, community_platform_name: str, variant: Optional[str] ) -> Tuple[Union[Type[AsyncNetworkDriver], Type[AsyncGenericDriver]], Dict[str, Any]]: \"\"\" Get community driver Args: community_platform_name: name of community variant: optional name of variant of community platform Returns: NetworkDriver: final driver class Raises: N/A \"\"\" platform_details = _get_community_platform_details( community_platform_name=community_platform_name ) final_driver = cls._get_driver_class(platform_details=platform_details, variant=variant) final_platform_kwargs = _get_driver_kwargs( platform_details=platform_details, variant=variant, _async=True ) return final_driver, final_platform_kwargs @classmethod def _get_driver( cls, platform: str, variant: Optional[str] ) -> Tuple[Union[Type[AsyncNetworkDriver], Type[AsyncGenericDriver]], Dict[str, Any]]: \"\"\" Parent get driver method for sync Scrapli Args: platform: name of target platform; i.e. `cisco_iosxe`, `arista_eos`, etc. variant: name of the target platform variant Returns: NetworkDriver: final driver class; generally NetworkDriver, but for some community platforms could be GenericDriver, also returns any additional kwargs comming from the community platform (if any) Raises: N/A \"\"\" additional_kwargs: Dict[str, Any] = {} final_driver: Union[Type[AsyncGenericDriver], Type[AsyncNetworkDriver]] if platform in cls.CORE_PLATFORM_MAP: final_driver = cls.CORE_PLATFORM_MAP[platform] msg = f\"Driver '{final_driver}' selected from scrapli core drivers\" else: final_driver, additional_kwargs = cls._get_community_driver( community_platform_name=platform, variant=variant ) msg = ( f\"Driver '{final_driver}' selected from scrapli community platforms, with the \" f\"following platform arguments: '{additional_kwargs}'\" ) logger.info(msg) return final_driver, additional_kwargs def __new__( # pylint: disable=R0914 cls, platform: str, host: str, privilege_levels: Optional[Dict[str, PrivilegeLevel]] = None, default_desired_privilege_level: Optional[str] = None, port: Optional[int] = None, auth_username: Optional[str] = None, auth_password: Optional[str] = None, auth_private_key: Optional[str] = None, auth_private_key_passphrase: Optional[str] = None, auth_strict_key: Optional[bool] = None, auth_bypass: Optional[bool] = None, timeout_socket: Optional[float] = None, timeout_transport: Optional[float] = None, timeout_ops: Optional[float] = None, comms_return_char: Optional[str] = None, ssh_config_file: Optional[Union[str, bool]] = None, ssh_known_hosts_file: Optional[Union[str, bool]] = None, on_init: Optional[Callable[..., Any]] = None, on_open: Optional[Callable[..., Any]] = None, on_close: Optional[Callable[..., Any]] = None, transport: Optional[str] = None, transport_options: Optional[Dict[str, Any]] = None, channel_log: Optional[Union[str, bool, BytesIO]] = None, channel_log_mode: Optional[str] = None, channel_lock: Optional[bool] = None, logging_uid: Optional[str] = None, auth_secondary: Optional[str] = None, failed_when_contains: Optional[List[str]] = None, textfsm_platform: Optional[str] = None, genie_platform: Optional[str] = None, variant: Optional[str] = None, **kwargs: Dict[Any, Any], ) -> \"AsyncScrapli\": r\"\"\" Scrapli Factory method for asynchronous drivers Args: platform: name of the scrapli platform to return a connection object for; should be one of the \"core\" platforms or a valid community platform name host: host ip/name to connect to port: port to connect to auth_username: username for authentication auth_private_key: path to private key for authentication auth_private_key_passphrase: passphrase for decrypting ssh key if necessary auth_password: password for authentication auth_strict_key: strict host checking or not auth_bypass: bypass \"in channel\" authentication -- only supported with telnet, asynctelnet, and system transport plugins timeout_socket: timeout for establishing socket/initial connection in seconds timeout_transport: timeout for ssh|telnet transport in seconds timeout_ops: timeout for ssh channel operations comms_return_char: character to use to send returns to host ssh_config_file: string to path for ssh config file, True to use default ssh config file or False to ignore default ssh config file ssh_known_hosts_file: string to path for ssh known hosts file, True to use default known file locations. Only applicable/needed if `auth_strict_key` is set to True on_init: callable that accepts the class instance as its only argument. this callable, if provided, is executed as the last step of object instantiation -- its purpose is primarily to provide a mechanism for scrapli community platforms to have an easy way to modify initialization arguments/object attributes without needing to create a class that extends the driver, instead allowing the community platforms to simply build from the GenericDriver or NetworkDriver classes, and pass this callable to do things such as appending to a username (looking at you RouterOS!!). Note that this is *always* a synchronous function (even for asyncio drivers)! on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar transport: name of the transport plugin to use for the actual telnet/ssh/netconf connection. Available \"core\" transports are: - system - telnet - asynctelnet - ssh2 - paramiko - asyncssh Please see relevant transport plugin section for details. Additionally third party transport plugins may be available. transport_options: dictionary of options to pass to selected transport class; see docs for given transport class for details of what to pass here channel_lock: True/False to lock the channel (threading.Lock/asyncio.Lock) during any channel operations, defaults to False channel_log: True/False or a string path to a file of where to write out channel logs -- these are not \"logs\" in the normal logging module sense, but only the output that is read from the channel. In other words, the output of the channel log should look similar to what you would see as a human connecting to a device channel_log_mode: \"write\"|\"append\", all other values will raise ValueError, does what it sounds like it should by setting the channel log to the provided mode logging_uid: unique identifier (string) to associate to log messages; useful if you have multiple connections to the same device (i.e. one console, one ssh, or one to each supervisor module, etc.) failed_when_contains: list of strings indicating command/config failure textfsm_platform: string to use to fetch ntc-templates templates for textfsm parsing genie_platform: string to use to fetch genie parser templates privilege_levels: optional user provided privilege levels, if left None will default to scrapli standard privilege levels default_desired_privilege_level: string of name of default desired priv, this is the priv level that is generally used to disable paging/set terminal width and things like that upon first login, and is also the priv level scrapli will try to acquire for normal \"command\" operations (`send_command`, `send_commands`) auth_secondary: password to use for secondary authentication (enable) failed_when_contains: List of strings that indicate a command/config has failed variant: name of the community platform variant if desired **kwargs: should be unused, but here to accept any additional kwargs from users Returns: final_driver: asynchronous driver class for provided driver Raises: ScrapliValueError: if provided transport is asyncio ScrapliTypeError: if `platform` not in keyword arguments \"\"\" logger.debug(\"AsyncScrapli factory initialized\") if transport not in ASYNCIO_TRANSPORTS: raise ScrapliValueError(\"Use 'Scrapli' if using a synchronous transport!\") if not isinstance(platform, str): raise ScrapliTypeError(f\"Argument 'platform' must be 'str' got '{type(platform)}'\") provided_kwargs = _build_provided_kwargs_dict( host=host, port=port, auth_username=auth_username, auth_password=auth_password, auth_private_key=auth_private_key, auth_private_key_passphrase=auth_private_key_passphrase, auth_strict_key=auth_strict_key, auth_bypass=auth_bypass, timeout_socket=timeout_socket, timeout_transport=timeout_transport, timeout_ops=timeout_ops, comms_return_char=comms_return_char, ssh_config_file=ssh_config_file, ssh_known_hosts_file=ssh_known_hosts_file, on_init=on_init, on_open=on_open, on_close=on_close, transport=transport, transport_options=transport_options, channel_log=channel_log, channel_log_mode=channel_log_mode, channel_lock=channel_lock, logging_uid=logging_uid, privilege_levels=privilege_levels, default_desired_privilege_level=default_desired_privilege_level, auth_secondary=auth_secondary, failed_when_contains=failed_when_contains, textfsm_platform=textfsm_platform, genie_platform=genie_platform, **kwargs, ) final_driver, additional_kwargs = cls._get_driver(platform=platform, variant=variant) # at this point will need to merge the additional kwargs in (for community drivers), # ensure that kwargs passed by user supersede the ones coming from community platform if additional_kwargs: final_kwargs = {**additional_kwargs, **provided_kwargs} else: final_kwargs = provided_kwargs final_conn = final_driver(**final_kwargs) # cast the final conn to type Scrapli to appease mypy -- we know it will be a NetworkDriver # or GenericDriver, but thats ok =) final_conn = cast(AsyncScrapli, final_conn) return final_conn Classes \u00b6 AsyncScrapli \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 BaseDriver Object BaseDriver is the root for all Scrapli driver classes. The synchronous and asyncio driver base driver classes can be used to provide a semi-pexpect like experience over top of whatever transport a user prefers. Generally, however, the base driver classes should not be used directly. It is best to use the GenericDriver (or AsyncGenericDriver) or NetworkDriver (or AsyncNetworkDriver) sub-classes of the base drivers. Args: host: host ip/name to connect to port: port to connect to auth_username: username for authentication auth_private_key: path to private key for authentication auth_private_key_passphrase: passphrase for decrypting ssh key if necessary auth_password: password for authentication auth_strict_key: strict host checking or not auth_bypass: bypass \"in channel\" authentication -- only supported with telnet, asynctelnet, and system transport plugins timeout_socket: timeout for establishing socket/initial connection in seconds timeout_transport: timeout for ssh|telnet transport in seconds timeout_ops: timeout for ssh channel operations comms_prompt_pattern: raw string regex pattern -- preferably use `^` and `$` anchors! this is the single most important attribute here! if this does not match a prompt, scrapli will not work! IMPORTANT: regex search uses multi-line + case insensitive flags. multi-line allows for highly reliably matching for prompts however we do NOT strip trailing whitespace for each line, so be sure to add '\\\\s?' or similar if your device needs that. This should be mostly sorted for you if using network drivers (i.e. `IOSXEDriver`). Lastly, the case insensitive is just a convenience factor so i can be lazy. comms_return_char: character to use to send returns to host ssh_config_file: string to path for ssh config file, True to use default ssh config file or False to ignore default ssh config file ssh_known_hosts_file: string to path for ssh known hosts file, True to use default known file locations. Only applicable/needed if `auth_strict_key` is set to True on_init: callable that accepts the class instance as its only argument. this callable, if provided, is executed as the last step of object instantiation -- its purpose is primarily to provide a mechanism for scrapli community platforms to have an easy way to modify initialization arguments/object attributes without needing to create a class that extends the driver, instead allowing the community platforms to simply build from the GenericDriver or NetworkDriver classes, and pass this callable to do things such as appending to a username (looking at you RouterOS!!). Note that this is *always* a synchronous function (even for asyncio drivers)! on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar transport: name of the transport plugin to use for the actual telnet/ssh/netconf connection. Available \"core\" transports are: - system - telnet - asynctelnet - ssh2 - paramiko - asyncssh Please see relevant transport plugin section for details. Additionally third party transport plugins may be available. transport_options: dictionary of options to pass to selected transport class; see docs for given transport class for details of what to pass here channel_lock: True/False to lock the channel (threading.Lock/asyncio.Lock) during any channel operations, defaults to False channel_log: True/False or a string path to a file of where to write out channel logs -- these are not \"logs\" in the normal logging module sense, but only the output that is read from the channel. In other words, the output of the channel log should look similar to what you would see as a human connecting to a device channel_log_mode: \"write\"|\"append\", all other values will raise ValueError, does what it sounds like it should by setting the channel log to the provided mode logging_uid: unique identifier (string) to associate to log messages; useful if you have multiple connections to the same device (i.e. one console, one ssh, or one to each supervisor module, etc.) Returns: None Raises: N/A Expand source code class AsyncScrapli(AsyncNetworkDriver): CORE_PLATFORM_MAP = { \"arista_eos\": AsyncEOSDriver, \"cisco_iosxe\": AsyncIOSXEDriver, \"cisco_iosxr\": AsyncIOSXRDriver, \"cisco_nxos\": AsyncNXOSDriver, \"juniper_junos\": AsyncJunosDriver, } DRIVER_MAP = {\"network\": AsyncNetworkDriver, \"generic\": AsyncGenericDriver} @classmethod def _get_driver_class( cls, platform_details: Dict[str, Any], variant: Optional[str] ) -> Union[Type[AsyncNetworkDriver], Type[AsyncGenericDriver]]: \"\"\" Fetch community driver class based on platform details Args: platform_details: dict of details about community platform from scrapli_community library variant: optional name of variant of community platform Returns: NetworkDriver: final driver class Raises: N/A \"\"\" final_driver: Union[ Type[AsyncNetworkDriver], Type[AsyncGenericDriver], ] if variant and platform_details[\"variants\"][variant].get(\"driver_type\"): variant_driver_data = platform_details[\"variants\"][variant].pop(\"driver_type\") final_driver = variant_driver_data[\"async\"] return final_driver if isinstance(platform_details[\"driver_type\"], str): driver_type = platform_details[\"driver_type\"] standard_final_driver = cls.DRIVER_MAP.get(driver_type, None) if standard_final_driver: return standard_final_driver final_driver = platform_details[\"driver_type\"][\"async\"] return final_driver @classmethod def _get_community_driver( cls, community_platform_name: str, variant: Optional[str] ) -> Tuple[Union[Type[AsyncNetworkDriver], Type[AsyncGenericDriver]], Dict[str, Any]]: \"\"\" Get community driver Args: community_platform_name: name of community variant: optional name of variant of community platform Returns: NetworkDriver: final driver class Raises: N/A \"\"\" platform_details = _get_community_platform_details( community_platform_name=community_platform_name ) final_driver = cls._get_driver_class(platform_details=platform_details, variant=variant) final_platform_kwargs = _get_driver_kwargs( platform_details=platform_details, variant=variant, _async=True ) return final_driver, final_platform_kwargs @classmethod def _get_driver( cls, platform: str, variant: Optional[str] ) -> Tuple[Union[Type[AsyncNetworkDriver], Type[AsyncGenericDriver]], Dict[str, Any]]: \"\"\" Parent get driver method for sync Scrapli Args: platform: name of target platform; i.e. `cisco_iosxe`, `arista_eos`, etc. variant: name of the target platform variant Returns: NetworkDriver: final driver class; generally NetworkDriver, but for some community platforms could be GenericDriver, also returns any additional kwargs comming from the community platform (if any) Raises: N/A \"\"\" additional_kwargs: Dict[str, Any] = {} final_driver: Union[Type[AsyncGenericDriver], Type[AsyncNetworkDriver]] if platform in cls.CORE_PLATFORM_MAP: final_driver = cls.CORE_PLATFORM_MAP[platform] msg = f\"Driver '{final_driver}' selected from scrapli core drivers\" else: final_driver, additional_kwargs = cls._get_community_driver( community_platform_name=platform, variant=variant ) msg = ( f\"Driver '{final_driver}' selected from scrapli community platforms, with the \" f\"following platform arguments: '{additional_kwargs}'\" ) logger.info(msg) return final_driver, additional_kwargs def __new__( # pylint: disable=R0914 cls, platform: str, host: str, privilege_levels: Optional[Dict[str, PrivilegeLevel]] = None, default_desired_privilege_level: Optional[str] = None, port: Optional[int] = None, auth_username: Optional[str] = None, auth_password: Optional[str] = None, auth_private_key: Optional[str] = None, auth_private_key_passphrase: Optional[str] = None, auth_strict_key: Optional[bool] = None, auth_bypass: Optional[bool] = None, timeout_socket: Optional[float] = None, timeout_transport: Optional[float] = None, timeout_ops: Optional[float] = None, comms_return_char: Optional[str] = None, ssh_config_file: Optional[Union[str, bool]] = None, ssh_known_hosts_file: Optional[Union[str, bool]] = None, on_init: Optional[Callable[..., Any]] = None, on_open: Optional[Callable[..., Any]] = None, on_close: Optional[Callable[..., Any]] = None, transport: Optional[str] = None, transport_options: Optional[Dict[str, Any]] = None, channel_log: Optional[Union[str, bool, BytesIO]] = None, channel_log_mode: Optional[str] = None, channel_lock: Optional[bool] = None, logging_uid: Optional[str] = None, auth_secondary: Optional[str] = None, failed_when_contains: Optional[List[str]] = None, textfsm_platform: Optional[str] = None, genie_platform: Optional[str] = None, variant: Optional[str] = None, **kwargs: Dict[Any, Any], ) -> \"AsyncScrapli\": r\"\"\" Scrapli Factory method for asynchronous drivers Args: platform: name of the scrapli platform to return a connection object for; should be one of the \"core\" platforms or a valid community platform name host: host ip/name to connect to port: port to connect to auth_username: username for authentication auth_private_key: path to private key for authentication auth_private_key_passphrase: passphrase for decrypting ssh key if necessary auth_password: password for authentication auth_strict_key: strict host checking or not auth_bypass: bypass \"in channel\" authentication -- only supported with telnet, asynctelnet, and system transport plugins timeout_socket: timeout for establishing socket/initial connection in seconds timeout_transport: timeout for ssh|telnet transport in seconds timeout_ops: timeout for ssh channel operations comms_return_char: character to use to send returns to host ssh_config_file: string to path for ssh config file, True to use default ssh config file or False to ignore default ssh config file ssh_known_hosts_file: string to path for ssh known hosts file, True to use default known file locations. Only applicable/needed if `auth_strict_key` is set to True on_init: callable that accepts the class instance as its only argument. this callable, if provided, is executed as the last step of object instantiation -- its purpose is primarily to provide a mechanism for scrapli community platforms to have an easy way to modify initialization arguments/object attributes without needing to create a class that extends the driver, instead allowing the community platforms to simply build from the GenericDriver or NetworkDriver classes, and pass this callable to do things such as appending to a username (looking at you RouterOS!!). Note that this is *always* a synchronous function (even for asyncio drivers)! on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar transport: name of the transport plugin to use for the actual telnet/ssh/netconf connection. Available \"core\" transports are: - system - telnet - asynctelnet - ssh2 - paramiko - asyncssh Please see relevant transport plugin section for details. Additionally third party transport plugins may be available. transport_options: dictionary of options to pass to selected transport class; see docs for given transport class for details of what to pass here channel_lock: True/False to lock the channel (threading.Lock/asyncio.Lock) during any channel operations, defaults to False channel_log: True/False or a string path to a file of where to write out channel logs -- these are not \"logs\" in the normal logging module sense, but only the output that is read from the channel. In other words, the output of the channel log should look similar to what you would see as a human connecting to a device channel_log_mode: \"write\"|\"append\", all other values will raise ValueError, does what it sounds like it should by setting the channel log to the provided mode logging_uid: unique identifier (string) to associate to log messages; useful if you have multiple connections to the same device (i.e. one console, one ssh, or one to each supervisor module, etc.) failed_when_contains: list of strings indicating command/config failure textfsm_platform: string to use to fetch ntc-templates templates for textfsm parsing genie_platform: string to use to fetch genie parser templates privilege_levels: optional user provided privilege levels, if left None will default to scrapli standard privilege levels default_desired_privilege_level: string of name of default desired priv, this is the priv level that is generally used to disable paging/set terminal width and things like that upon first login, and is also the priv level scrapli will try to acquire for normal \"command\" operations (`send_command`, `send_commands`) auth_secondary: password to use for secondary authentication (enable) failed_when_contains: List of strings that indicate a command/config has failed variant: name of the community platform variant if desired **kwargs: should be unused, but here to accept any additional kwargs from users Returns: final_driver: asynchronous driver class for provided driver Raises: ScrapliValueError: if provided transport is asyncio ScrapliTypeError: if `platform` not in keyword arguments \"\"\" logger.debug(\"AsyncScrapli factory initialized\") if transport not in ASYNCIO_TRANSPORTS: raise ScrapliValueError(\"Use 'Scrapli' if using a synchronous transport!\") if not isinstance(platform, str): raise ScrapliTypeError(f\"Argument 'platform' must be 'str' got '{type(platform)}'\") provided_kwargs = _build_provided_kwargs_dict( host=host, port=port, auth_username=auth_username, auth_password=auth_password, auth_private_key=auth_private_key, auth_private_key_passphrase=auth_private_key_passphrase, auth_strict_key=auth_strict_key, auth_bypass=auth_bypass, timeout_socket=timeout_socket, timeout_transport=timeout_transport, timeout_ops=timeout_ops, comms_return_char=comms_return_char, ssh_config_file=ssh_config_file, ssh_known_hosts_file=ssh_known_hosts_file, on_init=on_init, on_open=on_open, on_close=on_close, transport=transport, transport_options=transport_options, channel_log=channel_log, channel_log_mode=channel_log_mode, channel_lock=channel_lock, logging_uid=logging_uid, privilege_levels=privilege_levels, default_desired_privilege_level=default_desired_privilege_level, auth_secondary=auth_secondary, failed_when_contains=failed_when_contains, textfsm_platform=textfsm_platform, genie_platform=genie_platform, **kwargs, ) final_driver, additional_kwargs = cls._get_driver(platform=platform, variant=variant) # at this point will need to merge the additional kwargs in (for community drivers), # ensure that kwargs passed by user supersede the ones coming from community platform if additional_kwargs: final_kwargs = {**additional_kwargs, **provided_kwargs} else: final_kwargs = provided_kwargs final_conn = final_driver(**final_kwargs) # cast the final conn to type Scrapli to appease mypy -- we know it will be a NetworkDriver # or GenericDriver, but thats ok =) final_conn = cast(AsyncScrapli, final_conn) return final_conn Ancestors (in MRO) \u00b6 scrapli.driver.network.async_driver.AsyncNetworkDriver scrapli.driver.generic.async_driver.AsyncGenericDriver scrapli.driver.base.async_driver.AsyncDriver scrapli.driver.base.base_driver.BaseDriver scrapli.driver.generic.base_driver.BaseGenericDriver scrapli.driver.network.base_driver.BaseNetworkDriver Class variables \u00b6 CORE_PLATFORM_MAP DRIVER_MAP Scrapli \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 BaseDriver Object BaseDriver is the root for all Scrapli driver classes. The synchronous and asyncio driver base driver classes can be used to provide a semi-pexpect like experience over top of whatever transport a user prefers. Generally, however, the base driver classes should not be used directly. It is best to use the GenericDriver (or AsyncGenericDriver) or NetworkDriver (or AsyncNetworkDriver) sub-classes of the base drivers. Args: host: host ip/name to connect to port: port to connect to auth_username: username for authentication auth_private_key: path to private key for authentication auth_private_key_passphrase: passphrase for decrypting ssh key if necessary auth_password: password for authentication auth_strict_key: strict host checking or not auth_bypass: bypass \"in channel\" authentication -- only supported with telnet, asynctelnet, and system transport plugins timeout_socket: timeout for establishing socket/initial connection in seconds timeout_transport: timeout for ssh|telnet transport in seconds timeout_ops: timeout for ssh channel operations comms_prompt_pattern: raw string regex pattern -- preferably use `^` and `$` anchors! this is the single most important attribute here! if this does not match a prompt, scrapli will not work! IMPORTANT: regex search uses multi-line + case insensitive flags. multi-line allows for highly reliably matching for prompts however we do NOT strip trailing whitespace for each line, so be sure to add '\\\\s?' or similar if your device needs that. This should be mostly sorted for you if using network drivers (i.e. `IOSXEDriver`). Lastly, the case insensitive is just a convenience factor so i can be lazy. comms_return_char: character to use to send returns to host ssh_config_file: string to path for ssh config file, True to use default ssh config file or False to ignore default ssh config file ssh_known_hosts_file: string to path for ssh known hosts file, True to use default known file locations. Only applicable/needed if `auth_strict_key` is set to True on_init: callable that accepts the class instance as its only argument. this callable, if provided, is executed as the last step of object instantiation -- its purpose is primarily to provide a mechanism for scrapli community platforms to have an easy way to modify initialization arguments/object attributes without needing to create a class that extends the driver, instead allowing the community platforms to simply build from the GenericDriver or NetworkDriver classes, and pass this callable to do things such as appending to a username (looking at you RouterOS!!). Note that this is *always* a synchronous function (even for asyncio drivers)! on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar transport: name of the transport plugin to use for the actual telnet/ssh/netconf connection. Available \"core\" transports are: - system - telnet - asynctelnet - ssh2 - paramiko - asyncssh Please see relevant transport plugin section for details. Additionally third party transport plugins may be available. transport_options: dictionary of options to pass to selected transport class; see docs for given transport class for details of what to pass here channel_lock: True/False to lock the channel (threading.Lock/asyncio.Lock) during any channel operations, defaults to False channel_log: True/False or a string path to a file of where to write out channel logs -- these are not \"logs\" in the normal logging module sense, but only the output that is read from the channel. In other words, the output of the channel log should look similar to what you would see as a human connecting to a device channel_log_mode: \"write\"|\"append\", all other values will raise ValueError, does what it sounds like it should by setting the channel log to the provided mode logging_uid: unique identifier (string) to associate to log messages; useful if you have multiple connections to the same device (i.e. one console, one ssh, or one to each supervisor module, etc.) Returns: None Raises: N/A Expand source code class Scrapli(NetworkDriver): CORE_PLATFORM_MAP = { \"arista_eos\": EOSDriver, \"cisco_iosxe\": IOSXEDriver, \"cisco_iosxr\": IOSXRDriver, \"cisco_nxos\": NXOSDriver, \"juniper_junos\": JunosDriver, } DRIVER_MAP = {\"network\": NetworkDriver, \"generic\": GenericDriver} @classmethod def _get_driver_class( cls, platform_details: Dict[str, Any], variant: Optional[str] ) -> Union[Type[NetworkDriver], Type[GenericDriver]]: \"\"\" Fetch community driver class based on platform details Args: platform_details: dict of details about community platform from scrapli_community library variant: optional name of variant of community platform Returns: NetworkDriver: final driver class Raises: N/A \"\"\" final_driver: Union[ Type[NetworkDriver], Type[GenericDriver], ] if variant and platform_details[\"variants\"][variant].get(\"driver_type\"): variant_driver_data = platform_details[\"variants\"][variant].pop(\"driver_type\") final_driver = variant_driver_data[\"sync\"] return final_driver if isinstance(platform_details[\"driver_type\"], str): driver_type = platform_details[\"driver_type\"] standard_final_driver = cls.DRIVER_MAP.get(driver_type, None) if standard_final_driver: return standard_final_driver final_driver = platform_details[\"driver_type\"][\"sync\"] return final_driver @classmethod def _get_community_driver( cls, community_platform_name: str, variant: Optional[str] ) -> Tuple[Union[Type[NetworkDriver], Type[GenericDriver]], Dict[str, Any]]: \"\"\" Get community driver Args: community_platform_name: name of community variant: optional name of variant of community platform Returns: NetworkDriver: final driver class Raises: N/A \"\"\" platform_details = _get_community_platform_details( community_platform_name=community_platform_name ) final_driver = cls._get_driver_class(platform_details=platform_details, variant=variant) final_platform_kwargs = _get_driver_kwargs( platform_details=platform_details, variant=variant, _async=False ) return final_driver, final_platform_kwargs @classmethod def _get_driver( cls, platform: str, variant: Optional[str] ) -> Tuple[Union[Type[NetworkDriver], Type[GenericDriver]], Dict[str, Any]]: \"\"\" Parent get driver method for sync Scrapli Args: platform: name of target platform; i.e. `cisco_iosxe`, `arista_eos`, etc. variant: name of the target platform variant Returns: NetworkDriver: final driver class; generally NetworkDriver, but for some community platforms could be GenericDriver, also returns any additional kwargs comming from the community platform (if any) Raises: N/A \"\"\" additional_kwargs: Dict[str, Any] = {} final_driver: Union[Type[GenericDriver], Type[NetworkDriver]] if platform in cls.CORE_PLATFORM_MAP: final_driver = cls.CORE_PLATFORM_MAP[platform] msg = f\"Driver '{final_driver}' selected from scrapli core drivers\" else: final_driver, additional_kwargs = cls._get_community_driver( community_platform_name=platform, variant=variant ) msg = ( f\"Driver '{final_driver}' selected from scrapli community platforms, with the \" f\"following platform arguments: '{additional_kwargs}'\" ) logger.info(msg) return final_driver, additional_kwargs def __new__( # pylint: disable=R0914 cls, platform: str, host: str, privilege_levels: Optional[Dict[str, PrivilegeLevel]] = None, default_desired_privilege_level: Optional[str] = None, port: Optional[int] = None, auth_username: Optional[str] = None, auth_password: Optional[str] = None, auth_private_key: Optional[str] = None, auth_private_key_passphrase: Optional[str] = None, auth_strict_key: Optional[bool] = None, auth_bypass: Optional[bool] = None, timeout_socket: Optional[float] = None, timeout_transport: Optional[float] = None, timeout_ops: Optional[float] = None, comms_return_char: Optional[str] = None, ssh_config_file: Optional[Union[str, bool]] = None, ssh_known_hosts_file: Optional[Union[str, bool]] = None, on_init: Optional[Callable[..., Any]] = None, on_open: Optional[Callable[..., Any]] = None, on_close: Optional[Callable[..., Any]] = None, transport: Optional[str] = None, transport_options: Optional[Dict[str, Any]] = None, channel_log: Optional[Union[str, bool, BytesIO]] = None, channel_lock: Optional[bool] = None, channel_log_mode: Optional[str] = None, logging_uid: Optional[str] = None, auth_secondary: Optional[str] = None, failed_when_contains: Optional[List[str]] = None, textfsm_platform: Optional[str] = None, genie_platform: Optional[str] = None, variant: Optional[str] = None, **kwargs: Dict[Any, Any], ) -> \"Scrapli\": r\"\"\" Scrapli Factory method for synchronous drivers Args: platform: name of the scrapli platform to return a connection object for; should be one of the \"core\" platforms or a valid community platform name host: host ip/name to connect to port: port to connect to auth_username: username for authentication auth_private_key: path to private key for authentication auth_private_key_passphrase: passphrase for decrypting ssh key if necessary auth_password: password for authentication auth_strict_key: strict host checking or not auth_bypass: bypass \"in channel\" authentication -- only supported with telnet, asynctelnet, and system transport plugins timeout_socket: timeout for establishing socket/initial connection in seconds timeout_transport: timeout for ssh|telnet transport in seconds timeout_ops: timeout for ssh channel operations comms_return_char: character to use to send returns to host ssh_config_file: string to path for ssh config file, True to use default ssh config file or False to ignore default ssh config file ssh_known_hosts_file: string to path for ssh known hosts file, True to use default known file locations. Only applicable/needed if `auth_strict_key` is set to True on_init: callable that accepts the class instance as its only argument. this callable, if provided, is executed as the last step of object instantiation -- its purpose is primarily to provide a mechanism for scrapli community platforms to have an easy way to modify initialization arguments/object attributes without needing to create a class that extends the driver, instead allowing the community platforms to simply build from the GenericDriver or NetworkDriver classes, and pass this callable to do things such as appending to a username (looking at you RouterOS!!). Note that this is *always* a synchronous function (even for asyncio drivers)! on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar transport: name of the transport plugin to use for the actual telnet/ssh/netconf connection. Available \"core\" transports are: - system - telnet - asynctelnet - ssh2 - paramiko - asyncssh Please see relevant transport plugin section for details. Additionally third party transport plugins may be available. transport_options: dictionary of options to pass to selected transport class; see docs for given transport class for details of what to pass here channel_lock: True/False to lock the channel (threading.Lock/asyncio.Lock) during any channel operations, defaults to False channel_log: True/False or a string path to a file of where to write out channel logs -- these are not \"logs\" in the normal logging module sense, but only the output that is read from the channel. In other words, the output of the channel log should look similar to what you would see as a human connecting to a device channel_log_mode: \"write\"|\"append\", all other values will raise ValueError, does what it sounds like it should by setting the channel log to the provided mode logging_uid: unique identifier (string) to associate to log messages; useful if you have multiple connections to the same device (i.e. one console, one ssh, or one to each supervisor module, etc.) failed_when_contains: list of strings indicating command/config failure textfsm_platform: string to use to fetch ntc-templates templates for textfsm parsing genie_platform: string to use to fetch genie parser templates privilege_levels: optional user provided privilege levels, if left None will default to scrapli standard privilege levels default_desired_privilege_level: string of name of default desired priv, this is the priv level that is generally used to disable paging/set terminal width and things like that upon first login, and is also the priv level scrapli will try to acquire for normal \"command\" operations (`send_command`, `send_commands`) auth_secondary: password to use for secondary authentication (enable) failed_when_contains: List of strings that indicate a command/config has failed variant: name of the community platform variant if desired **kwargs: should be unused, but here to accept any additional kwargs from users Returns: final_driver: synchronous driver class for provided driver Raises: ScrapliValueError: if provided transport is asyncio ScrapliTypeError: if `platform` not in keyword arguments \"\"\" logger.debug(\"Scrapli factory initialized\") if transport in ASYNCIO_TRANSPORTS: raise ScrapliValueError(\"Use 'AsyncScrapli' if using an async transport!\") if not isinstance(platform, str): raise ScrapliTypeError(f\"Argument 'platform' must be 'str' got '{type(platform)}'\") provided_kwargs = _build_provided_kwargs_dict( host=host, port=port, auth_username=auth_username, auth_password=auth_password, auth_private_key=auth_private_key, auth_private_key_passphrase=auth_private_key_passphrase, auth_strict_key=auth_strict_key, auth_bypass=auth_bypass, timeout_socket=timeout_socket, timeout_transport=timeout_transport, timeout_ops=timeout_ops, comms_return_char=comms_return_char, ssh_config_file=ssh_config_file, ssh_known_hosts_file=ssh_known_hosts_file, on_init=on_init, on_open=on_open, on_close=on_close, transport=transport, transport_options=transport_options, channel_log=channel_log, channel_log_mode=channel_log_mode, channel_lock=channel_lock, logging_uid=logging_uid, privilege_levels=privilege_levels, default_desired_privilege_level=default_desired_privilege_level, auth_secondary=auth_secondary, failed_when_contains=failed_when_contains, textfsm_platform=textfsm_platform, genie_platform=genie_platform, **kwargs, ) final_driver, additional_kwargs = cls._get_driver(platform=platform, variant=variant) # at this point will need to merge the additional kwargs in (for community drivers), # ensure that kwargs passed by user supersede the ones coming from community platform if additional_kwargs: final_kwargs = {**additional_kwargs, **provided_kwargs} else: final_kwargs = provided_kwargs final_conn = final_driver(**final_kwargs) # cast the final conn to type Scrapli to appease mypy -- we know it will be a NetworkDriver # or GenericDriver, but thats ok =) final_conn = cast(Scrapli, final_conn) return final_conn Ancestors (in MRO) \u00b6 scrapli.driver.network.sync_driver.NetworkDriver scrapli.driver.generic.sync_driver.GenericDriver scrapli.driver.base.sync_driver.Driver scrapli.driver.base.base_driver.BaseDriver scrapli.driver.generic.base_driver.BaseGenericDriver scrapli.driver.network.base_driver.BaseNetworkDriver Class variables \u00b6 CORE_PLATFORM_MAP DRIVER_MAP","title":"Factory"},{"location":"api_docs/factory/#module-scraplifactory","text":"scrapli.factory Expand source code \"\"\"scrapli.factory\"\"\" import importlib from copy import deepcopy from io import BytesIO from typing import Any, Callable, Dict, List, Optional, Tuple, Type, Union, cast from scrapli.driver import AsyncGenericDriver, AsyncNetworkDriver, GenericDriver, NetworkDriver from scrapli.driver.core import ( AsyncEOSDriver, AsyncIOSXEDriver, AsyncIOSXRDriver, AsyncJunosDriver, AsyncNXOSDriver, EOSDriver, IOSXEDriver, IOSXRDriver, JunosDriver, NXOSDriver, ) from scrapli.driver.network.base_driver import PrivilegeLevel from scrapli.exceptions import ( ScrapliException, ScrapliModuleNotFound, ScrapliTypeError, ScrapliValueError, ) from scrapli.helper import format_user_warning from scrapli.logging import logger from scrapli.transport import ASYNCIO_TRANSPORTS def _build_provided_kwargs_dict( # pylint: disable=R0914 host: str, privilege_levels: Optional[Dict[str, PrivilegeLevel]], default_desired_privilege_level: Optional[str], port: Optional[int], auth_username: Optional[str], auth_password: Optional[str], auth_private_key: Optional[str], auth_private_key_passphrase: Optional[str], auth_strict_key: Optional[bool], auth_bypass: Optional[bool], timeout_socket: Optional[float], timeout_transport: Optional[float], timeout_ops: Optional[float], comms_return_char: Optional[str], ssh_config_file: Optional[Union[str, bool]], ssh_known_hosts_file: Optional[Union[str, bool]], on_init: Optional[Callable[..., Any]], on_open: Optional[Callable[..., Any]], on_close: Optional[Callable[..., Any]], transport: Optional[str], transport_options: Optional[Dict[str, Any]], channel_log: Optional[Union[str, bool, BytesIO]], channel_log_mode: Optional[str], channel_lock: Optional[bool], logging_uid: Optional[str], auth_secondary: Optional[str], failed_when_contains: Optional[List[str]], textfsm_platform: Optional[str], genie_platform: Optional[str], **kwargs: Dict[Any, Any], ) -> Dict[str, Any]: r\"\"\" Build arguments dict based on provided inputs This function builds the dict of keyword args to unpack and send to the driver -- in the factory context this also needs to convert the arguments that have defaults that evaluate to False (i.e ssh_config_file which defaults to False) from None which is their default in the factory, back to their normal default if they are still None -OR- to whatever the user provided. # noqa: DAR101 Args: N/A Returns: dict: dictionary with user args merged with the appropriate default options Raises: N/A \"\"\" # dict of all args coming from the factories _provided_args: Dict[str, Any] = { \"host\": host, \"privilege_levels\": privilege_levels, \"default_desired_privilege_level\": default_desired_privilege_level, \"port\": port, \"auth_username\": auth_username, \"auth_password\": auth_password, \"auth_private_key\": auth_private_key, \"auth_private_key_passphrase\": auth_private_key_passphrase, \"auth_strict_key\": auth_strict_key, \"auth_bypass\": auth_bypass, \"timeout_socket\": timeout_socket, \"timeout_transport\": timeout_transport, \"timeout_ops\": timeout_ops, \"comms_return_char\": comms_return_char, \"ssh_config_file\": ssh_config_file, \"ssh_known_hosts_file\": ssh_known_hosts_file, \"on_init\": on_init, \"on_open\": on_open, \"on_close\": on_close, \"transport\": transport, \"transport_options\": transport_options, \"channel_log\": channel_log, \"channel_log_mode\": channel_log_mode, \"channel_lock\": channel_lock, \"logging_uid\": logging_uid, \"auth_secondary\": auth_secondary, \"failed_when_contains\": failed_when_contains, \"textfsm_platform\": textfsm_platform, \"genie_platform\": genie_platform, } # add back in the None/False args _provided_args = {key: value for key, value in _provided_args.items() if value is not None} # merge in any kwargs that maybe need to get passed down return {**_provided_args, **kwargs} def _get_community_platform_details(community_platform_name: str) -> Dict[str, Any]: \"\"\" Fetch community platform details Args: community_platform_name: name of community Returns: platform_details: dict of details about community platform from scrapli_community library Raises: ScrapliModuleNotFound: if scrapli_community is not importable ScrapliModuleNotFound: if provided community_platform_name package is not importable ScrapliException: if community platform is missing \"SCRAPLI_PLATFORM\" attribute \"\"\" try: importlib.import_module(name=\"scrapli_community\") except ModuleNotFoundError as exc: title = \"Module not found!\" message = ( \"Scrapli Community package is not installed!\\n\" \"To resolve this issue, install the transport plugin. You can do this in one of \" \"the following ways:\\n\" \"1: 'pip install -r requirements-community.txt'\\n\" \"2: 'pip install scrapli[community]'\" ) warning = format_user_warning(title=title, message=message) raise ScrapliModuleNotFound(warning) from exc try: # replace any underscores in platform name with \".\"; should support any future platforms # that dont have \"child\" os types -- i.e. just \"cisco\" instead of \"cisco_iosxe\" scrapli_community_platform = importlib.import_module( name=f\"scrapli_community.{community_platform_name.replace('_', '.')}\" ) except ModuleNotFoundError as exc: title = \"Module not found!\" message = ( f\"Scrapli Community platform '{community_platform_name}` not found!\\n\" \"To resolve this issue, ensure you have the correct platform name, and that a scrapli \" \" community platform of that name exists!\" ) warning = format_user_warning(title=title, message=message) raise ScrapliModuleNotFound(warning) from exc platform_details_original = getattr(scrapli_community_platform, \"SCRAPLI_PLATFORM\", {}) if not platform_details_original: msg = \"Community platform missing required attribute `SCRAPLI_PLATFORM`\" raise ScrapliException(msg) platform_details: Dict[str, Any] = deepcopy(platform_details_original) return platform_details def _get_driver_kwargs( platform_details: Dict[str, Any], variant: Optional[str], _async: bool = False ) -> Dict[str, Any]: \"\"\" Parent get driver method Args: platform_details: dict of details about community platform from scrapli_community library variant: optional name of variant of community platform _async: True/False this is for an asyncio transport driver Returns: final_platform_kwargs: dict of final driver kwargs Raises: N/A \"\"\" platform_kwargs = platform_details[\"defaults\"] if variant: variant_kwargs = platform_details[\"variants\"][variant] final_platform_kwargs = {**platform_kwargs, **variant_kwargs} else: final_platform_kwargs = platform_kwargs if not _async: # remove unnecessary asyncio things final_platform_kwargs.pop(\"async_on_open\") final_platform_kwargs.pop(\"async_on_close\") # rename sync_on_(open|close) keys to just \"on_open\"/\"on_close\" final_platform_kwargs[\"on_open\"] = final_platform_kwargs.pop(\"sync_on_open\") final_platform_kwargs[\"on_close\"] = final_platform_kwargs.pop(\"sync_on_close\") else: # remove unnecessary sync things final_platform_kwargs.pop(\"sync_on_open\") final_platform_kwargs.pop(\"sync_on_close\") # rename sync_on_(open|close) keys to just \"on_open\"/\"on_close\" final_platform_kwargs[\"on_open\"] = final_platform_kwargs.pop(\"async_on_open\") final_platform_kwargs[\"on_close\"] = final_platform_kwargs.pop(\"async_on_close\") return final_platform_kwargs class Scrapli(NetworkDriver): CORE_PLATFORM_MAP = { \"arista_eos\": EOSDriver, \"cisco_iosxe\": IOSXEDriver, \"cisco_iosxr\": IOSXRDriver, \"cisco_nxos\": NXOSDriver, \"juniper_junos\": JunosDriver, } DRIVER_MAP = {\"network\": NetworkDriver, \"generic\": GenericDriver} @classmethod def _get_driver_class( cls, platform_details: Dict[str, Any], variant: Optional[str] ) -> Union[Type[NetworkDriver], Type[GenericDriver]]: \"\"\" Fetch community driver class based on platform details Args: platform_details: dict of details about community platform from scrapli_community library variant: optional name of variant of community platform Returns: NetworkDriver: final driver class Raises: N/A \"\"\" final_driver: Union[ Type[NetworkDriver], Type[GenericDriver], ] if variant and platform_details[\"variants\"][variant].get(\"driver_type\"): variant_driver_data = platform_details[\"variants\"][variant].pop(\"driver_type\") final_driver = variant_driver_data[\"sync\"] return final_driver if isinstance(platform_details[\"driver_type\"], str): driver_type = platform_details[\"driver_type\"] standard_final_driver = cls.DRIVER_MAP.get(driver_type, None) if standard_final_driver: return standard_final_driver final_driver = platform_details[\"driver_type\"][\"sync\"] return final_driver @classmethod def _get_community_driver( cls, community_platform_name: str, variant: Optional[str] ) -> Tuple[Union[Type[NetworkDriver], Type[GenericDriver]], Dict[str, Any]]: \"\"\" Get community driver Args: community_platform_name: name of community variant: optional name of variant of community platform Returns: NetworkDriver: final driver class Raises: N/A \"\"\" platform_details = _get_community_platform_details( community_platform_name=community_platform_name ) final_driver = cls._get_driver_class(platform_details=platform_details, variant=variant) final_platform_kwargs = _get_driver_kwargs( platform_details=platform_details, variant=variant, _async=False ) return final_driver, final_platform_kwargs @classmethod def _get_driver( cls, platform: str, variant: Optional[str] ) -> Tuple[Union[Type[NetworkDriver], Type[GenericDriver]], Dict[str, Any]]: \"\"\" Parent get driver method for sync Scrapli Args: platform: name of target platform; i.e. `cisco_iosxe`, `arista_eos`, etc. variant: name of the target platform variant Returns: NetworkDriver: final driver class; generally NetworkDriver, but for some community platforms could be GenericDriver, also returns any additional kwargs comming from the community platform (if any) Raises: N/A \"\"\" additional_kwargs: Dict[str, Any] = {} final_driver: Union[Type[GenericDriver], Type[NetworkDriver]] if platform in cls.CORE_PLATFORM_MAP: final_driver = cls.CORE_PLATFORM_MAP[platform] msg = f\"Driver '{final_driver}' selected from scrapli core drivers\" else: final_driver, additional_kwargs = cls._get_community_driver( community_platform_name=platform, variant=variant ) msg = ( f\"Driver '{final_driver}' selected from scrapli community platforms, with the \" f\"following platform arguments: '{additional_kwargs}'\" ) logger.info(msg) return final_driver, additional_kwargs def __new__( # pylint: disable=R0914 cls, platform: str, host: str, privilege_levels: Optional[Dict[str, PrivilegeLevel]] = None, default_desired_privilege_level: Optional[str] = None, port: Optional[int] = None, auth_username: Optional[str] = None, auth_password: Optional[str] = None, auth_private_key: Optional[str] = None, auth_private_key_passphrase: Optional[str] = None, auth_strict_key: Optional[bool] = None, auth_bypass: Optional[bool] = None, timeout_socket: Optional[float] = None, timeout_transport: Optional[float] = None, timeout_ops: Optional[float] = None, comms_return_char: Optional[str] = None, ssh_config_file: Optional[Union[str, bool]] = None, ssh_known_hosts_file: Optional[Union[str, bool]] = None, on_init: Optional[Callable[..., Any]] = None, on_open: Optional[Callable[..., Any]] = None, on_close: Optional[Callable[..., Any]] = None, transport: Optional[str] = None, transport_options: Optional[Dict[str, Any]] = None, channel_log: Optional[Union[str, bool, BytesIO]] = None, channel_lock: Optional[bool] = None, channel_log_mode: Optional[str] = None, logging_uid: Optional[str] = None, auth_secondary: Optional[str] = None, failed_when_contains: Optional[List[str]] = None, textfsm_platform: Optional[str] = None, genie_platform: Optional[str] = None, variant: Optional[str] = None, **kwargs: Dict[Any, Any], ) -> \"Scrapli\": r\"\"\" Scrapli Factory method for synchronous drivers Args: platform: name of the scrapli platform to return a connection object for; should be one of the \"core\" platforms or a valid community platform name host: host ip/name to connect to port: port to connect to auth_username: username for authentication auth_private_key: path to private key for authentication auth_private_key_passphrase: passphrase for decrypting ssh key if necessary auth_password: password for authentication auth_strict_key: strict host checking or not auth_bypass: bypass \"in channel\" authentication -- only supported with telnet, asynctelnet, and system transport plugins timeout_socket: timeout for establishing socket/initial connection in seconds timeout_transport: timeout for ssh|telnet transport in seconds timeout_ops: timeout for ssh channel operations comms_return_char: character to use to send returns to host ssh_config_file: string to path for ssh config file, True to use default ssh config file or False to ignore default ssh config file ssh_known_hosts_file: string to path for ssh known hosts file, True to use default known file locations. Only applicable/needed if `auth_strict_key` is set to True on_init: callable that accepts the class instance as its only argument. this callable, if provided, is executed as the last step of object instantiation -- its purpose is primarily to provide a mechanism for scrapli community platforms to have an easy way to modify initialization arguments/object attributes without needing to create a class that extends the driver, instead allowing the community platforms to simply build from the GenericDriver or NetworkDriver classes, and pass this callable to do things such as appending to a username (looking at you RouterOS!!). Note that this is *always* a synchronous function (even for asyncio drivers)! on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar transport: name of the transport plugin to use for the actual telnet/ssh/netconf connection. Available \"core\" transports are: - system - telnet - asynctelnet - ssh2 - paramiko - asyncssh Please see relevant transport plugin section for details. Additionally third party transport plugins may be available. transport_options: dictionary of options to pass to selected transport class; see docs for given transport class for details of what to pass here channel_lock: True/False to lock the channel (threading.Lock/asyncio.Lock) during any channel operations, defaults to False channel_log: True/False or a string path to a file of where to write out channel logs -- these are not \"logs\" in the normal logging module sense, but only the output that is read from the channel. In other words, the output of the channel log should look similar to what you would see as a human connecting to a device channel_log_mode: \"write\"|\"append\", all other values will raise ValueError, does what it sounds like it should by setting the channel log to the provided mode logging_uid: unique identifier (string) to associate to log messages; useful if you have multiple connections to the same device (i.e. one console, one ssh, or one to each supervisor module, etc.) failed_when_contains: list of strings indicating command/config failure textfsm_platform: string to use to fetch ntc-templates templates for textfsm parsing genie_platform: string to use to fetch genie parser templates privilege_levels: optional user provided privilege levels, if left None will default to scrapli standard privilege levels default_desired_privilege_level: string of name of default desired priv, this is the priv level that is generally used to disable paging/set terminal width and things like that upon first login, and is also the priv level scrapli will try to acquire for normal \"command\" operations (`send_command`, `send_commands`) auth_secondary: password to use for secondary authentication (enable) failed_when_contains: List of strings that indicate a command/config has failed variant: name of the community platform variant if desired **kwargs: should be unused, but here to accept any additional kwargs from users Returns: final_driver: synchronous driver class for provided driver Raises: ScrapliValueError: if provided transport is asyncio ScrapliTypeError: if `platform` not in keyword arguments \"\"\" logger.debug(\"Scrapli factory initialized\") if transport in ASYNCIO_TRANSPORTS: raise ScrapliValueError(\"Use 'AsyncScrapli' if using an async transport!\") if not isinstance(platform, str): raise ScrapliTypeError(f\"Argument 'platform' must be 'str' got '{type(platform)}'\") provided_kwargs = _build_provided_kwargs_dict( host=host, port=port, auth_username=auth_username, auth_password=auth_password, auth_private_key=auth_private_key, auth_private_key_passphrase=auth_private_key_passphrase, auth_strict_key=auth_strict_key, auth_bypass=auth_bypass, timeout_socket=timeout_socket, timeout_transport=timeout_transport, timeout_ops=timeout_ops, comms_return_char=comms_return_char, ssh_config_file=ssh_config_file, ssh_known_hosts_file=ssh_known_hosts_file, on_init=on_init, on_open=on_open, on_close=on_close, transport=transport, transport_options=transport_options, channel_log=channel_log, channel_log_mode=channel_log_mode, channel_lock=channel_lock, logging_uid=logging_uid, privilege_levels=privilege_levels, default_desired_privilege_level=default_desired_privilege_level, auth_secondary=auth_secondary, failed_when_contains=failed_when_contains, textfsm_platform=textfsm_platform, genie_platform=genie_platform, **kwargs, ) final_driver, additional_kwargs = cls._get_driver(platform=platform, variant=variant) # at this point will need to merge the additional kwargs in (for community drivers), # ensure that kwargs passed by user supersede the ones coming from community platform if additional_kwargs: final_kwargs = {**additional_kwargs, **provided_kwargs} else: final_kwargs = provided_kwargs final_conn = final_driver(**final_kwargs) # cast the final conn to type Scrapli to appease mypy -- we know it will be a NetworkDriver # or GenericDriver, but thats ok =) final_conn = cast(Scrapli, final_conn) return final_conn class AsyncScrapli(AsyncNetworkDriver): CORE_PLATFORM_MAP = { \"arista_eos\": AsyncEOSDriver, \"cisco_iosxe\": AsyncIOSXEDriver, \"cisco_iosxr\": AsyncIOSXRDriver, \"cisco_nxos\": AsyncNXOSDriver, \"juniper_junos\": AsyncJunosDriver, } DRIVER_MAP = {\"network\": AsyncNetworkDriver, \"generic\": AsyncGenericDriver} @classmethod def _get_driver_class( cls, platform_details: Dict[str, Any], variant: Optional[str] ) -> Union[Type[AsyncNetworkDriver], Type[AsyncGenericDriver]]: \"\"\" Fetch community driver class based on platform details Args: platform_details: dict of details about community platform from scrapli_community library variant: optional name of variant of community platform Returns: NetworkDriver: final driver class Raises: N/A \"\"\" final_driver: Union[ Type[AsyncNetworkDriver], Type[AsyncGenericDriver], ] if variant and platform_details[\"variants\"][variant].get(\"driver_type\"): variant_driver_data = platform_details[\"variants\"][variant].pop(\"driver_type\") final_driver = variant_driver_data[\"async\"] return final_driver if isinstance(platform_details[\"driver_type\"], str): driver_type = platform_details[\"driver_type\"] standard_final_driver = cls.DRIVER_MAP.get(driver_type, None) if standard_final_driver: return standard_final_driver final_driver = platform_details[\"driver_type\"][\"async\"] return final_driver @classmethod def _get_community_driver( cls, community_platform_name: str, variant: Optional[str] ) -> Tuple[Union[Type[AsyncNetworkDriver], Type[AsyncGenericDriver]], Dict[str, Any]]: \"\"\" Get community driver Args: community_platform_name: name of community variant: optional name of variant of community platform Returns: NetworkDriver: final driver class Raises: N/A \"\"\" platform_details = _get_community_platform_details( community_platform_name=community_platform_name ) final_driver = cls._get_driver_class(platform_details=platform_details, variant=variant) final_platform_kwargs = _get_driver_kwargs( platform_details=platform_details, variant=variant, _async=True ) return final_driver, final_platform_kwargs @classmethod def _get_driver( cls, platform: str, variant: Optional[str] ) -> Tuple[Union[Type[AsyncNetworkDriver], Type[AsyncGenericDriver]], Dict[str, Any]]: \"\"\" Parent get driver method for sync Scrapli Args: platform: name of target platform; i.e. `cisco_iosxe`, `arista_eos`, etc. variant: name of the target platform variant Returns: NetworkDriver: final driver class; generally NetworkDriver, but for some community platforms could be GenericDriver, also returns any additional kwargs comming from the community platform (if any) Raises: N/A \"\"\" additional_kwargs: Dict[str, Any] = {} final_driver: Union[Type[AsyncGenericDriver], Type[AsyncNetworkDriver]] if platform in cls.CORE_PLATFORM_MAP: final_driver = cls.CORE_PLATFORM_MAP[platform] msg = f\"Driver '{final_driver}' selected from scrapli core drivers\" else: final_driver, additional_kwargs = cls._get_community_driver( community_platform_name=platform, variant=variant ) msg = ( f\"Driver '{final_driver}' selected from scrapli community platforms, with the \" f\"following platform arguments: '{additional_kwargs}'\" ) logger.info(msg) return final_driver, additional_kwargs def __new__( # pylint: disable=R0914 cls, platform: str, host: str, privilege_levels: Optional[Dict[str, PrivilegeLevel]] = None, default_desired_privilege_level: Optional[str] = None, port: Optional[int] = None, auth_username: Optional[str] = None, auth_password: Optional[str] = None, auth_private_key: Optional[str] = None, auth_private_key_passphrase: Optional[str] = None, auth_strict_key: Optional[bool] = None, auth_bypass: Optional[bool] = None, timeout_socket: Optional[float] = None, timeout_transport: Optional[float] = None, timeout_ops: Optional[float] = None, comms_return_char: Optional[str] = None, ssh_config_file: Optional[Union[str, bool]] = None, ssh_known_hosts_file: Optional[Union[str, bool]] = None, on_init: Optional[Callable[..., Any]] = None, on_open: Optional[Callable[..., Any]] = None, on_close: Optional[Callable[..., Any]] = None, transport: Optional[str] = None, transport_options: Optional[Dict[str, Any]] = None, channel_log: Optional[Union[str, bool, BytesIO]] = None, channel_log_mode: Optional[str] = None, channel_lock: Optional[bool] = None, logging_uid: Optional[str] = None, auth_secondary: Optional[str] = None, failed_when_contains: Optional[List[str]] = None, textfsm_platform: Optional[str] = None, genie_platform: Optional[str] = None, variant: Optional[str] = None, **kwargs: Dict[Any, Any], ) -> \"AsyncScrapli\": r\"\"\" Scrapli Factory method for asynchronous drivers Args: platform: name of the scrapli platform to return a connection object for; should be one of the \"core\" platforms or a valid community platform name host: host ip/name to connect to port: port to connect to auth_username: username for authentication auth_private_key: path to private key for authentication auth_private_key_passphrase: passphrase for decrypting ssh key if necessary auth_password: password for authentication auth_strict_key: strict host checking or not auth_bypass: bypass \"in channel\" authentication -- only supported with telnet, asynctelnet, and system transport plugins timeout_socket: timeout for establishing socket/initial connection in seconds timeout_transport: timeout for ssh|telnet transport in seconds timeout_ops: timeout for ssh channel operations comms_return_char: character to use to send returns to host ssh_config_file: string to path for ssh config file, True to use default ssh config file or False to ignore default ssh config file ssh_known_hosts_file: string to path for ssh known hosts file, True to use default known file locations. Only applicable/needed if `auth_strict_key` is set to True on_init: callable that accepts the class instance as its only argument. this callable, if provided, is executed as the last step of object instantiation -- its purpose is primarily to provide a mechanism for scrapli community platforms to have an easy way to modify initialization arguments/object attributes without needing to create a class that extends the driver, instead allowing the community platforms to simply build from the GenericDriver or NetworkDriver classes, and pass this callable to do things such as appending to a username (looking at you RouterOS!!). Note that this is *always* a synchronous function (even for asyncio drivers)! on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar transport: name of the transport plugin to use for the actual telnet/ssh/netconf connection. Available \"core\" transports are: - system - telnet - asynctelnet - ssh2 - paramiko - asyncssh Please see relevant transport plugin section for details. Additionally third party transport plugins may be available. transport_options: dictionary of options to pass to selected transport class; see docs for given transport class for details of what to pass here channel_lock: True/False to lock the channel (threading.Lock/asyncio.Lock) during any channel operations, defaults to False channel_log: True/False or a string path to a file of where to write out channel logs -- these are not \"logs\" in the normal logging module sense, but only the output that is read from the channel. In other words, the output of the channel log should look similar to what you would see as a human connecting to a device channel_log_mode: \"write\"|\"append\", all other values will raise ValueError, does what it sounds like it should by setting the channel log to the provided mode logging_uid: unique identifier (string) to associate to log messages; useful if you have multiple connections to the same device (i.e. one console, one ssh, or one to each supervisor module, etc.) failed_when_contains: list of strings indicating command/config failure textfsm_platform: string to use to fetch ntc-templates templates for textfsm parsing genie_platform: string to use to fetch genie parser templates privilege_levels: optional user provided privilege levels, if left None will default to scrapli standard privilege levels default_desired_privilege_level: string of name of default desired priv, this is the priv level that is generally used to disable paging/set terminal width and things like that upon first login, and is also the priv level scrapli will try to acquire for normal \"command\" operations (`send_command`, `send_commands`) auth_secondary: password to use for secondary authentication (enable) failed_when_contains: List of strings that indicate a command/config has failed variant: name of the community platform variant if desired **kwargs: should be unused, but here to accept any additional kwargs from users Returns: final_driver: asynchronous driver class for provided driver Raises: ScrapliValueError: if provided transport is asyncio ScrapliTypeError: if `platform` not in keyword arguments \"\"\" logger.debug(\"AsyncScrapli factory initialized\") if transport not in ASYNCIO_TRANSPORTS: raise ScrapliValueError(\"Use 'Scrapli' if using a synchronous transport!\") if not isinstance(platform, str): raise ScrapliTypeError(f\"Argument 'platform' must be 'str' got '{type(platform)}'\") provided_kwargs = _build_provided_kwargs_dict( host=host, port=port, auth_username=auth_username, auth_password=auth_password, auth_private_key=auth_private_key, auth_private_key_passphrase=auth_private_key_passphrase, auth_strict_key=auth_strict_key, auth_bypass=auth_bypass, timeout_socket=timeout_socket, timeout_transport=timeout_transport, timeout_ops=timeout_ops, comms_return_char=comms_return_char, ssh_config_file=ssh_config_file, ssh_known_hosts_file=ssh_known_hosts_file, on_init=on_init, on_open=on_open, on_close=on_close, transport=transport, transport_options=transport_options, channel_log=channel_log, channel_log_mode=channel_log_mode, channel_lock=channel_lock, logging_uid=logging_uid, privilege_levels=privilege_levels, default_desired_privilege_level=default_desired_privilege_level, auth_secondary=auth_secondary, failed_when_contains=failed_when_contains, textfsm_platform=textfsm_platform, genie_platform=genie_platform, **kwargs, ) final_driver, additional_kwargs = cls._get_driver(platform=platform, variant=variant) # at this point will need to merge the additional kwargs in (for community drivers), # ensure that kwargs passed by user supersede the ones coming from community platform if additional_kwargs: final_kwargs = {**additional_kwargs, **provided_kwargs} else: final_kwargs = provided_kwargs final_conn = final_driver(**final_kwargs) # cast the final conn to type Scrapli to appease mypy -- we know it will be a NetworkDriver # or GenericDriver, but thats ok =) final_conn = cast(AsyncScrapli, final_conn) return final_conn","title":"Module scrapli.factory"},{"location":"api_docs/factory/#classes","text":"","title":"Classes"},{"location":"api_docs/factory/#asyncscrapli","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 BaseDriver Object BaseDriver is the root for all Scrapli driver classes. The synchronous and asyncio driver base driver classes can be used to provide a semi-pexpect like experience over top of whatever transport a user prefers. Generally, however, the base driver classes should not be used directly. It is best to use the GenericDriver (or AsyncGenericDriver) or NetworkDriver (or AsyncNetworkDriver) sub-classes of the base drivers. Args: host: host ip/name to connect to port: port to connect to auth_username: username for authentication auth_private_key: path to private key for authentication auth_private_key_passphrase: passphrase for decrypting ssh key if necessary auth_password: password for authentication auth_strict_key: strict host checking or not auth_bypass: bypass \"in channel\" authentication -- only supported with telnet, asynctelnet, and system transport plugins timeout_socket: timeout for establishing socket/initial connection in seconds timeout_transport: timeout for ssh|telnet transport in seconds timeout_ops: timeout for ssh channel operations comms_prompt_pattern: raw string regex pattern -- preferably use `^` and `$` anchors! this is the single most important attribute here! if this does not match a prompt, scrapli will not work! IMPORTANT: regex search uses multi-line + case insensitive flags. multi-line allows for highly reliably matching for prompts however we do NOT strip trailing whitespace for each line, so be sure to add '\\\\s?' or similar if your device needs that. This should be mostly sorted for you if using network drivers (i.e. `IOSXEDriver`). Lastly, the case insensitive is just a convenience factor so i can be lazy. comms_return_char: character to use to send returns to host ssh_config_file: string to path for ssh config file, True to use default ssh config file or False to ignore default ssh config file ssh_known_hosts_file: string to path for ssh known hosts file, True to use default known file locations. Only applicable/needed if `auth_strict_key` is set to True on_init: callable that accepts the class instance as its only argument. this callable, if provided, is executed as the last step of object instantiation -- its purpose is primarily to provide a mechanism for scrapli community platforms to have an easy way to modify initialization arguments/object attributes without needing to create a class that extends the driver, instead allowing the community platforms to simply build from the GenericDriver or NetworkDriver classes, and pass this callable to do things such as appending to a username (looking at you RouterOS!!). Note that this is *always* a synchronous function (even for asyncio drivers)! on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar transport: name of the transport plugin to use for the actual telnet/ssh/netconf connection. Available \"core\" transports are: - system - telnet - asynctelnet - ssh2 - paramiko - asyncssh Please see relevant transport plugin section for details. Additionally third party transport plugins may be available. transport_options: dictionary of options to pass to selected transport class; see docs for given transport class for details of what to pass here channel_lock: True/False to lock the channel (threading.Lock/asyncio.Lock) during any channel operations, defaults to False channel_log: True/False or a string path to a file of where to write out channel logs -- these are not \"logs\" in the normal logging module sense, but only the output that is read from the channel. In other words, the output of the channel log should look similar to what you would see as a human connecting to a device channel_log_mode: \"write\"|\"append\", all other values will raise ValueError, does what it sounds like it should by setting the channel log to the provided mode logging_uid: unique identifier (string) to associate to log messages; useful if you have multiple connections to the same device (i.e. one console, one ssh, or one to each supervisor module, etc.) Returns: None Raises: N/A Expand source code class AsyncScrapli(AsyncNetworkDriver): CORE_PLATFORM_MAP = { \"arista_eos\": AsyncEOSDriver, \"cisco_iosxe\": AsyncIOSXEDriver, \"cisco_iosxr\": AsyncIOSXRDriver, \"cisco_nxos\": AsyncNXOSDriver, \"juniper_junos\": AsyncJunosDriver, } DRIVER_MAP = {\"network\": AsyncNetworkDriver, \"generic\": AsyncGenericDriver} @classmethod def _get_driver_class( cls, platform_details: Dict[str, Any], variant: Optional[str] ) -> Union[Type[AsyncNetworkDriver], Type[AsyncGenericDriver]]: \"\"\" Fetch community driver class based on platform details Args: platform_details: dict of details about community platform from scrapli_community library variant: optional name of variant of community platform Returns: NetworkDriver: final driver class Raises: N/A \"\"\" final_driver: Union[ Type[AsyncNetworkDriver], Type[AsyncGenericDriver], ] if variant and platform_details[\"variants\"][variant].get(\"driver_type\"): variant_driver_data = platform_details[\"variants\"][variant].pop(\"driver_type\") final_driver = variant_driver_data[\"async\"] return final_driver if isinstance(platform_details[\"driver_type\"], str): driver_type = platform_details[\"driver_type\"] standard_final_driver = cls.DRIVER_MAP.get(driver_type, None) if standard_final_driver: return standard_final_driver final_driver = platform_details[\"driver_type\"][\"async\"] return final_driver @classmethod def _get_community_driver( cls, community_platform_name: str, variant: Optional[str] ) -> Tuple[Union[Type[AsyncNetworkDriver], Type[AsyncGenericDriver]], Dict[str, Any]]: \"\"\" Get community driver Args: community_platform_name: name of community variant: optional name of variant of community platform Returns: NetworkDriver: final driver class Raises: N/A \"\"\" platform_details = _get_community_platform_details( community_platform_name=community_platform_name ) final_driver = cls._get_driver_class(platform_details=platform_details, variant=variant) final_platform_kwargs = _get_driver_kwargs( platform_details=platform_details, variant=variant, _async=True ) return final_driver, final_platform_kwargs @classmethod def _get_driver( cls, platform: str, variant: Optional[str] ) -> Tuple[Union[Type[AsyncNetworkDriver], Type[AsyncGenericDriver]], Dict[str, Any]]: \"\"\" Parent get driver method for sync Scrapli Args: platform: name of target platform; i.e. `cisco_iosxe`, `arista_eos`, etc. variant: name of the target platform variant Returns: NetworkDriver: final driver class; generally NetworkDriver, but for some community platforms could be GenericDriver, also returns any additional kwargs comming from the community platform (if any) Raises: N/A \"\"\" additional_kwargs: Dict[str, Any] = {} final_driver: Union[Type[AsyncGenericDriver], Type[AsyncNetworkDriver]] if platform in cls.CORE_PLATFORM_MAP: final_driver = cls.CORE_PLATFORM_MAP[platform] msg = f\"Driver '{final_driver}' selected from scrapli core drivers\" else: final_driver, additional_kwargs = cls._get_community_driver( community_platform_name=platform, variant=variant ) msg = ( f\"Driver '{final_driver}' selected from scrapli community platforms, with the \" f\"following platform arguments: '{additional_kwargs}'\" ) logger.info(msg) return final_driver, additional_kwargs def __new__( # pylint: disable=R0914 cls, platform: str, host: str, privilege_levels: Optional[Dict[str, PrivilegeLevel]] = None, default_desired_privilege_level: Optional[str] = None, port: Optional[int] = None, auth_username: Optional[str] = None, auth_password: Optional[str] = None, auth_private_key: Optional[str] = None, auth_private_key_passphrase: Optional[str] = None, auth_strict_key: Optional[bool] = None, auth_bypass: Optional[bool] = None, timeout_socket: Optional[float] = None, timeout_transport: Optional[float] = None, timeout_ops: Optional[float] = None, comms_return_char: Optional[str] = None, ssh_config_file: Optional[Union[str, bool]] = None, ssh_known_hosts_file: Optional[Union[str, bool]] = None, on_init: Optional[Callable[..., Any]] = None, on_open: Optional[Callable[..., Any]] = None, on_close: Optional[Callable[..., Any]] = None, transport: Optional[str] = None, transport_options: Optional[Dict[str, Any]] = None, channel_log: Optional[Union[str, bool, BytesIO]] = None, channel_log_mode: Optional[str] = None, channel_lock: Optional[bool] = None, logging_uid: Optional[str] = None, auth_secondary: Optional[str] = None, failed_when_contains: Optional[List[str]] = None, textfsm_platform: Optional[str] = None, genie_platform: Optional[str] = None, variant: Optional[str] = None, **kwargs: Dict[Any, Any], ) -> \"AsyncScrapli\": r\"\"\" Scrapli Factory method for asynchronous drivers Args: platform: name of the scrapli platform to return a connection object for; should be one of the \"core\" platforms or a valid community platform name host: host ip/name to connect to port: port to connect to auth_username: username for authentication auth_private_key: path to private key for authentication auth_private_key_passphrase: passphrase for decrypting ssh key if necessary auth_password: password for authentication auth_strict_key: strict host checking or not auth_bypass: bypass \"in channel\" authentication -- only supported with telnet, asynctelnet, and system transport plugins timeout_socket: timeout for establishing socket/initial connection in seconds timeout_transport: timeout for ssh|telnet transport in seconds timeout_ops: timeout for ssh channel operations comms_return_char: character to use to send returns to host ssh_config_file: string to path for ssh config file, True to use default ssh config file or False to ignore default ssh config file ssh_known_hosts_file: string to path for ssh known hosts file, True to use default known file locations. Only applicable/needed if `auth_strict_key` is set to True on_init: callable that accepts the class instance as its only argument. this callable, if provided, is executed as the last step of object instantiation -- its purpose is primarily to provide a mechanism for scrapli community platforms to have an easy way to modify initialization arguments/object attributes without needing to create a class that extends the driver, instead allowing the community platforms to simply build from the GenericDriver or NetworkDriver classes, and pass this callable to do things such as appending to a username (looking at you RouterOS!!). Note that this is *always* a synchronous function (even for asyncio drivers)! on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar transport: name of the transport plugin to use for the actual telnet/ssh/netconf connection. Available \"core\" transports are: - system - telnet - asynctelnet - ssh2 - paramiko - asyncssh Please see relevant transport plugin section for details. Additionally third party transport plugins may be available. transport_options: dictionary of options to pass to selected transport class; see docs for given transport class for details of what to pass here channel_lock: True/False to lock the channel (threading.Lock/asyncio.Lock) during any channel operations, defaults to False channel_log: True/False or a string path to a file of where to write out channel logs -- these are not \"logs\" in the normal logging module sense, but only the output that is read from the channel. In other words, the output of the channel log should look similar to what you would see as a human connecting to a device channel_log_mode: \"write\"|\"append\", all other values will raise ValueError, does what it sounds like it should by setting the channel log to the provided mode logging_uid: unique identifier (string) to associate to log messages; useful if you have multiple connections to the same device (i.e. one console, one ssh, or one to each supervisor module, etc.) failed_when_contains: list of strings indicating command/config failure textfsm_platform: string to use to fetch ntc-templates templates for textfsm parsing genie_platform: string to use to fetch genie parser templates privilege_levels: optional user provided privilege levels, if left None will default to scrapli standard privilege levels default_desired_privilege_level: string of name of default desired priv, this is the priv level that is generally used to disable paging/set terminal width and things like that upon first login, and is also the priv level scrapli will try to acquire for normal \"command\" operations (`send_command`, `send_commands`) auth_secondary: password to use for secondary authentication (enable) failed_when_contains: List of strings that indicate a command/config has failed variant: name of the community platform variant if desired **kwargs: should be unused, but here to accept any additional kwargs from users Returns: final_driver: asynchronous driver class for provided driver Raises: ScrapliValueError: if provided transport is asyncio ScrapliTypeError: if `platform` not in keyword arguments \"\"\" logger.debug(\"AsyncScrapli factory initialized\") if transport not in ASYNCIO_TRANSPORTS: raise ScrapliValueError(\"Use 'Scrapli' if using a synchronous transport!\") if not isinstance(platform, str): raise ScrapliTypeError(f\"Argument 'platform' must be 'str' got '{type(platform)}'\") provided_kwargs = _build_provided_kwargs_dict( host=host, port=port, auth_username=auth_username, auth_password=auth_password, auth_private_key=auth_private_key, auth_private_key_passphrase=auth_private_key_passphrase, auth_strict_key=auth_strict_key, auth_bypass=auth_bypass, timeout_socket=timeout_socket, timeout_transport=timeout_transport, timeout_ops=timeout_ops, comms_return_char=comms_return_char, ssh_config_file=ssh_config_file, ssh_known_hosts_file=ssh_known_hosts_file, on_init=on_init, on_open=on_open, on_close=on_close, transport=transport, transport_options=transport_options, channel_log=channel_log, channel_log_mode=channel_log_mode, channel_lock=channel_lock, logging_uid=logging_uid, privilege_levels=privilege_levels, default_desired_privilege_level=default_desired_privilege_level, auth_secondary=auth_secondary, failed_when_contains=failed_when_contains, textfsm_platform=textfsm_platform, genie_platform=genie_platform, **kwargs, ) final_driver, additional_kwargs = cls._get_driver(platform=platform, variant=variant) # at this point will need to merge the additional kwargs in (for community drivers), # ensure that kwargs passed by user supersede the ones coming from community platform if additional_kwargs: final_kwargs = {**additional_kwargs, **provided_kwargs} else: final_kwargs = provided_kwargs final_conn = final_driver(**final_kwargs) # cast the final conn to type Scrapli to appease mypy -- we know it will be a NetworkDriver # or GenericDriver, but thats ok =) final_conn = cast(AsyncScrapli, final_conn) return final_conn","title":"AsyncScrapli"},{"location":"api_docs/factory/#ancestors-in-mro","text":"scrapli.driver.network.async_driver.AsyncNetworkDriver scrapli.driver.generic.async_driver.AsyncGenericDriver scrapli.driver.base.async_driver.AsyncDriver scrapli.driver.base.base_driver.BaseDriver scrapli.driver.generic.base_driver.BaseGenericDriver scrapli.driver.network.base_driver.BaseNetworkDriver","title":"Ancestors (in MRO)"},{"location":"api_docs/factory/#class-variables","text":"CORE_PLATFORM_MAP DRIVER_MAP","title":"Class variables"},{"location":"api_docs/factory/#scrapli","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 BaseDriver Object BaseDriver is the root for all Scrapli driver classes. The synchronous and asyncio driver base driver classes can be used to provide a semi-pexpect like experience over top of whatever transport a user prefers. Generally, however, the base driver classes should not be used directly. It is best to use the GenericDriver (or AsyncGenericDriver) or NetworkDriver (or AsyncNetworkDriver) sub-classes of the base drivers. Args: host: host ip/name to connect to port: port to connect to auth_username: username for authentication auth_private_key: path to private key for authentication auth_private_key_passphrase: passphrase for decrypting ssh key if necessary auth_password: password for authentication auth_strict_key: strict host checking or not auth_bypass: bypass \"in channel\" authentication -- only supported with telnet, asynctelnet, and system transport plugins timeout_socket: timeout for establishing socket/initial connection in seconds timeout_transport: timeout for ssh|telnet transport in seconds timeout_ops: timeout for ssh channel operations comms_prompt_pattern: raw string regex pattern -- preferably use `^` and `$` anchors! this is the single most important attribute here! if this does not match a prompt, scrapli will not work! IMPORTANT: regex search uses multi-line + case insensitive flags. multi-line allows for highly reliably matching for prompts however we do NOT strip trailing whitespace for each line, so be sure to add '\\\\s?' or similar if your device needs that. This should be mostly sorted for you if using network drivers (i.e. `IOSXEDriver`). Lastly, the case insensitive is just a convenience factor so i can be lazy. comms_return_char: character to use to send returns to host ssh_config_file: string to path for ssh config file, True to use default ssh config file or False to ignore default ssh config file ssh_known_hosts_file: string to path for ssh known hosts file, True to use default known file locations. Only applicable/needed if `auth_strict_key` is set to True on_init: callable that accepts the class instance as its only argument. this callable, if provided, is executed as the last step of object instantiation -- its purpose is primarily to provide a mechanism for scrapli community platforms to have an easy way to modify initialization arguments/object attributes without needing to create a class that extends the driver, instead allowing the community platforms to simply build from the GenericDriver or NetworkDriver classes, and pass this callable to do things such as appending to a username (looking at you RouterOS!!). Note that this is *always* a synchronous function (even for asyncio drivers)! on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar transport: name of the transport plugin to use for the actual telnet/ssh/netconf connection. Available \"core\" transports are: - system - telnet - asynctelnet - ssh2 - paramiko - asyncssh Please see relevant transport plugin section for details. Additionally third party transport plugins may be available. transport_options: dictionary of options to pass to selected transport class; see docs for given transport class for details of what to pass here channel_lock: True/False to lock the channel (threading.Lock/asyncio.Lock) during any channel operations, defaults to False channel_log: True/False or a string path to a file of where to write out channel logs -- these are not \"logs\" in the normal logging module sense, but only the output that is read from the channel. In other words, the output of the channel log should look similar to what you would see as a human connecting to a device channel_log_mode: \"write\"|\"append\", all other values will raise ValueError, does what it sounds like it should by setting the channel log to the provided mode logging_uid: unique identifier (string) to associate to log messages; useful if you have multiple connections to the same device (i.e. one console, one ssh, or one to each supervisor module, etc.) Returns: None Raises: N/A Expand source code class Scrapli(NetworkDriver): CORE_PLATFORM_MAP = { \"arista_eos\": EOSDriver, \"cisco_iosxe\": IOSXEDriver, \"cisco_iosxr\": IOSXRDriver, \"cisco_nxos\": NXOSDriver, \"juniper_junos\": JunosDriver, } DRIVER_MAP = {\"network\": NetworkDriver, \"generic\": GenericDriver} @classmethod def _get_driver_class( cls, platform_details: Dict[str, Any], variant: Optional[str] ) -> Union[Type[NetworkDriver], Type[GenericDriver]]: \"\"\" Fetch community driver class based on platform details Args: platform_details: dict of details about community platform from scrapli_community library variant: optional name of variant of community platform Returns: NetworkDriver: final driver class Raises: N/A \"\"\" final_driver: Union[ Type[NetworkDriver], Type[GenericDriver], ] if variant and platform_details[\"variants\"][variant].get(\"driver_type\"): variant_driver_data = platform_details[\"variants\"][variant].pop(\"driver_type\") final_driver = variant_driver_data[\"sync\"] return final_driver if isinstance(platform_details[\"driver_type\"], str): driver_type = platform_details[\"driver_type\"] standard_final_driver = cls.DRIVER_MAP.get(driver_type, None) if standard_final_driver: return standard_final_driver final_driver = platform_details[\"driver_type\"][\"sync\"] return final_driver @classmethod def _get_community_driver( cls, community_platform_name: str, variant: Optional[str] ) -> Tuple[Union[Type[NetworkDriver], Type[GenericDriver]], Dict[str, Any]]: \"\"\" Get community driver Args: community_platform_name: name of community variant: optional name of variant of community platform Returns: NetworkDriver: final driver class Raises: N/A \"\"\" platform_details = _get_community_platform_details( community_platform_name=community_platform_name ) final_driver = cls._get_driver_class(platform_details=platform_details, variant=variant) final_platform_kwargs = _get_driver_kwargs( platform_details=platform_details, variant=variant, _async=False ) return final_driver, final_platform_kwargs @classmethod def _get_driver( cls, platform: str, variant: Optional[str] ) -> Tuple[Union[Type[NetworkDriver], Type[GenericDriver]], Dict[str, Any]]: \"\"\" Parent get driver method for sync Scrapli Args: platform: name of target platform; i.e. `cisco_iosxe`, `arista_eos`, etc. variant: name of the target platform variant Returns: NetworkDriver: final driver class; generally NetworkDriver, but for some community platforms could be GenericDriver, also returns any additional kwargs comming from the community platform (if any) Raises: N/A \"\"\" additional_kwargs: Dict[str, Any] = {} final_driver: Union[Type[GenericDriver], Type[NetworkDriver]] if platform in cls.CORE_PLATFORM_MAP: final_driver = cls.CORE_PLATFORM_MAP[platform] msg = f\"Driver '{final_driver}' selected from scrapli core drivers\" else: final_driver, additional_kwargs = cls._get_community_driver( community_platform_name=platform, variant=variant ) msg = ( f\"Driver '{final_driver}' selected from scrapli community platforms, with the \" f\"following platform arguments: '{additional_kwargs}'\" ) logger.info(msg) return final_driver, additional_kwargs def __new__( # pylint: disable=R0914 cls, platform: str, host: str, privilege_levels: Optional[Dict[str, PrivilegeLevel]] = None, default_desired_privilege_level: Optional[str] = None, port: Optional[int] = None, auth_username: Optional[str] = None, auth_password: Optional[str] = None, auth_private_key: Optional[str] = None, auth_private_key_passphrase: Optional[str] = None, auth_strict_key: Optional[bool] = None, auth_bypass: Optional[bool] = None, timeout_socket: Optional[float] = None, timeout_transport: Optional[float] = None, timeout_ops: Optional[float] = None, comms_return_char: Optional[str] = None, ssh_config_file: Optional[Union[str, bool]] = None, ssh_known_hosts_file: Optional[Union[str, bool]] = None, on_init: Optional[Callable[..., Any]] = None, on_open: Optional[Callable[..., Any]] = None, on_close: Optional[Callable[..., Any]] = None, transport: Optional[str] = None, transport_options: Optional[Dict[str, Any]] = None, channel_log: Optional[Union[str, bool, BytesIO]] = None, channel_lock: Optional[bool] = None, channel_log_mode: Optional[str] = None, logging_uid: Optional[str] = None, auth_secondary: Optional[str] = None, failed_when_contains: Optional[List[str]] = None, textfsm_platform: Optional[str] = None, genie_platform: Optional[str] = None, variant: Optional[str] = None, **kwargs: Dict[Any, Any], ) -> \"Scrapli\": r\"\"\" Scrapli Factory method for synchronous drivers Args: platform: name of the scrapli platform to return a connection object for; should be one of the \"core\" platforms or a valid community platform name host: host ip/name to connect to port: port to connect to auth_username: username for authentication auth_private_key: path to private key for authentication auth_private_key_passphrase: passphrase for decrypting ssh key if necessary auth_password: password for authentication auth_strict_key: strict host checking or not auth_bypass: bypass \"in channel\" authentication -- only supported with telnet, asynctelnet, and system transport plugins timeout_socket: timeout for establishing socket/initial connection in seconds timeout_transport: timeout for ssh|telnet transport in seconds timeout_ops: timeout for ssh channel operations comms_return_char: character to use to send returns to host ssh_config_file: string to path for ssh config file, True to use default ssh config file or False to ignore default ssh config file ssh_known_hosts_file: string to path for ssh known hosts file, True to use default known file locations. Only applicable/needed if `auth_strict_key` is set to True on_init: callable that accepts the class instance as its only argument. this callable, if provided, is executed as the last step of object instantiation -- its purpose is primarily to provide a mechanism for scrapli community platforms to have an easy way to modify initialization arguments/object attributes without needing to create a class that extends the driver, instead allowing the community platforms to simply build from the GenericDriver or NetworkDriver classes, and pass this callable to do things such as appending to a username (looking at you RouterOS!!). Note that this is *always* a synchronous function (even for asyncio drivers)! on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar transport: name of the transport plugin to use for the actual telnet/ssh/netconf connection. Available \"core\" transports are: - system - telnet - asynctelnet - ssh2 - paramiko - asyncssh Please see relevant transport plugin section for details. Additionally third party transport plugins may be available. transport_options: dictionary of options to pass to selected transport class; see docs for given transport class for details of what to pass here channel_lock: True/False to lock the channel (threading.Lock/asyncio.Lock) during any channel operations, defaults to False channel_log: True/False or a string path to a file of where to write out channel logs -- these are not \"logs\" in the normal logging module sense, but only the output that is read from the channel. In other words, the output of the channel log should look similar to what you would see as a human connecting to a device channel_log_mode: \"write\"|\"append\", all other values will raise ValueError, does what it sounds like it should by setting the channel log to the provided mode logging_uid: unique identifier (string) to associate to log messages; useful if you have multiple connections to the same device (i.e. one console, one ssh, or one to each supervisor module, etc.) failed_when_contains: list of strings indicating command/config failure textfsm_platform: string to use to fetch ntc-templates templates for textfsm parsing genie_platform: string to use to fetch genie parser templates privilege_levels: optional user provided privilege levels, if left None will default to scrapli standard privilege levels default_desired_privilege_level: string of name of default desired priv, this is the priv level that is generally used to disable paging/set terminal width and things like that upon first login, and is also the priv level scrapli will try to acquire for normal \"command\" operations (`send_command`, `send_commands`) auth_secondary: password to use for secondary authentication (enable) failed_when_contains: List of strings that indicate a command/config has failed variant: name of the community platform variant if desired **kwargs: should be unused, but here to accept any additional kwargs from users Returns: final_driver: synchronous driver class for provided driver Raises: ScrapliValueError: if provided transport is asyncio ScrapliTypeError: if `platform` not in keyword arguments \"\"\" logger.debug(\"Scrapli factory initialized\") if transport in ASYNCIO_TRANSPORTS: raise ScrapliValueError(\"Use 'AsyncScrapli' if using an async transport!\") if not isinstance(platform, str): raise ScrapliTypeError(f\"Argument 'platform' must be 'str' got '{type(platform)}'\") provided_kwargs = _build_provided_kwargs_dict( host=host, port=port, auth_username=auth_username, auth_password=auth_password, auth_private_key=auth_private_key, auth_private_key_passphrase=auth_private_key_passphrase, auth_strict_key=auth_strict_key, auth_bypass=auth_bypass, timeout_socket=timeout_socket, timeout_transport=timeout_transport, timeout_ops=timeout_ops, comms_return_char=comms_return_char, ssh_config_file=ssh_config_file, ssh_known_hosts_file=ssh_known_hosts_file, on_init=on_init, on_open=on_open, on_close=on_close, transport=transport, transport_options=transport_options, channel_log=channel_log, channel_log_mode=channel_log_mode, channel_lock=channel_lock, logging_uid=logging_uid, privilege_levels=privilege_levels, default_desired_privilege_level=default_desired_privilege_level, auth_secondary=auth_secondary, failed_when_contains=failed_when_contains, textfsm_platform=textfsm_platform, genie_platform=genie_platform, **kwargs, ) final_driver, additional_kwargs = cls._get_driver(platform=platform, variant=variant) # at this point will need to merge the additional kwargs in (for community drivers), # ensure that kwargs passed by user supersede the ones coming from community platform if additional_kwargs: final_kwargs = {**additional_kwargs, **provided_kwargs} else: final_kwargs = provided_kwargs final_conn = final_driver(**final_kwargs) # cast the final conn to type Scrapli to appease mypy -- we know it will be a NetworkDriver # or GenericDriver, but thats ok =) final_conn = cast(Scrapli, final_conn) return final_conn","title":"Scrapli"},{"location":"api_docs/factory/#ancestors-in-mro_1","text":"scrapli.driver.network.sync_driver.NetworkDriver scrapli.driver.generic.sync_driver.GenericDriver scrapli.driver.base.sync_driver.Driver scrapli.driver.base.base_driver.BaseDriver scrapli.driver.generic.base_driver.BaseGenericDriver scrapli.driver.network.base_driver.BaseNetworkDriver","title":"Ancestors (in MRO)"},{"location":"api_docs/factory/#class-variables_1","text":"CORE_PLATFORM_MAP DRIVER_MAP","title":"Class variables"},{"location":"api_docs/helper/","text":"window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting()) Module scrapli.helper \u00b6 scrapli.helper Expand source code \"\"\"scrapli.helper\"\"\" import importlib import urllib.request from io import BytesIO, TextIOWrapper from pathlib import Path from shutil import get_terminal_size from typing import Any, Dict, List, Optional, TextIO, Union from warnings import warn import pkg_resources # pylint: disable=C0411 from scrapli.exceptions import ScrapliValueError from scrapli.logging import logger from scrapli.settings import Settings def _textfsm_get_template(platform: str, command: str) -> Optional[TextIO]: \"\"\" Find correct TextFSM template based on platform and command executed Args: platform: ntc-templates device type; i.e. cisco_ios, arista_eos, etc. command: string of command that was executed (to find appropriate template) Returns: None or TextIO of opened template Raises: N/A \"\"\" try: importlib.import_module(name=\".templates\", package=\"ntc_templates\") CliTable = getattr(importlib.import_module(name=\".clitable\", package=\"textfsm\"), \"CliTable\") except ModuleNotFoundError as exc: title = \"Optional Extra Not Installed!\" message = ( \"Optional extra 'textfsm' is not installed!\\n\" f\"To resolve this issue, install '{exc.name}'. You can do this in one of the following\" \" ways:\\n\" \"1: 'pip install -r requirements-textfsm.txt'\\n\" \"2: 'pip install scrapli[textfsm]'\" ) user_warning(title=title, message=message) return None template_dir = pkg_resources.resource_filename(\"ntc_templates\", \"templates\") cli_table = CliTable(\"index\", template_dir) template_index = cli_table.index.GetRowMatch({\"Platform\": platform, \"Command\": command}) if not template_index: logger.warning( f\"No match in ntc_templates index for platform `{platform}` and command `{command}`\" ) return None template_name = cli_table.index.index[template_index][\"Template\"] return open(f\"{template_dir}/{template_name}\", encoding=\"utf-8\") def _textfsm_to_dict( structured_output: Union[List[Any], Dict[str, Any]], header: List[str] ) -> Union[List[Any], Dict[str, Any]]: \"\"\" Create list of dicts from textfsm output and header Args: structured_output: parsed textfsm output header: list of strings representing column headers for textfsm output Returns: output: structured data Raises: N/A \"\"\" logger.debug(\"converting textfsm output to dictionary representation\") header_lower = [h.lower() for h in header] structured_output = [dict(zip(header_lower, row)) for row in structured_output] return structured_output def textfsm_parse( template: Union[str, TextIOWrapper], output: str, to_dict: bool = True ) -> Union[List[Any], Dict[str, Any]]: \"\"\" Parse output with TextFSM and ntc-templates, try to return structured output Args: template: TextIOWrapper or string of URL or filesystem path to template to use to parse data output: unstructured output from device to parse to_dict: convert textfsm output from list of lists to list of dicts -- basically create dict from header and row data so it is easier to read/parse the output Returns: output: structured data Raises: N/A \"\"\" import textfsm # pylint: disable=C0415 if not isinstance(template, TextIOWrapper): if template.startswith(\"http://\") or template.startswith(\"https://\"): with urllib.request.urlopen(template) as response: template_file = TextIOWrapper( BytesIO(response.read()), encoding=response.headers.get_content_charset(), ) else: template_file = TextIOWrapper(open(template, mode=\"rb\")) # pylint: disable=R1732 else: template_file = template re_table = textfsm.TextFSM(template_file) try: structured_output: Union[List[Any], Dict[str, Any]] = re_table.ParseText(output) if to_dict: structured_output = _textfsm_to_dict( structured_output=structured_output, header=re_table.header ) return structured_output except textfsm.parser.TextFSMError: logger.warning(\"failed to parse data with textfsm\") return [] def genie_parse(platform: str, command: str, output: str) -> Union[List[Any], Dict[str, Any]]: \"\"\" Parse output with Cisco genie parsers, try to return structured output Args: platform: genie device type; i.e. iosxe, iosxr, etc. command: string of command that was executed (to find appropriate parser) output: unstructured output from device to parse Returns: output: structured data Raises: N/A \"\"\" try: Device = getattr(importlib.import_module(name=\".conf.base\", package=\"genie\"), \"Device\") get_parser = getattr( importlib.import_module(name=\".libs.parser.utils\", package=\"genie\"), \"get_parser\" ) except ModuleNotFoundError as exc: title = \"Optional Extra Not Installed!\" message = ( \"Optional extra 'genie' is not installed!\\n\" f\"To resolve this issue, install '{exc.name}'. You can do this in one of the following\" \" ways:\\n\" \"1: 'pip install -r requirements-genie.txt'\\n\" \"2: 'pip install scrapli[genie]'\" ) user_warning(title=title, message=message) return [] genie_device = Device(\"scrapli_device\", custom={\"abstraction\": {\"order\": [\"os\"]}}, os=platform) try: get_parser(command, genie_device) genie_parsed_result = genie_device.parse(command, output=output) if isinstance(genie_parsed_result, (list, dict)): return genie_parsed_result except Exception as exc: # pylint: disable=W0703 logger.warning(f\"failed to parse data with genie, genie raised exception: `{exc}`\") return [] def ttp_parse(template: Union[str, TextIOWrapper], output: str) -> Union[List[Any], Dict[str, Any]]: \"\"\" Parse output with TTP, try to return structured output Args: template: TextIOWrapper or string path to template to use to parse data output: unstructured output from device to parse Returns: output: structured data Raises: N/A \"\"\" try: ttp = getattr(importlib.import_module(name=\"ttp\"), \"ttp\") except ModuleNotFoundError as exc: title = \"Optional Extra Not Installed!\" message = ( \"Optional extra 'ttp' is not installed!\\n\" f\"To resolve this issue, install '{exc.name}'. You can do this in one of the following\" \" ways:\\n\" \"1: 'pip install -r requirements-ttp.txt'\\n\" \"2: 'pip install scrapli[ttp]'\" ) user_warning(title=title, message=message) return [] if not isinstance(template, (str, TextIOWrapper)): logger.info(f\"invalid template `{template}`; template should be string or TextIOWrapper\") return [] ttp_parser_template_name = \"scrapli_ttp_parse\" ttp_parser = ttp() ttp_parser.add_template(template=template, template_name=ttp_parser_template_name) ttp_parser.add_input(data=output, template_name=ttp_parser_template_name) ttp_parser.parse() ttp_result: Dict[str, List[Any]] = ttp_parser.result(structure=\"dictionary\") return ttp_result[ttp_parser_template_name] def resolve_file(file: str) -> str: \"\"\" Resolve file from provided string Args: file: string path to file Returns: str: string path to file Raises: ScrapliValueError: if file cannot be resolved \"\"\" if Path(file).is_file(): return str(Path(file)) if Path(file).expanduser().is_file(): return str(Path(file).expanduser()) raise ScrapliValueError(f\"File path `{file}` could not be resolved\") def format_user_warning(title: str, message: str) -> str: \"\"\" Nicely format a warning message for users Args: title: title of the warning message message: actual message body Returns: str: nicely formatted warning Raises: N/A \"\"\" terminal_width = get_terminal_size().columns warning_banner_char = \"*\" if len(title) > (terminal_width - 4): warning_header = warning_banner_char * terminal_width else: banner_char_count = terminal_width - len(title) - 2 left_banner_char_count = banner_char_count // 2 right_banner_char_count = ( banner_char_count / 2 if banner_char_count % 2 == 0 else (banner_char_count // 2) + 1 ) warning_header = ( f\"{warning_banner_char:{warning_banner_char}>{left_banner_char_count}}\" f\" {title} \" f\"{warning_banner_char:{warning_banner_char} < {right_banner_char_count}}\" ) warning_footer = warning_banner_char * terminal_width return ( \"\\n\\n\" + warning_header + \"\\n\" + message.center(terminal_width) + \"\\n\" + warning_footer + \"\\n\" ) def user_warning(title: str, message: str) -> None: \"\"\" Nicely raise warning messages for users Args: title: title of the warning message message: actual message body Returns: None Raises: N/A \"\"\" warning_message = format_user_warning(title=title, message=message) logger.warning(warning_message) if Settings.SUPPRESS_USER_WARNINGS is False: warn(warning_message) Functions \u00b6 format_user_warning \u00b6 format_user_warning(title: str, message: str) \u2011> str 1 2 3 4 5 6 7 8 9 10 11 Nicely format a warning message for users Args: title: title of the warning message message: actual message body Returns: str: nicely formatted warning Raises: N/A genie_parse \u00b6 genie_parse(platform: str, command: str, output: str) \u2011> Union[List[Any], Dict[str, Any]] 1 2 3 4 5 6 7 8 9 10 11 12 Parse output with Cisco genie parsers, try to return structured output Args: platform: genie device type; i.e. iosxe, iosxr, etc. command: string of command that was executed (to find appropriate parser) output: unstructured output from device to parse Returns: output: structured data Raises: N/A resolve_file \u00b6 resolve_file(file: str) \u2011> str 1 2 3 4 5 6 7 8 9 10 Resolve file from provided string Args: file: string path to file Returns: str: string path to file Raises: ScrapliValueError: if file cannot be resolved textfsm_parse \u00b6 textfsm_parse(template: Union[str, _io.TextIOWrapper], output: str, to_dict: bool = True) \u2011> Union[List[Any], Dict[str, Any]] 1 2 3 4 5 6 7 8 9 10 11 12 13 Parse output with TextFSM and ntc-templates, try to return structured output Args: template: TextIOWrapper or string of URL or filesystem path to template to use to parse data output: unstructured output from device to parse to_dict: convert textfsm output from list of lists to list of dicts -- basically create dict from header and row data so it is easier to read/parse the output Returns: output: structured data Raises: N/A ttp_parse \u00b6 ttp_parse(template: Union[str, _io.TextIOWrapper], output: str) \u2011> Union[List[Any], Dict[str, Any]] 1 2 3 4 5 6 7 8 9 10 11 Parse output with TTP, try to return structured output Args: template: TextIOWrapper or string path to template to use to parse data output: unstructured output from device to parse Returns: output: structured data Raises: N/A user_warning \u00b6 user_warning(title: str, message: str) \u2011> None 1 2 3 4 5 6 7 8 9 10 11 Nicely raise warning messages for users Args: title: title of the warning message message: actual message body Returns: None Raises: N/A","title":"Helper"},{"location":"api_docs/helper/#module-scraplihelper","text":"scrapli.helper Expand source code \"\"\"scrapli.helper\"\"\" import importlib import urllib.request from io import BytesIO, TextIOWrapper from pathlib import Path from shutil import get_terminal_size from typing import Any, Dict, List, Optional, TextIO, Union from warnings import warn import pkg_resources # pylint: disable=C0411 from scrapli.exceptions import ScrapliValueError from scrapli.logging import logger from scrapli.settings import Settings def _textfsm_get_template(platform: str, command: str) -> Optional[TextIO]: \"\"\" Find correct TextFSM template based on platform and command executed Args: platform: ntc-templates device type; i.e. cisco_ios, arista_eos, etc. command: string of command that was executed (to find appropriate template) Returns: None or TextIO of opened template Raises: N/A \"\"\" try: importlib.import_module(name=\".templates\", package=\"ntc_templates\") CliTable = getattr(importlib.import_module(name=\".clitable\", package=\"textfsm\"), \"CliTable\") except ModuleNotFoundError as exc: title = \"Optional Extra Not Installed!\" message = ( \"Optional extra 'textfsm' is not installed!\\n\" f\"To resolve this issue, install '{exc.name}'. You can do this in one of the following\" \" ways:\\n\" \"1: 'pip install -r requirements-textfsm.txt'\\n\" \"2: 'pip install scrapli[textfsm]'\" ) user_warning(title=title, message=message) return None template_dir = pkg_resources.resource_filename(\"ntc_templates\", \"templates\") cli_table = CliTable(\"index\", template_dir) template_index = cli_table.index.GetRowMatch({\"Platform\": platform, \"Command\": command}) if not template_index: logger.warning( f\"No match in ntc_templates index for platform `{platform}` and command `{command}`\" ) return None template_name = cli_table.index.index[template_index][\"Template\"] return open(f\"{template_dir}/{template_name}\", encoding=\"utf-8\") def _textfsm_to_dict( structured_output: Union[List[Any], Dict[str, Any]], header: List[str] ) -> Union[List[Any], Dict[str, Any]]: \"\"\" Create list of dicts from textfsm output and header Args: structured_output: parsed textfsm output header: list of strings representing column headers for textfsm output Returns: output: structured data Raises: N/A \"\"\" logger.debug(\"converting textfsm output to dictionary representation\") header_lower = [h.lower() for h in header] structured_output = [dict(zip(header_lower, row)) for row in structured_output] return structured_output def textfsm_parse( template: Union[str, TextIOWrapper], output: str, to_dict: bool = True ) -> Union[List[Any], Dict[str, Any]]: \"\"\" Parse output with TextFSM and ntc-templates, try to return structured output Args: template: TextIOWrapper or string of URL or filesystem path to template to use to parse data output: unstructured output from device to parse to_dict: convert textfsm output from list of lists to list of dicts -- basically create dict from header and row data so it is easier to read/parse the output Returns: output: structured data Raises: N/A \"\"\" import textfsm # pylint: disable=C0415 if not isinstance(template, TextIOWrapper): if template.startswith(\"http://\") or template.startswith(\"https://\"): with urllib.request.urlopen(template) as response: template_file = TextIOWrapper( BytesIO(response.read()), encoding=response.headers.get_content_charset(), ) else: template_file = TextIOWrapper(open(template, mode=\"rb\")) # pylint: disable=R1732 else: template_file = template re_table = textfsm.TextFSM(template_file) try: structured_output: Union[List[Any], Dict[str, Any]] = re_table.ParseText(output) if to_dict: structured_output = _textfsm_to_dict( structured_output=structured_output, header=re_table.header ) return structured_output except textfsm.parser.TextFSMError: logger.warning(\"failed to parse data with textfsm\") return [] def genie_parse(platform: str, command: str, output: str) -> Union[List[Any], Dict[str, Any]]: \"\"\" Parse output with Cisco genie parsers, try to return structured output Args: platform: genie device type; i.e. iosxe, iosxr, etc. command: string of command that was executed (to find appropriate parser) output: unstructured output from device to parse Returns: output: structured data Raises: N/A \"\"\" try: Device = getattr(importlib.import_module(name=\".conf.base\", package=\"genie\"), \"Device\") get_parser = getattr( importlib.import_module(name=\".libs.parser.utils\", package=\"genie\"), \"get_parser\" ) except ModuleNotFoundError as exc: title = \"Optional Extra Not Installed!\" message = ( \"Optional extra 'genie' is not installed!\\n\" f\"To resolve this issue, install '{exc.name}'. You can do this in one of the following\" \" ways:\\n\" \"1: 'pip install -r requirements-genie.txt'\\n\" \"2: 'pip install scrapli[genie]'\" ) user_warning(title=title, message=message) return [] genie_device = Device(\"scrapli_device\", custom={\"abstraction\": {\"order\": [\"os\"]}}, os=platform) try: get_parser(command, genie_device) genie_parsed_result = genie_device.parse(command, output=output) if isinstance(genie_parsed_result, (list, dict)): return genie_parsed_result except Exception as exc: # pylint: disable=W0703 logger.warning(f\"failed to parse data with genie, genie raised exception: `{exc}`\") return [] def ttp_parse(template: Union[str, TextIOWrapper], output: str) -> Union[List[Any], Dict[str, Any]]: \"\"\" Parse output with TTP, try to return structured output Args: template: TextIOWrapper or string path to template to use to parse data output: unstructured output from device to parse Returns: output: structured data Raises: N/A \"\"\" try: ttp = getattr(importlib.import_module(name=\"ttp\"), \"ttp\") except ModuleNotFoundError as exc: title = \"Optional Extra Not Installed!\" message = ( \"Optional extra 'ttp' is not installed!\\n\" f\"To resolve this issue, install '{exc.name}'. You can do this in one of the following\" \" ways:\\n\" \"1: 'pip install -r requirements-ttp.txt'\\n\" \"2: 'pip install scrapli[ttp]'\" ) user_warning(title=title, message=message) return [] if not isinstance(template, (str, TextIOWrapper)): logger.info(f\"invalid template `{template}`; template should be string or TextIOWrapper\") return [] ttp_parser_template_name = \"scrapli_ttp_parse\" ttp_parser = ttp() ttp_parser.add_template(template=template, template_name=ttp_parser_template_name) ttp_parser.add_input(data=output, template_name=ttp_parser_template_name) ttp_parser.parse() ttp_result: Dict[str, List[Any]] = ttp_parser.result(structure=\"dictionary\") return ttp_result[ttp_parser_template_name] def resolve_file(file: str) -> str: \"\"\" Resolve file from provided string Args: file: string path to file Returns: str: string path to file Raises: ScrapliValueError: if file cannot be resolved \"\"\" if Path(file).is_file(): return str(Path(file)) if Path(file).expanduser().is_file(): return str(Path(file).expanduser()) raise ScrapliValueError(f\"File path `{file}` could not be resolved\") def format_user_warning(title: str, message: str) -> str: \"\"\" Nicely format a warning message for users Args: title: title of the warning message message: actual message body Returns: str: nicely formatted warning Raises: N/A \"\"\" terminal_width = get_terminal_size().columns warning_banner_char = \"*\" if len(title) > (terminal_width - 4): warning_header = warning_banner_char * terminal_width else: banner_char_count = terminal_width - len(title) - 2 left_banner_char_count = banner_char_count // 2 right_banner_char_count = ( banner_char_count / 2 if banner_char_count % 2 == 0 else (banner_char_count // 2) + 1 ) warning_header = ( f\"{warning_banner_char:{warning_banner_char}>{left_banner_char_count}}\" f\" {title} \" f\"{warning_banner_char:{warning_banner_char} < {right_banner_char_count}}\" ) warning_footer = warning_banner_char * terminal_width return ( \"\\n\\n\" + warning_header + \"\\n\" + message.center(terminal_width) + \"\\n\" + warning_footer + \"\\n\" ) def user_warning(title: str, message: str) -> None: \"\"\" Nicely raise warning messages for users Args: title: title of the warning message message: actual message body Returns: None Raises: N/A \"\"\" warning_message = format_user_warning(title=title, message=message) logger.warning(warning_message) if Settings.SUPPRESS_USER_WARNINGS is False: warn(warning_message)","title":"Module scrapli.helper"},{"location":"api_docs/helper/#functions","text":"","title":"Functions"},{"location":"api_docs/helper/#format_user_warning","text":"format_user_warning(title: str, message: str) \u2011> str 1 2 3 4 5 6 7 8 9 10 11 Nicely format a warning message for users Args: title: title of the warning message message: actual message body Returns: str: nicely formatted warning Raises: N/A","title":"format_user_warning"},{"location":"api_docs/helper/#genie_parse","text":"genie_parse(platform: str, command: str, output: str) \u2011> Union[List[Any], Dict[str, Any]] 1 2 3 4 5 6 7 8 9 10 11 12 Parse output with Cisco genie parsers, try to return structured output Args: platform: genie device type; i.e. iosxe, iosxr, etc. command: string of command that was executed (to find appropriate parser) output: unstructured output from device to parse Returns: output: structured data Raises: N/A","title":"genie_parse"},{"location":"api_docs/helper/#resolve_file","text":"resolve_file(file: str) \u2011> str 1 2 3 4 5 6 7 8 9 10 Resolve file from provided string Args: file: string path to file Returns: str: string path to file Raises: ScrapliValueError: if file cannot be resolved","title":"resolve_file"},{"location":"api_docs/helper/#textfsm_parse","text":"textfsm_parse(template: Union[str, _io.TextIOWrapper], output: str, to_dict: bool = True) \u2011> Union[List[Any], Dict[str, Any]] 1 2 3 4 5 6 7 8 9 10 11 12 13 Parse output with TextFSM and ntc-templates, try to return structured output Args: template: TextIOWrapper or string of URL or filesystem path to template to use to parse data output: unstructured output from device to parse to_dict: convert textfsm output from list of lists to list of dicts -- basically create dict from header and row data so it is easier to read/parse the output Returns: output: structured data Raises: N/A","title":"textfsm_parse"},{"location":"api_docs/helper/#ttp_parse","text":"ttp_parse(template: Union[str, _io.TextIOWrapper], output: str) \u2011> Union[List[Any], Dict[str, Any]] 1 2 3 4 5 6 7 8 9 10 11 Parse output with TTP, try to return structured output Args: template: TextIOWrapper or string path to template to use to parse data output: unstructured output from device to parse Returns: output: structured data Raises: N/A","title":"ttp_parse"},{"location":"api_docs/helper/#user_warning","text":"user_warning(title: str, message: str) \u2011> None 1 2 3 4 5 6 7 8 9 10 11 Nicely raise warning messages for users Args: title: title of the warning message message: actual message body Returns: None Raises: N/A","title":"user_warning"},{"location":"api_docs/logging/","text":"window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting()) Module scrapli.logging \u00b6 scrapli.logging Expand source code \"\"\"scrapli.logging\"\"\" from ast import literal_eval from logging import FileHandler, Formatter, Logger, LoggerAdapter, LogRecord, NullHandler, getLogger from typing import TYPE_CHECKING, Optional, Union, cast from scrapli.exceptions import ScrapliException if TYPE_CHECKING: LoggerAdapterT = LoggerAdapter[Logger] # pylint:disable=E1136 else: LoggerAdapterT = LoggerAdapter class ScrapliLogRecord(LogRecord): message_id: int uid: str host: str port: str target: str class ScrapliFormatter(Formatter): def __init__(self, log_header: bool = True, caller_info: bool = False) -> None: \"\"\" Scrapli's opinionated custom log formatter class Only applied/used when explicitly requested by the user, otherwise we leave logging up to the user as any library should! Args: log_header: add the \"header\" row to logging output (or not) caller_info: add caller (module/package/line) info to log output Returns: None Raises: N/A \"\"\" log_format = \"{message_id: < 5} | {asctime} | {levelname: < 8} | {target: < 25} | {message}\" if caller_info: log_format = ( \"{message_id: < 5} | {asctime} | {levelname: < 8} | {target: < 25} | \" \"{module: < 20} | {funcName: < 20} | {lineno: < 5} | {message}\" ) super().__init__(fmt=log_format, style=\"{\") self.log_header = log_header self.caller_info = caller_info self.message_id = 1 self.header_record = ScrapliLogRecord( name=\"header\", level=0, pathname=\"\", lineno=0, msg=\"MESSAGE\", args=(), exc_info=None, ) self.header_record.message_id = 0 self.header_record.asctime = \"TIMESTAMP\".ljust(23, \" \") self.header_record.levelname = \"LEVEL\" self.header_record.uid = \"(UID:)\" self.header_record.host = \"HOST\" self.header_record.port = \"PORT\" self.header_record.module = \"MODULE\" self.header_record.funcName = \"FUNCNAME\" self.header_record.lineno = 0 self.header_record.message = \"MESSAGE\" def formatMessage(self, record: LogRecord) -> str: \"\"\" Override standard library logging Formatter.formatMessage Args: record: LogRecord to format Returns: str: log string to emit Raises: N/A \"\"\" record = cast(ScrapliLogRecord, record) record.message_id = self.message_id if not hasattr(record, \"host\"): # if no host/port set, assign to the record so formatting does not fail record.host = \"\" record.port = \"\" _host_port = \"\" else: _host_port = f\"{record.host}:{record.port}\" _uid = \"\" if not hasattr(record, \"uid\") else f\"{record.uid}:\" # maybe this name changes... but a uid in the event you have multiple connections to a # single host... w/ this you can assign the uid so you know which is which record.target = f\"{_uid}{_host_port}\" # add colon to the uid so the log messages are pretty record.target = ( record.target[:25] if len(record.target) < = 25 else f\"{record.target[:22]}...\" ) if self.caller_info: record.module = ( record.module[:20] if len(record.module) < = 20 else f\"{record.module[:17]}...\" ) record.funcName = ( record.funcName[:20] if len(record.funcName) < = 20 else f\"{record.funcName[:17]}...\" ) message = self._style.format(record) if self.message_id == 1 and self.log_header: # ignoring type for these fields so we can put \"pretty\" data into the log \"header\" row self.header_record.message_id = \"ID\" # type: ignore self.header_record.lineno = \"LINE\" # type: ignore self.header_record.target = \"(UID:)HOST:PORT\".ljust(len(record.target)) header_message = self._style.format(self.header_record) message = header_message + \"\\n\" + message self.message_id += 1 return message class ScrapliFileHandler(FileHandler): def __init__( self, filename: str, mode: str = \"a\", encoding: Optional[str] = None, delay: bool = False, ) -> None: \"\"\" Handle \"buffering\" log read messages for logging.FileHandler Args: filename: name of file to create mode: file mode encoding: encoding to use for file delay: actually not sure what this is for :) Returns: None Raises: N/A \"\"\" super().__init__( filename=filename, mode=mode, encoding=encoding, delay=delay, ) self._record_buf: Optional[LogRecord] = None self._record_msg_buf: bytes = b\"\" self._read_msg_prefix = \"read: \" self._read_msg_prefix_len = len(self._read_msg_prefix) def emit_buffered(self) -> None: \"\"\" Emit a buffered read message to the FileHandler Args: N/A Returns: None Raises: ScrapliException: should never be raised! \"\"\" if not self._record_buf: raise ScrapliException( \"something unexpected happened in the ScrapliFileHandler log handler\" ) self._record_buf.msg = f\"read : {repr(self._record_msg_buf)}\" super().emit(record=self._record_buf) self._record_buf = None self._record_msg_buf = b\"\" def emit(self, record: LogRecord) -> None: \"\"\" Override standard library FileHandler.emit to \"buffer\" subsequent read messages Args: record: log record to check Returns: None Raises: N/A \"\"\" if not record.msg.startswith(self._read_msg_prefix): # everytime we get a message *not* starting with \"read: \" we check to see if there is # any buffered message ready to send, if so send it. otherwise, treat the message # normally by super'ing to the \"normal\" handler if self._record_buf: self.emit_buffered() super().emit(record=record) return if self._record_buf is None: # no message in the buffer, set the current record to the _record_buf self._record_buf = record # get the payload of the message after \"read: \" and re-convert it to bytes self._record_msg_buf = literal_eval(record.msg[self._read_msg_prefix_len :]) # noqa return # if we get here we know we are getting subsequent read messages we want to buffer -- the # log record data will all be the same, its just the payload that will be new, so add that # current payload to the _record_msg_buf buffer self._record_msg_buf += literal_eval(record.msg[self._read_msg_prefix_len :]) # noqa def get_instance_logger( instance_name: str, host: str = \"\", port: int = 0, uid: str = \"\" ) -> LoggerAdapterT: \"\"\" Get an adapted logger instance for a given instance (driver/channel/transport) Args: instance_name: logger/instance name, i.e. \"scrapli.driver\" host: host to add to logging extras if applicable port: port to add to logging extras if applicable uid: unique id for a logging instance Returns: LoggerAdapterT: adapter logger for the instance Raises: N/A \"\"\" extras = {} if host and port: extras[\"host\"] = host extras[\"port\"] = str(port) if uid: extras[\"uid\"] = uid _logger = getLogger(instance_name) return LoggerAdapter(_logger, extra=extras) def enable_basic_logging( file: Union[str, bool] = False, level: str = \"info\", caller_info: bool = False, buffer_log: bool = True, mode: str = \"write\", ) -> None: \"\"\" Enable opinionated logging for scrapli Args: file: True to output to default log path (\"scrapli.log\"), otherwise string path to write log file to level: string name of logging level to use, i.e. \"info\", \"debug\", etc. caller_info: add info about module/function/line in the log entry buffer_log: buffer log read outputs mode: string of \"write\" or \"append\" Returns: None Raises: ScrapliException: if invalid mode is passed \"\"\" logger.propagate = False logger.setLevel(level=level.upper()) scrapli_formatter = ScrapliFormatter(caller_info=caller_info) if mode.lower() not in ( \"write\", \"append\", ): raise ScrapliException(\"logging file 'mode' must be 'write' or 'append'!\") file_mode = \"a\" if mode.lower() == \"append\" else \"w\" if file: filename = \"scrapli.log\" if isinstance(file, bool) else file if not buffer_log: fh = FileHandler(filename=filename, mode=file_mode) else: fh = ScrapliFileHandler(filename=filename, mode=file_mode) fh.setFormatter(scrapli_formatter) logger.addHandler(fh) # get the root scrapli logger and apply NullHandler like a good library should, leave logging things # up to the user! logger = getLogger(\"scrapli\") logger.addHandler(NullHandler()) Functions \u00b6 enable_basic_logging \u00b6 enable_basic_logging(file: Union[str, bool] = False, level: str = 'info', caller_info: bool = False, buffer_log: bool = True, mode: str = 'write') \u2011> None 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 Enable opinionated logging for scrapli Args: file: True to output to default log path (\"scrapli.log\"), otherwise string path to write log file to level: string name of logging level to use, i.e. \"info\", \"debug\", etc. caller_info: add info about module/function/line in the log entry buffer_log: buffer log read outputs mode: string of \"write\" or \"append\" Returns: None Raises: ScrapliException: if invalid mode is passed get_instance_logger \u00b6 get_instance_logger(instance_name: str, host: str = '', port: int = 0, uid: str = '') \u2011> logging.LoggerAdapter 1 2 3 4 5 6 7 8 9 10 11 12 13 Get an adapted logger instance for a given instance (driver/channel/transport) Args: instance_name: logger/instance name, i.e. \"scrapli.driver\" host: host to add to logging extras if applicable port: port to add to logging extras if applicable uid: unique id for a logging instance Returns: LoggerAdapterT: adapter logger for the instance Raises: N/A Classes \u00b6 ScrapliFileHandler \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 A handler class which writes formatted logging records to disk files. Handle \"buffering\" log read messages for logging.FileHandler Args: filename: name of file to create mode: file mode encoding: encoding to use for file delay: actually not sure what this is for :) Returns: None Raises: N/A Expand source code class ScrapliFileHandler(FileHandler): def __init__( self, filename: str, mode: str = \"a\", encoding: Optional[str] = None, delay: bool = False, ) -> None: \"\"\" Handle \"buffering\" log read messages for logging.FileHandler Args: filename: name of file to create mode: file mode encoding: encoding to use for file delay: actually not sure what this is for :) Returns: None Raises: N/A \"\"\" super().__init__( filename=filename, mode=mode, encoding=encoding, delay=delay, ) self._record_buf: Optional[LogRecord] = None self._record_msg_buf: bytes = b\"\" self._read_msg_prefix = \"read: \" self._read_msg_prefix_len = len(self._read_msg_prefix) def emit_buffered(self) -> None: \"\"\" Emit a buffered read message to the FileHandler Args: N/A Returns: None Raises: ScrapliException: should never be raised! \"\"\" if not self._record_buf: raise ScrapliException( \"something unexpected happened in the ScrapliFileHandler log handler\" ) self._record_buf.msg = f\"read : {repr(self._record_msg_buf)}\" super().emit(record=self._record_buf) self._record_buf = None self._record_msg_buf = b\"\" def emit(self, record: LogRecord) -> None: \"\"\" Override standard library FileHandler.emit to \"buffer\" subsequent read messages Args: record: log record to check Returns: None Raises: N/A \"\"\" if not record.msg.startswith(self._read_msg_prefix): # everytime we get a message *not* starting with \"read: \" we check to see if there is # any buffered message ready to send, if so send it. otherwise, treat the message # normally by super'ing to the \"normal\" handler if self._record_buf: self.emit_buffered() super().emit(record=record) return if self._record_buf is None: # no message in the buffer, set the current record to the _record_buf self._record_buf = record # get the payload of the message after \"read: \" and re-convert it to bytes self._record_msg_buf = literal_eval(record.msg[self._read_msg_prefix_len :]) # noqa return # if we get here we know we are getting subsequent read messages we want to buffer -- the # log record data will all be the same, its just the payload that will be new, so add that # current payload to the _record_msg_buf buffer self._record_msg_buf += literal_eval(record.msg[self._read_msg_prefix_len :]) # noqa Ancestors (in MRO) \u00b6 logging.FileHandler logging.StreamHandler logging.Handler logging.Filterer Methods \u00b6 emit \u00b6 emit(self, record: logging.LogRecord) \u2011> None 1 2 3 4 5 6 7 8 9 10 Override standard library FileHandler.emit to \"buffer\" subsequent read messages Args: record: log record to check Returns: None Raises: N/A emit_buffered \u00b6 emit_buffered(self) \u2011> None 1 2 3 4 5 6 7 8 9 10 Emit a buffered read message to the FileHandler Args: N/A Returns: None Raises: ScrapliException: should never be raised! ScrapliFormatter \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 Formatter instances are used to convert a LogRecord to text. Formatters need to know how a LogRecord is constructed. They are responsible for converting a LogRecord to (usually) a string which can be interpreted by either a human or an external system. The base Formatter allows a formatting string to be specified. If none is supplied, the style-dependent default value, \"%(message)s\", \"{message}\", or \"${message}\", is used. The Formatter can be initialized with a format string which makes use of knowledge of the LogRecord attributes - e.g. the default value mentioned above makes use of the fact that the user's message and arguments are pre- formatted into a LogRecord's message attribute. Currently, the useful attributes in a LogRecord are described by: %(name)s Name of the logger (logging channel) %(levelno)s Numeric logging level for the message (DEBUG, INFO, WARNING, ERROR, CRITICAL) %(levelname)s Text logging level for the message (\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\") %(pathname)s Full pathname of the source file where the logging call was issued (if available) %(filename)s Filename portion of pathname %(module)s Module (name portion of filename) %(lineno)d Source line number where the logging call was issued (if available) %(funcName)s Function name %(created)f Time when the LogRecord was created (time.time() return value) %(asctime)s Textual time when the LogRecord was created %(msecs)d Millisecond portion of the creation time %(relativeCreated)d Time in milliseconds when the LogRecord was created, relative to the time the logging module was loaded (typically at application startup time) %(thread)d Thread ID (if available) %(threadName)s Thread name (if available) %(process)d Process ID (if available) %(message)s The result of record.getMessage(), computed just as the record is emitted Scrapli's opinionated custom log formatter class Only applied/used when explicitly requested by the user, otherwise we leave logging up to the user as any library should! Args: log_header: add the \"header\" row to logging output (or not) caller_info: add caller (module/package/line) info to log output Returns: None Raises: N/A Expand source code class ScrapliFormatter(Formatter): def __init__(self, log_header: bool = True, caller_info: bool = False) -> None: \"\"\" Scrapli's opinionated custom log formatter class Only applied/used when explicitly requested by the user, otherwise we leave logging up to the user as any library should! Args: log_header: add the \"header\" row to logging output (or not) caller_info: add caller (module/package/line) info to log output Returns: None Raises: N/A \"\"\" log_format = \"{message_id: < 5} | {asctime} | {levelname: < 8} | {target: < 25} | {message}\" if caller_info: log_format = ( \"{message_id: < 5} | {asctime} | {levelname: < 8} | {target: < 25} | \" \"{module: < 20} | {funcName: < 20} | {lineno: < 5} | {message}\" ) super().__init__(fmt=log_format, style=\"{\") self.log_header = log_header self.caller_info = caller_info self.message_id = 1 self.header_record = ScrapliLogRecord( name=\"header\", level=0, pathname=\"\", lineno=0, msg=\"MESSAGE\", args=(), exc_info=None, ) self.header_record.message_id = 0 self.header_record.asctime = \"TIMESTAMP\".ljust(23, \" \") self.header_record.levelname = \"LEVEL\" self.header_record.uid = \"(UID:)\" self.header_record.host = \"HOST\" self.header_record.port = \"PORT\" self.header_record.module = \"MODULE\" self.header_record.funcName = \"FUNCNAME\" self.header_record.lineno = 0 self.header_record.message = \"MESSAGE\" def formatMessage(self, record: LogRecord) -> str: \"\"\" Override standard library logging Formatter.formatMessage Args: record: LogRecord to format Returns: str: log string to emit Raises: N/A \"\"\" record = cast(ScrapliLogRecord, record) record.message_id = self.message_id if not hasattr(record, \"host\"): # if no host/port set, assign to the record so formatting does not fail record.host = \"\" record.port = \"\" _host_port = \"\" else: _host_port = f\"{record.host}:{record.port}\" _uid = \"\" if not hasattr(record, \"uid\") else f\"{record.uid}:\" # maybe this name changes... but a uid in the event you have multiple connections to a # single host... w/ this you can assign the uid so you know which is which record.target = f\"{_uid}{_host_port}\" # add colon to the uid so the log messages are pretty record.target = ( record.target[:25] if len(record.target) < = 25 else f\"{record.target[:22]}...\" ) if self.caller_info: record.module = ( record.module[:20] if len(record.module) < = 20 else f\"{record.module[:17]}...\" ) record.funcName = ( record.funcName[:20] if len(record.funcName) < = 20 else f\"{record.funcName[:17]}...\" ) message = self._style.format(record) if self.message_id == 1 and self.log_header: # ignoring type for these fields so we can put \"pretty\" data into the log \"header\" row self.header_record.message_id = \"ID\" # type: ignore self.header_record.lineno = \"LINE\" # type: ignore self.header_record.target = \"(UID:)HOST:PORT\".ljust(len(record.target)) header_message = self._style.format(self.header_record) message = header_message + \"\\n\" + message self.message_id += 1 return message Ancestors (in MRO) \u00b6 logging.Formatter Methods \u00b6 formatMessage \u00b6 formatMessage(self, record: logging.LogRecord) \u2011> str 1 2 3 4 5 6 7 8 9 10 Override standard library logging Formatter.formatMessage Args: record: LogRecord to format Returns: str: log string to emit Raises: N/A ScrapliLogRecord \u00b6 1 2 3 4 5 6 7 8 9 10 11 A LogRecord instance represents an event being logged. LogRecord instances are created every time something is logged. They contain all the information pertinent to the event being logged. The main information passed in is in msg and args, which are combined using str(msg) % args to create the message field of the record. The record also includes information such as when the record was created, the source line where the logging call was made, and any exception information to be logged. Initialize a logging record with interesting information. Expand source code class ScrapliLogRecord(LogRecord): message_id: int uid: str host: str port: str target: str Ancestors (in MRO) \u00b6 logging.LogRecord Class variables \u00b6 host: str message_id: int port: str target: str uid: str","title":"Logging"},{"location":"api_docs/logging/#module-scraplilogging","text":"scrapli.logging Expand source code \"\"\"scrapli.logging\"\"\" from ast import literal_eval from logging import FileHandler, Formatter, Logger, LoggerAdapter, LogRecord, NullHandler, getLogger from typing import TYPE_CHECKING, Optional, Union, cast from scrapli.exceptions import ScrapliException if TYPE_CHECKING: LoggerAdapterT = LoggerAdapter[Logger] # pylint:disable=E1136 else: LoggerAdapterT = LoggerAdapter class ScrapliLogRecord(LogRecord): message_id: int uid: str host: str port: str target: str class ScrapliFormatter(Formatter): def __init__(self, log_header: bool = True, caller_info: bool = False) -> None: \"\"\" Scrapli's opinionated custom log formatter class Only applied/used when explicitly requested by the user, otherwise we leave logging up to the user as any library should! Args: log_header: add the \"header\" row to logging output (or not) caller_info: add caller (module/package/line) info to log output Returns: None Raises: N/A \"\"\" log_format = \"{message_id: < 5} | {asctime} | {levelname: < 8} | {target: < 25} | {message}\" if caller_info: log_format = ( \"{message_id: < 5} | {asctime} | {levelname: < 8} | {target: < 25} | \" \"{module: < 20} | {funcName: < 20} | {lineno: < 5} | {message}\" ) super().__init__(fmt=log_format, style=\"{\") self.log_header = log_header self.caller_info = caller_info self.message_id = 1 self.header_record = ScrapliLogRecord( name=\"header\", level=0, pathname=\"\", lineno=0, msg=\"MESSAGE\", args=(), exc_info=None, ) self.header_record.message_id = 0 self.header_record.asctime = \"TIMESTAMP\".ljust(23, \" \") self.header_record.levelname = \"LEVEL\" self.header_record.uid = \"(UID:)\" self.header_record.host = \"HOST\" self.header_record.port = \"PORT\" self.header_record.module = \"MODULE\" self.header_record.funcName = \"FUNCNAME\" self.header_record.lineno = 0 self.header_record.message = \"MESSAGE\" def formatMessage(self, record: LogRecord) -> str: \"\"\" Override standard library logging Formatter.formatMessage Args: record: LogRecord to format Returns: str: log string to emit Raises: N/A \"\"\" record = cast(ScrapliLogRecord, record) record.message_id = self.message_id if not hasattr(record, \"host\"): # if no host/port set, assign to the record so formatting does not fail record.host = \"\" record.port = \"\" _host_port = \"\" else: _host_port = f\"{record.host}:{record.port}\" _uid = \"\" if not hasattr(record, \"uid\") else f\"{record.uid}:\" # maybe this name changes... but a uid in the event you have multiple connections to a # single host... w/ this you can assign the uid so you know which is which record.target = f\"{_uid}{_host_port}\" # add colon to the uid so the log messages are pretty record.target = ( record.target[:25] if len(record.target) < = 25 else f\"{record.target[:22]}...\" ) if self.caller_info: record.module = ( record.module[:20] if len(record.module) < = 20 else f\"{record.module[:17]}...\" ) record.funcName = ( record.funcName[:20] if len(record.funcName) < = 20 else f\"{record.funcName[:17]}...\" ) message = self._style.format(record) if self.message_id == 1 and self.log_header: # ignoring type for these fields so we can put \"pretty\" data into the log \"header\" row self.header_record.message_id = \"ID\" # type: ignore self.header_record.lineno = \"LINE\" # type: ignore self.header_record.target = \"(UID:)HOST:PORT\".ljust(len(record.target)) header_message = self._style.format(self.header_record) message = header_message + \"\\n\" + message self.message_id += 1 return message class ScrapliFileHandler(FileHandler): def __init__( self, filename: str, mode: str = \"a\", encoding: Optional[str] = None, delay: bool = False, ) -> None: \"\"\" Handle \"buffering\" log read messages for logging.FileHandler Args: filename: name of file to create mode: file mode encoding: encoding to use for file delay: actually not sure what this is for :) Returns: None Raises: N/A \"\"\" super().__init__( filename=filename, mode=mode, encoding=encoding, delay=delay, ) self._record_buf: Optional[LogRecord] = None self._record_msg_buf: bytes = b\"\" self._read_msg_prefix = \"read: \" self._read_msg_prefix_len = len(self._read_msg_prefix) def emit_buffered(self) -> None: \"\"\" Emit a buffered read message to the FileHandler Args: N/A Returns: None Raises: ScrapliException: should never be raised! \"\"\" if not self._record_buf: raise ScrapliException( \"something unexpected happened in the ScrapliFileHandler log handler\" ) self._record_buf.msg = f\"read : {repr(self._record_msg_buf)}\" super().emit(record=self._record_buf) self._record_buf = None self._record_msg_buf = b\"\" def emit(self, record: LogRecord) -> None: \"\"\" Override standard library FileHandler.emit to \"buffer\" subsequent read messages Args: record: log record to check Returns: None Raises: N/A \"\"\" if not record.msg.startswith(self._read_msg_prefix): # everytime we get a message *not* starting with \"read: \" we check to see if there is # any buffered message ready to send, if so send it. otherwise, treat the message # normally by super'ing to the \"normal\" handler if self._record_buf: self.emit_buffered() super().emit(record=record) return if self._record_buf is None: # no message in the buffer, set the current record to the _record_buf self._record_buf = record # get the payload of the message after \"read: \" and re-convert it to bytes self._record_msg_buf = literal_eval(record.msg[self._read_msg_prefix_len :]) # noqa return # if we get here we know we are getting subsequent read messages we want to buffer -- the # log record data will all be the same, its just the payload that will be new, so add that # current payload to the _record_msg_buf buffer self._record_msg_buf += literal_eval(record.msg[self._read_msg_prefix_len :]) # noqa def get_instance_logger( instance_name: str, host: str = \"\", port: int = 0, uid: str = \"\" ) -> LoggerAdapterT: \"\"\" Get an adapted logger instance for a given instance (driver/channel/transport) Args: instance_name: logger/instance name, i.e. \"scrapli.driver\" host: host to add to logging extras if applicable port: port to add to logging extras if applicable uid: unique id for a logging instance Returns: LoggerAdapterT: adapter logger for the instance Raises: N/A \"\"\" extras = {} if host and port: extras[\"host\"] = host extras[\"port\"] = str(port) if uid: extras[\"uid\"] = uid _logger = getLogger(instance_name) return LoggerAdapter(_logger, extra=extras) def enable_basic_logging( file: Union[str, bool] = False, level: str = \"info\", caller_info: bool = False, buffer_log: bool = True, mode: str = \"write\", ) -> None: \"\"\" Enable opinionated logging for scrapli Args: file: True to output to default log path (\"scrapli.log\"), otherwise string path to write log file to level: string name of logging level to use, i.e. \"info\", \"debug\", etc. caller_info: add info about module/function/line in the log entry buffer_log: buffer log read outputs mode: string of \"write\" or \"append\" Returns: None Raises: ScrapliException: if invalid mode is passed \"\"\" logger.propagate = False logger.setLevel(level=level.upper()) scrapli_formatter = ScrapliFormatter(caller_info=caller_info) if mode.lower() not in ( \"write\", \"append\", ): raise ScrapliException(\"logging file 'mode' must be 'write' or 'append'!\") file_mode = \"a\" if mode.lower() == \"append\" else \"w\" if file: filename = \"scrapli.log\" if isinstance(file, bool) else file if not buffer_log: fh = FileHandler(filename=filename, mode=file_mode) else: fh = ScrapliFileHandler(filename=filename, mode=file_mode) fh.setFormatter(scrapli_formatter) logger.addHandler(fh) # get the root scrapli logger and apply NullHandler like a good library should, leave logging things # up to the user! logger = getLogger(\"scrapli\") logger.addHandler(NullHandler())","title":"Module scrapli.logging"},{"location":"api_docs/logging/#functions","text":"","title":"Functions"},{"location":"api_docs/logging/#enable_basic_logging","text":"enable_basic_logging(file: Union[str, bool] = False, level: str = 'info', caller_info: bool = False, buffer_log: bool = True, mode: str = 'write') \u2011> None 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 Enable opinionated logging for scrapli Args: file: True to output to default log path (\"scrapli.log\"), otherwise string path to write log file to level: string name of logging level to use, i.e. \"info\", \"debug\", etc. caller_info: add info about module/function/line in the log entry buffer_log: buffer log read outputs mode: string of \"write\" or \"append\" Returns: None Raises: ScrapliException: if invalid mode is passed","title":"enable_basic_logging"},{"location":"api_docs/logging/#get_instance_logger","text":"get_instance_logger(instance_name: str, host: str = '', port: int = 0, uid: str = '') \u2011> logging.LoggerAdapter 1 2 3 4 5 6 7 8 9 10 11 12 13 Get an adapted logger instance for a given instance (driver/channel/transport) Args: instance_name: logger/instance name, i.e. \"scrapli.driver\" host: host to add to logging extras if applicable port: port to add to logging extras if applicable uid: unique id for a logging instance Returns: LoggerAdapterT: adapter logger for the instance Raises: N/A","title":"get_instance_logger"},{"location":"api_docs/logging/#classes","text":"","title":"Classes"},{"location":"api_docs/logging/#scraplifilehandler","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 A handler class which writes formatted logging records to disk files. Handle \"buffering\" log read messages for logging.FileHandler Args: filename: name of file to create mode: file mode encoding: encoding to use for file delay: actually not sure what this is for :) Returns: None Raises: N/A Expand source code class ScrapliFileHandler(FileHandler): def __init__( self, filename: str, mode: str = \"a\", encoding: Optional[str] = None, delay: bool = False, ) -> None: \"\"\" Handle \"buffering\" log read messages for logging.FileHandler Args: filename: name of file to create mode: file mode encoding: encoding to use for file delay: actually not sure what this is for :) Returns: None Raises: N/A \"\"\" super().__init__( filename=filename, mode=mode, encoding=encoding, delay=delay, ) self._record_buf: Optional[LogRecord] = None self._record_msg_buf: bytes = b\"\" self._read_msg_prefix = \"read: \" self._read_msg_prefix_len = len(self._read_msg_prefix) def emit_buffered(self) -> None: \"\"\" Emit a buffered read message to the FileHandler Args: N/A Returns: None Raises: ScrapliException: should never be raised! \"\"\" if not self._record_buf: raise ScrapliException( \"something unexpected happened in the ScrapliFileHandler log handler\" ) self._record_buf.msg = f\"read : {repr(self._record_msg_buf)}\" super().emit(record=self._record_buf) self._record_buf = None self._record_msg_buf = b\"\" def emit(self, record: LogRecord) -> None: \"\"\" Override standard library FileHandler.emit to \"buffer\" subsequent read messages Args: record: log record to check Returns: None Raises: N/A \"\"\" if not record.msg.startswith(self._read_msg_prefix): # everytime we get a message *not* starting with \"read: \" we check to see if there is # any buffered message ready to send, if so send it. otherwise, treat the message # normally by super'ing to the \"normal\" handler if self._record_buf: self.emit_buffered() super().emit(record=record) return if self._record_buf is None: # no message in the buffer, set the current record to the _record_buf self._record_buf = record # get the payload of the message after \"read: \" and re-convert it to bytes self._record_msg_buf = literal_eval(record.msg[self._read_msg_prefix_len :]) # noqa return # if we get here we know we are getting subsequent read messages we want to buffer -- the # log record data will all be the same, its just the payload that will be new, so add that # current payload to the _record_msg_buf buffer self._record_msg_buf += literal_eval(record.msg[self._read_msg_prefix_len :]) # noqa","title":"ScrapliFileHandler"},{"location":"api_docs/logging/#ancestors-in-mro","text":"logging.FileHandler logging.StreamHandler logging.Handler logging.Filterer","title":"Ancestors (in MRO)"},{"location":"api_docs/logging/#methods","text":"","title":"Methods"},{"location":"api_docs/logging/#emit","text":"emit(self, record: logging.LogRecord) \u2011> None 1 2 3 4 5 6 7 8 9 10 Override standard library FileHandler.emit to \"buffer\" subsequent read messages Args: record: log record to check Returns: None Raises: N/A","title":"emit"},{"location":"api_docs/logging/#emit_buffered","text":"emit_buffered(self) \u2011> None 1 2 3 4 5 6 7 8 9 10 Emit a buffered read message to the FileHandler Args: N/A Returns: None Raises: ScrapliException: should never be raised!","title":"emit_buffered"},{"location":"api_docs/logging/#scrapliformatter","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 Formatter instances are used to convert a LogRecord to text. Formatters need to know how a LogRecord is constructed. They are responsible for converting a LogRecord to (usually) a string which can be interpreted by either a human or an external system. The base Formatter allows a formatting string to be specified. If none is supplied, the style-dependent default value, \"%(message)s\", \"{message}\", or \"${message}\", is used. The Formatter can be initialized with a format string which makes use of knowledge of the LogRecord attributes - e.g. the default value mentioned above makes use of the fact that the user's message and arguments are pre- formatted into a LogRecord's message attribute. Currently, the useful attributes in a LogRecord are described by: %(name)s Name of the logger (logging channel) %(levelno)s Numeric logging level for the message (DEBUG, INFO, WARNING, ERROR, CRITICAL) %(levelname)s Text logging level for the message (\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\") %(pathname)s Full pathname of the source file where the logging call was issued (if available) %(filename)s Filename portion of pathname %(module)s Module (name portion of filename) %(lineno)d Source line number where the logging call was issued (if available) %(funcName)s Function name %(created)f Time when the LogRecord was created (time.time() return value) %(asctime)s Textual time when the LogRecord was created %(msecs)d Millisecond portion of the creation time %(relativeCreated)d Time in milliseconds when the LogRecord was created, relative to the time the logging module was loaded (typically at application startup time) %(thread)d Thread ID (if available) %(threadName)s Thread name (if available) %(process)d Process ID (if available) %(message)s The result of record.getMessage(), computed just as the record is emitted Scrapli's opinionated custom log formatter class Only applied/used when explicitly requested by the user, otherwise we leave logging up to the user as any library should! Args: log_header: add the \"header\" row to logging output (or not) caller_info: add caller (module/package/line) info to log output Returns: None Raises: N/A Expand source code class ScrapliFormatter(Formatter): def __init__(self, log_header: bool = True, caller_info: bool = False) -> None: \"\"\" Scrapli's opinionated custom log formatter class Only applied/used when explicitly requested by the user, otherwise we leave logging up to the user as any library should! Args: log_header: add the \"header\" row to logging output (or not) caller_info: add caller (module/package/line) info to log output Returns: None Raises: N/A \"\"\" log_format = \"{message_id: < 5} | {asctime} | {levelname: < 8} | {target: < 25} | {message}\" if caller_info: log_format = ( \"{message_id: < 5} | {asctime} | {levelname: < 8} | {target: < 25} | \" \"{module: < 20} | {funcName: < 20} | {lineno: < 5} | {message}\" ) super().__init__(fmt=log_format, style=\"{\") self.log_header = log_header self.caller_info = caller_info self.message_id = 1 self.header_record = ScrapliLogRecord( name=\"header\", level=0, pathname=\"\", lineno=0, msg=\"MESSAGE\", args=(), exc_info=None, ) self.header_record.message_id = 0 self.header_record.asctime = \"TIMESTAMP\".ljust(23, \" \") self.header_record.levelname = \"LEVEL\" self.header_record.uid = \"(UID:)\" self.header_record.host = \"HOST\" self.header_record.port = \"PORT\" self.header_record.module = \"MODULE\" self.header_record.funcName = \"FUNCNAME\" self.header_record.lineno = 0 self.header_record.message = \"MESSAGE\" def formatMessage(self, record: LogRecord) -> str: \"\"\" Override standard library logging Formatter.formatMessage Args: record: LogRecord to format Returns: str: log string to emit Raises: N/A \"\"\" record = cast(ScrapliLogRecord, record) record.message_id = self.message_id if not hasattr(record, \"host\"): # if no host/port set, assign to the record so formatting does not fail record.host = \"\" record.port = \"\" _host_port = \"\" else: _host_port = f\"{record.host}:{record.port}\" _uid = \"\" if not hasattr(record, \"uid\") else f\"{record.uid}:\" # maybe this name changes... but a uid in the event you have multiple connections to a # single host... w/ this you can assign the uid so you know which is which record.target = f\"{_uid}{_host_port}\" # add colon to the uid so the log messages are pretty record.target = ( record.target[:25] if len(record.target) < = 25 else f\"{record.target[:22]}...\" ) if self.caller_info: record.module = ( record.module[:20] if len(record.module) < = 20 else f\"{record.module[:17]}...\" ) record.funcName = ( record.funcName[:20] if len(record.funcName) < = 20 else f\"{record.funcName[:17]}...\" ) message = self._style.format(record) if self.message_id == 1 and self.log_header: # ignoring type for these fields so we can put \"pretty\" data into the log \"header\" row self.header_record.message_id = \"ID\" # type: ignore self.header_record.lineno = \"LINE\" # type: ignore self.header_record.target = \"(UID:)HOST:PORT\".ljust(len(record.target)) header_message = self._style.format(self.header_record) message = header_message + \"\\n\" + message self.message_id += 1 return message","title":"ScrapliFormatter"},{"location":"api_docs/logging/#ancestors-in-mro_1","text":"logging.Formatter","title":"Ancestors (in MRO)"},{"location":"api_docs/logging/#methods_1","text":"","title":"Methods"},{"location":"api_docs/logging/#formatmessage","text":"formatMessage(self, record: logging.LogRecord) \u2011> str 1 2 3 4 5 6 7 8 9 10 Override standard library logging Formatter.formatMessage Args: record: LogRecord to format Returns: str: log string to emit Raises: N/A","title":"formatMessage"},{"location":"api_docs/logging/#scraplilogrecord","text":"1 2 3 4 5 6 7 8 9 10 11 A LogRecord instance represents an event being logged. LogRecord instances are created every time something is logged. They contain all the information pertinent to the event being logged. The main information passed in is in msg and args, which are combined using str(msg) % args to create the message field of the record. The record also includes information such as when the record was created, the source line where the logging call was made, and any exception information to be logged. Initialize a logging record with interesting information. Expand source code class ScrapliLogRecord(LogRecord): message_id: int uid: str host: str port: str target: str","title":"ScrapliLogRecord"},{"location":"api_docs/logging/#ancestors-in-mro_2","text":"logging.LogRecord","title":"Ancestors (in MRO)"},{"location":"api_docs/logging/#class-variables","text":"host: str message_id: int port: str target: str uid: str","title":"Class variables"},{"location":"api_docs/response/","text":"window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting()) Module scrapli.response \u00b6 scrapli.response Expand source code \"\"\"scrapli.response\"\"\" from collections import UserList from datetime import datetime from io import TextIOWrapper from typing import TYPE_CHECKING, Any, Dict, Iterable, List, Optional, TextIO, Union, cast from scrapli.exceptions import ScrapliCommandFailure from scrapli.helper import _textfsm_get_template, genie_parse, textfsm_parse, ttp_parse class Response: def __init__( self, host: str, channel_input: str, textfsm_platform: str = \"\", genie_platform: str = \"\", failed_when_contains: Optional[Union[str, List[str]]] = None, ): \"\"\" Scrapli Response Store channel_input, resulting output, and start/end/elapsed time information. Attempt to determine if command was successful or not and reflect that in a failed attribute. Args: host: host that was operated on channel_input: input that got sent down the channel textfsm_platform: ntc-templates friendly platform type genie_platform: cisco pyats/genie friendly platform type failed_when_contains: list of strings that, if present in final output, represent a failed command/interaction Returns: None Raises: N/A \"\"\" self.host = host self.start_time = datetime.now() self.finish_time: Optional[datetime] = None self.elapsed_time: Optional[float] = None self.channel_input = channel_input self.textfsm_platform = textfsm_platform self.genie_platform = genie_platform self.raw_result: bytes = b\"\" self.result: str = \"\" if isinstance(failed_when_contains, str): failed_when_contains = [failed_when_contains] self.failed_when_contains = failed_when_contains self.failed = True def __bool__(self) -> bool: \"\"\" Magic bool method based on channel_input being failed or not Args: N/A Returns: bool: True/False if channel_input failed Raises: N/A \"\"\" return self.failed def __repr__(self) -> str: \"\"\" Magic repr method for Response class Args: N/A Returns: str: repr for class object Raises: N/A \"\"\" return ( f\"{self.__class__.__name__}(\" f\"host={self.host!r},\" f\"channel_input={self.channel_input!r},\" f\"textfsm_platform={self.textfsm_platform!r},\" f\"genie_platform={self.genie_platform!r},\" f\"failed_when_contains={self.failed_when_contains!r})\" ) def __str__(self) -> str: \"\"\" Magic str method for Response class Args: N/A Returns: str: str for class object Raises: N/A \"\"\" return f\"{self.__class__.__name__} \" def record_response(self, result: bytes) -> None: \"\"\" Record channel_input results and elapsed time of channel input/reading output Args: result: string result of channel_input Returns: None Raises: N/A \"\"\" self.finish_time = datetime.now() self.elapsed_time = (self.finish_time - self.start_time).total_seconds() self.raw_result = result try: self.result = result.decode() except UnicodeDecodeError: # sometimes we get some \"garbage\" characters, the iso encoding seems to handle these # better but unclear what the other impact is so we'll just catch exceptions and try # this encoding self.result = result.decode(encoding=\"ISO-8859-1\") if not self.failed_when_contains: self.failed = False elif all(err not in self.result for err in self.failed_when_contains): self.failed = False def textfsm_parse_output( self, template: Union[str, TextIO, None] = None, to_dict: bool = True ) -> Union[Dict[str, Any], List[Any]]: \"\"\" Parse results with textfsm, always return structured data Returns an empty list if parsing fails! Args: template: string path to textfsm template or opened textfsm template file to_dict: convert textfsm output from list of lists to list of dicts -- basically create dict from header and row data so it is easier to read/parse the output Returns: structured_result: empty list or parsed data from textfsm Raises: N/A \"\"\" if template is None: template = _textfsm_get_template( platform=self.textfsm_platform, command=self.channel_input ) if template is None: return [] template = cast(Union[str, TextIOWrapper], template) return textfsm_parse(template=template, output=self.result, to_dict=to_dict) or [] def genie_parse_output(self) -> Union[Dict[str, Any], List[Any]]: \"\"\" Parse results with genie, always return structured data Returns an empty list if parsing fails! Args: N/A Returns: structured_result: empty list or parsed data from genie Raises: N/A \"\"\" return genie_parse( platform=self.genie_platform, command=self.channel_input, output=self.result, ) def ttp_parse_output( self, template: Union[str, TextIOWrapper] ) -> Union[Dict[str, Any], List[Any]]: \"\"\" Parse results with ttp, always return structured data Returns an empty list if parsing fails! Args: template: string path to ttp template or opened ttp template file Returns: structured_result: empty list or parsed data from ttp Raises: N/A \"\"\" return ttp_parse(template=template, output=self.result) or [] def raise_for_status(self) -> None: \"\"\" Raise a `ScrapliCommandFailure` if command/config failed Args: N/A Returns: None Raises: ScrapliCommandFailure: if command/config failed \"\"\" if self.failed: raise ScrapliCommandFailure() if TYPE_CHECKING: ScrapliMultiResponse = UserList[Response] # pylint: disable=E1136; # pragma: no cover else: ScrapliMultiResponse = UserList class MultiResponse(ScrapliMultiResponse): def __init__(self, initlist: Optional[Iterable[Any]] = None) -> None: \"\"\" Initialize list of responses Args: initlist: initial list seed data, if any Returns: None Raises: N/A \"\"\" super().__init__(initlist=initlist) self.data: List[Response] def __str__(self) -> str: \"\"\" Magic str method for MultiResponse class Args: N/A Returns: str: str for class object Raises: N/A \"\"\" return ( f\"{self.__class__.__name__} \" ) @property def host(self) -> str: \"\"\" Return the host of the multiresponse Args: N/A Returns: str: The host of the associated responses Raises: N/A \"\"\" try: response = self.data[0] except IndexError: return \"\" return response.host @property def failed(self) -> bool: \"\"\" Determine if any elements of MultiResponse are failed Args: N/A Returns: bool: True for failed Raises: N/A \"\"\" return any(response.failed for response in self.data) @property def result(self) -> str: \"\"\" Build a unified result from all elements of MultiResponse Args: N/A Returns: str: Unified result by combining results of all elements of MultiResponse Raises: N/A \"\"\" return \"\".join( \"\\n\".join([response.channel_input, response.result]) for response in self.data ) def raise_for_status(self) -> None: \"\"\" Raise a `ScrapliCommandFailure` if any elements are failed Args: N/A Returns: None Raises: ScrapliCommandFailure: if any elements are failed \"\"\" if self.failed: raise ScrapliCommandFailure() Classes \u00b6 MultiResponse \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 A more or less complete user-defined wrapper around list objects. Initialize list of responses Args: initlist: initial list seed data, if any Returns: None Raises: N/A Expand source code class MultiResponse(ScrapliMultiResponse): def __init__(self, initlist: Optional[Iterable[Any]] = None) -> None: \"\"\" Initialize list of responses Args: initlist: initial list seed data, if any Returns: None Raises: N/A \"\"\" super().__init__(initlist=initlist) self.data: List[Response] def __str__(self) -> str: \"\"\" Magic str method for MultiResponse class Args: N/A Returns: str: str for class object Raises: N/A \"\"\" return ( f\"{self.__class__.__name__} \" ) @property def host(self) -> str: \"\"\" Return the host of the multiresponse Args: N/A Returns: str: The host of the associated responses Raises: N/A \"\"\" try: response = self.data[0] except IndexError: return \"\" return response.host @property def failed(self) -> bool: \"\"\" Determine if any elements of MultiResponse are failed Args: N/A Returns: bool: True for failed Raises: N/A \"\"\" return any(response.failed for response in self.data) @property def result(self) -> str: \"\"\" Build a unified result from all elements of MultiResponse Args: N/A Returns: str: Unified result by combining results of all elements of MultiResponse Raises: N/A \"\"\" return \"\".join( \"\\n\".join([response.channel_input, response.result]) for response in self.data ) def raise_for_status(self) -> None: \"\"\" Raise a `ScrapliCommandFailure` if any elements are failed Args: N/A Returns: None Raises: ScrapliCommandFailure: if any elements are failed \"\"\" if self.failed: raise ScrapliCommandFailure() Ancestors (in MRO) \u00b6 collections.UserList collections.abc.MutableSequence collections.abc.Sequence collections.abc.Reversible collections.abc.Collection collections.abc.Sized collections.abc.Iterable collections.abc.Container Instance variables \u00b6 failed: bool 1 2 3 4 5 6 7 8 9 10 Determine if any elements of MultiResponse are failed Args: N/A Returns: bool: True for failed Raises: N/A host: str 1 2 3 4 5 6 7 8 9 10 Return the host of the multiresponse Args: N/A Returns: str: The host of the associated responses Raises: N/A result: str 1 2 3 4 5 6 7 8 9 10 Build a unified result from all elements of MultiResponse Args: N/A Returns: str: Unified result by combining results of all elements of MultiResponse Raises: N/A Methods \u00b6 raise_for_status \u00b6 raise_for_status(self) \u2011> None 1 2 3 4 5 6 7 8 9 10 Raise a `ScrapliCommandFailure` if any elements are failed Args: N/A Returns: None Raises: ScrapliCommandFailure: if any elements are failed Response \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 Scrapli Response Store channel_input, resulting output, and start/end/elapsed time information. Attempt to determine if command was successful or not and reflect that in a failed attribute. Args: host: host that was operated on channel_input: input that got sent down the channel textfsm_platform: ntc-templates friendly platform type genie_platform: cisco pyats/genie friendly platform type failed_when_contains: list of strings that, if present in final output, represent a failed command/interaction Returns: None Raises: N/A Expand source code class Response: def __init__( self, host: str, channel_input: str, textfsm_platform: str = \"\", genie_platform: str = \"\", failed_when_contains: Optional[Union[str, List[str]]] = None, ): \"\"\" Scrapli Response Store channel_input, resulting output, and start/end/elapsed time information. Attempt to determine if command was successful or not and reflect that in a failed attribute. Args: host: host that was operated on channel_input: input that got sent down the channel textfsm_platform: ntc-templates friendly platform type genie_platform: cisco pyats/genie friendly platform type failed_when_contains: list of strings that, if present in final output, represent a failed command/interaction Returns: None Raises: N/A \"\"\" self.host = host self.start_time = datetime.now() self.finish_time: Optional[datetime] = None self.elapsed_time: Optional[float] = None self.channel_input = channel_input self.textfsm_platform = textfsm_platform self.genie_platform = genie_platform self.raw_result: bytes = b\"\" self.result: str = \"\" if isinstance(failed_when_contains, str): failed_when_contains = [failed_when_contains] self.failed_when_contains = failed_when_contains self.failed = True def __bool__(self) -> bool: \"\"\" Magic bool method based on channel_input being failed or not Args: N/A Returns: bool: True/False if channel_input failed Raises: N/A \"\"\" return self.failed def __repr__(self) -> str: \"\"\" Magic repr method for Response class Args: N/A Returns: str: repr for class object Raises: N/A \"\"\" return ( f\"{self.__class__.__name__}(\" f\"host={self.host!r},\" f\"channel_input={self.channel_input!r},\" f\"textfsm_platform={self.textfsm_platform!r},\" f\"genie_platform={self.genie_platform!r},\" f\"failed_when_contains={self.failed_when_contains!r})\" ) def __str__(self) -> str: \"\"\" Magic str method for Response class Args: N/A Returns: str: str for class object Raises: N/A \"\"\" return f\"{self.__class__.__name__} \" def record_response(self, result: bytes) -> None: \"\"\" Record channel_input results and elapsed time of channel input/reading output Args: result: string result of channel_input Returns: None Raises: N/A \"\"\" self.finish_time = datetime.now() self.elapsed_time = (self.finish_time - self.start_time).total_seconds() self.raw_result = result try: self.result = result.decode() except UnicodeDecodeError: # sometimes we get some \"garbage\" characters, the iso encoding seems to handle these # better but unclear what the other impact is so we'll just catch exceptions and try # this encoding self.result = result.decode(encoding=\"ISO-8859-1\") if not self.failed_when_contains: self.failed = False elif all(err not in self.result for err in self.failed_when_contains): self.failed = False def textfsm_parse_output( self, template: Union[str, TextIO, None] = None, to_dict: bool = True ) -> Union[Dict[str, Any], List[Any]]: \"\"\" Parse results with textfsm, always return structured data Returns an empty list if parsing fails! Args: template: string path to textfsm template or opened textfsm template file to_dict: convert textfsm output from list of lists to list of dicts -- basically create dict from header and row data so it is easier to read/parse the output Returns: structured_result: empty list or parsed data from textfsm Raises: N/A \"\"\" if template is None: template = _textfsm_get_template( platform=self.textfsm_platform, command=self.channel_input ) if template is None: return [] template = cast(Union[str, TextIOWrapper], template) return textfsm_parse(template=template, output=self.result, to_dict=to_dict) or [] def genie_parse_output(self) -> Union[Dict[str, Any], List[Any]]: \"\"\" Parse results with genie, always return structured data Returns an empty list if parsing fails! Args: N/A Returns: structured_result: empty list or parsed data from genie Raises: N/A \"\"\" return genie_parse( platform=self.genie_platform, command=self.channel_input, output=self.result, ) def ttp_parse_output( self, template: Union[str, TextIOWrapper] ) -> Union[Dict[str, Any], List[Any]]: \"\"\" Parse results with ttp, always return structured data Returns an empty list if parsing fails! Args: template: string path to ttp template or opened ttp template file Returns: structured_result: empty list or parsed data from ttp Raises: N/A \"\"\" return ttp_parse(template=template, output=self.result) or [] def raise_for_status(self) -> None: \"\"\" Raise a `ScrapliCommandFailure` if command/config failed Args: N/A Returns: None Raises: ScrapliCommandFailure: if command/config failed \"\"\" if self.failed: raise ScrapliCommandFailure() Methods \u00b6 genie_parse_output \u00b6 genie_parse_output(self) \u2011> Union[List[Any], Dict[str, Any]] 1 2 3 4 5 6 7 8 9 10 11 12 Parse results with genie, always return structured data Returns an empty list if parsing fails! Args: N/A Returns: structured_result: empty list or parsed data from genie Raises: N/A raise_for_status \u00b6 raise_for_status(self) \u2011> None 1 2 3 4 5 6 7 8 9 10 Raise a `ScrapliCommandFailure` if command/config failed Args: N/A Returns: None Raises: ScrapliCommandFailure: if command/config failed record_response \u00b6 record_response(self, result: bytes) \u2011> None 1 2 3 4 5 6 7 8 9 10 Record channel_input results and elapsed time of channel input/reading output Args: result: string result of channel_input Returns: None Raises: N/A textfsm_parse_output \u00b6 textfsm_parse_output(self, template: Union[str, TextIO, ForwardRef(None)] = None, to_dict: bool = True) \u2011> Union[List[Any], Dict[str, Any]] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 Parse results with textfsm, always return structured data Returns an empty list if parsing fails! Args: template: string path to textfsm template or opened textfsm template file to_dict: convert textfsm output from list of lists to list of dicts -- basically create dict from header and row data so it is easier to read/parse the output Returns: structured_result: empty list or parsed data from textfsm Raises: N/A ttp_parse_output \u00b6 ttp_parse_output(self, template: Union[str, _io.TextIOWrapper]) \u2011> Union[List[Any], Dict[str, Any]] 1 2 3 4 5 6 7 8 9 10 11 12 Parse results with ttp, always return structured data Returns an empty list if parsing fails! Args: template: string path to ttp template or opened ttp template file Returns: structured_result: empty list or parsed data from ttp Raises: N/A","title":"Response"},{"location":"api_docs/response/#module-scrapliresponse","text":"scrapli.response Expand source code \"\"\"scrapli.response\"\"\" from collections import UserList from datetime import datetime from io import TextIOWrapper from typing import TYPE_CHECKING, Any, Dict, Iterable, List, Optional, TextIO, Union, cast from scrapli.exceptions import ScrapliCommandFailure from scrapli.helper import _textfsm_get_template, genie_parse, textfsm_parse, ttp_parse class Response: def __init__( self, host: str, channel_input: str, textfsm_platform: str = \"\", genie_platform: str = \"\", failed_when_contains: Optional[Union[str, List[str]]] = None, ): \"\"\" Scrapli Response Store channel_input, resulting output, and start/end/elapsed time information. Attempt to determine if command was successful or not and reflect that in a failed attribute. Args: host: host that was operated on channel_input: input that got sent down the channel textfsm_platform: ntc-templates friendly platform type genie_platform: cisco pyats/genie friendly platform type failed_when_contains: list of strings that, if present in final output, represent a failed command/interaction Returns: None Raises: N/A \"\"\" self.host = host self.start_time = datetime.now() self.finish_time: Optional[datetime] = None self.elapsed_time: Optional[float] = None self.channel_input = channel_input self.textfsm_platform = textfsm_platform self.genie_platform = genie_platform self.raw_result: bytes = b\"\" self.result: str = \"\" if isinstance(failed_when_contains, str): failed_when_contains = [failed_when_contains] self.failed_when_contains = failed_when_contains self.failed = True def __bool__(self) -> bool: \"\"\" Magic bool method based on channel_input being failed or not Args: N/A Returns: bool: True/False if channel_input failed Raises: N/A \"\"\" return self.failed def __repr__(self) -> str: \"\"\" Magic repr method for Response class Args: N/A Returns: str: repr for class object Raises: N/A \"\"\" return ( f\"{self.__class__.__name__}(\" f\"host={self.host!r},\" f\"channel_input={self.channel_input!r},\" f\"textfsm_platform={self.textfsm_platform!r},\" f\"genie_platform={self.genie_platform!r},\" f\"failed_when_contains={self.failed_when_contains!r})\" ) def __str__(self) -> str: \"\"\" Magic str method for Response class Args: N/A Returns: str: str for class object Raises: N/A \"\"\" return f\"{self.__class__.__name__} \" def record_response(self, result: bytes) -> None: \"\"\" Record channel_input results and elapsed time of channel input/reading output Args: result: string result of channel_input Returns: None Raises: N/A \"\"\" self.finish_time = datetime.now() self.elapsed_time = (self.finish_time - self.start_time).total_seconds() self.raw_result = result try: self.result = result.decode() except UnicodeDecodeError: # sometimes we get some \"garbage\" characters, the iso encoding seems to handle these # better but unclear what the other impact is so we'll just catch exceptions and try # this encoding self.result = result.decode(encoding=\"ISO-8859-1\") if not self.failed_when_contains: self.failed = False elif all(err not in self.result for err in self.failed_when_contains): self.failed = False def textfsm_parse_output( self, template: Union[str, TextIO, None] = None, to_dict: bool = True ) -> Union[Dict[str, Any], List[Any]]: \"\"\" Parse results with textfsm, always return structured data Returns an empty list if parsing fails! Args: template: string path to textfsm template or opened textfsm template file to_dict: convert textfsm output from list of lists to list of dicts -- basically create dict from header and row data so it is easier to read/parse the output Returns: structured_result: empty list or parsed data from textfsm Raises: N/A \"\"\" if template is None: template = _textfsm_get_template( platform=self.textfsm_platform, command=self.channel_input ) if template is None: return [] template = cast(Union[str, TextIOWrapper], template) return textfsm_parse(template=template, output=self.result, to_dict=to_dict) or [] def genie_parse_output(self) -> Union[Dict[str, Any], List[Any]]: \"\"\" Parse results with genie, always return structured data Returns an empty list if parsing fails! Args: N/A Returns: structured_result: empty list or parsed data from genie Raises: N/A \"\"\" return genie_parse( platform=self.genie_platform, command=self.channel_input, output=self.result, ) def ttp_parse_output( self, template: Union[str, TextIOWrapper] ) -> Union[Dict[str, Any], List[Any]]: \"\"\" Parse results with ttp, always return structured data Returns an empty list if parsing fails! Args: template: string path to ttp template or opened ttp template file Returns: structured_result: empty list or parsed data from ttp Raises: N/A \"\"\" return ttp_parse(template=template, output=self.result) or [] def raise_for_status(self) -> None: \"\"\" Raise a `ScrapliCommandFailure` if command/config failed Args: N/A Returns: None Raises: ScrapliCommandFailure: if command/config failed \"\"\" if self.failed: raise ScrapliCommandFailure() if TYPE_CHECKING: ScrapliMultiResponse = UserList[Response] # pylint: disable=E1136; # pragma: no cover else: ScrapliMultiResponse = UserList class MultiResponse(ScrapliMultiResponse): def __init__(self, initlist: Optional[Iterable[Any]] = None) -> None: \"\"\" Initialize list of responses Args: initlist: initial list seed data, if any Returns: None Raises: N/A \"\"\" super().__init__(initlist=initlist) self.data: List[Response] def __str__(self) -> str: \"\"\" Magic str method for MultiResponse class Args: N/A Returns: str: str for class object Raises: N/A \"\"\" return ( f\"{self.__class__.__name__} \" ) @property def host(self) -> str: \"\"\" Return the host of the multiresponse Args: N/A Returns: str: The host of the associated responses Raises: N/A \"\"\" try: response = self.data[0] except IndexError: return \"\" return response.host @property def failed(self) -> bool: \"\"\" Determine if any elements of MultiResponse are failed Args: N/A Returns: bool: True for failed Raises: N/A \"\"\" return any(response.failed for response in self.data) @property def result(self) -> str: \"\"\" Build a unified result from all elements of MultiResponse Args: N/A Returns: str: Unified result by combining results of all elements of MultiResponse Raises: N/A \"\"\" return \"\".join( \"\\n\".join([response.channel_input, response.result]) for response in self.data ) def raise_for_status(self) -> None: \"\"\" Raise a `ScrapliCommandFailure` if any elements are failed Args: N/A Returns: None Raises: ScrapliCommandFailure: if any elements are failed \"\"\" if self.failed: raise ScrapliCommandFailure()","title":"Module scrapli.response"},{"location":"api_docs/response/#classes","text":"","title":"Classes"},{"location":"api_docs/response/#multiresponse","text":"1 2 3 4 5 6 7 8 9 10 11 12 A more or less complete user-defined wrapper around list objects. Initialize list of responses Args: initlist: initial list seed data, if any Returns: None Raises: N/A Expand source code class MultiResponse(ScrapliMultiResponse): def __init__(self, initlist: Optional[Iterable[Any]] = None) -> None: \"\"\" Initialize list of responses Args: initlist: initial list seed data, if any Returns: None Raises: N/A \"\"\" super().__init__(initlist=initlist) self.data: List[Response] def __str__(self) -> str: \"\"\" Magic str method for MultiResponse class Args: N/A Returns: str: str for class object Raises: N/A \"\"\" return ( f\"{self.__class__.__name__} \" ) @property def host(self) -> str: \"\"\" Return the host of the multiresponse Args: N/A Returns: str: The host of the associated responses Raises: N/A \"\"\" try: response = self.data[0] except IndexError: return \"\" return response.host @property def failed(self) -> bool: \"\"\" Determine if any elements of MultiResponse are failed Args: N/A Returns: bool: True for failed Raises: N/A \"\"\" return any(response.failed for response in self.data) @property def result(self) -> str: \"\"\" Build a unified result from all elements of MultiResponse Args: N/A Returns: str: Unified result by combining results of all elements of MultiResponse Raises: N/A \"\"\" return \"\".join( \"\\n\".join([response.channel_input, response.result]) for response in self.data ) def raise_for_status(self) -> None: \"\"\" Raise a `ScrapliCommandFailure` if any elements are failed Args: N/A Returns: None Raises: ScrapliCommandFailure: if any elements are failed \"\"\" if self.failed: raise ScrapliCommandFailure()","title":"MultiResponse"},{"location":"api_docs/response/#ancestors-in-mro","text":"collections.UserList collections.abc.MutableSequence collections.abc.Sequence collections.abc.Reversible collections.abc.Collection collections.abc.Sized collections.abc.Iterable collections.abc.Container","title":"Ancestors (in MRO)"},{"location":"api_docs/response/#instance-variables","text":"failed: bool 1 2 3 4 5 6 7 8 9 10 Determine if any elements of MultiResponse are failed Args: N/A Returns: bool: True for failed Raises: N/A host: str 1 2 3 4 5 6 7 8 9 10 Return the host of the multiresponse Args: N/A Returns: str: The host of the associated responses Raises: N/A result: str 1 2 3 4 5 6 7 8 9 10 Build a unified result from all elements of MultiResponse Args: N/A Returns: str: Unified result by combining results of all elements of MultiResponse Raises: N/A","title":"Instance variables"},{"location":"api_docs/response/#methods","text":"","title":"Methods"},{"location":"api_docs/response/#raise_for_status","text":"raise_for_status(self) \u2011> None 1 2 3 4 5 6 7 8 9 10 Raise a `ScrapliCommandFailure` if any elements are failed Args: N/A Returns: None Raises: ScrapliCommandFailure: if any elements are failed","title":"raise_for_status"},{"location":"api_docs/response/#response","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 Scrapli Response Store channel_input, resulting output, and start/end/elapsed time information. Attempt to determine if command was successful or not and reflect that in a failed attribute. Args: host: host that was operated on channel_input: input that got sent down the channel textfsm_platform: ntc-templates friendly platform type genie_platform: cisco pyats/genie friendly platform type failed_when_contains: list of strings that, if present in final output, represent a failed command/interaction Returns: None Raises: N/A Expand source code class Response: def __init__( self, host: str, channel_input: str, textfsm_platform: str = \"\", genie_platform: str = \"\", failed_when_contains: Optional[Union[str, List[str]]] = None, ): \"\"\" Scrapli Response Store channel_input, resulting output, and start/end/elapsed time information. Attempt to determine if command was successful or not and reflect that in a failed attribute. Args: host: host that was operated on channel_input: input that got sent down the channel textfsm_platform: ntc-templates friendly platform type genie_platform: cisco pyats/genie friendly platform type failed_when_contains: list of strings that, if present in final output, represent a failed command/interaction Returns: None Raises: N/A \"\"\" self.host = host self.start_time = datetime.now() self.finish_time: Optional[datetime] = None self.elapsed_time: Optional[float] = None self.channel_input = channel_input self.textfsm_platform = textfsm_platform self.genie_platform = genie_platform self.raw_result: bytes = b\"\" self.result: str = \"\" if isinstance(failed_when_contains, str): failed_when_contains = [failed_when_contains] self.failed_when_contains = failed_when_contains self.failed = True def __bool__(self) -> bool: \"\"\" Magic bool method based on channel_input being failed or not Args: N/A Returns: bool: True/False if channel_input failed Raises: N/A \"\"\" return self.failed def __repr__(self) -> str: \"\"\" Magic repr method for Response class Args: N/A Returns: str: repr for class object Raises: N/A \"\"\" return ( f\"{self.__class__.__name__}(\" f\"host={self.host!r},\" f\"channel_input={self.channel_input!r},\" f\"textfsm_platform={self.textfsm_platform!r},\" f\"genie_platform={self.genie_platform!r},\" f\"failed_when_contains={self.failed_when_contains!r})\" ) def __str__(self) -> str: \"\"\" Magic str method for Response class Args: N/A Returns: str: str for class object Raises: N/A \"\"\" return f\"{self.__class__.__name__} \" def record_response(self, result: bytes) -> None: \"\"\" Record channel_input results and elapsed time of channel input/reading output Args: result: string result of channel_input Returns: None Raises: N/A \"\"\" self.finish_time = datetime.now() self.elapsed_time = (self.finish_time - self.start_time).total_seconds() self.raw_result = result try: self.result = result.decode() except UnicodeDecodeError: # sometimes we get some \"garbage\" characters, the iso encoding seems to handle these # better but unclear what the other impact is so we'll just catch exceptions and try # this encoding self.result = result.decode(encoding=\"ISO-8859-1\") if not self.failed_when_contains: self.failed = False elif all(err not in self.result for err in self.failed_when_contains): self.failed = False def textfsm_parse_output( self, template: Union[str, TextIO, None] = None, to_dict: bool = True ) -> Union[Dict[str, Any], List[Any]]: \"\"\" Parse results with textfsm, always return structured data Returns an empty list if parsing fails! Args: template: string path to textfsm template or opened textfsm template file to_dict: convert textfsm output from list of lists to list of dicts -- basically create dict from header and row data so it is easier to read/parse the output Returns: structured_result: empty list or parsed data from textfsm Raises: N/A \"\"\" if template is None: template = _textfsm_get_template( platform=self.textfsm_platform, command=self.channel_input ) if template is None: return [] template = cast(Union[str, TextIOWrapper], template) return textfsm_parse(template=template, output=self.result, to_dict=to_dict) or [] def genie_parse_output(self) -> Union[Dict[str, Any], List[Any]]: \"\"\" Parse results with genie, always return structured data Returns an empty list if parsing fails! Args: N/A Returns: structured_result: empty list or parsed data from genie Raises: N/A \"\"\" return genie_parse( platform=self.genie_platform, command=self.channel_input, output=self.result, ) def ttp_parse_output( self, template: Union[str, TextIOWrapper] ) -> Union[Dict[str, Any], List[Any]]: \"\"\" Parse results with ttp, always return structured data Returns an empty list if parsing fails! Args: template: string path to ttp template or opened ttp template file Returns: structured_result: empty list or parsed data from ttp Raises: N/A \"\"\" return ttp_parse(template=template, output=self.result) or [] def raise_for_status(self) -> None: \"\"\" Raise a `ScrapliCommandFailure` if command/config failed Args: N/A Returns: None Raises: ScrapliCommandFailure: if command/config failed \"\"\" if self.failed: raise ScrapliCommandFailure()","title":"Response"},{"location":"api_docs/response/#methods_1","text":"","title":"Methods"},{"location":"api_docs/response/#genie_parse_output","text":"genie_parse_output(self) \u2011> Union[List[Any], Dict[str, Any]] 1 2 3 4 5 6 7 8 9 10 11 12 Parse results with genie, always return structured data Returns an empty list if parsing fails! Args: N/A Returns: structured_result: empty list or parsed data from genie Raises: N/A","title":"genie_parse_output"},{"location":"api_docs/response/#raise_for_status_1","text":"raise_for_status(self) \u2011> None 1 2 3 4 5 6 7 8 9 10 Raise a `ScrapliCommandFailure` if command/config failed Args: N/A Returns: None Raises: ScrapliCommandFailure: if command/config failed","title":"raise_for_status"},{"location":"api_docs/response/#record_response","text":"record_response(self, result: bytes) \u2011> None 1 2 3 4 5 6 7 8 9 10 Record channel_input results and elapsed time of channel input/reading output Args: result: string result of channel_input Returns: None Raises: N/A","title":"record_response"},{"location":"api_docs/response/#textfsm_parse_output","text":"textfsm_parse_output(self, template: Union[str, TextIO, ForwardRef(None)] = None, to_dict: bool = True) \u2011> Union[List[Any], Dict[str, Any]] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 Parse results with textfsm, always return structured data Returns an empty list if parsing fails! Args: template: string path to textfsm template or opened textfsm template file to_dict: convert textfsm output from list of lists to list of dicts -- basically create dict from header and row data so it is easier to read/parse the output Returns: structured_result: empty list or parsed data from textfsm Raises: N/A","title":"textfsm_parse_output"},{"location":"api_docs/response/#ttp_parse_output","text":"ttp_parse_output(self, template: Union[str, _io.TextIOWrapper]) \u2011> Union[List[Any], Dict[str, Any]] 1 2 3 4 5 6 7 8 9 10 11 12 Parse results with ttp, always return structured data Returns an empty list if parsing fails! Args: template: string path to ttp template or opened ttp template file Returns: structured_result: empty list or parsed data from ttp Raises: N/A","title":"ttp_parse_output"},{"location":"api_docs/ssh_config/","text":"window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting()) Module scrapli.ssh_config \u00b6 scrapli.ssh_config Expand source code \"\"\"scrapli.ssh_config\"\"\" import base64 import hmac import os import re import shlex import sys from copy import deepcopy from typing import Dict, Optional from scrapli.exceptions import ScrapliTypeError if sys.version_info >= (3, 8): Match = re.Match else: from typing import Match # pragma: no cover HOST_ATTRS = ( \"port\", \"user\", \"address_family\", \"bind_address\", \"connect_timeout\", \"identities_only\", \"identity_file\", \"keyboard_interactive\", \"password_authentication\", \"preferred_authentication\", ) class SSHConfig: _config_files: Dict[str, \"SSHConfig\"] = {} def __init__(self, ssh_config_file: str) -> None: \"\"\" Initialize SSHConfig Object Parse OpenSSH config file Try to load the following data for all entries in config file: Host HostName Port User *AddressFamily *BindAddress *ConnectTimeout IdentitiesOnly IdentityFile *KbdInteractiveAuthentication *PasswordAuthentication *PreferredAuthentications * items are mostly ready to load but are unused in scrapli right now so are not being set at this point. NOTE: this does *not* accept duplicate \"*\" entries -- the final \"*\" entry will overwrite any previous \"*\" entries. In general for system transport this shouldn't matter much because scrapli only cares about parsing the config file to see if a key (any key) exists for a given host (we care about that because ideally we use \"pipes\" auth, but this is only an option if we have a key to auth with). Args: ssh_config_file: string path to ssh configuration file Returns: None Raises: ScrapliTypeError: if non-string value provided for ssh_config_file \"\"\" if not isinstance(ssh_config_file, str): raise ScrapliTypeError(f\"`ssh_config_file` expected str, got {type(ssh_config_file)}\") self.ssh_config_file = os.path.expanduser(ssh_config_file) if self.ssh_config_file: with open(self.ssh_config_file, \"r\", encoding=\"utf-8\") as f: self.ssh_config = f.read() self.hosts = self._parse() if not self.hosts: self.hosts = {} if \"*\" not in self.hosts: self.hosts[\"*\"] = Host() self.hosts[\"*\"].hosts = \"*\" else: self.hosts = {} self.hosts[\"*\"] = Host() self.hosts[\"*\"].hosts = \"*\" # finally merge all args from less specific hosts into the more specific hosts, preserving # the options from the more specific hosts of course self._merge_hosts() def __str__(self) -> str: \"\"\" Magic str method for SSHConfig class Args: N/A Returns: str: string representation of object Raises: N/A \"\"\" return \"SSHConfig Object\" def __repr__(self) -> str: \"\"\" Magic repr method for SSHConfig class Args: N/A Returns: str: repr for class object Raises: N/A \"\"\" class_dict = self.__dict__.copy() del class_dict[\"ssh_config\"] return f\"SSHConfig {class_dict}\" def __bool__(self) -> bool: \"\"\" Magic bool method; return True if ssh_config_file Args: N/A Returns: bool: True/False if ssh_config_file Raises: N/A \"\"\" return bool(self.ssh_config) @staticmethod def _strip_comments(line: str) -> str: \"\"\" Strip out comments from ssh config file lines Args: line: to strip comments from Returns: str: rejoined ssh config file line after stripping comments Raises: N/A \"\"\" line = \" \".join(shlex.split(line, comments=True)) return line def _parse(self) -> Dict[str, \"Host\"]: \"\"\" Parse SSH configuration file Args: N/A Returns: discovered_hosts: dict of host objects discovered in ssh config file Raises: N/A \"\"\" # uncomment next line and handle global patterns (stuff before hosts) at some point # global_config_pattern = re.compile(r\"^.*?\\b(?=host)\", flags=re.I | re.S) # use word boundaries with a positive lookahead to get everything between the word host # need to do this as whitespace/formatting is not really a thing in ssh_config file # match host\\s to ensure we don't pick up hostname and split things there accidentally host_pattern = re.compile(r\"\\bhost.*?\\b(?=host\\s|\\s+$|$)\", flags=re.I | re.S) host_entries = re.findall(pattern=host_pattern, string=self.ssh_config) discovered_hosts: Dict[str, Host] = {} if not host_entries: return discovered_hosts # do we need to add whitespace between match and end of line to ensure we match correctly? hosts_pattern = re.compile(r\"^\\s*host[\\s=]+(.*)$\", flags=re.I | re.M) hostname_pattern = re.compile(r\"^\\s*hostname[\\s=]+([\\w.-]*)$\", flags=re.I | re.M) port_pattern = re.compile(r\"^\\s*port[\\s=]+([\\d]*)$\", flags=re.I | re.M) user_pattern = re.compile(r\"^\\s*user[\\s=]+([\\w]*)$\", flags=re.I | re.M) # address_family_pattern = None # bind_address_pattern = None # connect_timeout_pattern = None identities_only_pattern = re.compile( r\"^\\s*identitiesonly[\\s=]+(yes|no)$\", flags=re.I | re.M ) identity_file_pattern = re.compile( r\"^\\s*identityfile[\\s=]+([\\w.\\/\\@~-]*)$\", flags=re.I | re.M ) # keyboard_interactive_pattern = None # password_authentication_pattern = None # preferred_authentication_pattern = None for host_entry in host_entries: host = Host() host_line = re.search(pattern=hosts_pattern, string=host_entry) if isinstance(host_line, Match): host.hosts = self._strip_comments(host_line.groups()[0]) else: host.hosts = \"\" hostname = re.search(pattern=hostname_pattern, string=host_entry) if isinstance(hostname, Match): host.hostname = self._strip_comments(hostname.groups()[0]) port = re.search(pattern=port_pattern, string=host_entry) if isinstance(port, Match): host.port = int(self._strip_comments(port.groups()[0])) user = re.search(pattern=user_pattern, string=host_entry) if isinstance(user, Match): host.user = self._strip_comments(user.groups()[0]) # address_family = re.search(user_pattern, host_entry[0]) # bind_address = re.search(user_pattern, host_entry[0]) # connect_timeout = re.search(user_pattern, host_entry[0]) identities_only = re.search(pattern=identities_only_pattern, string=host_entry) if isinstance(identities_only, Match): host.identities_only = self._strip_comments(identities_only.groups()[0]) identity_file = re.search(pattern=identity_file_pattern, string=host_entry) if isinstance(identity_file, Match): host.identity_file = os.path.expanduser( self._strip_comments(identity_file.groups()[0]) ) # keyboard_interactive = re.search(user_pattern, host_entry[0]) # password_authentication = re.search(user_pattern, host_entry[0]) # preferred_authentication = re.search(user_pattern, host_entry[0]) discovered_hosts[host.hosts] = host return discovered_hosts def _merge_hosts(self) -> None: \"\"\" Merge less specific host pattern data into a given host Args: N/A Returns: None Raises: N/A \"\"\" for host in self.hosts: # pylint: disable=C0206 _current_hosts = deepcopy(self.hosts) while True: fuzzy_match = self._lookup_fuzzy_match(host=host, hosts=_current_hosts) for attr in HOST_ATTRS: if not getattr(self.hosts[host], attr): setattr(self.hosts[host], attr, getattr(self.hosts[fuzzy_match], attr)) try: _current_hosts.pop(fuzzy_match) except KeyError: # this means we hit the \"*\" entry twice and we can bail out break def _lookup_fuzzy_match(self, host: str, hosts: Optional[Dict[str, \"Host\"]] = None) -> str: \"\"\" Look up fuzzy matched hosts Get the best match ssh config Host entry for a given host; this allows for using the splat and question-mark operators in ssh config file Args: host: host to lookup in discovered_hosts dict hosts: hosts dict to operate on; used for passing in partial dict of hosts while performing merge operations Returns: str: Nearest match (if applicable) host or `*` if none found Raises: N/A \"\"\" hosts = hosts or self.hosts possible_matches = [] for host_entry in hosts.keys(): host_list = host_entry.split() for host_pattern in host_list: # replace periods with literal period # replace asterisk (match 0 or more things) with appropriate regex # replace question mark (match one thing) with appropriate regex cleaned_host_pattern = ( host_pattern.replace(\".\", r\"\\.\").replace(\"*\", r\"(.*)\").replace(\"?\", r\"(.)\") ) # compile with case insensitive search_pattern = re.compile(cleaned_host_pattern, flags=re.I) result = re.search(pattern=search_pattern, string=host) # if we get a result, append it and the original pattern to the possible matches if result: possible_matches.append((result, host_entry)) # initialize a None best match current_match = None for match in possible_matches: if current_match is None: current_match = match # count how many chars were replaced to get regex to work chars_replaced = sum( end_char - start_char for start_char, end_char in match[0].regs[1:] ) # count how many chars were replaced to get regex to work on best match best_match_chars_replaced = sum( end_char - start_char for start_char, end_char in current_match[0].regs[1:] ) # if match replaced less chars than \"best_match\" we have a new best match if chars_replaced < best_match_chars_replaced: current_match = match return current_match[1] if current_match is not None else \"*\" def lookup(self, host: str) -> \"Host\": \"\"\" Lookup a given host Args: host: host to lookup in discovered_hosts dict Returns: Host: best matched host from parsed ssh config file hosts, \"*\" if no better match found Raises: N/A \"\"\" # return exact 1:1 match if exists if host in self.hosts: return self.hosts[host] # return match if given host is an exact match for a host entry for host_line, host_entry in self.hosts.items(): host_list = host_line.split() if host in host_list: return host_entry # otherwise need to select the most correct host entry fuzzy_match = self._lookup_fuzzy_match(host) return self.hosts[fuzzy_match] class Host: def __init__(self) -> None: \"\"\" Host Object Create a Host object based on ssh config file information \"\"\" self.hosts: str = \"\" self.hostname: Optional[str] = None self.port: Optional[int] = None self.user: str = \"\" self.address_family: Optional[str] = None self.bind_address: Optional[str] = None self.connect_timeout: Optional[str] = None self.identities_only: Optional[str] = None self.identity_file: Optional[str] = None self.keyboard_interactive: Optional[str] = None self.password_authentication: Optional[str] = None self.preferred_authentication: Optional[str] = None def __str__(self) -> str: \"\"\" Magic str method for HostEntry class Args: N/A Returns: str: string for class object Raises: N/A \"\"\" return f\"Host: {self.hosts}\" def __repr__(self) -> str: \"\"\" Magic repr method for HostEntry class Args: N/A Returns: str: repr for class object Raises: N/A \"\"\" class_dict = self.__dict__.copy() return f\"Host {class_dict}\" class SSHKnownHosts: def __init__(self, ssh_known_hosts_file: str) -> None: \"\"\" Initialize SSHKnownHosts Object Parse OpenSSH known hosts file Try to load the following data for all entries in known hosts file: Host Key Type Public Key Args: ssh_known_hosts_file: string path to ssh known hosts file Returns: None Raises: TypeError: if non-string value provided for ssh_known_hosts \"\"\" if not isinstance(ssh_known_hosts_file, str): raise TypeError( f\"`ssh_known_hosts_file` expected str, got {type(ssh_known_hosts_file)}\" ) self.ssh_known_hosts_file = os.path.expanduser(ssh_known_hosts_file) if self.ssh_known_hosts_file: with open(self.ssh_known_hosts_file, \"r\", encoding=\"utf-8\") as f: self.ssh_known_hosts = f.read() self.hosts = self._parse() if not self.hosts: self.hosts = {} else: self.hosts = {} def _parse(self) -> Dict[str, Dict[str, str]]: \"\"\" Parse OpenSSH known hosts file Args: N/A Returns: known_hosts: dict of host public keys discovered in known hosts file Raises: N/A \"\"\" # match any non whitespace from start of the line... this should cover v4/v6/names # skip a space and match any word (also w/ hyphen) to get key type, lastly # match any non whitespace to the end of the line to get the public key host_pattern = re.compile(r\"^\\S+\\s[\\w\\-]+\\s\\S+$\", flags=re.I | re.M) host_entries = re.findall(pattern=host_pattern, string=self.ssh_known_hosts) known_hosts: Dict[str, Dict[str, str]] = {} for host_entry in host_entries: host, key_type, public_key = host_entry.split() # to simplify lookups down the line, split any list of hosts and just create a unique # entry per host for individual_host in host.split(\",\"): known_hosts[individual_host] = {\"key_type\": key_type, \"public_key\": public_key} return known_hosts def lookup(self, host: str) -> Dict[str, str]: \"\"\" Lookup a given host's public key Args: host: host to lookup in known_hosts dict Returns: host_public_key: matched host public key from parsed ssh known hosts file, empty dict if not found Raises: N/A \"\"\" # return exact 1:1 match if exists if host in self.hosts: return self.hosts[host] # return match if given host is an exact match for a hashed host entry raw_host = host.encode(encoding=\"utf-8\") for host_id, host_public_key in self.hosts.items(): if host_id.startswith(\"|1|\"): _, _, encoded_salt, encoded_hashed_host = host_id.split(\"|\") raw_salt = base64.b64decode(encoded_salt) raw_hashed_host = base64.b64decode(encoded_hashed_host) if hmac.HMAC(raw_salt, raw_host, \"sha1\").digest() == raw_hashed_host: return host_public_key # otherwise return empty dict return {} def ssh_config_factory(ssh_config_file: str) -> SSHConfig: \"\"\" Sorta kinda make a singleton out of SSHConfig Not exactly a singleton in that its more like a singleton *per ssh config file path* since a user may elect to use different ssh config files for different things! The only place this should ever be called from is the base driver which has already resolved the ssh config file path -- so we should get only fully qualified paths. We then use this path as the key in the `_config_files` dict of the SSHConfig object, storing the actual object we instantiate as the value. This allows us to only ever create one instance of SSHConfig for each provided ssh config file! Args: ssh_config_file: fully qualified string path to ssh config file Returns: SSHConfig: instantiated SSHConfig object Raises: N/A \"\"\" config_files = SSHConfig._config_files # pylint: disable=W0212 if ssh_config_file in config_files: return config_files[ssh_config_file] ssh_config = SSHConfig(ssh_config_file=ssh_config_file) config_files[ssh_config_file] = ssh_config return ssh_config Functions \u00b6 ssh_config_factory \u00b6 ssh_config_factory(ssh_config_file: str) \u2011> scrapli.ssh_config.SSHConfig 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 Sorta kinda make a singleton out of SSHConfig Not exactly a singleton in that its more like a singleton *per ssh config file path* since a user may elect to use different ssh config files for different things! The only place this should ever be called from is the base driver which has already resolved the ssh config file path -- so we should get only fully qualified paths. We then use this path as the key in the `_config_files` dict of the SSHConfig object, storing the actual object we instantiate as the value. This allows us to only ever create one instance of SSHConfig for each provided ssh config file! Args: ssh_config_file: fully qualified string path to ssh config file Returns: SSHConfig: instantiated SSHConfig object Raises: N/A Classes \u00b6 Host \u00b6 1 2 3 Host Object Create a Host object based on ssh config file information Expand source code class Host: def __init__(self) -> None: \"\"\" Host Object Create a Host object based on ssh config file information \"\"\" self.hosts: str = \"\" self.hostname: Optional[str] = None self.port: Optional[int] = None self.user: str = \"\" self.address_family: Optional[str] = None self.bind_address: Optional[str] = None self.connect_timeout: Optional[str] = None self.identities_only: Optional[str] = None self.identity_file: Optional[str] = None self.keyboard_interactive: Optional[str] = None self.password_authentication: Optional[str] = None self.preferred_authentication: Optional[str] = None def __str__(self) -> str: \"\"\" Magic str method for HostEntry class Args: N/A Returns: str: string for class object Raises: N/A \"\"\" return f\"Host: {self.hosts}\" def __repr__(self) -> str: \"\"\" Magic repr method for HostEntry class Args: N/A Returns: str: repr for class object Raises: N/A \"\"\" class_dict = self.__dict__.copy() return f\"Host {class_dict}\" SSHConfig \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 Initialize SSHConfig Object Parse OpenSSH config file Try to load the following data for all entries in config file: Host HostName Port User *AddressFamily *BindAddress *ConnectTimeout IdentitiesOnly IdentityFile *KbdInteractiveAuthentication *PasswordAuthentication *PreferredAuthentications * items are mostly ready to load but are unused in scrapli right now so are not being set at this point. NOTE: this does *not* accept duplicate \"*\" entries -- the final \"*\" entry will overwrite any previous \"*\" entries. In general for system transport this shouldn't matter much because scrapli only cares about parsing the config file to see if a key (any key) exists for a given host (we care about that because ideally we use \"pipes\" auth, but this is only an option if we have a key to auth with). Args: ssh_config_file: string path to ssh configuration file Returns: None Raises: ScrapliTypeError: if non-string value provided for ssh_config_file Expand source code class SSHConfig: _config_files: Dict[str, \"SSHConfig\"] = {} def __init__(self, ssh_config_file: str) -> None: \"\"\" Initialize SSHConfig Object Parse OpenSSH config file Try to load the following data for all entries in config file: Host HostName Port User *AddressFamily *BindAddress *ConnectTimeout IdentitiesOnly IdentityFile *KbdInteractiveAuthentication *PasswordAuthentication *PreferredAuthentications * items are mostly ready to load but are unused in scrapli right now so are not being set at this point. NOTE: this does *not* accept duplicate \"*\" entries -- the final \"*\" entry will overwrite any previous \"*\" entries. In general for system transport this shouldn't matter much because scrapli only cares about parsing the config file to see if a key (any key) exists for a given host (we care about that because ideally we use \"pipes\" auth, but this is only an option if we have a key to auth with). Args: ssh_config_file: string path to ssh configuration file Returns: None Raises: ScrapliTypeError: if non-string value provided for ssh_config_file \"\"\" if not isinstance(ssh_config_file, str): raise ScrapliTypeError(f\"`ssh_config_file` expected str, got {type(ssh_config_file)}\") self.ssh_config_file = os.path.expanduser(ssh_config_file) if self.ssh_config_file: with open(self.ssh_config_file, \"r\", encoding=\"utf-8\") as f: self.ssh_config = f.read() self.hosts = self._parse() if not self.hosts: self.hosts = {} if \"*\" not in self.hosts: self.hosts[\"*\"] = Host() self.hosts[\"*\"].hosts = \"*\" else: self.hosts = {} self.hosts[\"*\"] = Host() self.hosts[\"*\"].hosts = \"*\" # finally merge all args from less specific hosts into the more specific hosts, preserving # the options from the more specific hosts of course self._merge_hosts() def __str__(self) -> str: \"\"\" Magic str method for SSHConfig class Args: N/A Returns: str: string representation of object Raises: N/A \"\"\" return \"SSHConfig Object\" def __repr__(self) -> str: \"\"\" Magic repr method for SSHConfig class Args: N/A Returns: str: repr for class object Raises: N/A \"\"\" class_dict = self.__dict__.copy() del class_dict[\"ssh_config\"] return f\"SSHConfig {class_dict}\" def __bool__(self) -> bool: \"\"\" Magic bool method; return True if ssh_config_file Args: N/A Returns: bool: True/False if ssh_config_file Raises: N/A \"\"\" return bool(self.ssh_config) @staticmethod def _strip_comments(line: str) -> str: \"\"\" Strip out comments from ssh config file lines Args: line: to strip comments from Returns: str: rejoined ssh config file line after stripping comments Raises: N/A \"\"\" line = \" \".join(shlex.split(line, comments=True)) return line def _parse(self) -> Dict[str, \"Host\"]: \"\"\" Parse SSH configuration file Args: N/A Returns: discovered_hosts: dict of host objects discovered in ssh config file Raises: N/A \"\"\" # uncomment next line and handle global patterns (stuff before hosts) at some point # global_config_pattern = re.compile(r\"^.*?\\b(?=host)\", flags=re.I | re.S) # use word boundaries with a positive lookahead to get everything between the word host # need to do this as whitespace/formatting is not really a thing in ssh_config file # match host\\s to ensure we don't pick up hostname and split things there accidentally host_pattern = re.compile(r\"\\bhost.*?\\b(?=host\\s|\\s+$|$)\", flags=re.I | re.S) host_entries = re.findall(pattern=host_pattern, string=self.ssh_config) discovered_hosts: Dict[str, Host] = {} if not host_entries: return discovered_hosts # do we need to add whitespace between match and end of line to ensure we match correctly? hosts_pattern = re.compile(r\"^\\s*host[\\s=]+(.*)$\", flags=re.I | re.M) hostname_pattern = re.compile(r\"^\\s*hostname[\\s=]+([\\w.-]*)$\", flags=re.I | re.M) port_pattern = re.compile(r\"^\\s*port[\\s=]+([\\d]*)$\", flags=re.I | re.M) user_pattern = re.compile(r\"^\\s*user[\\s=]+([\\w]*)$\", flags=re.I | re.M) # address_family_pattern = None # bind_address_pattern = None # connect_timeout_pattern = None identities_only_pattern = re.compile( r\"^\\s*identitiesonly[\\s=]+(yes|no)$\", flags=re.I | re.M ) identity_file_pattern = re.compile( r\"^\\s*identityfile[\\s=]+([\\w.\\/\\@~-]*)$\", flags=re.I | re.M ) # keyboard_interactive_pattern = None # password_authentication_pattern = None # preferred_authentication_pattern = None for host_entry in host_entries: host = Host() host_line = re.search(pattern=hosts_pattern, string=host_entry) if isinstance(host_line, Match): host.hosts = self._strip_comments(host_line.groups()[0]) else: host.hosts = \"\" hostname = re.search(pattern=hostname_pattern, string=host_entry) if isinstance(hostname, Match): host.hostname = self._strip_comments(hostname.groups()[0]) port = re.search(pattern=port_pattern, string=host_entry) if isinstance(port, Match): host.port = int(self._strip_comments(port.groups()[0])) user = re.search(pattern=user_pattern, string=host_entry) if isinstance(user, Match): host.user = self._strip_comments(user.groups()[0]) # address_family = re.search(user_pattern, host_entry[0]) # bind_address = re.search(user_pattern, host_entry[0]) # connect_timeout = re.search(user_pattern, host_entry[0]) identities_only = re.search(pattern=identities_only_pattern, string=host_entry) if isinstance(identities_only, Match): host.identities_only = self._strip_comments(identities_only.groups()[0]) identity_file = re.search(pattern=identity_file_pattern, string=host_entry) if isinstance(identity_file, Match): host.identity_file = os.path.expanduser( self._strip_comments(identity_file.groups()[0]) ) # keyboard_interactive = re.search(user_pattern, host_entry[0]) # password_authentication = re.search(user_pattern, host_entry[0]) # preferred_authentication = re.search(user_pattern, host_entry[0]) discovered_hosts[host.hosts] = host return discovered_hosts def _merge_hosts(self) -> None: \"\"\" Merge less specific host pattern data into a given host Args: N/A Returns: None Raises: N/A \"\"\" for host in self.hosts: # pylint: disable=C0206 _current_hosts = deepcopy(self.hosts) while True: fuzzy_match = self._lookup_fuzzy_match(host=host, hosts=_current_hosts) for attr in HOST_ATTRS: if not getattr(self.hosts[host], attr): setattr(self.hosts[host], attr, getattr(self.hosts[fuzzy_match], attr)) try: _current_hosts.pop(fuzzy_match) except KeyError: # this means we hit the \"*\" entry twice and we can bail out break def _lookup_fuzzy_match(self, host: str, hosts: Optional[Dict[str, \"Host\"]] = None) -> str: \"\"\" Look up fuzzy matched hosts Get the best match ssh config Host entry for a given host; this allows for using the splat and question-mark operators in ssh config file Args: host: host to lookup in discovered_hosts dict hosts: hosts dict to operate on; used for passing in partial dict of hosts while performing merge operations Returns: str: Nearest match (if applicable) host or `*` if none found Raises: N/A \"\"\" hosts = hosts or self.hosts possible_matches = [] for host_entry in hosts.keys(): host_list = host_entry.split() for host_pattern in host_list: # replace periods with literal period # replace asterisk (match 0 or more things) with appropriate regex # replace question mark (match one thing) with appropriate regex cleaned_host_pattern = ( host_pattern.replace(\".\", r\"\\.\").replace(\"*\", r\"(.*)\").replace(\"?\", r\"(.)\") ) # compile with case insensitive search_pattern = re.compile(cleaned_host_pattern, flags=re.I) result = re.search(pattern=search_pattern, string=host) # if we get a result, append it and the original pattern to the possible matches if result: possible_matches.append((result, host_entry)) # initialize a None best match current_match = None for match in possible_matches: if current_match is None: current_match = match # count how many chars were replaced to get regex to work chars_replaced = sum( end_char - start_char for start_char, end_char in match[0].regs[1:] ) # count how many chars were replaced to get regex to work on best match best_match_chars_replaced = sum( end_char - start_char for start_char, end_char in current_match[0].regs[1:] ) # if match replaced less chars than \"best_match\" we have a new best match if chars_replaced < best_match_chars_replaced: current_match = match return current_match[1] if current_match is not None else \"*\" def lookup(self, host: str) -> \"Host\": \"\"\" Lookup a given host Args: host: host to lookup in discovered_hosts dict Returns: Host: best matched host from parsed ssh config file hosts, \"*\" if no better match found Raises: N/A \"\"\" # return exact 1:1 match if exists if host in self.hosts: return self.hosts[host] # return match if given host is an exact match for a host entry for host_line, host_entry in self.hosts.items(): host_list = host_line.split() if host in host_list: return host_entry # otherwise need to select the most correct host entry fuzzy_match = self._lookup_fuzzy_match(host) return self.hosts[fuzzy_match] Methods \u00b6 lookup \u00b6 lookup(self, host: str) \u2011> scrapli.ssh_config.Host 1 2 3 4 5 6 7 8 9 10 Lookup a given host Args: host: host to lookup in discovered_hosts dict Returns: Host: best matched host from parsed ssh config file hosts, \"*\" if no better match found Raises: N/A SSHKnownHosts \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 Initialize SSHKnownHosts Object Parse OpenSSH known hosts file Try to load the following data for all entries in known hosts file: Host Key Type Public Key Args: ssh_known_hosts_file: string path to ssh known hosts file Returns: None Raises: TypeError: if non-string value provided for ssh_known_hosts Expand source code class SSHKnownHosts: def __init__(self, ssh_known_hosts_file: str) -> None: \"\"\" Initialize SSHKnownHosts Object Parse OpenSSH known hosts file Try to load the following data for all entries in known hosts file: Host Key Type Public Key Args: ssh_known_hosts_file: string path to ssh known hosts file Returns: None Raises: TypeError: if non-string value provided for ssh_known_hosts \"\"\" if not isinstance(ssh_known_hosts_file, str): raise TypeError( f\"`ssh_known_hosts_file` expected str, got {type(ssh_known_hosts_file)}\" ) self.ssh_known_hosts_file = os.path.expanduser(ssh_known_hosts_file) if self.ssh_known_hosts_file: with open(self.ssh_known_hosts_file, \"r\", encoding=\"utf-8\") as f: self.ssh_known_hosts = f.read() self.hosts = self._parse() if not self.hosts: self.hosts = {} else: self.hosts = {} def _parse(self) -> Dict[str, Dict[str, str]]: \"\"\" Parse OpenSSH known hosts file Args: N/A Returns: known_hosts: dict of host public keys discovered in known hosts file Raises: N/A \"\"\" # match any non whitespace from start of the line... this should cover v4/v6/names # skip a space and match any word (also w/ hyphen) to get key type, lastly # match any non whitespace to the end of the line to get the public key host_pattern = re.compile(r\"^\\S+\\s[\\w\\-]+\\s\\S+$\", flags=re.I | re.M) host_entries = re.findall(pattern=host_pattern, string=self.ssh_known_hosts) known_hosts: Dict[str, Dict[str, str]] = {} for host_entry in host_entries: host, key_type, public_key = host_entry.split() # to simplify lookups down the line, split any list of hosts and just create a unique # entry per host for individual_host in host.split(\",\"): known_hosts[individual_host] = {\"key_type\": key_type, \"public_key\": public_key} return known_hosts def lookup(self, host: str) -> Dict[str, str]: \"\"\" Lookup a given host's public key Args: host: host to lookup in known_hosts dict Returns: host_public_key: matched host public key from parsed ssh known hosts file, empty dict if not found Raises: N/A \"\"\" # return exact 1:1 match if exists if host in self.hosts: return self.hosts[host] # return match if given host is an exact match for a hashed host entry raw_host = host.encode(encoding=\"utf-8\") for host_id, host_public_key in self.hosts.items(): if host_id.startswith(\"|1|\"): _, _, encoded_salt, encoded_hashed_host = host_id.split(\"|\") raw_salt = base64.b64decode(encoded_salt) raw_hashed_host = base64.b64decode(encoded_hashed_host) if hmac.HMAC(raw_salt, raw_host, \"sha1\").digest() == raw_hashed_host: return host_public_key # otherwise return empty dict return {} Methods \u00b6 lookup \u00b6 lookup(self, host: str) \u2011> Dict[str, str] 1 2 3 4 5 6 7 8 9 10 11 Lookup a given host's public key Args: host: host to lookup in known_hosts dict Returns: host_public_key: matched host public key from parsed ssh known hosts file, empty dict if not found Raises: N/A","title":"SSH Config"},{"location":"api_docs/ssh_config/#module-scraplissh_config","text":"scrapli.ssh_config Expand source code \"\"\"scrapli.ssh_config\"\"\" import base64 import hmac import os import re import shlex import sys from copy import deepcopy from typing import Dict, Optional from scrapli.exceptions import ScrapliTypeError if sys.version_info >= (3, 8): Match = re.Match else: from typing import Match # pragma: no cover HOST_ATTRS = ( \"port\", \"user\", \"address_family\", \"bind_address\", \"connect_timeout\", \"identities_only\", \"identity_file\", \"keyboard_interactive\", \"password_authentication\", \"preferred_authentication\", ) class SSHConfig: _config_files: Dict[str, \"SSHConfig\"] = {} def __init__(self, ssh_config_file: str) -> None: \"\"\" Initialize SSHConfig Object Parse OpenSSH config file Try to load the following data for all entries in config file: Host HostName Port User *AddressFamily *BindAddress *ConnectTimeout IdentitiesOnly IdentityFile *KbdInteractiveAuthentication *PasswordAuthentication *PreferredAuthentications * items are mostly ready to load but are unused in scrapli right now so are not being set at this point. NOTE: this does *not* accept duplicate \"*\" entries -- the final \"*\" entry will overwrite any previous \"*\" entries. In general for system transport this shouldn't matter much because scrapli only cares about parsing the config file to see if a key (any key) exists for a given host (we care about that because ideally we use \"pipes\" auth, but this is only an option if we have a key to auth with). Args: ssh_config_file: string path to ssh configuration file Returns: None Raises: ScrapliTypeError: if non-string value provided for ssh_config_file \"\"\" if not isinstance(ssh_config_file, str): raise ScrapliTypeError(f\"`ssh_config_file` expected str, got {type(ssh_config_file)}\") self.ssh_config_file = os.path.expanduser(ssh_config_file) if self.ssh_config_file: with open(self.ssh_config_file, \"r\", encoding=\"utf-8\") as f: self.ssh_config = f.read() self.hosts = self._parse() if not self.hosts: self.hosts = {} if \"*\" not in self.hosts: self.hosts[\"*\"] = Host() self.hosts[\"*\"].hosts = \"*\" else: self.hosts = {} self.hosts[\"*\"] = Host() self.hosts[\"*\"].hosts = \"*\" # finally merge all args from less specific hosts into the more specific hosts, preserving # the options from the more specific hosts of course self._merge_hosts() def __str__(self) -> str: \"\"\" Magic str method for SSHConfig class Args: N/A Returns: str: string representation of object Raises: N/A \"\"\" return \"SSHConfig Object\" def __repr__(self) -> str: \"\"\" Magic repr method for SSHConfig class Args: N/A Returns: str: repr for class object Raises: N/A \"\"\" class_dict = self.__dict__.copy() del class_dict[\"ssh_config\"] return f\"SSHConfig {class_dict}\" def __bool__(self) -> bool: \"\"\" Magic bool method; return True if ssh_config_file Args: N/A Returns: bool: True/False if ssh_config_file Raises: N/A \"\"\" return bool(self.ssh_config) @staticmethod def _strip_comments(line: str) -> str: \"\"\" Strip out comments from ssh config file lines Args: line: to strip comments from Returns: str: rejoined ssh config file line after stripping comments Raises: N/A \"\"\" line = \" \".join(shlex.split(line, comments=True)) return line def _parse(self) -> Dict[str, \"Host\"]: \"\"\" Parse SSH configuration file Args: N/A Returns: discovered_hosts: dict of host objects discovered in ssh config file Raises: N/A \"\"\" # uncomment next line and handle global patterns (stuff before hosts) at some point # global_config_pattern = re.compile(r\"^.*?\\b(?=host)\", flags=re.I | re.S) # use word boundaries with a positive lookahead to get everything between the word host # need to do this as whitespace/formatting is not really a thing in ssh_config file # match host\\s to ensure we don't pick up hostname and split things there accidentally host_pattern = re.compile(r\"\\bhost.*?\\b(?=host\\s|\\s+$|$)\", flags=re.I | re.S) host_entries = re.findall(pattern=host_pattern, string=self.ssh_config) discovered_hosts: Dict[str, Host] = {} if not host_entries: return discovered_hosts # do we need to add whitespace between match and end of line to ensure we match correctly? hosts_pattern = re.compile(r\"^\\s*host[\\s=]+(.*)$\", flags=re.I | re.M) hostname_pattern = re.compile(r\"^\\s*hostname[\\s=]+([\\w.-]*)$\", flags=re.I | re.M) port_pattern = re.compile(r\"^\\s*port[\\s=]+([\\d]*)$\", flags=re.I | re.M) user_pattern = re.compile(r\"^\\s*user[\\s=]+([\\w]*)$\", flags=re.I | re.M) # address_family_pattern = None # bind_address_pattern = None # connect_timeout_pattern = None identities_only_pattern = re.compile( r\"^\\s*identitiesonly[\\s=]+(yes|no)$\", flags=re.I | re.M ) identity_file_pattern = re.compile( r\"^\\s*identityfile[\\s=]+([\\w.\\/\\@~-]*)$\", flags=re.I | re.M ) # keyboard_interactive_pattern = None # password_authentication_pattern = None # preferred_authentication_pattern = None for host_entry in host_entries: host = Host() host_line = re.search(pattern=hosts_pattern, string=host_entry) if isinstance(host_line, Match): host.hosts = self._strip_comments(host_line.groups()[0]) else: host.hosts = \"\" hostname = re.search(pattern=hostname_pattern, string=host_entry) if isinstance(hostname, Match): host.hostname = self._strip_comments(hostname.groups()[0]) port = re.search(pattern=port_pattern, string=host_entry) if isinstance(port, Match): host.port = int(self._strip_comments(port.groups()[0])) user = re.search(pattern=user_pattern, string=host_entry) if isinstance(user, Match): host.user = self._strip_comments(user.groups()[0]) # address_family = re.search(user_pattern, host_entry[0]) # bind_address = re.search(user_pattern, host_entry[0]) # connect_timeout = re.search(user_pattern, host_entry[0]) identities_only = re.search(pattern=identities_only_pattern, string=host_entry) if isinstance(identities_only, Match): host.identities_only = self._strip_comments(identities_only.groups()[0]) identity_file = re.search(pattern=identity_file_pattern, string=host_entry) if isinstance(identity_file, Match): host.identity_file = os.path.expanduser( self._strip_comments(identity_file.groups()[0]) ) # keyboard_interactive = re.search(user_pattern, host_entry[0]) # password_authentication = re.search(user_pattern, host_entry[0]) # preferred_authentication = re.search(user_pattern, host_entry[0]) discovered_hosts[host.hosts] = host return discovered_hosts def _merge_hosts(self) -> None: \"\"\" Merge less specific host pattern data into a given host Args: N/A Returns: None Raises: N/A \"\"\" for host in self.hosts: # pylint: disable=C0206 _current_hosts = deepcopy(self.hosts) while True: fuzzy_match = self._lookup_fuzzy_match(host=host, hosts=_current_hosts) for attr in HOST_ATTRS: if not getattr(self.hosts[host], attr): setattr(self.hosts[host], attr, getattr(self.hosts[fuzzy_match], attr)) try: _current_hosts.pop(fuzzy_match) except KeyError: # this means we hit the \"*\" entry twice and we can bail out break def _lookup_fuzzy_match(self, host: str, hosts: Optional[Dict[str, \"Host\"]] = None) -> str: \"\"\" Look up fuzzy matched hosts Get the best match ssh config Host entry for a given host; this allows for using the splat and question-mark operators in ssh config file Args: host: host to lookup in discovered_hosts dict hosts: hosts dict to operate on; used for passing in partial dict of hosts while performing merge operations Returns: str: Nearest match (if applicable) host or `*` if none found Raises: N/A \"\"\" hosts = hosts or self.hosts possible_matches = [] for host_entry in hosts.keys(): host_list = host_entry.split() for host_pattern in host_list: # replace periods with literal period # replace asterisk (match 0 or more things) with appropriate regex # replace question mark (match one thing) with appropriate regex cleaned_host_pattern = ( host_pattern.replace(\".\", r\"\\.\").replace(\"*\", r\"(.*)\").replace(\"?\", r\"(.)\") ) # compile with case insensitive search_pattern = re.compile(cleaned_host_pattern, flags=re.I) result = re.search(pattern=search_pattern, string=host) # if we get a result, append it and the original pattern to the possible matches if result: possible_matches.append((result, host_entry)) # initialize a None best match current_match = None for match in possible_matches: if current_match is None: current_match = match # count how many chars were replaced to get regex to work chars_replaced = sum( end_char - start_char for start_char, end_char in match[0].regs[1:] ) # count how many chars were replaced to get regex to work on best match best_match_chars_replaced = sum( end_char - start_char for start_char, end_char in current_match[0].regs[1:] ) # if match replaced less chars than \"best_match\" we have a new best match if chars_replaced < best_match_chars_replaced: current_match = match return current_match[1] if current_match is not None else \"*\" def lookup(self, host: str) -> \"Host\": \"\"\" Lookup a given host Args: host: host to lookup in discovered_hosts dict Returns: Host: best matched host from parsed ssh config file hosts, \"*\" if no better match found Raises: N/A \"\"\" # return exact 1:1 match if exists if host in self.hosts: return self.hosts[host] # return match if given host is an exact match for a host entry for host_line, host_entry in self.hosts.items(): host_list = host_line.split() if host in host_list: return host_entry # otherwise need to select the most correct host entry fuzzy_match = self._lookup_fuzzy_match(host) return self.hosts[fuzzy_match] class Host: def __init__(self) -> None: \"\"\" Host Object Create a Host object based on ssh config file information \"\"\" self.hosts: str = \"\" self.hostname: Optional[str] = None self.port: Optional[int] = None self.user: str = \"\" self.address_family: Optional[str] = None self.bind_address: Optional[str] = None self.connect_timeout: Optional[str] = None self.identities_only: Optional[str] = None self.identity_file: Optional[str] = None self.keyboard_interactive: Optional[str] = None self.password_authentication: Optional[str] = None self.preferred_authentication: Optional[str] = None def __str__(self) -> str: \"\"\" Magic str method for HostEntry class Args: N/A Returns: str: string for class object Raises: N/A \"\"\" return f\"Host: {self.hosts}\" def __repr__(self) -> str: \"\"\" Magic repr method for HostEntry class Args: N/A Returns: str: repr for class object Raises: N/A \"\"\" class_dict = self.__dict__.copy() return f\"Host {class_dict}\" class SSHKnownHosts: def __init__(self, ssh_known_hosts_file: str) -> None: \"\"\" Initialize SSHKnownHosts Object Parse OpenSSH known hosts file Try to load the following data for all entries in known hosts file: Host Key Type Public Key Args: ssh_known_hosts_file: string path to ssh known hosts file Returns: None Raises: TypeError: if non-string value provided for ssh_known_hosts \"\"\" if not isinstance(ssh_known_hosts_file, str): raise TypeError( f\"`ssh_known_hosts_file` expected str, got {type(ssh_known_hosts_file)}\" ) self.ssh_known_hosts_file = os.path.expanduser(ssh_known_hosts_file) if self.ssh_known_hosts_file: with open(self.ssh_known_hosts_file, \"r\", encoding=\"utf-8\") as f: self.ssh_known_hosts = f.read() self.hosts = self._parse() if not self.hosts: self.hosts = {} else: self.hosts = {} def _parse(self) -> Dict[str, Dict[str, str]]: \"\"\" Parse OpenSSH known hosts file Args: N/A Returns: known_hosts: dict of host public keys discovered in known hosts file Raises: N/A \"\"\" # match any non whitespace from start of the line... this should cover v4/v6/names # skip a space and match any word (also w/ hyphen) to get key type, lastly # match any non whitespace to the end of the line to get the public key host_pattern = re.compile(r\"^\\S+\\s[\\w\\-]+\\s\\S+$\", flags=re.I | re.M) host_entries = re.findall(pattern=host_pattern, string=self.ssh_known_hosts) known_hosts: Dict[str, Dict[str, str]] = {} for host_entry in host_entries: host, key_type, public_key = host_entry.split() # to simplify lookups down the line, split any list of hosts and just create a unique # entry per host for individual_host in host.split(\",\"): known_hosts[individual_host] = {\"key_type\": key_type, \"public_key\": public_key} return known_hosts def lookup(self, host: str) -> Dict[str, str]: \"\"\" Lookup a given host's public key Args: host: host to lookup in known_hosts dict Returns: host_public_key: matched host public key from parsed ssh known hosts file, empty dict if not found Raises: N/A \"\"\" # return exact 1:1 match if exists if host in self.hosts: return self.hosts[host] # return match if given host is an exact match for a hashed host entry raw_host = host.encode(encoding=\"utf-8\") for host_id, host_public_key in self.hosts.items(): if host_id.startswith(\"|1|\"): _, _, encoded_salt, encoded_hashed_host = host_id.split(\"|\") raw_salt = base64.b64decode(encoded_salt) raw_hashed_host = base64.b64decode(encoded_hashed_host) if hmac.HMAC(raw_salt, raw_host, \"sha1\").digest() == raw_hashed_host: return host_public_key # otherwise return empty dict return {} def ssh_config_factory(ssh_config_file: str) -> SSHConfig: \"\"\" Sorta kinda make a singleton out of SSHConfig Not exactly a singleton in that its more like a singleton *per ssh config file path* since a user may elect to use different ssh config files for different things! The only place this should ever be called from is the base driver which has already resolved the ssh config file path -- so we should get only fully qualified paths. We then use this path as the key in the `_config_files` dict of the SSHConfig object, storing the actual object we instantiate as the value. This allows us to only ever create one instance of SSHConfig for each provided ssh config file! Args: ssh_config_file: fully qualified string path to ssh config file Returns: SSHConfig: instantiated SSHConfig object Raises: N/A \"\"\" config_files = SSHConfig._config_files # pylint: disable=W0212 if ssh_config_file in config_files: return config_files[ssh_config_file] ssh_config = SSHConfig(ssh_config_file=ssh_config_file) config_files[ssh_config_file] = ssh_config return ssh_config","title":"Module scrapli.ssh_config"},{"location":"api_docs/ssh_config/#functions","text":"","title":"Functions"},{"location":"api_docs/ssh_config/#ssh_config_factory","text":"ssh_config_factory(ssh_config_file: str) \u2011> scrapli.ssh_config.SSHConfig 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 Sorta kinda make a singleton out of SSHConfig Not exactly a singleton in that its more like a singleton *per ssh config file path* since a user may elect to use different ssh config files for different things! The only place this should ever be called from is the base driver which has already resolved the ssh config file path -- so we should get only fully qualified paths. We then use this path as the key in the `_config_files` dict of the SSHConfig object, storing the actual object we instantiate as the value. This allows us to only ever create one instance of SSHConfig for each provided ssh config file! Args: ssh_config_file: fully qualified string path to ssh config file Returns: SSHConfig: instantiated SSHConfig object Raises: N/A","title":"ssh_config_factory"},{"location":"api_docs/ssh_config/#classes","text":"","title":"Classes"},{"location":"api_docs/ssh_config/#host","text":"1 2 3 Host Object Create a Host object based on ssh config file information Expand source code class Host: def __init__(self) -> None: \"\"\" Host Object Create a Host object based on ssh config file information \"\"\" self.hosts: str = \"\" self.hostname: Optional[str] = None self.port: Optional[int] = None self.user: str = \"\" self.address_family: Optional[str] = None self.bind_address: Optional[str] = None self.connect_timeout: Optional[str] = None self.identities_only: Optional[str] = None self.identity_file: Optional[str] = None self.keyboard_interactive: Optional[str] = None self.password_authentication: Optional[str] = None self.preferred_authentication: Optional[str] = None def __str__(self) -> str: \"\"\" Magic str method for HostEntry class Args: N/A Returns: str: string for class object Raises: N/A \"\"\" return f\"Host: {self.hosts}\" def __repr__(self) -> str: \"\"\" Magic repr method for HostEntry class Args: N/A Returns: str: repr for class object Raises: N/A \"\"\" class_dict = self.__dict__.copy() return f\"Host {class_dict}\"","title":"Host"},{"location":"api_docs/ssh_config/#sshconfig","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 Initialize SSHConfig Object Parse OpenSSH config file Try to load the following data for all entries in config file: Host HostName Port User *AddressFamily *BindAddress *ConnectTimeout IdentitiesOnly IdentityFile *KbdInteractiveAuthentication *PasswordAuthentication *PreferredAuthentications * items are mostly ready to load but are unused in scrapli right now so are not being set at this point. NOTE: this does *not* accept duplicate \"*\" entries -- the final \"*\" entry will overwrite any previous \"*\" entries. In general for system transport this shouldn't matter much because scrapli only cares about parsing the config file to see if a key (any key) exists for a given host (we care about that because ideally we use \"pipes\" auth, but this is only an option if we have a key to auth with). Args: ssh_config_file: string path to ssh configuration file Returns: None Raises: ScrapliTypeError: if non-string value provided for ssh_config_file Expand source code class SSHConfig: _config_files: Dict[str, \"SSHConfig\"] = {} def __init__(self, ssh_config_file: str) -> None: \"\"\" Initialize SSHConfig Object Parse OpenSSH config file Try to load the following data for all entries in config file: Host HostName Port User *AddressFamily *BindAddress *ConnectTimeout IdentitiesOnly IdentityFile *KbdInteractiveAuthentication *PasswordAuthentication *PreferredAuthentications * items are mostly ready to load but are unused in scrapli right now so are not being set at this point. NOTE: this does *not* accept duplicate \"*\" entries -- the final \"*\" entry will overwrite any previous \"*\" entries. In general for system transport this shouldn't matter much because scrapli only cares about parsing the config file to see if a key (any key) exists for a given host (we care about that because ideally we use \"pipes\" auth, but this is only an option if we have a key to auth with). Args: ssh_config_file: string path to ssh configuration file Returns: None Raises: ScrapliTypeError: if non-string value provided for ssh_config_file \"\"\" if not isinstance(ssh_config_file, str): raise ScrapliTypeError(f\"`ssh_config_file` expected str, got {type(ssh_config_file)}\") self.ssh_config_file = os.path.expanduser(ssh_config_file) if self.ssh_config_file: with open(self.ssh_config_file, \"r\", encoding=\"utf-8\") as f: self.ssh_config = f.read() self.hosts = self._parse() if not self.hosts: self.hosts = {} if \"*\" not in self.hosts: self.hosts[\"*\"] = Host() self.hosts[\"*\"].hosts = \"*\" else: self.hosts = {} self.hosts[\"*\"] = Host() self.hosts[\"*\"].hosts = \"*\" # finally merge all args from less specific hosts into the more specific hosts, preserving # the options from the more specific hosts of course self._merge_hosts() def __str__(self) -> str: \"\"\" Magic str method for SSHConfig class Args: N/A Returns: str: string representation of object Raises: N/A \"\"\" return \"SSHConfig Object\" def __repr__(self) -> str: \"\"\" Magic repr method for SSHConfig class Args: N/A Returns: str: repr for class object Raises: N/A \"\"\" class_dict = self.__dict__.copy() del class_dict[\"ssh_config\"] return f\"SSHConfig {class_dict}\" def __bool__(self) -> bool: \"\"\" Magic bool method; return True if ssh_config_file Args: N/A Returns: bool: True/False if ssh_config_file Raises: N/A \"\"\" return bool(self.ssh_config) @staticmethod def _strip_comments(line: str) -> str: \"\"\" Strip out comments from ssh config file lines Args: line: to strip comments from Returns: str: rejoined ssh config file line after stripping comments Raises: N/A \"\"\" line = \" \".join(shlex.split(line, comments=True)) return line def _parse(self) -> Dict[str, \"Host\"]: \"\"\" Parse SSH configuration file Args: N/A Returns: discovered_hosts: dict of host objects discovered in ssh config file Raises: N/A \"\"\" # uncomment next line and handle global patterns (stuff before hosts) at some point # global_config_pattern = re.compile(r\"^.*?\\b(?=host)\", flags=re.I | re.S) # use word boundaries with a positive lookahead to get everything between the word host # need to do this as whitespace/formatting is not really a thing in ssh_config file # match host\\s to ensure we don't pick up hostname and split things there accidentally host_pattern = re.compile(r\"\\bhost.*?\\b(?=host\\s|\\s+$|$)\", flags=re.I | re.S) host_entries = re.findall(pattern=host_pattern, string=self.ssh_config) discovered_hosts: Dict[str, Host] = {} if not host_entries: return discovered_hosts # do we need to add whitespace between match and end of line to ensure we match correctly? hosts_pattern = re.compile(r\"^\\s*host[\\s=]+(.*)$\", flags=re.I | re.M) hostname_pattern = re.compile(r\"^\\s*hostname[\\s=]+([\\w.-]*)$\", flags=re.I | re.M) port_pattern = re.compile(r\"^\\s*port[\\s=]+([\\d]*)$\", flags=re.I | re.M) user_pattern = re.compile(r\"^\\s*user[\\s=]+([\\w]*)$\", flags=re.I | re.M) # address_family_pattern = None # bind_address_pattern = None # connect_timeout_pattern = None identities_only_pattern = re.compile( r\"^\\s*identitiesonly[\\s=]+(yes|no)$\", flags=re.I | re.M ) identity_file_pattern = re.compile( r\"^\\s*identityfile[\\s=]+([\\w.\\/\\@~-]*)$\", flags=re.I | re.M ) # keyboard_interactive_pattern = None # password_authentication_pattern = None # preferred_authentication_pattern = None for host_entry in host_entries: host = Host() host_line = re.search(pattern=hosts_pattern, string=host_entry) if isinstance(host_line, Match): host.hosts = self._strip_comments(host_line.groups()[0]) else: host.hosts = \"\" hostname = re.search(pattern=hostname_pattern, string=host_entry) if isinstance(hostname, Match): host.hostname = self._strip_comments(hostname.groups()[0]) port = re.search(pattern=port_pattern, string=host_entry) if isinstance(port, Match): host.port = int(self._strip_comments(port.groups()[0])) user = re.search(pattern=user_pattern, string=host_entry) if isinstance(user, Match): host.user = self._strip_comments(user.groups()[0]) # address_family = re.search(user_pattern, host_entry[0]) # bind_address = re.search(user_pattern, host_entry[0]) # connect_timeout = re.search(user_pattern, host_entry[0]) identities_only = re.search(pattern=identities_only_pattern, string=host_entry) if isinstance(identities_only, Match): host.identities_only = self._strip_comments(identities_only.groups()[0]) identity_file = re.search(pattern=identity_file_pattern, string=host_entry) if isinstance(identity_file, Match): host.identity_file = os.path.expanduser( self._strip_comments(identity_file.groups()[0]) ) # keyboard_interactive = re.search(user_pattern, host_entry[0]) # password_authentication = re.search(user_pattern, host_entry[0]) # preferred_authentication = re.search(user_pattern, host_entry[0]) discovered_hosts[host.hosts] = host return discovered_hosts def _merge_hosts(self) -> None: \"\"\" Merge less specific host pattern data into a given host Args: N/A Returns: None Raises: N/A \"\"\" for host in self.hosts: # pylint: disable=C0206 _current_hosts = deepcopy(self.hosts) while True: fuzzy_match = self._lookup_fuzzy_match(host=host, hosts=_current_hosts) for attr in HOST_ATTRS: if not getattr(self.hosts[host], attr): setattr(self.hosts[host], attr, getattr(self.hosts[fuzzy_match], attr)) try: _current_hosts.pop(fuzzy_match) except KeyError: # this means we hit the \"*\" entry twice and we can bail out break def _lookup_fuzzy_match(self, host: str, hosts: Optional[Dict[str, \"Host\"]] = None) -> str: \"\"\" Look up fuzzy matched hosts Get the best match ssh config Host entry for a given host; this allows for using the splat and question-mark operators in ssh config file Args: host: host to lookup in discovered_hosts dict hosts: hosts dict to operate on; used for passing in partial dict of hosts while performing merge operations Returns: str: Nearest match (if applicable) host or `*` if none found Raises: N/A \"\"\" hosts = hosts or self.hosts possible_matches = [] for host_entry in hosts.keys(): host_list = host_entry.split() for host_pattern in host_list: # replace periods with literal period # replace asterisk (match 0 or more things) with appropriate regex # replace question mark (match one thing) with appropriate regex cleaned_host_pattern = ( host_pattern.replace(\".\", r\"\\.\").replace(\"*\", r\"(.*)\").replace(\"?\", r\"(.)\") ) # compile with case insensitive search_pattern = re.compile(cleaned_host_pattern, flags=re.I) result = re.search(pattern=search_pattern, string=host) # if we get a result, append it and the original pattern to the possible matches if result: possible_matches.append((result, host_entry)) # initialize a None best match current_match = None for match in possible_matches: if current_match is None: current_match = match # count how many chars were replaced to get regex to work chars_replaced = sum( end_char - start_char for start_char, end_char in match[0].regs[1:] ) # count how many chars were replaced to get regex to work on best match best_match_chars_replaced = sum( end_char - start_char for start_char, end_char in current_match[0].regs[1:] ) # if match replaced less chars than \"best_match\" we have a new best match if chars_replaced < best_match_chars_replaced: current_match = match return current_match[1] if current_match is not None else \"*\" def lookup(self, host: str) -> \"Host\": \"\"\" Lookup a given host Args: host: host to lookup in discovered_hosts dict Returns: Host: best matched host from parsed ssh config file hosts, \"*\" if no better match found Raises: N/A \"\"\" # return exact 1:1 match if exists if host in self.hosts: return self.hosts[host] # return match if given host is an exact match for a host entry for host_line, host_entry in self.hosts.items(): host_list = host_line.split() if host in host_list: return host_entry # otherwise need to select the most correct host entry fuzzy_match = self._lookup_fuzzy_match(host) return self.hosts[fuzzy_match]","title":"SSHConfig"},{"location":"api_docs/ssh_config/#methods","text":"","title":"Methods"},{"location":"api_docs/ssh_config/#lookup","text":"lookup(self, host: str) \u2011> scrapli.ssh_config.Host 1 2 3 4 5 6 7 8 9 10 Lookup a given host Args: host: host to lookup in discovered_hosts dict Returns: Host: best matched host from parsed ssh config file hosts, \"*\" if no better match found Raises: N/A","title":"lookup"},{"location":"api_docs/ssh_config/#sshknownhosts","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 Initialize SSHKnownHosts Object Parse OpenSSH known hosts file Try to load the following data for all entries in known hosts file: Host Key Type Public Key Args: ssh_known_hosts_file: string path to ssh known hosts file Returns: None Raises: TypeError: if non-string value provided for ssh_known_hosts Expand source code class SSHKnownHosts: def __init__(self, ssh_known_hosts_file: str) -> None: \"\"\" Initialize SSHKnownHosts Object Parse OpenSSH known hosts file Try to load the following data for all entries in known hosts file: Host Key Type Public Key Args: ssh_known_hosts_file: string path to ssh known hosts file Returns: None Raises: TypeError: if non-string value provided for ssh_known_hosts \"\"\" if not isinstance(ssh_known_hosts_file, str): raise TypeError( f\"`ssh_known_hosts_file` expected str, got {type(ssh_known_hosts_file)}\" ) self.ssh_known_hosts_file = os.path.expanduser(ssh_known_hosts_file) if self.ssh_known_hosts_file: with open(self.ssh_known_hosts_file, \"r\", encoding=\"utf-8\") as f: self.ssh_known_hosts = f.read() self.hosts = self._parse() if not self.hosts: self.hosts = {} else: self.hosts = {} def _parse(self) -> Dict[str, Dict[str, str]]: \"\"\" Parse OpenSSH known hosts file Args: N/A Returns: known_hosts: dict of host public keys discovered in known hosts file Raises: N/A \"\"\" # match any non whitespace from start of the line... this should cover v4/v6/names # skip a space and match any word (also w/ hyphen) to get key type, lastly # match any non whitespace to the end of the line to get the public key host_pattern = re.compile(r\"^\\S+\\s[\\w\\-]+\\s\\S+$\", flags=re.I | re.M) host_entries = re.findall(pattern=host_pattern, string=self.ssh_known_hosts) known_hosts: Dict[str, Dict[str, str]] = {} for host_entry in host_entries: host, key_type, public_key = host_entry.split() # to simplify lookups down the line, split any list of hosts and just create a unique # entry per host for individual_host in host.split(\",\"): known_hosts[individual_host] = {\"key_type\": key_type, \"public_key\": public_key} return known_hosts def lookup(self, host: str) -> Dict[str, str]: \"\"\" Lookup a given host's public key Args: host: host to lookup in known_hosts dict Returns: host_public_key: matched host public key from parsed ssh known hosts file, empty dict if not found Raises: N/A \"\"\" # return exact 1:1 match if exists if host in self.hosts: return self.hosts[host] # return match if given host is an exact match for a hashed host entry raw_host = host.encode(encoding=\"utf-8\") for host_id, host_public_key in self.hosts.items(): if host_id.startswith(\"|1|\"): _, _, encoded_salt, encoded_hashed_host = host_id.split(\"|\") raw_salt = base64.b64decode(encoded_salt) raw_hashed_host = base64.b64decode(encoded_hashed_host) if hmac.HMAC(raw_salt, raw_host, \"sha1\").digest() == raw_hashed_host: return host_public_key # otherwise return empty dict return {}","title":"SSHKnownHosts"},{"location":"api_docs/ssh_config/#methods_1","text":"","title":"Methods"},{"location":"api_docs/ssh_config/#lookup_1","text":"lookup(self, host: str) \u2011> Dict[str, str] 1 2 3 4 5 6 7 8 9 10 11 Lookup a given host's public key Args: host: host to lookup in known_hosts dict Returns: host_public_key: matched host public key from parsed ssh known hosts file, empty dict if not found Raises: N/A","title":"lookup"},{"location":"api_docs/channel/async_channel/","text":"window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting()) Module scrapli.channel.async_channel \u00b6 scrapli.channel.async_channel Expand source code \"\"\"scrapli.channel.async_channel\"\"\" import asyncio import re import time from contextlib import asynccontextmanager from datetime import datetime from io import BytesIO from typing import AsyncIterator, List, Optional, Tuple from scrapli.channel.base_channel import BaseChannel, BaseChannelArgs from scrapli.decorators import timeout_wrapper from scrapli.exceptions import ScrapliAuthenticationFailed, ScrapliTimeout from scrapli.transport.base import AsyncTransport class AsyncChannel(BaseChannel): def __init__( self, transport: AsyncTransport, base_channel_args: BaseChannelArgs, ) -> None: super().__init__( transport=transport, base_channel_args=base_channel_args, ) self.transport: AsyncTransport self.channel_lock: Optional[asyncio.Lock] = None if self._base_channel_args.channel_lock: self.channel_lock = asyncio.Lock() @asynccontextmanager async def _channel_lock(self) -> AsyncIterator[None]: \"\"\" Lock the channel during public channel operations if channel_lock is enabled Args: N/A Yields: None Raises: N/A \"\"\" if self.channel_lock: async with self.channel_lock: yield else: yield async def read(self) -> bytes: r\"\"\" Read chunks of output from the channel Replaces any \\r characters that sometimes get stuffed into the output from the devices Args: N/A Returns: bytes: output read from channel Raises: N/A \"\"\" buf = await self.transport.read() buf = buf.replace(b\"\\r\", b\"\") self.logger.debug(f\"read: {repr(buf)}\") if self.channel_log: self.channel_log.write(buf) if b\"\\x1b\" in buf.lower(): buf = self._strip_ansi(buf=buf) return buf async def _read_until_input(self, channel_input: bytes) -> bytes: \"\"\" Read until all channel_input has been read on the channel Args: channel_input: bytes that should have been written to the channel Returns: bytes: output read from channel while checking for the input in the channel stream Raises: N/A \"\"\" buf = b\"\" if not channel_input: return buf # squish all channel input words together and cast to lower to make comparison easier processed_channel_input = b\"\".join(channel_input.lower().split()) while True: buf += await self.read() # replace any backspace chars (particular problem w/ junos), and remove any added spaces # this is just for comparison of the inputs to what was read from channel if processed_channel_input in b\"\".join(buf.lower().replace(b\"\\x08\", b\"\").split()): return buf async def _read_until_prompt(self, buf: bytes = b\"\") -> bytes: \"\"\" Read until expected prompt is seen. This reads until the \"normal\" `_base_channel_args.comms_prompt_pattern` is seen. The `_read_until_explicit_prompt` method can be used to read until some pattern in an arbitrary list of patterns is seen. Args: buf: output from previous reads if needed (used by scrapli netconf) Returns: bytes: output read from channel Raises: N/A \"\"\" search_pattern = self._get_prompt_pattern( class_pattern=self._base_channel_args.comms_prompt_pattern ) read_buf = BytesIO(buf) while True: b = await self.read() read_buf.write(b) search_buf = self._process_read_buf(read_buf=read_buf) channel_match = re.search( pattern=search_pattern, string=search_buf, ) if channel_match: return read_buf.getvalue() async def _read_until_explicit_prompt(self, prompts: List[str]) -> bytes: \"\"\" Read until expected prompt is seen. This method is for *explicit* prompt patterns instead of the \"standard\" prompt patterns contained in the `_base_channel_args.comms_prompt_pattern` attribute. Generally this is only used for `send_interactive` though it could be used elsewhere as well. Args: prompts: list of prompt patterns to look for, will return upon seeing any match Returns: bytes: output read from channel Raises: N/A \"\"\" search_patterns = [ self._get_prompt_pattern( class_pattern=self._base_channel_args.comms_prompt_pattern, pattern=prompt ) for prompt in prompts ] read_buf = BytesIO(b\"\") while True: b = await self.read() read_buf.write(b) search_buf = self._process_read_buf(read_buf=read_buf) for search_pattern in search_patterns: channel_match = re.search( pattern=search_pattern, string=search_buf, ) if channel_match: return read_buf.getvalue() async def _read_until_prompt_or_time( self, buf: bytes = b\"\", channel_outputs: Optional[List[bytes]] = None, read_duration: Optional[float] = None, ) -> bytes: \"\"\" Read until expected prompt is seen, outputs are seen, or for duration, whichever comes first As transport reading may block, transport timeout is temporarily set to the read_duration and any `ScrapliTimeout` that is raised while reading is ignored. Args: buf: bytes from previous reads if needed channel_outputs: List of bytes to search for in channel output, if any are seen, return read output read_duration: duration to read from channel for Returns: bytes: output read from channel Raises: N/A \"\"\" search_pattern = self._get_prompt_pattern( class_pattern=self._base_channel_args.comms_prompt_pattern, ) if channel_outputs is None: channel_outputs = [] if read_duration is None: read_duration = 2.5 regex_channel_outputs_pattern = self._join_and_compile(channel_outputs=channel_outputs) _transport_args = self.transport._base_transport_args # pylint: disable=W0212 previous_timeout_transport = _transport_args.timeout_transport _transport_args.timeout_transport = int(read_duration) read_buf = BytesIO(buf) start = time.time() while True: try: b = await self.read() read_buf.write(b) except ScrapliTimeout: pass search_buf = self._process_read_buf(read_buf=read_buf) if (time.time() - start) > read_duration: break if any((channel_output in search_buf for channel_output in channel_outputs)): break if re.search(pattern=regex_channel_outputs_pattern, string=search_buf): break if re.search(pattern=search_pattern, string=search_buf): break _transport_args.timeout_transport = previous_timeout_transport return read_buf.getvalue() @timeout_wrapper async def channel_authenticate_ssh( self, auth_password: str, auth_private_key_passphrase: str ) -> None: \"\"\" Handle SSH Authentication for transports that only operate \"in the channel\" (i.e. system) Args: auth_password: password to authenticate with auth_private_key_passphrase: passphrase for ssh key if necessary Returns: None Raises: ScrapliAuthenticationFailed: if password prompt seen more than twice ScrapliAuthenticationFailed: if passphrase prompt seen more than twice \"\"\" self.logger.debug(\"attempting in channel ssh authentication\") password_count = 0 passphrase_count = 0 authenticate_buf = b\"\" ( password_pattern, passphrase_pattern, prompt_pattern, ) = self._pre_channel_authenticate_ssh() async with self._channel_lock(): while True: try: buf = await asyncio.wait_for(self.read(), timeout=1) except asyncio.TimeoutError: buf = b\"\" authenticate_buf += buf.lower() if re.search( pattern=password_pattern, string=authenticate_buf, ): # clear the authentication buffer so we don't re-read the password prompt authenticate_buf = b\"\" password_count += 1 if password_count > 2: msg = \"password prompt seen more than once, assuming auth failed\" self.logger.critical(msg) raise ScrapliAuthenticationFailed(msg) self.write(channel_input=auth_password, redacted=True) self.send_return() if re.search( pattern=passphrase_pattern, string=authenticate_buf, ): # clear the authentication buffer so we don't re-read the passphrase prompt authenticate_buf = b\"\" passphrase_count += 1 if passphrase_count > 2: msg = \"passphrase prompt seen more than once, assuming auth failed\" self.logger.critical(msg) raise ScrapliAuthenticationFailed(msg) self.write(channel_input=auth_private_key_passphrase, redacted=True) self.send_return() if re.search( pattern=prompt_pattern, string=authenticate_buf, ): return @timeout_wrapper async def channel_authenticate_telnet( # noqa: C901 self, auth_username: str = \"\", auth_password: str = \"\" ) -> None: \"\"\" Handle Telnet Authentication Args: auth_username: username to use for telnet authentication auth_password: password to use for telnet authentication Returns: None Raises: ScrapliAuthenticationFailed: if password prompt seen more than twice ScrapliAuthenticationFailed: if login prompt seen more than twice \"\"\" self.logger.debug(\"attempting in channel telnet authentication\") username_count = 0 password_count = 0 authenticate_buf = b\"\" ( username_pattern, password_pattern, prompt_pattern, auth_start_time, return_interval, ) = self._pre_channel_authenticate_telnet() read_interval = self._base_channel_args.timeout_ops / 20 return_attempts = 1 async with self._channel_lock(): while True: try: buf = await asyncio.wait_for(self.read(), timeout=read_interval) except asyncio.TimeoutError: buf = b\"\" if not buf: current_iteration_time = datetime.now().timestamp() if (current_iteration_time - auth_start_time) > ( return_interval * return_attempts ): self.send_return() return_attempts += 1 authenticate_buf += buf.lower() if re.search( pattern=username_pattern, string=authenticate_buf, ): # clear the authentication buffer so we don't re-read the username prompt authenticate_buf = b\"\" username_count += 1 if username_count > 2: msg = \"username/login prompt seen more than once, assuming auth failed\" self.logger.critical(msg) raise ScrapliAuthenticationFailed(msg) self.write(channel_input=auth_username) self.send_return() if re.search( pattern=password_pattern, string=authenticate_buf, ): # clear the authentication buffer so we don't re-read the password prompt authenticate_buf = b\"\" password_count += 1 if password_count > 2: msg = \"password prompt seen more than once, assuming auth failed\" self.logger.critical(msg) raise ScrapliAuthenticationFailed(msg) self.write(channel_input=auth_password, redacted=True) self.send_return() if re.search( pattern=prompt_pattern, string=authenticate_buf, ): return @timeout_wrapper async def get_prompt(self) -> str: \"\"\" Get current channel prompt Args: N/A Returns: str: string of the current prompt Raises: N/A \"\"\" buf = b\"\" search_pattern = self._get_prompt_pattern( class_pattern=self._base_channel_args.comms_prompt_pattern ) async with self._channel_lock(): self.send_return() while True: buf += await self.read() channel_match = re.search( pattern=search_pattern, string=buf, ) if channel_match: current_prompt = channel_match.group(0) return current_prompt.decode().strip() @timeout_wrapper async def send_input( self, channel_input: str, *, strip_prompt: bool = True, eager: bool = False, ) -> Tuple[bytes, bytes]: \"\"\" Primary entry point to send data to devices in shell mode; accept input and returns result Args: channel_input: string input to send to channel strip_prompt: strip prompt or not, defaults to True (yes, strip the prompt) eager: eager mode reads and returns the `_read_until_input` value, but does not attempt to read to the prompt pattern -- this should not be used manually! (only used by `send_configs` with the eager flag set) Returns: Tuple[bytes, bytes]: tuple of \"raw\" output and \"processed\" (cleaned up/stripped) output Raises: N/A \"\"\" self._pre_send_input(channel_input=channel_input) buf = b\"\" bytes_channel_input = channel_input.encode() self.logger.info( f\"sending channel input: {channel_input}; strip_prompt: {strip_prompt}; eager: {eager}\" ) async with self._channel_lock(): self.write(channel_input=channel_input) _buf_until_input = await self._read_until_input(channel_input=bytes_channel_input) self.send_return() if not eager: buf += await self._read_until_prompt() processed_buf = self._process_output( buf=buf, strip_prompt=strip_prompt, ) return buf, processed_buf @timeout_wrapper async def send_input_and_read( self, channel_input: str, *, strip_prompt: bool = True, expected_outputs: Optional[List[str]] = None, read_duration: Optional[float] = None, ) -> Tuple[bytes, bytes]: \"\"\" Send a command and read until expected prompt is seen, outputs are seen, or for duration Args: channel_input: string input to send to channel strip_prompt: strip prompt or not, defaults to True (yes, strip the prompt) expected_outputs: list of strings to look for in output; if any of these are seen, return output read up till that read read_duration: float duration to read for Returns: Tuple[bytes, bytes]: tuple of \"raw\" output and \"processed\" (cleaned up/stripped) output Raises: N/A \"\"\" self._pre_send_input(channel_input=channel_input) buf = b\"\" bytes_channel_input = channel_input.encode() bytes_channel_outputs = [ channel_output.encode() for channel_output in expected_outputs or [] ] self.logger.info( f\"sending channel input and read: {channel_input}; strip_prompt: {strip_prompt}; \" f\"expected_outputs: {expected_outputs}; read_duration: {read_duration}\" ) async with self._channel_lock(): self.write(channel_input=channel_input) _buf_until_input = await self._read_until_input(channel_input=bytes_channel_input) self.send_return() buf += await self._read_until_prompt_or_time( channel_outputs=bytes_channel_outputs, read_duration=read_duration ) processed_buf = self._process_output( buf=buf, strip_prompt=strip_prompt, ) return buf, processed_buf @timeout_wrapper async def send_inputs_interact( self, interact_events: List[Tuple[str, str, Optional[bool]]], *, interaction_complete_patterns: Optional[List[str]] = None, ) -> Tuple[bytes, bytes]: \"\"\" Interact with a device with changing prompts per input. Used to interact with devices where prompts change per input, and where inputs may be hidden such as in the case of a password input. This can be used to respond to challenges from devices such as the confirmation for the command \"clear logging\" on IOSXE devices for example. You may have as many elements in the \"interact_events\" list as needed, and each element of that list should be a tuple of two or three elements. The first element is always the input to send as a string, the second should be the expected response as a string, and the optional third a bool for whether or not the input is \"hidden\" (i.e. password input) An example where we need this sort of capability: ''' 3560CX#copy flash: scp: Source filename []? test1.txt Address or name of remote host []? 172.31.254.100 Destination username [carl]? Writing test1.txt Password: Password: Sink: C0644 639 test1.txt ! 639 bytes copied in 12.066 secs (53 bytes/sec) 3560CX# ''' To accomplish this we can use the following: ''' interact = conn.channel.send_inputs_interact( [ (\"copy flash: scp:\", \"Source filename []?\", False), (\"test1.txt\", \"Address or name of remote host []?\", False), (\"172.31.254.100\", \"Destination username [carl]?\", False), (\"carl\", \"Password:\", False), (\"super_secure_password\", prompt, True), ] ) ''' If we needed to deal with more prompts we could simply continue adding tuples to the list of interact \"events\". Args: interact_events: list of tuples containing the \"interactions\" with the device each list element must have an input and an expected response, and may have an optional bool for the third and final element -- the optional bool specifies if the input that is sent to the device is \"hidden\" (ex: password), if the hidden param is not provided it is assumed the input is \"normal\" (not hidden) interaction_complete_patterns: list of patterns, that if seen, indicate the interactive \"session\" has ended and we should exit the interactive session. Returns: Tuple[bytes, bytes]: output read from the channel with no whitespace trimming/cleaning, and the output read from the channel that has been \"cleaned up\" Raises: N/A \"\"\" self._pre_send_inputs_interact(interact_events=interact_events) buf = b\"\" processed_buf = b\"\" async with self._channel_lock(): for interact_event in interact_events: channel_input = interact_event[0] bytes_channel_input = channel_input.encode() channel_response = interact_event[1] prompts = [channel_response] if interaction_complete_patterns is not None: prompts.extend(interaction_complete_patterns) try: hidden_input = interact_event[2] except IndexError: hidden_input = False _channel_input = channel_input if not hidden_input else \"REDACTED\" self.logger.info( f\"sending interactive input: {_channel_input}; \" f\"expecting: {channel_response}; \" f\"hidden_input: {hidden_input}\" ) self.write(channel_input=channel_input, redacted=bool(hidden_input)) if channel_response and hidden_input is not True: buf += await self._read_until_input(channel_input=bytes_channel_input) self.send_return() buf += await self._read_until_explicit_prompt(prompts=prompts) processed_buf += self._process_output( buf=buf, strip_prompt=False, ) return buf, processed_buf Classes \u00b6 AsyncChannel \u00b6 1 2 3 4 5 6 7 8 9 10 11 BaseChannel Object -- provides convenience methods to both sync and async Channels Args: transport: initialized scrapli Transport/AsyncTransport object base_channel_args: BaseChannelArgs object Returns: None Raises: N/A Expand source code class AsyncChannel(BaseChannel): def __init__( self, transport: AsyncTransport, base_channel_args: BaseChannelArgs, ) -> None: super().__init__( transport=transport, base_channel_args=base_channel_args, ) self.transport: AsyncTransport self.channel_lock: Optional[asyncio.Lock] = None if self._base_channel_args.channel_lock: self.channel_lock = asyncio.Lock() @asynccontextmanager async def _channel_lock(self) -> AsyncIterator[None]: \"\"\" Lock the channel during public channel operations if channel_lock is enabled Args: N/A Yields: None Raises: N/A \"\"\" if self.channel_lock: async with self.channel_lock: yield else: yield async def read(self) -> bytes: r\"\"\" Read chunks of output from the channel Replaces any \\r characters that sometimes get stuffed into the output from the devices Args: N/A Returns: bytes: output read from channel Raises: N/A \"\"\" buf = await self.transport.read() buf = buf.replace(b\"\\r\", b\"\") self.logger.debug(f\"read: {repr(buf)}\") if self.channel_log: self.channel_log.write(buf) if b\"\\x1b\" in buf.lower(): buf = self._strip_ansi(buf=buf) return buf async def _read_until_input(self, channel_input: bytes) -> bytes: \"\"\" Read until all channel_input has been read on the channel Args: channel_input: bytes that should have been written to the channel Returns: bytes: output read from channel while checking for the input in the channel stream Raises: N/A \"\"\" buf = b\"\" if not channel_input: return buf # squish all channel input words together and cast to lower to make comparison easier processed_channel_input = b\"\".join(channel_input.lower().split()) while True: buf += await self.read() # replace any backspace chars (particular problem w/ junos), and remove any added spaces # this is just for comparison of the inputs to what was read from channel if processed_channel_input in b\"\".join(buf.lower().replace(b\"\\x08\", b\"\").split()): return buf async def _read_until_prompt(self, buf: bytes = b\"\") -> bytes: \"\"\" Read until expected prompt is seen. This reads until the \"normal\" `_base_channel_args.comms_prompt_pattern` is seen. The `_read_until_explicit_prompt` method can be used to read until some pattern in an arbitrary list of patterns is seen. Args: buf: output from previous reads if needed (used by scrapli netconf) Returns: bytes: output read from channel Raises: N/A \"\"\" search_pattern = self._get_prompt_pattern( class_pattern=self._base_channel_args.comms_prompt_pattern ) read_buf = BytesIO(buf) while True: b = await self.read() read_buf.write(b) search_buf = self._process_read_buf(read_buf=read_buf) channel_match = re.search( pattern=search_pattern, string=search_buf, ) if channel_match: return read_buf.getvalue() async def _read_until_explicit_prompt(self, prompts: List[str]) -> bytes: \"\"\" Read until expected prompt is seen. This method is for *explicit* prompt patterns instead of the \"standard\" prompt patterns contained in the `_base_channel_args.comms_prompt_pattern` attribute. Generally this is only used for `send_interactive` though it could be used elsewhere as well. Args: prompts: list of prompt patterns to look for, will return upon seeing any match Returns: bytes: output read from channel Raises: N/A \"\"\" search_patterns = [ self._get_prompt_pattern( class_pattern=self._base_channel_args.comms_prompt_pattern, pattern=prompt ) for prompt in prompts ] read_buf = BytesIO(b\"\") while True: b = await self.read() read_buf.write(b) search_buf = self._process_read_buf(read_buf=read_buf) for search_pattern in search_patterns: channel_match = re.search( pattern=search_pattern, string=search_buf, ) if channel_match: return read_buf.getvalue() async def _read_until_prompt_or_time( self, buf: bytes = b\"\", channel_outputs: Optional[List[bytes]] = None, read_duration: Optional[float] = None, ) -> bytes: \"\"\" Read until expected prompt is seen, outputs are seen, or for duration, whichever comes first As transport reading may block, transport timeout is temporarily set to the read_duration and any `ScrapliTimeout` that is raised while reading is ignored. Args: buf: bytes from previous reads if needed channel_outputs: List of bytes to search for in channel output, if any are seen, return read output read_duration: duration to read from channel for Returns: bytes: output read from channel Raises: N/A \"\"\" search_pattern = self._get_prompt_pattern( class_pattern=self._base_channel_args.comms_prompt_pattern, ) if channel_outputs is None: channel_outputs = [] if read_duration is None: read_duration = 2.5 regex_channel_outputs_pattern = self._join_and_compile(channel_outputs=channel_outputs) _transport_args = self.transport._base_transport_args # pylint: disable=W0212 previous_timeout_transport = _transport_args.timeout_transport _transport_args.timeout_transport = int(read_duration) read_buf = BytesIO(buf) start = time.time() while True: try: b = await self.read() read_buf.write(b) except ScrapliTimeout: pass search_buf = self._process_read_buf(read_buf=read_buf) if (time.time() - start) > read_duration: break if any((channel_output in search_buf for channel_output in channel_outputs)): break if re.search(pattern=regex_channel_outputs_pattern, string=search_buf): break if re.search(pattern=search_pattern, string=search_buf): break _transport_args.timeout_transport = previous_timeout_transport return read_buf.getvalue() @timeout_wrapper async def channel_authenticate_ssh( self, auth_password: str, auth_private_key_passphrase: str ) -> None: \"\"\" Handle SSH Authentication for transports that only operate \"in the channel\" (i.e. system) Args: auth_password: password to authenticate with auth_private_key_passphrase: passphrase for ssh key if necessary Returns: None Raises: ScrapliAuthenticationFailed: if password prompt seen more than twice ScrapliAuthenticationFailed: if passphrase prompt seen more than twice \"\"\" self.logger.debug(\"attempting in channel ssh authentication\") password_count = 0 passphrase_count = 0 authenticate_buf = b\"\" ( password_pattern, passphrase_pattern, prompt_pattern, ) = self._pre_channel_authenticate_ssh() async with self._channel_lock(): while True: try: buf = await asyncio.wait_for(self.read(), timeout=1) except asyncio.TimeoutError: buf = b\"\" authenticate_buf += buf.lower() if re.search( pattern=password_pattern, string=authenticate_buf, ): # clear the authentication buffer so we don't re-read the password prompt authenticate_buf = b\"\" password_count += 1 if password_count > 2: msg = \"password prompt seen more than once, assuming auth failed\" self.logger.critical(msg) raise ScrapliAuthenticationFailed(msg) self.write(channel_input=auth_password, redacted=True) self.send_return() if re.search( pattern=passphrase_pattern, string=authenticate_buf, ): # clear the authentication buffer so we don't re-read the passphrase prompt authenticate_buf = b\"\" passphrase_count += 1 if passphrase_count > 2: msg = \"passphrase prompt seen more than once, assuming auth failed\" self.logger.critical(msg) raise ScrapliAuthenticationFailed(msg) self.write(channel_input=auth_private_key_passphrase, redacted=True) self.send_return() if re.search( pattern=prompt_pattern, string=authenticate_buf, ): return @timeout_wrapper async def channel_authenticate_telnet( # noqa: C901 self, auth_username: str = \"\", auth_password: str = \"\" ) -> None: \"\"\" Handle Telnet Authentication Args: auth_username: username to use for telnet authentication auth_password: password to use for telnet authentication Returns: None Raises: ScrapliAuthenticationFailed: if password prompt seen more than twice ScrapliAuthenticationFailed: if login prompt seen more than twice \"\"\" self.logger.debug(\"attempting in channel telnet authentication\") username_count = 0 password_count = 0 authenticate_buf = b\"\" ( username_pattern, password_pattern, prompt_pattern, auth_start_time, return_interval, ) = self._pre_channel_authenticate_telnet() read_interval = self._base_channel_args.timeout_ops / 20 return_attempts = 1 async with self._channel_lock(): while True: try: buf = await asyncio.wait_for(self.read(), timeout=read_interval) except asyncio.TimeoutError: buf = b\"\" if not buf: current_iteration_time = datetime.now().timestamp() if (current_iteration_time - auth_start_time) > ( return_interval * return_attempts ): self.send_return() return_attempts += 1 authenticate_buf += buf.lower() if re.search( pattern=username_pattern, string=authenticate_buf, ): # clear the authentication buffer so we don't re-read the username prompt authenticate_buf = b\"\" username_count += 1 if username_count > 2: msg = \"username/login prompt seen more than once, assuming auth failed\" self.logger.critical(msg) raise ScrapliAuthenticationFailed(msg) self.write(channel_input=auth_username) self.send_return() if re.search( pattern=password_pattern, string=authenticate_buf, ): # clear the authentication buffer so we don't re-read the password prompt authenticate_buf = b\"\" password_count += 1 if password_count > 2: msg = \"password prompt seen more than once, assuming auth failed\" self.logger.critical(msg) raise ScrapliAuthenticationFailed(msg) self.write(channel_input=auth_password, redacted=True) self.send_return() if re.search( pattern=prompt_pattern, string=authenticate_buf, ): return @timeout_wrapper async def get_prompt(self) -> str: \"\"\" Get current channel prompt Args: N/A Returns: str: string of the current prompt Raises: N/A \"\"\" buf = b\"\" search_pattern = self._get_prompt_pattern( class_pattern=self._base_channel_args.comms_prompt_pattern ) async with self._channel_lock(): self.send_return() while True: buf += await self.read() channel_match = re.search( pattern=search_pattern, string=buf, ) if channel_match: current_prompt = channel_match.group(0) return current_prompt.decode().strip() @timeout_wrapper async def send_input( self, channel_input: str, *, strip_prompt: bool = True, eager: bool = False, ) -> Tuple[bytes, bytes]: \"\"\" Primary entry point to send data to devices in shell mode; accept input and returns result Args: channel_input: string input to send to channel strip_prompt: strip prompt or not, defaults to True (yes, strip the prompt) eager: eager mode reads and returns the `_read_until_input` value, but does not attempt to read to the prompt pattern -- this should not be used manually! (only used by `send_configs` with the eager flag set) Returns: Tuple[bytes, bytes]: tuple of \"raw\" output and \"processed\" (cleaned up/stripped) output Raises: N/A \"\"\" self._pre_send_input(channel_input=channel_input) buf = b\"\" bytes_channel_input = channel_input.encode() self.logger.info( f\"sending channel input: {channel_input}; strip_prompt: {strip_prompt}; eager: {eager}\" ) async with self._channel_lock(): self.write(channel_input=channel_input) _buf_until_input = await self._read_until_input(channel_input=bytes_channel_input) self.send_return() if not eager: buf += await self._read_until_prompt() processed_buf = self._process_output( buf=buf, strip_prompt=strip_prompt, ) return buf, processed_buf @timeout_wrapper async def send_input_and_read( self, channel_input: str, *, strip_prompt: bool = True, expected_outputs: Optional[List[str]] = None, read_duration: Optional[float] = None, ) -> Tuple[bytes, bytes]: \"\"\" Send a command and read until expected prompt is seen, outputs are seen, or for duration Args: channel_input: string input to send to channel strip_prompt: strip prompt or not, defaults to True (yes, strip the prompt) expected_outputs: list of strings to look for in output; if any of these are seen, return output read up till that read read_duration: float duration to read for Returns: Tuple[bytes, bytes]: tuple of \"raw\" output and \"processed\" (cleaned up/stripped) output Raises: N/A \"\"\" self._pre_send_input(channel_input=channel_input) buf = b\"\" bytes_channel_input = channel_input.encode() bytes_channel_outputs = [ channel_output.encode() for channel_output in expected_outputs or [] ] self.logger.info( f\"sending channel input and read: {channel_input}; strip_prompt: {strip_prompt}; \" f\"expected_outputs: {expected_outputs}; read_duration: {read_duration}\" ) async with self._channel_lock(): self.write(channel_input=channel_input) _buf_until_input = await self._read_until_input(channel_input=bytes_channel_input) self.send_return() buf += await self._read_until_prompt_or_time( channel_outputs=bytes_channel_outputs, read_duration=read_duration ) processed_buf = self._process_output( buf=buf, strip_prompt=strip_prompt, ) return buf, processed_buf @timeout_wrapper async def send_inputs_interact( self, interact_events: List[Tuple[str, str, Optional[bool]]], *, interaction_complete_patterns: Optional[List[str]] = None, ) -> Tuple[bytes, bytes]: \"\"\" Interact with a device with changing prompts per input. Used to interact with devices where prompts change per input, and where inputs may be hidden such as in the case of a password input. This can be used to respond to challenges from devices such as the confirmation for the command \"clear logging\" on IOSXE devices for example. You may have as many elements in the \"interact_events\" list as needed, and each element of that list should be a tuple of two or three elements. The first element is always the input to send as a string, the second should be the expected response as a string, and the optional third a bool for whether or not the input is \"hidden\" (i.e. password input) An example where we need this sort of capability: ''' 3560CX#copy flash: scp: Source filename []? test1.txt Address or name of remote host []? 172.31.254.100 Destination username [carl]? Writing test1.txt Password: Password: Sink: C0644 639 test1.txt ! 639 bytes copied in 12.066 secs (53 bytes/sec) 3560CX# ''' To accomplish this we can use the following: ''' interact = conn.channel.send_inputs_interact( [ (\"copy flash: scp:\", \"Source filename []?\", False), (\"test1.txt\", \"Address or name of remote host []?\", False), (\"172.31.254.100\", \"Destination username [carl]?\", False), (\"carl\", \"Password:\", False), (\"super_secure_password\", prompt, True), ] ) ''' If we needed to deal with more prompts we could simply continue adding tuples to the list of interact \"events\". Args: interact_events: list of tuples containing the \"interactions\" with the device each list element must have an input and an expected response, and may have an optional bool for the third and final element -- the optional bool specifies if the input that is sent to the device is \"hidden\" (ex: password), if the hidden param is not provided it is assumed the input is \"normal\" (not hidden) interaction_complete_patterns: list of patterns, that if seen, indicate the interactive \"session\" has ended and we should exit the interactive session. Returns: Tuple[bytes, bytes]: output read from the channel with no whitespace trimming/cleaning, and the output read from the channel that has been \"cleaned up\" Raises: N/A \"\"\" self._pre_send_inputs_interact(interact_events=interact_events) buf = b\"\" processed_buf = b\"\" async with self._channel_lock(): for interact_event in interact_events: channel_input = interact_event[0] bytes_channel_input = channel_input.encode() channel_response = interact_event[1] prompts = [channel_response] if interaction_complete_patterns is not None: prompts.extend(interaction_complete_patterns) try: hidden_input = interact_event[2] except IndexError: hidden_input = False _channel_input = channel_input if not hidden_input else \"REDACTED\" self.logger.info( f\"sending interactive input: {_channel_input}; \" f\"expecting: {channel_response}; \" f\"hidden_input: {hidden_input}\" ) self.write(channel_input=channel_input, redacted=bool(hidden_input)) if channel_response and hidden_input is not True: buf += await self._read_until_input(channel_input=bytes_channel_input) self.send_return() buf += await self._read_until_explicit_prompt(prompts=prompts) processed_buf += self._process_output( buf=buf, strip_prompt=False, ) return buf, processed_buf Ancestors (in MRO) \u00b6 scrapli.channel.base_channel.BaseChannel Methods \u00b6 channel_authenticate_ssh \u00b6 channel_authenticate_ssh(self, auth_password: str, auth_private_key_passphrase: str) \u2011> None 1 2 3 4 5 6 7 8 9 10 11 12 Handle SSH Authentication for transports that only operate \"in the channel\" (i.e. system) Args: auth_password: password to authenticate with auth_private_key_passphrase: passphrase for ssh key if necessary Returns: None Raises: ScrapliAuthenticationFailed: if password prompt seen more than twice ScrapliAuthenticationFailed: if passphrase prompt seen more than twice channel_authenticate_telnet \u00b6 channel_authenticate_telnet(self, auth_username: str = '', auth_password: str = '') \u2011> None 1 2 3 4 5 6 7 8 9 10 11 12 Handle Telnet Authentication Args: auth_username: username to use for telnet authentication auth_password: password to use for telnet authentication Returns: None Raises: ScrapliAuthenticationFailed: if password prompt seen more than twice ScrapliAuthenticationFailed: if login prompt seen more than twice get_prompt \u00b6 get_prompt(self) \u2011> str 1 2 3 4 5 6 7 8 9 10 Get current channel prompt Args: N/A Returns: str: string of the current prompt Raises: N/A read \u00b6 read(self) \u2011> bytes 1 2 3 4 5 6 7 8 9 10 11 12 Read chunks of output from the channel Replaces any \\r characters that sometimes get stuffed into the output from the devices Args: N/A Returns: bytes: output read from channel Raises: N/A send_input \u00b6 send_input(self, channel_input: str, *, strip_prompt: bool = True, eager: bool = False) \u2011> Tuple[bytes, bytes] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 Primary entry point to send data to devices in shell mode; accept input and returns result Args: channel_input: string input to send to channel strip_prompt: strip prompt or not, defaults to True (yes, strip the prompt) eager: eager mode reads and returns the `_read_until_input` value, but does not attempt to read to the prompt pattern -- this should not be used manually! (only used by `send_configs` with the eager flag set) Returns: Tuple[bytes, bytes]: tuple of \"raw\" output and \"processed\" (cleaned up/stripped) output Raises: N/A send_input_and_read \u00b6 send_input_and_read(self, channel_input: str, *, strip_prompt: bool = True, expected_outputs: Optional[List[str]] = None, read_duration: Optional[float] = None) \u2011> Tuple[bytes, bytes] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 Send a command and read until expected prompt is seen, outputs are seen, or for duration Args: channel_input: string input to send to channel strip_prompt: strip prompt or not, defaults to True (yes, strip the prompt) expected_outputs: list of strings to look for in output; if any of these are seen, return output read up till that read read_duration: float duration to read for Returns: Tuple[bytes, bytes]: tuple of \"raw\" output and \"processed\" (cleaned up/stripped) output Raises: N/A send_inputs_interact \u00b6 send_inputs_interact(self, interact_events: List[Tuple[str, str, Optional[bool]]], *, interaction_complete_patterns: Optional[List[str]] = None) \u2011> Tuple[bytes, bytes] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 Interact with a device with changing prompts per input. Used to interact with devices where prompts change per input, and where inputs may be hidden such as in the case of a password input. This can be used to respond to challenges from devices such as the confirmation for the command \"clear logging\" on IOSXE devices for example. You may have as many elements in the \"interact_events\" list as needed, and each element of that list should be a tuple of two or three elements. The first element is always the input to send as a string, the second should be the expected response as a string, and the optional third a bool for whether or not the input is \"hidden\" (i.e. password input) An example where we need this sort of capability: ''' 3560CX#copy flash: scp: Source filename []? test1.txt Address or name of remote host []? 172.31.254.100 Destination username [carl]? Writing test1.txt Password: Password: Sink: C0644 639 test1.txt ! 639 bytes copied in 12.066 secs (53 bytes/sec) 3560CX# ''' To accomplish this we can use the following: ''' interact = conn.channel.send_inputs_interact( [ (\"copy flash: scp:\", \"Source filename []?\", False), (\"test1.txt\", \"Address or name of remote host []?\", False), (\"172.31.254.100\", \"Destination username [carl]?\", False), (\"carl\", \"Password:\", False), (\"super_secure_password\", prompt, True), ] ) ''' If we needed to deal with more prompts we could simply continue adding tuples to the list of interact \"events\". Args: interact_events: list of tuples containing the \"interactions\" with the device each list element must have an input and an expected response, and may have an optional bool for the third and final element -- the optional bool specifies if the input that is sent to the device is \"hidden\" (ex: password), if the hidden param is not provided it is assumed the input is \"normal\" (not hidden) interaction_complete_patterns: list of patterns, that if seen, indicate the interactive \"session\" has ended and we should exit the interactive session. Returns: Tuple[bytes, bytes]: output read from the channel with no whitespace trimming/cleaning, and the output read from the channel that has been \"cleaned up\" Raises: N/A","title":"Async Channel"},{"location":"api_docs/channel/async_channel/#module-scraplichannelasync_channel","text":"scrapli.channel.async_channel Expand source code \"\"\"scrapli.channel.async_channel\"\"\" import asyncio import re import time from contextlib import asynccontextmanager from datetime import datetime from io import BytesIO from typing import AsyncIterator, List, Optional, Tuple from scrapli.channel.base_channel import BaseChannel, BaseChannelArgs from scrapli.decorators import timeout_wrapper from scrapli.exceptions import ScrapliAuthenticationFailed, ScrapliTimeout from scrapli.transport.base import AsyncTransport class AsyncChannel(BaseChannel): def __init__( self, transport: AsyncTransport, base_channel_args: BaseChannelArgs, ) -> None: super().__init__( transport=transport, base_channel_args=base_channel_args, ) self.transport: AsyncTransport self.channel_lock: Optional[asyncio.Lock] = None if self._base_channel_args.channel_lock: self.channel_lock = asyncio.Lock() @asynccontextmanager async def _channel_lock(self) -> AsyncIterator[None]: \"\"\" Lock the channel during public channel operations if channel_lock is enabled Args: N/A Yields: None Raises: N/A \"\"\" if self.channel_lock: async with self.channel_lock: yield else: yield async def read(self) -> bytes: r\"\"\" Read chunks of output from the channel Replaces any \\r characters that sometimes get stuffed into the output from the devices Args: N/A Returns: bytes: output read from channel Raises: N/A \"\"\" buf = await self.transport.read() buf = buf.replace(b\"\\r\", b\"\") self.logger.debug(f\"read: {repr(buf)}\") if self.channel_log: self.channel_log.write(buf) if b\"\\x1b\" in buf.lower(): buf = self._strip_ansi(buf=buf) return buf async def _read_until_input(self, channel_input: bytes) -> bytes: \"\"\" Read until all channel_input has been read on the channel Args: channel_input: bytes that should have been written to the channel Returns: bytes: output read from channel while checking for the input in the channel stream Raises: N/A \"\"\" buf = b\"\" if not channel_input: return buf # squish all channel input words together and cast to lower to make comparison easier processed_channel_input = b\"\".join(channel_input.lower().split()) while True: buf += await self.read() # replace any backspace chars (particular problem w/ junos), and remove any added spaces # this is just for comparison of the inputs to what was read from channel if processed_channel_input in b\"\".join(buf.lower().replace(b\"\\x08\", b\"\").split()): return buf async def _read_until_prompt(self, buf: bytes = b\"\") -> bytes: \"\"\" Read until expected prompt is seen. This reads until the \"normal\" `_base_channel_args.comms_prompt_pattern` is seen. The `_read_until_explicit_prompt` method can be used to read until some pattern in an arbitrary list of patterns is seen. Args: buf: output from previous reads if needed (used by scrapli netconf) Returns: bytes: output read from channel Raises: N/A \"\"\" search_pattern = self._get_prompt_pattern( class_pattern=self._base_channel_args.comms_prompt_pattern ) read_buf = BytesIO(buf) while True: b = await self.read() read_buf.write(b) search_buf = self._process_read_buf(read_buf=read_buf) channel_match = re.search( pattern=search_pattern, string=search_buf, ) if channel_match: return read_buf.getvalue() async def _read_until_explicit_prompt(self, prompts: List[str]) -> bytes: \"\"\" Read until expected prompt is seen. This method is for *explicit* prompt patterns instead of the \"standard\" prompt patterns contained in the `_base_channel_args.comms_prompt_pattern` attribute. Generally this is only used for `send_interactive` though it could be used elsewhere as well. Args: prompts: list of prompt patterns to look for, will return upon seeing any match Returns: bytes: output read from channel Raises: N/A \"\"\" search_patterns = [ self._get_prompt_pattern( class_pattern=self._base_channel_args.comms_prompt_pattern, pattern=prompt ) for prompt in prompts ] read_buf = BytesIO(b\"\") while True: b = await self.read() read_buf.write(b) search_buf = self._process_read_buf(read_buf=read_buf) for search_pattern in search_patterns: channel_match = re.search( pattern=search_pattern, string=search_buf, ) if channel_match: return read_buf.getvalue() async def _read_until_prompt_or_time( self, buf: bytes = b\"\", channel_outputs: Optional[List[bytes]] = None, read_duration: Optional[float] = None, ) -> bytes: \"\"\" Read until expected prompt is seen, outputs are seen, or for duration, whichever comes first As transport reading may block, transport timeout is temporarily set to the read_duration and any `ScrapliTimeout` that is raised while reading is ignored. Args: buf: bytes from previous reads if needed channel_outputs: List of bytes to search for in channel output, if any are seen, return read output read_duration: duration to read from channel for Returns: bytes: output read from channel Raises: N/A \"\"\" search_pattern = self._get_prompt_pattern( class_pattern=self._base_channel_args.comms_prompt_pattern, ) if channel_outputs is None: channel_outputs = [] if read_duration is None: read_duration = 2.5 regex_channel_outputs_pattern = self._join_and_compile(channel_outputs=channel_outputs) _transport_args = self.transport._base_transport_args # pylint: disable=W0212 previous_timeout_transport = _transport_args.timeout_transport _transport_args.timeout_transport = int(read_duration) read_buf = BytesIO(buf) start = time.time() while True: try: b = await self.read() read_buf.write(b) except ScrapliTimeout: pass search_buf = self._process_read_buf(read_buf=read_buf) if (time.time() - start) > read_duration: break if any((channel_output in search_buf for channel_output in channel_outputs)): break if re.search(pattern=regex_channel_outputs_pattern, string=search_buf): break if re.search(pattern=search_pattern, string=search_buf): break _transport_args.timeout_transport = previous_timeout_transport return read_buf.getvalue() @timeout_wrapper async def channel_authenticate_ssh( self, auth_password: str, auth_private_key_passphrase: str ) -> None: \"\"\" Handle SSH Authentication for transports that only operate \"in the channel\" (i.e. system) Args: auth_password: password to authenticate with auth_private_key_passphrase: passphrase for ssh key if necessary Returns: None Raises: ScrapliAuthenticationFailed: if password prompt seen more than twice ScrapliAuthenticationFailed: if passphrase prompt seen more than twice \"\"\" self.logger.debug(\"attempting in channel ssh authentication\") password_count = 0 passphrase_count = 0 authenticate_buf = b\"\" ( password_pattern, passphrase_pattern, prompt_pattern, ) = self._pre_channel_authenticate_ssh() async with self._channel_lock(): while True: try: buf = await asyncio.wait_for(self.read(), timeout=1) except asyncio.TimeoutError: buf = b\"\" authenticate_buf += buf.lower() if re.search( pattern=password_pattern, string=authenticate_buf, ): # clear the authentication buffer so we don't re-read the password prompt authenticate_buf = b\"\" password_count += 1 if password_count > 2: msg = \"password prompt seen more than once, assuming auth failed\" self.logger.critical(msg) raise ScrapliAuthenticationFailed(msg) self.write(channel_input=auth_password, redacted=True) self.send_return() if re.search( pattern=passphrase_pattern, string=authenticate_buf, ): # clear the authentication buffer so we don't re-read the passphrase prompt authenticate_buf = b\"\" passphrase_count += 1 if passphrase_count > 2: msg = \"passphrase prompt seen more than once, assuming auth failed\" self.logger.critical(msg) raise ScrapliAuthenticationFailed(msg) self.write(channel_input=auth_private_key_passphrase, redacted=True) self.send_return() if re.search( pattern=prompt_pattern, string=authenticate_buf, ): return @timeout_wrapper async def channel_authenticate_telnet( # noqa: C901 self, auth_username: str = \"\", auth_password: str = \"\" ) -> None: \"\"\" Handle Telnet Authentication Args: auth_username: username to use for telnet authentication auth_password: password to use for telnet authentication Returns: None Raises: ScrapliAuthenticationFailed: if password prompt seen more than twice ScrapliAuthenticationFailed: if login prompt seen more than twice \"\"\" self.logger.debug(\"attempting in channel telnet authentication\") username_count = 0 password_count = 0 authenticate_buf = b\"\" ( username_pattern, password_pattern, prompt_pattern, auth_start_time, return_interval, ) = self._pre_channel_authenticate_telnet() read_interval = self._base_channel_args.timeout_ops / 20 return_attempts = 1 async with self._channel_lock(): while True: try: buf = await asyncio.wait_for(self.read(), timeout=read_interval) except asyncio.TimeoutError: buf = b\"\" if not buf: current_iteration_time = datetime.now().timestamp() if (current_iteration_time - auth_start_time) > ( return_interval * return_attempts ): self.send_return() return_attempts += 1 authenticate_buf += buf.lower() if re.search( pattern=username_pattern, string=authenticate_buf, ): # clear the authentication buffer so we don't re-read the username prompt authenticate_buf = b\"\" username_count += 1 if username_count > 2: msg = \"username/login prompt seen more than once, assuming auth failed\" self.logger.critical(msg) raise ScrapliAuthenticationFailed(msg) self.write(channel_input=auth_username) self.send_return() if re.search( pattern=password_pattern, string=authenticate_buf, ): # clear the authentication buffer so we don't re-read the password prompt authenticate_buf = b\"\" password_count += 1 if password_count > 2: msg = \"password prompt seen more than once, assuming auth failed\" self.logger.critical(msg) raise ScrapliAuthenticationFailed(msg) self.write(channel_input=auth_password, redacted=True) self.send_return() if re.search( pattern=prompt_pattern, string=authenticate_buf, ): return @timeout_wrapper async def get_prompt(self) -> str: \"\"\" Get current channel prompt Args: N/A Returns: str: string of the current prompt Raises: N/A \"\"\" buf = b\"\" search_pattern = self._get_prompt_pattern( class_pattern=self._base_channel_args.comms_prompt_pattern ) async with self._channel_lock(): self.send_return() while True: buf += await self.read() channel_match = re.search( pattern=search_pattern, string=buf, ) if channel_match: current_prompt = channel_match.group(0) return current_prompt.decode().strip() @timeout_wrapper async def send_input( self, channel_input: str, *, strip_prompt: bool = True, eager: bool = False, ) -> Tuple[bytes, bytes]: \"\"\" Primary entry point to send data to devices in shell mode; accept input and returns result Args: channel_input: string input to send to channel strip_prompt: strip prompt or not, defaults to True (yes, strip the prompt) eager: eager mode reads and returns the `_read_until_input` value, but does not attempt to read to the prompt pattern -- this should not be used manually! (only used by `send_configs` with the eager flag set) Returns: Tuple[bytes, bytes]: tuple of \"raw\" output and \"processed\" (cleaned up/stripped) output Raises: N/A \"\"\" self._pre_send_input(channel_input=channel_input) buf = b\"\" bytes_channel_input = channel_input.encode() self.logger.info( f\"sending channel input: {channel_input}; strip_prompt: {strip_prompt}; eager: {eager}\" ) async with self._channel_lock(): self.write(channel_input=channel_input) _buf_until_input = await self._read_until_input(channel_input=bytes_channel_input) self.send_return() if not eager: buf += await self._read_until_prompt() processed_buf = self._process_output( buf=buf, strip_prompt=strip_prompt, ) return buf, processed_buf @timeout_wrapper async def send_input_and_read( self, channel_input: str, *, strip_prompt: bool = True, expected_outputs: Optional[List[str]] = None, read_duration: Optional[float] = None, ) -> Tuple[bytes, bytes]: \"\"\" Send a command and read until expected prompt is seen, outputs are seen, or for duration Args: channel_input: string input to send to channel strip_prompt: strip prompt or not, defaults to True (yes, strip the prompt) expected_outputs: list of strings to look for in output; if any of these are seen, return output read up till that read read_duration: float duration to read for Returns: Tuple[bytes, bytes]: tuple of \"raw\" output and \"processed\" (cleaned up/stripped) output Raises: N/A \"\"\" self._pre_send_input(channel_input=channel_input) buf = b\"\" bytes_channel_input = channel_input.encode() bytes_channel_outputs = [ channel_output.encode() for channel_output in expected_outputs or [] ] self.logger.info( f\"sending channel input and read: {channel_input}; strip_prompt: {strip_prompt}; \" f\"expected_outputs: {expected_outputs}; read_duration: {read_duration}\" ) async with self._channel_lock(): self.write(channel_input=channel_input) _buf_until_input = await self._read_until_input(channel_input=bytes_channel_input) self.send_return() buf += await self._read_until_prompt_or_time( channel_outputs=bytes_channel_outputs, read_duration=read_duration ) processed_buf = self._process_output( buf=buf, strip_prompt=strip_prompt, ) return buf, processed_buf @timeout_wrapper async def send_inputs_interact( self, interact_events: List[Tuple[str, str, Optional[bool]]], *, interaction_complete_patterns: Optional[List[str]] = None, ) -> Tuple[bytes, bytes]: \"\"\" Interact with a device with changing prompts per input. Used to interact with devices where prompts change per input, and where inputs may be hidden such as in the case of a password input. This can be used to respond to challenges from devices such as the confirmation for the command \"clear logging\" on IOSXE devices for example. You may have as many elements in the \"interact_events\" list as needed, and each element of that list should be a tuple of two or three elements. The first element is always the input to send as a string, the second should be the expected response as a string, and the optional third a bool for whether or not the input is \"hidden\" (i.e. password input) An example where we need this sort of capability: ''' 3560CX#copy flash: scp: Source filename []? test1.txt Address or name of remote host []? 172.31.254.100 Destination username [carl]? Writing test1.txt Password: Password: Sink: C0644 639 test1.txt ! 639 bytes copied in 12.066 secs (53 bytes/sec) 3560CX# ''' To accomplish this we can use the following: ''' interact = conn.channel.send_inputs_interact( [ (\"copy flash: scp:\", \"Source filename []?\", False), (\"test1.txt\", \"Address or name of remote host []?\", False), (\"172.31.254.100\", \"Destination username [carl]?\", False), (\"carl\", \"Password:\", False), (\"super_secure_password\", prompt, True), ] ) ''' If we needed to deal with more prompts we could simply continue adding tuples to the list of interact \"events\". Args: interact_events: list of tuples containing the \"interactions\" with the device each list element must have an input and an expected response, and may have an optional bool for the third and final element -- the optional bool specifies if the input that is sent to the device is \"hidden\" (ex: password), if the hidden param is not provided it is assumed the input is \"normal\" (not hidden) interaction_complete_patterns: list of patterns, that if seen, indicate the interactive \"session\" has ended and we should exit the interactive session. Returns: Tuple[bytes, bytes]: output read from the channel with no whitespace trimming/cleaning, and the output read from the channel that has been \"cleaned up\" Raises: N/A \"\"\" self._pre_send_inputs_interact(interact_events=interact_events) buf = b\"\" processed_buf = b\"\" async with self._channel_lock(): for interact_event in interact_events: channel_input = interact_event[0] bytes_channel_input = channel_input.encode() channel_response = interact_event[1] prompts = [channel_response] if interaction_complete_patterns is not None: prompts.extend(interaction_complete_patterns) try: hidden_input = interact_event[2] except IndexError: hidden_input = False _channel_input = channel_input if not hidden_input else \"REDACTED\" self.logger.info( f\"sending interactive input: {_channel_input}; \" f\"expecting: {channel_response}; \" f\"hidden_input: {hidden_input}\" ) self.write(channel_input=channel_input, redacted=bool(hidden_input)) if channel_response and hidden_input is not True: buf += await self._read_until_input(channel_input=bytes_channel_input) self.send_return() buf += await self._read_until_explicit_prompt(prompts=prompts) processed_buf += self._process_output( buf=buf, strip_prompt=False, ) return buf, processed_buf","title":"Module scrapli.channel.async_channel"},{"location":"api_docs/channel/async_channel/#classes","text":"","title":"Classes"},{"location":"api_docs/channel/async_channel/#asyncchannel","text":"1 2 3 4 5 6 7 8 9 10 11 BaseChannel Object -- provides convenience methods to both sync and async Channels Args: transport: initialized scrapli Transport/AsyncTransport object base_channel_args: BaseChannelArgs object Returns: None Raises: N/A Expand source code class AsyncChannel(BaseChannel): def __init__( self, transport: AsyncTransport, base_channel_args: BaseChannelArgs, ) -> None: super().__init__( transport=transport, base_channel_args=base_channel_args, ) self.transport: AsyncTransport self.channel_lock: Optional[asyncio.Lock] = None if self._base_channel_args.channel_lock: self.channel_lock = asyncio.Lock() @asynccontextmanager async def _channel_lock(self) -> AsyncIterator[None]: \"\"\" Lock the channel during public channel operations if channel_lock is enabled Args: N/A Yields: None Raises: N/A \"\"\" if self.channel_lock: async with self.channel_lock: yield else: yield async def read(self) -> bytes: r\"\"\" Read chunks of output from the channel Replaces any \\r characters that sometimes get stuffed into the output from the devices Args: N/A Returns: bytes: output read from channel Raises: N/A \"\"\" buf = await self.transport.read() buf = buf.replace(b\"\\r\", b\"\") self.logger.debug(f\"read: {repr(buf)}\") if self.channel_log: self.channel_log.write(buf) if b\"\\x1b\" in buf.lower(): buf = self._strip_ansi(buf=buf) return buf async def _read_until_input(self, channel_input: bytes) -> bytes: \"\"\" Read until all channel_input has been read on the channel Args: channel_input: bytes that should have been written to the channel Returns: bytes: output read from channel while checking for the input in the channel stream Raises: N/A \"\"\" buf = b\"\" if not channel_input: return buf # squish all channel input words together and cast to lower to make comparison easier processed_channel_input = b\"\".join(channel_input.lower().split()) while True: buf += await self.read() # replace any backspace chars (particular problem w/ junos), and remove any added spaces # this is just for comparison of the inputs to what was read from channel if processed_channel_input in b\"\".join(buf.lower().replace(b\"\\x08\", b\"\").split()): return buf async def _read_until_prompt(self, buf: bytes = b\"\") -> bytes: \"\"\" Read until expected prompt is seen. This reads until the \"normal\" `_base_channel_args.comms_prompt_pattern` is seen. The `_read_until_explicit_prompt` method can be used to read until some pattern in an arbitrary list of patterns is seen. Args: buf: output from previous reads if needed (used by scrapli netconf) Returns: bytes: output read from channel Raises: N/A \"\"\" search_pattern = self._get_prompt_pattern( class_pattern=self._base_channel_args.comms_prompt_pattern ) read_buf = BytesIO(buf) while True: b = await self.read() read_buf.write(b) search_buf = self._process_read_buf(read_buf=read_buf) channel_match = re.search( pattern=search_pattern, string=search_buf, ) if channel_match: return read_buf.getvalue() async def _read_until_explicit_prompt(self, prompts: List[str]) -> bytes: \"\"\" Read until expected prompt is seen. This method is for *explicit* prompt patterns instead of the \"standard\" prompt patterns contained in the `_base_channel_args.comms_prompt_pattern` attribute. Generally this is only used for `send_interactive` though it could be used elsewhere as well. Args: prompts: list of prompt patterns to look for, will return upon seeing any match Returns: bytes: output read from channel Raises: N/A \"\"\" search_patterns = [ self._get_prompt_pattern( class_pattern=self._base_channel_args.comms_prompt_pattern, pattern=prompt ) for prompt in prompts ] read_buf = BytesIO(b\"\") while True: b = await self.read() read_buf.write(b) search_buf = self._process_read_buf(read_buf=read_buf) for search_pattern in search_patterns: channel_match = re.search( pattern=search_pattern, string=search_buf, ) if channel_match: return read_buf.getvalue() async def _read_until_prompt_or_time( self, buf: bytes = b\"\", channel_outputs: Optional[List[bytes]] = None, read_duration: Optional[float] = None, ) -> bytes: \"\"\" Read until expected prompt is seen, outputs are seen, or for duration, whichever comes first As transport reading may block, transport timeout is temporarily set to the read_duration and any `ScrapliTimeout` that is raised while reading is ignored. Args: buf: bytes from previous reads if needed channel_outputs: List of bytes to search for in channel output, if any are seen, return read output read_duration: duration to read from channel for Returns: bytes: output read from channel Raises: N/A \"\"\" search_pattern = self._get_prompt_pattern( class_pattern=self._base_channel_args.comms_prompt_pattern, ) if channel_outputs is None: channel_outputs = [] if read_duration is None: read_duration = 2.5 regex_channel_outputs_pattern = self._join_and_compile(channel_outputs=channel_outputs) _transport_args = self.transport._base_transport_args # pylint: disable=W0212 previous_timeout_transport = _transport_args.timeout_transport _transport_args.timeout_transport = int(read_duration) read_buf = BytesIO(buf) start = time.time() while True: try: b = await self.read() read_buf.write(b) except ScrapliTimeout: pass search_buf = self._process_read_buf(read_buf=read_buf) if (time.time() - start) > read_duration: break if any((channel_output in search_buf for channel_output in channel_outputs)): break if re.search(pattern=regex_channel_outputs_pattern, string=search_buf): break if re.search(pattern=search_pattern, string=search_buf): break _transport_args.timeout_transport = previous_timeout_transport return read_buf.getvalue() @timeout_wrapper async def channel_authenticate_ssh( self, auth_password: str, auth_private_key_passphrase: str ) -> None: \"\"\" Handle SSH Authentication for transports that only operate \"in the channel\" (i.e. system) Args: auth_password: password to authenticate with auth_private_key_passphrase: passphrase for ssh key if necessary Returns: None Raises: ScrapliAuthenticationFailed: if password prompt seen more than twice ScrapliAuthenticationFailed: if passphrase prompt seen more than twice \"\"\" self.logger.debug(\"attempting in channel ssh authentication\") password_count = 0 passphrase_count = 0 authenticate_buf = b\"\" ( password_pattern, passphrase_pattern, prompt_pattern, ) = self._pre_channel_authenticate_ssh() async with self._channel_lock(): while True: try: buf = await asyncio.wait_for(self.read(), timeout=1) except asyncio.TimeoutError: buf = b\"\" authenticate_buf += buf.lower() if re.search( pattern=password_pattern, string=authenticate_buf, ): # clear the authentication buffer so we don't re-read the password prompt authenticate_buf = b\"\" password_count += 1 if password_count > 2: msg = \"password prompt seen more than once, assuming auth failed\" self.logger.critical(msg) raise ScrapliAuthenticationFailed(msg) self.write(channel_input=auth_password, redacted=True) self.send_return() if re.search( pattern=passphrase_pattern, string=authenticate_buf, ): # clear the authentication buffer so we don't re-read the passphrase prompt authenticate_buf = b\"\" passphrase_count += 1 if passphrase_count > 2: msg = \"passphrase prompt seen more than once, assuming auth failed\" self.logger.critical(msg) raise ScrapliAuthenticationFailed(msg) self.write(channel_input=auth_private_key_passphrase, redacted=True) self.send_return() if re.search( pattern=prompt_pattern, string=authenticate_buf, ): return @timeout_wrapper async def channel_authenticate_telnet( # noqa: C901 self, auth_username: str = \"\", auth_password: str = \"\" ) -> None: \"\"\" Handle Telnet Authentication Args: auth_username: username to use for telnet authentication auth_password: password to use for telnet authentication Returns: None Raises: ScrapliAuthenticationFailed: if password prompt seen more than twice ScrapliAuthenticationFailed: if login prompt seen more than twice \"\"\" self.logger.debug(\"attempting in channel telnet authentication\") username_count = 0 password_count = 0 authenticate_buf = b\"\" ( username_pattern, password_pattern, prompt_pattern, auth_start_time, return_interval, ) = self._pre_channel_authenticate_telnet() read_interval = self._base_channel_args.timeout_ops / 20 return_attempts = 1 async with self._channel_lock(): while True: try: buf = await asyncio.wait_for(self.read(), timeout=read_interval) except asyncio.TimeoutError: buf = b\"\" if not buf: current_iteration_time = datetime.now().timestamp() if (current_iteration_time - auth_start_time) > ( return_interval * return_attempts ): self.send_return() return_attempts += 1 authenticate_buf += buf.lower() if re.search( pattern=username_pattern, string=authenticate_buf, ): # clear the authentication buffer so we don't re-read the username prompt authenticate_buf = b\"\" username_count += 1 if username_count > 2: msg = \"username/login prompt seen more than once, assuming auth failed\" self.logger.critical(msg) raise ScrapliAuthenticationFailed(msg) self.write(channel_input=auth_username) self.send_return() if re.search( pattern=password_pattern, string=authenticate_buf, ): # clear the authentication buffer so we don't re-read the password prompt authenticate_buf = b\"\" password_count += 1 if password_count > 2: msg = \"password prompt seen more than once, assuming auth failed\" self.logger.critical(msg) raise ScrapliAuthenticationFailed(msg) self.write(channel_input=auth_password, redacted=True) self.send_return() if re.search( pattern=prompt_pattern, string=authenticate_buf, ): return @timeout_wrapper async def get_prompt(self) -> str: \"\"\" Get current channel prompt Args: N/A Returns: str: string of the current prompt Raises: N/A \"\"\" buf = b\"\" search_pattern = self._get_prompt_pattern( class_pattern=self._base_channel_args.comms_prompt_pattern ) async with self._channel_lock(): self.send_return() while True: buf += await self.read() channel_match = re.search( pattern=search_pattern, string=buf, ) if channel_match: current_prompt = channel_match.group(0) return current_prompt.decode().strip() @timeout_wrapper async def send_input( self, channel_input: str, *, strip_prompt: bool = True, eager: bool = False, ) -> Tuple[bytes, bytes]: \"\"\" Primary entry point to send data to devices in shell mode; accept input and returns result Args: channel_input: string input to send to channel strip_prompt: strip prompt or not, defaults to True (yes, strip the prompt) eager: eager mode reads and returns the `_read_until_input` value, but does not attempt to read to the prompt pattern -- this should not be used manually! (only used by `send_configs` with the eager flag set) Returns: Tuple[bytes, bytes]: tuple of \"raw\" output and \"processed\" (cleaned up/stripped) output Raises: N/A \"\"\" self._pre_send_input(channel_input=channel_input) buf = b\"\" bytes_channel_input = channel_input.encode() self.logger.info( f\"sending channel input: {channel_input}; strip_prompt: {strip_prompt}; eager: {eager}\" ) async with self._channel_lock(): self.write(channel_input=channel_input) _buf_until_input = await self._read_until_input(channel_input=bytes_channel_input) self.send_return() if not eager: buf += await self._read_until_prompt() processed_buf = self._process_output( buf=buf, strip_prompt=strip_prompt, ) return buf, processed_buf @timeout_wrapper async def send_input_and_read( self, channel_input: str, *, strip_prompt: bool = True, expected_outputs: Optional[List[str]] = None, read_duration: Optional[float] = None, ) -> Tuple[bytes, bytes]: \"\"\" Send a command and read until expected prompt is seen, outputs are seen, or for duration Args: channel_input: string input to send to channel strip_prompt: strip prompt or not, defaults to True (yes, strip the prompt) expected_outputs: list of strings to look for in output; if any of these are seen, return output read up till that read read_duration: float duration to read for Returns: Tuple[bytes, bytes]: tuple of \"raw\" output and \"processed\" (cleaned up/stripped) output Raises: N/A \"\"\" self._pre_send_input(channel_input=channel_input) buf = b\"\" bytes_channel_input = channel_input.encode() bytes_channel_outputs = [ channel_output.encode() for channel_output in expected_outputs or [] ] self.logger.info( f\"sending channel input and read: {channel_input}; strip_prompt: {strip_prompt}; \" f\"expected_outputs: {expected_outputs}; read_duration: {read_duration}\" ) async with self._channel_lock(): self.write(channel_input=channel_input) _buf_until_input = await self._read_until_input(channel_input=bytes_channel_input) self.send_return() buf += await self._read_until_prompt_or_time( channel_outputs=bytes_channel_outputs, read_duration=read_duration ) processed_buf = self._process_output( buf=buf, strip_prompt=strip_prompt, ) return buf, processed_buf @timeout_wrapper async def send_inputs_interact( self, interact_events: List[Tuple[str, str, Optional[bool]]], *, interaction_complete_patterns: Optional[List[str]] = None, ) -> Tuple[bytes, bytes]: \"\"\" Interact with a device with changing prompts per input. Used to interact with devices where prompts change per input, and where inputs may be hidden such as in the case of a password input. This can be used to respond to challenges from devices such as the confirmation for the command \"clear logging\" on IOSXE devices for example. You may have as many elements in the \"interact_events\" list as needed, and each element of that list should be a tuple of two or three elements. The first element is always the input to send as a string, the second should be the expected response as a string, and the optional third a bool for whether or not the input is \"hidden\" (i.e. password input) An example where we need this sort of capability: ''' 3560CX#copy flash: scp: Source filename []? test1.txt Address or name of remote host []? 172.31.254.100 Destination username [carl]? Writing test1.txt Password: Password: Sink: C0644 639 test1.txt ! 639 bytes copied in 12.066 secs (53 bytes/sec) 3560CX# ''' To accomplish this we can use the following: ''' interact = conn.channel.send_inputs_interact( [ (\"copy flash: scp:\", \"Source filename []?\", False), (\"test1.txt\", \"Address or name of remote host []?\", False), (\"172.31.254.100\", \"Destination username [carl]?\", False), (\"carl\", \"Password:\", False), (\"super_secure_password\", prompt, True), ] ) ''' If we needed to deal with more prompts we could simply continue adding tuples to the list of interact \"events\". Args: interact_events: list of tuples containing the \"interactions\" with the device each list element must have an input and an expected response, and may have an optional bool for the third and final element -- the optional bool specifies if the input that is sent to the device is \"hidden\" (ex: password), if the hidden param is not provided it is assumed the input is \"normal\" (not hidden) interaction_complete_patterns: list of patterns, that if seen, indicate the interactive \"session\" has ended and we should exit the interactive session. Returns: Tuple[bytes, bytes]: output read from the channel with no whitespace trimming/cleaning, and the output read from the channel that has been \"cleaned up\" Raises: N/A \"\"\" self._pre_send_inputs_interact(interact_events=interact_events) buf = b\"\" processed_buf = b\"\" async with self._channel_lock(): for interact_event in interact_events: channel_input = interact_event[0] bytes_channel_input = channel_input.encode() channel_response = interact_event[1] prompts = [channel_response] if interaction_complete_patterns is not None: prompts.extend(interaction_complete_patterns) try: hidden_input = interact_event[2] except IndexError: hidden_input = False _channel_input = channel_input if not hidden_input else \"REDACTED\" self.logger.info( f\"sending interactive input: {_channel_input}; \" f\"expecting: {channel_response}; \" f\"hidden_input: {hidden_input}\" ) self.write(channel_input=channel_input, redacted=bool(hidden_input)) if channel_response and hidden_input is not True: buf += await self._read_until_input(channel_input=bytes_channel_input) self.send_return() buf += await self._read_until_explicit_prompt(prompts=prompts) processed_buf += self._process_output( buf=buf, strip_prompt=False, ) return buf, processed_buf","title":"AsyncChannel"},{"location":"api_docs/channel/async_channel/#ancestors-in-mro","text":"scrapli.channel.base_channel.BaseChannel","title":"Ancestors (in MRO)"},{"location":"api_docs/channel/async_channel/#methods","text":"","title":"Methods"},{"location":"api_docs/channel/async_channel/#channel_authenticate_ssh","text":"channel_authenticate_ssh(self, auth_password: str, auth_private_key_passphrase: str) \u2011> None 1 2 3 4 5 6 7 8 9 10 11 12 Handle SSH Authentication for transports that only operate \"in the channel\" (i.e. system) Args: auth_password: password to authenticate with auth_private_key_passphrase: passphrase for ssh key if necessary Returns: None Raises: ScrapliAuthenticationFailed: if password prompt seen more than twice ScrapliAuthenticationFailed: if passphrase prompt seen more than twice","title":"channel_authenticate_ssh"},{"location":"api_docs/channel/async_channel/#channel_authenticate_telnet","text":"channel_authenticate_telnet(self, auth_username: str = '', auth_password: str = '') \u2011> None 1 2 3 4 5 6 7 8 9 10 11 12 Handle Telnet Authentication Args: auth_username: username to use for telnet authentication auth_password: password to use for telnet authentication Returns: None Raises: ScrapliAuthenticationFailed: if password prompt seen more than twice ScrapliAuthenticationFailed: if login prompt seen more than twice","title":"channel_authenticate_telnet"},{"location":"api_docs/channel/async_channel/#get_prompt","text":"get_prompt(self) \u2011> str 1 2 3 4 5 6 7 8 9 10 Get current channel prompt Args: N/A Returns: str: string of the current prompt Raises: N/A","title":"get_prompt"},{"location":"api_docs/channel/async_channel/#read","text":"read(self) \u2011> bytes 1 2 3 4 5 6 7 8 9 10 11 12 Read chunks of output from the channel Replaces any \\r characters that sometimes get stuffed into the output from the devices Args: N/A Returns: bytes: output read from channel Raises: N/A","title":"read"},{"location":"api_docs/channel/async_channel/#send_input","text":"send_input(self, channel_input: str, *, strip_prompt: bool = True, eager: bool = False) \u2011> Tuple[bytes, bytes] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 Primary entry point to send data to devices in shell mode; accept input and returns result Args: channel_input: string input to send to channel strip_prompt: strip prompt or not, defaults to True (yes, strip the prompt) eager: eager mode reads and returns the `_read_until_input` value, but does not attempt to read to the prompt pattern -- this should not be used manually! (only used by `send_configs` with the eager flag set) Returns: Tuple[bytes, bytes]: tuple of \"raw\" output and \"processed\" (cleaned up/stripped) output Raises: N/A","title":"send_input"},{"location":"api_docs/channel/async_channel/#send_input_and_read","text":"send_input_and_read(self, channel_input: str, *, strip_prompt: bool = True, expected_outputs: Optional[List[str]] = None, read_duration: Optional[float] = None) \u2011> Tuple[bytes, bytes] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 Send a command and read until expected prompt is seen, outputs are seen, or for duration Args: channel_input: string input to send to channel strip_prompt: strip prompt or not, defaults to True (yes, strip the prompt) expected_outputs: list of strings to look for in output; if any of these are seen, return output read up till that read read_duration: float duration to read for Returns: Tuple[bytes, bytes]: tuple of \"raw\" output and \"processed\" (cleaned up/stripped) output Raises: N/A","title":"send_input_and_read"},{"location":"api_docs/channel/async_channel/#send_inputs_interact","text":"send_inputs_interact(self, interact_events: List[Tuple[str, str, Optional[bool]]], *, interaction_complete_patterns: Optional[List[str]] = None) \u2011> Tuple[bytes, bytes] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 Interact with a device with changing prompts per input. Used to interact with devices where prompts change per input, and where inputs may be hidden such as in the case of a password input. This can be used to respond to challenges from devices such as the confirmation for the command \"clear logging\" on IOSXE devices for example. You may have as many elements in the \"interact_events\" list as needed, and each element of that list should be a tuple of two or three elements. The first element is always the input to send as a string, the second should be the expected response as a string, and the optional third a bool for whether or not the input is \"hidden\" (i.e. password input) An example where we need this sort of capability: ''' 3560CX#copy flash: scp: Source filename []? test1.txt Address or name of remote host []? 172.31.254.100 Destination username [carl]? Writing test1.txt Password: Password: Sink: C0644 639 test1.txt ! 639 bytes copied in 12.066 secs (53 bytes/sec) 3560CX# ''' To accomplish this we can use the following: ''' interact = conn.channel.send_inputs_interact( [ (\"copy flash: scp:\", \"Source filename []?\", False), (\"test1.txt\", \"Address or name of remote host []?\", False), (\"172.31.254.100\", \"Destination username [carl]?\", False), (\"carl\", \"Password:\", False), (\"super_secure_password\", prompt, True), ] ) ''' If we needed to deal with more prompts we could simply continue adding tuples to the list of interact \"events\". Args: interact_events: list of tuples containing the \"interactions\" with the device each list element must have an input and an expected response, and may have an optional bool for the third and final element -- the optional bool specifies if the input that is sent to the device is \"hidden\" (ex: password), if the hidden param is not provided it is assumed the input is \"normal\" (not hidden) interaction_complete_patterns: list of patterns, that if seen, indicate the interactive \"session\" has ended and we should exit the interactive session. Returns: Tuple[bytes, bytes]: output read from the channel with no whitespace trimming/cleaning, and the output read from the channel that has been \"cleaned up\" Raises: N/A","title":"send_inputs_interact"},{"location":"api_docs/channel/base_channel/","text":"window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting()) Module scrapli.channel.base_channel \u00b6 scrapli.channel.base_channel Expand source code \"\"\"scrapli.channel.base_channel\"\"\" import re from dataclasses import dataclass from datetime import datetime from functools import lru_cache from io import SEEK_END, BytesIO from typing import BinaryIO, List, Optional, Pattern, Tuple, Union from scrapli.exceptions import ScrapliAuthenticationFailed, ScrapliTypeError, ScrapliValueError from scrapli.logging import get_instance_logger from scrapli.transport.base import AsyncTransport, Transport ANSI_ESCAPE_PATTERN = re.compile(rb\"\\x1b(\\[.*?[@-~]|\\].*?(\\x07|\\x1b\\\\))\") @dataclass() class BaseChannelArgs: \"\"\" Dataclass for all base Channel arguments Args: comms_prompt_pattern: comms_prompt_pattern to assign to the channel; should generally be created/passed from the driver class comms_return_char: comms_return_char to assign to the channel, see above comms_prompt_search_depth: depth of the buffer to search in for searching for the prompt in \"read_until_prompt\"; smaller number here will generally be faster, though may be less reliable; default value is 1000 timeout_ops: timeout_ops to assign to the channel, see above channel_log: log \"channel\" output -- this would be the output you would normally see on a terminal. If `True` logs to `scrapli_channel.log`, if a string is provided, logs to wherever that string points channel_log_mode: \"write\"|\"append\", all other values will raise ValueError, does what it sounds like it should by setting the channel log to the provided mode channel_lock: bool indicated if channel lock should be used for all read/write operations Returns: None Raises: N/A \"\"\" comms_prompt_pattern: str = r\"^[a-z0-9.\\-@()/:]{1,32}[#>$]$\" comms_return_char: str = \"\\n\" comms_prompt_search_depth: int = 1000 timeout_ops: float = 30.0 channel_log: Union[str, bool, BytesIO] = False channel_log_mode: str = \"write\" channel_lock: bool = False def __post_init__(self) -> None: \"\"\" Validate dataclass arguments at end of initialization Args: N/A Returns: None Raises: ScrapliValueError: if invalid channel_log_mode provided \"\"\" if self.channel_log_mode.lower() not in ( \"write\", \"append\", ): raise ScrapliValueError( f\"provided channel_log_mode '{self.channel_log_mode}' is not valid, mode must be \" f\"one of: 'write', 'append'\" ) if self.channel_log_mode.lower() == \"write\": self.channel_log_mode = \"w\" else: self.channel_log_mode = \"a\" class BaseChannel: def __init__( self, transport: Union[AsyncTransport, Transport], base_channel_args: BaseChannelArgs, ): \"\"\" BaseChannel Object -- provides convenience methods to both sync and async Channels Args: transport: initialized scrapli Transport/AsyncTransport object base_channel_args: BaseChannelArgs object Returns: None Raises: N/A \"\"\" self.transport = transport self._base_channel_args = base_channel_args self.logger = get_instance_logger( instance_name=\"scrapli.channel\", host=self.transport._base_transport_args.host, port=self.transport._base_transport_args.port, uid=self.transport._base_transport_args.logging_uid, ) self.channel_log: Optional[BinaryIO] = None self._auth_telnet_login_pattern = r\"^(.*username:)|(.*login:)\\s?$\" self._auth_password_pattern = r\"(.*@.*)?password:\\s?$\" self._auth_passphrase_pattern = r\"enter passphrase for key\" @property def auth_telnet_login_pattern(self) -> Pattern[bytes]: \"\"\" Getter for `auth_telnet_login_pattern` attribute Args: N/A Returns: Pattern: compiled pattern of the set auth_telnet_login_pattern value Raises: N/A \"\"\" return re.compile(self._auth_telnet_login_pattern.encode(), flags=re.I | re.M) @auth_telnet_login_pattern.setter def auth_telnet_login_pattern(self, value: str) -> None: \"\"\" Setter for `auth_telnet_login_pattern` attribute Args: value: str value for auth_telnet_login_pattern; this value will be compiled withe re.I and re.M flags when the getter is called. Returns: None Raises: ScrapliTypeError: if value is not of type str \"\"\" self.logger.debug(f\"setting 'auth_telnet_login_pattern' value to '{value}'\") if not isinstance(value, str): raise ScrapliTypeError self._auth_telnet_login_pattern = value @property def auth_password_pattern(self) -> Pattern[bytes]: \"\"\" Getter for `auth_password_pattern` attribute Args: N/A Returns: Pattern: compiled pattern of the set auth_password_pattern value Raises: N/A \"\"\" return re.compile(self._auth_password_pattern.encode(), flags=re.I | re.M) @auth_password_pattern.setter def auth_password_pattern(self, value: str) -> None: \"\"\" Setter for `auth_password_pattern` attribute Args: value: str value for auth_password_pattern; this value will be compiled withe re.I and re.M flags when the getter is called. Returns: None Raises: ScrapliTypeError: if value is not of type str \"\"\" self.logger.debug(f\"setting 'auth_password_pattern' value to '{value}'\") if not isinstance(value, str): raise ScrapliTypeError self._auth_password_pattern = value @property def auth_passphrase_pattern(self) -> Pattern[bytes]: \"\"\" Getter for `auth_passphrase_pattern` attribute Args: N/A Returns: Pattern: compiled pattern of the set auth_passphrase_pattern value Raises: N/A \"\"\" return re.compile(self._auth_passphrase_pattern.encode(), flags=re.I | re.M) @auth_passphrase_pattern.setter def auth_passphrase_pattern(self, value: str) -> None: \"\"\" Setter for `auth_passphrase_pattern` attribute Args: value: str value for auth_passphrase_pattern; this value will be compiled withe re.I and re.M flags when the getter is called. Returns: None Raises: ScrapliTypeError: if value is not of type str \"\"\" self.logger.debug(f\"setting '_auth_passphrase_pattern' value to '{value}'\") if not isinstance(value, str): raise ScrapliTypeError self._auth_passphrase_pattern = value def open(self) -> None: \"\"\" Channel open method Args: N/A Returns: None Raises: N/A \"\"\" if self._base_channel_args.channel_log: if isinstance(self._base_channel_args.channel_log, BytesIO): self.channel_log = self._base_channel_args.channel_log else: channel_log_destination = \"scrapli_channel.log\" if isinstance(self._base_channel_args.channel_log, str): channel_log_destination = self._base_channel_args.channel_log self.logger.info( f\"channel log enabled, logging channel output to '{channel_log_destination}'\" ) # have to ignore type due to mypy not wanting to read the mode from formatted string # if you change the mode --> \"wb\" or \"ab\" it works as you would hope/expect; those # are the only values it can possibly be at this point though so we can safely # ignore here # note that this will *always* be binary mode, so there doesn't need to be any # encoding, hence ignoring that pylint message! self.channel_log = open( # pylint: disable=W1514,R1732 channel_log_destination, mode=f\"{self._base_channel_args.channel_log_mode}b\", # type: ignore ) def close(self) -> None: \"\"\" Channel close method Args: N/A Returns: None Raises: N/A \"\"\" if self.channel_log: self.channel_log.close() def _process_read_buf(self, read_buf: BytesIO) -> bytes: \"\"\" Process the read buffer Seeks backwards up to search depth then partitions on newlines. Partition is to ensure that the resulting search_buf does not end up with partial lines in the output which can cause prompt patterns to match places they should not match! Args: read_buf: bytesio object read from the transport Returns: bytes: cleaned up search buffer Raises: N/A \"\"\" read_buf.seek(-self._base_channel_args.comms_prompt_search_depth, SEEK_END) search_buf = read_buf.read() before, _, search_buf = search_buf.partition(b\"\\n\") if not search_buf: # didn't split on anything or nothing after partition search_buf = before return search_buf def write(self, channel_input: str, redacted: bool = False) -> None: \"\"\" Write input to the underlying Transport session Args: channel_input: string of input to send redacted: redact channel input from log or not Returns: None Raises: N/A \"\"\" log_output = \"REDACTED\" if redacted else repr(channel_input) self.logger.debug(f\"write: {log_output}\") self.transport.write(channel_input=channel_input.encode()) def send_return(self) -> None: \"\"\" Convenience method to send return char Args: N/A Returns: None Raises: N/A \"\"\" self.write(channel_input=self._base_channel_args.comms_return_char) @staticmethod def _join_and_compile(channel_outputs: Optional[List[bytes]]) -> Pattern[bytes]: \"\"\" Convenience method for read_until_prompt_or_time to join channel inputs into a regex pattern Args: channel_outputs: list of bytes channel inputs to join into a regex pattern Returns: Pattern: joined regex pattern or an empty pattern (empty bytes) Raises: N/A \"\"\" regex_channel_outputs = b\"\" if channel_outputs: regex_channel_outputs = b\"|\".join( [b\"(\" + channel_output + b\")\" for channel_output in channel_outputs] ) regex_channel_outputs_pattern = re.compile(pattern=regex_channel_outputs, flags=re.I | re.M) return regex_channel_outputs_pattern def _ssh_message_handler(self, output: bytes) -> None: # noqa: C901 \"\"\" Parse EOF messages from _pty_authenticate and create log/stack exception message Args: output: bytes output from _pty_authenticate Returns: N/A # noqa: DAR202 Raises: ScrapliAuthenticationFailed: if any errors are read in the output \"\"\" msg = \"\" if b\"host key verification failed\" in output.lower(): msg = \"Host key verification failed\" elif b\"operation timed out\" in output.lower() or b\"connection timed out\" in output.lower(): msg = \"Timed out connecting to host\" elif b\"no route to host\" in output.lower(): msg = \"No route to host\" elif b\"no matching key exchange\" in output.lower(): msg = \"No matching key exchange found for host\" key_exchange_pattern = re.compile( pattern=rb\"their offer: ([a-z0-9\\-,]*)\", flags=re.M | re.I ) offered_key_exchanges_match = re.search(pattern=key_exchange_pattern, string=output) if offered_key_exchanges_match: offered_key_exchanges = offered_key_exchanges_match.group(1).decode() msg += f\", their offer: {offered_key_exchanges}\" elif b\"no matching cipher\" in output.lower(): msg = \"No matching cipher found for host\" ciphers_pattern = re.compile(pattern=rb\"their offer: ([a-z0-9\\-,]*)\", flags=re.M | re.I) offered_ciphers_match = re.search(pattern=ciphers_pattern, string=output) if offered_ciphers_match: offered_ciphers = offered_ciphers_match.group(1).decode() msg += f\", their offer: {offered_ciphers}\" elif b\"bad configuration\" in output.lower(): msg = \"Bad SSH configuration option(s) for host\" configuration_pattern = re.compile( pattern=rb\"bad configuration option: ([a-z0-9\\+\\=,]*)\", flags=re.M | re.I ) configuration_issue_match = re.search(pattern=configuration_pattern, string=output) if configuration_issue_match: configuration_issues = configuration_issue_match.group(1).decode() msg += f\", bad option(s): {configuration_issues}\" elif b\"WARNING: UNPROTECTED PRIVATE KEY FILE!\" in output: msg = \"Permissions for private key are too open, authentication failed!\" elif b\"could not resolve hostname\" in output.lower(): msg = \"Could not resolve address for host\" elif b\"permission denied\" in output.lower(): msg = str(output) if msg: self.logger.critical(msg) raise ScrapliAuthenticationFailed(msg) @staticmethod @lru_cache() def _get_prompt_pattern(class_pattern: str, pattern: Optional[str] = None) -> Pattern[bytes]: \"\"\" Return compiled prompt pattern Given a potential prompt and the Channel class' prompt, return compiled prompt pattern Args: class_pattern: comms_prompt_pattern from the class itself; must be passed so that the arguments are recognized in lru cache; this way if a user changes the pattern during normal scrapli operations the lru cache can \"notice\" the pattern changed! pattern: optional regex pattern to compile, if not provided we use the class' pattern Returns: pattern: compiled regex pattern to use to search for a prompt in output data Raises: N/A \"\"\" if not pattern: return re.compile(class_pattern.encode(), flags=re.M | re.I) bytes_pattern = pattern.encode() if bytes_pattern.startswith(b\"^\") and bytes_pattern.endswith(b\"$\"): return re.compile(bytes_pattern, flags=re.M | re.I) return re.compile(re.escape(bytes_pattern)) def _pre_channel_authenticate_ssh( self, ) -> Tuple[Pattern[bytes], Pattern[bytes], Pattern[bytes]]: \"\"\" Handle pre ssh authentication work for parity between sync and sync versions. Args: N/A Returns: tuple: tuple of pass/passphrase/prompt patterns Raises: N/A \"\"\" prompt_pattern = self._get_prompt_pattern( class_pattern=self._base_channel_args.comms_prompt_pattern ) return self.auth_password_pattern, self.auth_passphrase_pattern, prompt_pattern def _pre_channel_authenticate_telnet( self, ) -> Tuple[Pattern[bytes], Pattern[bytes], Pattern[bytes], float, float]: \"\"\" Handle pre telnet authentication work for parity between sync and sync versions. Args: N/A Returns: tuple: tuple of user/pass/prompt patterns, start timestamp and return interval Raises: N/A \"\"\" prompt_pattern = self._get_prompt_pattern( class_pattern=self._base_channel_args.comms_prompt_pattern ) # capture the start time of the authentication event; we also set a \"return_interval\" which # is 1/10 the timout_ops value, we will send a return character at roughly this interval if # there is no output on the channel. we do this because sometimes telnet needs a kick to get # it to prompt for auth -- particularity when connecting to terminal server/console port auth_start_time = datetime.now().timestamp() return_interval = self._base_channel_args.timeout_ops / 10 return ( self.auth_telnet_login_pattern, self.auth_password_pattern, prompt_pattern, auth_start_time, return_interval, ) def _process_output(self, buf: bytes, strip_prompt: bool) -> bytes: \"\"\" Process output received form the device Remove inputs and prompts if desired Args: buf: bytes output from the device strip_prompt: True/False strip the prompt from the device output Returns: bytes: cleaned up byte string Raises: N/A \"\"\" buf = b\"\\n\".join([line.rstrip() for line in buf.splitlines()]) if strip_prompt: prompt_pattern = self._get_prompt_pattern( class_pattern=self._base_channel_args.comms_prompt_pattern ) buf = re.sub(pattern=prompt_pattern, repl=b\"\", string=buf) buf = buf.lstrip(self._base_channel_args.comms_return_char.encode()).rstrip() return buf @staticmethod def _strip_ansi(buf: bytes) -> bytes: \"\"\" Strip ansi characters from output Args: buf: bytes from previous reads if needed Returns: bytes: bytes output read from channel with ansi characters removed Raises: N/A \"\"\" buf = re.sub(pattern=ANSI_ESCAPE_PATTERN, repl=b\"\", string=buf) return buf @staticmethod def _pre_send_input(channel_input: str) -> None: \"\"\" Handle pre \"send_input\" tasks for consistency between sync/async versions Args: channel_input: string input to send to channel Returns: bytes: current channel buffer Raises: ScrapliTypeError: if input is anything but a string \"\"\" if not isinstance(channel_input, str): raise ScrapliTypeError( f\"`send_input` expects a single string, got {type(channel_input)}.\" ) @staticmethod def _pre_send_inputs_interact(interact_events: List[Tuple[str, str, Optional[bool]]]) -> None: \"\"\" Handle pre \"send_inputs_interact\" tasks for consistency between sync/async versions Args: interact_events: interact events passed to `send_inputs_interact` Returns: None Raises: ScrapliTypeError: if input is anything but a string \"\"\" if not isinstance(interact_events, list): raise ScrapliTypeError(f\"`interact_events` expects a List, got {type(interact_events)}\") Classes \u00b6 BaseChannel \u00b6 1 2 3 4 5 6 7 8 9 10 11 BaseChannel Object -- provides convenience methods to both sync and async Channels Args: transport: initialized scrapli Transport/AsyncTransport object base_channel_args: BaseChannelArgs object Returns: None Raises: N/A Expand source code class BaseChannel: def __init__( self, transport: Union[AsyncTransport, Transport], base_channel_args: BaseChannelArgs, ): \"\"\" BaseChannel Object -- provides convenience methods to both sync and async Channels Args: transport: initialized scrapli Transport/AsyncTransport object base_channel_args: BaseChannelArgs object Returns: None Raises: N/A \"\"\" self.transport = transport self._base_channel_args = base_channel_args self.logger = get_instance_logger( instance_name=\"scrapli.channel\", host=self.transport._base_transport_args.host, port=self.transport._base_transport_args.port, uid=self.transport._base_transport_args.logging_uid, ) self.channel_log: Optional[BinaryIO] = None self._auth_telnet_login_pattern = r\"^(.*username:)|(.*login:)\\s?$\" self._auth_password_pattern = r\"(.*@.*)?password:\\s?$\" self._auth_passphrase_pattern = r\"enter passphrase for key\" @property def auth_telnet_login_pattern(self) -> Pattern[bytes]: \"\"\" Getter for `auth_telnet_login_pattern` attribute Args: N/A Returns: Pattern: compiled pattern of the set auth_telnet_login_pattern value Raises: N/A \"\"\" return re.compile(self._auth_telnet_login_pattern.encode(), flags=re.I | re.M) @auth_telnet_login_pattern.setter def auth_telnet_login_pattern(self, value: str) -> None: \"\"\" Setter for `auth_telnet_login_pattern` attribute Args: value: str value for auth_telnet_login_pattern; this value will be compiled withe re.I and re.M flags when the getter is called. Returns: None Raises: ScrapliTypeError: if value is not of type str \"\"\" self.logger.debug(f\"setting 'auth_telnet_login_pattern' value to '{value}'\") if not isinstance(value, str): raise ScrapliTypeError self._auth_telnet_login_pattern = value @property def auth_password_pattern(self) -> Pattern[bytes]: \"\"\" Getter for `auth_password_pattern` attribute Args: N/A Returns: Pattern: compiled pattern of the set auth_password_pattern value Raises: N/A \"\"\" return re.compile(self._auth_password_pattern.encode(), flags=re.I | re.M) @auth_password_pattern.setter def auth_password_pattern(self, value: str) -> None: \"\"\" Setter for `auth_password_pattern` attribute Args: value: str value for auth_password_pattern; this value will be compiled withe re.I and re.M flags when the getter is called. Returns: None Raises: ScrapliTypeError: if value is not of type str \"\"\" self.logger.debug(f\"setting 'auth_password_pattern' value to '{value}'\") if not isinstance(value, str): raise ScrapliTypeError self._auth_password_pattern = value @property def auth_passphrase_pattern(self) -> Pattern[bytes]: \"\"\" Getter for `auth_passphrase_pattern` attribute Args: N/A Returns: Pattern: compiled pattern of the set auth_passphrase_pattern value Raises: N/A \"\"\" return re.compile(self._auth_passphrase_pattern.encode(), flags=re.I | re.M) @auth_passphrase_pattern.setter def auth_passphrase_pattern(self, value: str) -> None: \"\"\" Setter for `auth_passphrase_pattern` attribute Args: value: str value for auth_passphrase_pattern; this value will be compiled withe re.I and re.M flags when the getter is called. Returns: None Raises: ScrapliTypeError: if value is not of type str \"\"\" self.logger.debug(f\"setting '_auth_passphrase_pattern' value to '{value}'\") if not isinstance(value, str): raise ScrapliTypeError self._auth_passphrase_pattern = value def open(self) -> None: \"\"\" Channel open method Args: N/A Returns: None Raises: N/A \"\"\" if self._base_channel_args.channel_log: if isinstance(self._base_channel_args.channel_log, BytesIO): self.channel_log = self._base_channel_args.channel_log else: channel_log_destination = \"scrapli_channel.log\" if isinstance(self._base_channel_args.channel_log, str): channel_log_destination = self._base_channel_args.channel_log self.logger.info( f\"channel log enabled, logging channel output to '{channel_log_destination}'\" ) # have to ignore type due to mypy not wanting to read the mode from formatted string # if you change the mode --> \"wb\" or \"ab\" it works as you would hope/expect; those # are the only values it can possibly be at this point though so we can safely # ignore here # note that this will *always* be binary mode, so there doesn't need to be any # encoding, hence ignoring that pylint message! self.channel_log = open( # pylint: disable=W1514,R1732 channel_log_destination, mode=f\"{self._base_channel_args.channel_log_mode}b\", # type: ignore ) def close(self) -> None: \"\"\" Channel close method Args: N/A Returns: None Raises: N/A \"\"\" if self.channel_log: self.channel_log.close() def _process_read_buf(self, read_buf: BytesIO) -> bytes: \"\"\" Process the read buffer Seeks backwards up to search depth then partitions on newlines. Partition is to ensure that the resulting search_buf does not end up with partial lines in the output which can cause prompt patterns to match places they should not match! Args: read_buf: bytesio object read from the transport Returns: bytes: cleaned up search buffer Raises: N/A \"\"\" read_buf.seek(-self._base_channel_args.comms_prompt_search_depth, SEEK_END) search_buf = read_buf.read() before, _, search_buf = search_buf.partition(b\"\\n\") if not search_buf: # didn't split on anything or nothing after partition search_buf = before return search_buf def write(self, channel_input: str, redacted: bool = False) -> None: \"\"\" Write input to the underlying Transport session Args: channel_input: string of input to send redacted: redact channel input from log or not Returns: None Raises: N/A \"\"\" log_output = \"REDACTED\" if redacted else repr(channel_input) self.logger.debug(f\"write: {log_output}\") self.transport.write(channel_input=channel_input.encode()) def send_return(self) -> None: \"\"\" Convenience method to send return char Args: N/A Returns: None Raises: N/A \"\"\" self.write(channel_input=self._base_channel_args.comms_return_char) @staticmethod def _join_and_compile(channel_outputs: Optional[List[bytes]]) -> Pattern[bytes]: \"\"\" Convenience method for read_until_prompt_or_time to join channel inputs into a regex pattern Args: channel_outputs: list of bytes channel inputs to join into a regex pattern Returns: Pattern: joined regex pattern or an empty pattern (empty bytes) Raises: N/A \"\"\" regex_channel_outputs = b\"\" if channel_outputs: regex_channel_outputs = b\"|\".join( [b\"(\" + channel_output + b\")\" for channel_output in channel_outputs] ) regex_channel_outputs_pattern = re.compile(pattern=regex_channel_outputs, flags=re.I | re.M) return regex_channel_outputs_pattern def _ssh_message_handler(self, output: bytes) -> None: # noqa: C901 \"\"\" Parse EOF messages from _pty_authenticate and create log/stack exception message Args: output: bytes output from _pty_authenticate Returns: N/A # noqa: DAR202 Raises: ScrapliAuthenticationFailed: if any errors are read in the output \"\"\" msg = \"\" if b\"host key verification failed\" in output.lower(): msg = \"Host key verification failed\" elif b\"operation timed out\" in output.lower() or b\"connection timed out\" in output.lower(): msg = \"Timed out connecting to host\" elif b\"no route to host\" in output.lower(): msg = \"No route to host\" elif b\"no matching key exchange\" in output.lower(): msg = \"No matching key exchange found for host\" key_exchange_pattern = re.compile( pattern=rb\"their offer: ([a-z0-9\\-,]*)\", flags=re.M | re.I ) offered_key_exchanges_match = re.search(pattern=key_exchange_pattern, string=output) if offered_key_exchanges_match: offered_key_exchanges = offered_key_exchanges_match.group(1).decode() msg += f\", their offer: {offered_key_exchanges}\" elif b\"no matching cipher\" in output.lower(): msg = \"No matching cipher found for host\" ciphers_pattern = re.compile(pattern=rb\"their offer: ([a-z0-9\\-,]*)\", flags=re.M | re.I) offered_ciphers_match = re.search(pattern=ciphers_pattern, string=output) if offered_ciphers_match: offered_ciphers = offered_ciphers_match.group(1).decode() msg += f\", their offer: {offered_ciphers}\" elif b\"bad configuration\" in output.lower(): msg = \"Bad SSH configuration option(s) for host\" configuration_pattern = re.compile( pattern=rb\"bad configuration option: ([a-z0-9\\+\\=,]*)\", flags=re.M | re.I ) configuration_issue_match = re.search(pattern=configuration_pattern, string=output) if configuration_issue_match: configuration_issues = configuration_issue_match.group(1).decode() msg += f\", bad option(s): {configuration_issues}\" elif b\"WARNING: UNPROTECTED PRIVATE KEY FILE!\" in output: msg = \"Permissions for private key are too open, authentication failed!\" elif b\"could not resolve hostname\" in output.lower(): msg = \"Could not resolve address for host\" elif b\"permission denied\" in output.lower(): msg = str(output) if msg: self.logger.critical(msg) raise ScrapliAuthenticationFailed(msg) @staticmethod @lru_cache() def _get_prompt_pattern(class_pattern: str, pattern: Optional[str] = None) -> Pattern[bytes]: \"\"\" Return compiled prompt pattern Given a potential prompt and the Channel class' prompt, return compiled prompt pattern Args: class_pattern: comms_prompt_pattern from the class itself; must be passed so that the arguments are recognized in lru cache; this way if a user changes the pattern during normal scrapli operations the lru cache can \"notice\" the pattern changed! pattern: optional regex pattern to compile, if not provided we use the class' pattern Returns: pattern: compiled regex pattern to use to search for a prompt in output data Raises: N/A \"\"\" if not pattern: return re.compile(class_pattern.encode(), flags=re.M | re.I) bytes_pattern = pattern.encode() if bytes_pattern.startswith(b\"^\") and bytes_pattern.endswith(b\"$\"): return re.compile(bytes_pattern, flags=re.M | re.I) return re.compile(re.escape(bytes_pattern)) def _pre_channel_authenticate_ssh( self, ) -> Tuple[Pattern[bytes], Pattern[bytes], Pattern[bytes]]: \"\"\" Handle pre ssh authentication work for parity between sync and sync versions. Args: N/A Returns: tuple: tuple of pass/passphrase/prompt patterns Raises: N/A \"\"\" prompt_pattern = self._get_prompt_pattern( class_pattern=self._base_channel_args.comms_prompt_pattern ) return self.auth_password_pattern, self.auth_passphrase_pattern, prompt_pattern def _pre_channel_authenticate_telnet( self, ) -> Tuple[Pattern[bytes], Pattern[bytes], Pattern[bytes], float, float]: \"\"\" Handle pre telnet authentication work for parity between sync and sync versions. Args: N/A Returns: tuple: tuple of user/pass/prompt patterns, start timestamp and return interval Raises: N/A \"\"\" prompt_pattern = self._get_prompt_pattern( class_pattern=self._base_channel_args.comms_prompt_pattern ) # capture the start time of the authentication event; we also set a \"return_interval\" which # is 1/10 the timout_ops value, we will send a return character at roughly this interval if # there is no output on the channel. we do this because sometimes telnet needs a kick to get # it to prompt for auth -- particularity when connecting to terminal server/console port auth_start_time = datetime.now().timestamp() return_interval = self._base_channel_args.timeout_ops / 10 return ( self.auth_telnet_login_pattern, self.auth_password_pattern, prompt_pattern, auth_start_time, return_interval, ) def _process_output(self, buf: bytes, strip_prompt: bool) -> bytes: \"\"\" Process output received form the device Remove inputs and prompts if desired Args: buf: bytes output from the device strip_prompt: True/False strip the prompt from the device output Returns: bytes: cleaned up byte string Raises: N/A \"\"\" buf = b\"\\n\".join([line.rstrip() for line in buf.splitlines()]) if strip_prompt: prompt_pattern = self._get_prompt_pattern( class_pattern=self._base_channel_args.comms_prompt_pattern ) buf = re.sub(pattern=prompt_pattern, repl=b\"\", string=buf) buf = buf.lstrip(self._base_channel_args.comms_return_char.encode()).rstrip() return buf @staticmethod def _strip_ansi(buf: bytes) -> bytes: \"\"\" Strip ansi characters from output Args: buf: bytes from previous reads if needed Returns: bytes: bytes output read from channel with ansi characters removed Raises: N/A \"\"\" buf = re.sub(pattern=ANSI_ESCAPE_PATTERN, repl=b\"\", string=buf) return buf @staticmethod def _pre_send_input(channel_input: str) -> None: \"\"\" Handle pre \"send_input\" tasks for consistency between sync/async versions Args: channel_input: string input to send to channel Returns: bytes: current channel buffer Raises: ScrapliTypeError: if input is anything but a string \"\"\" if not isinstance(channel_input, str): raise ScrapliTypeError( f\"`send_input` expects a single string, got {type(channel_input)}.\" ) @staticmethod def _pre_send_inputs_interact(interact_events: List[Tuple[str, str, Optional[bool]]]) -> None: \"\"\" Handle pre \"send_inputs_interact\" tasks for consistency between sync/async versions Args: interact_events: interact events passed to `send_inputs_interact` Returns: None Raises: ScrapliTypeError: if input is anything but a string \"\"\" if not isinstance(interact_events, list): raise ScrapliTypeError(f\"`interact_events` expects a List, got {type(interact_events)}\") Descendants \u00b6 scrapli.channel.async_channel.AsyncChannel scrapli.channel.sync_channel.Channel Instance variables \u00b6 auth_passphrase_pattern: Pattern[bytes] 1 2 3 4 5 6 7 8 9 10 Getter for `auth_passphrase_pattern` attribute Args: N/A Returns: Pattern: compiled pattern of the set auth_passphrase_pattern value Raises: N/A auth_password_pattern: Pattern[bytes] 1 2 3 4 5 6 7 8 9 10 Getter for `auth_password_pattern` attribute Args: N/A Returns: Pattern: compiled pattern of the set auth_password_pattern value Raises: N/A auth_telnet_login_pattern: Pattern[bytes] 1 2 3 4 5 6 7 8 9 10 Getter for `auth_telnet_login_pattern` attribute Args: N/A Returns: Pattern: compiled pattern of the set auth_telnet_login_pattern value Raises: N/A Methods \u00b6 close \u00b6 close(self) \u2011> None 1 2 3 4 5 6 7 8 9 10 Channel close method Args: N/A Returns: None Raises: N/A open \u00b6 open(self) \u2011> None 1 2 3 4 5 6 7 8 9 10 Channel open method Args: N/A Returns: None Raises: N/A send_return \u00b6 send_return(self) \u2011> None 1 2 3 4 5 6 7 8 9 10 Convenience method to send return char Args: N/A Returns: None Raises: N/A write \u00b6 write(self, channel_input: str, redacted: bool = False) \u2011> None 1 2 3 4 5 6 7 8 9 10 11 Write input to the underlying Transport session Args: channel_input: string of input to send redacted: redact channel input from log or not Returns: None Raises: N/A BaseChannelArgs \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 Dataclass for all base Channel arguments Args: comms_prompt_pattern: comms_prompt_pattern to assign to the channel; should generally be created/passed from the driver class comms_return_char: comms_return_char to assign to the channel, see above comms_prompt_search_depth: depth of the buffer to search in for searching for the prompt in \"read_until_prompt\"; smaller number here will generally be faster, though may be less reliable; default value is 1000 timeout_ops: timeout_ops to assign to the channel, see above channel_log: log \"channel\" output -- this would be the output you would normally see on a terminal. If `True` logs to `scrapli_channel.log`, if a string is provided, logs to wherever that string points channel_log_mode: \"write\"|\"append\", all other values will raise ValueError, does what it sounds like it should by setting the channel log to the provided mode channel_lock: bool indicated if channel lock should be used for all read/write operations Returns: None Raises: N/A Expand source code @dataclass() class BaseChannelArgs: \"\"\" Dataclass for all base Channel arguments Args: comms_prompt_pattern: comms_prompt_pattern to assign to the channel; should generally be created/passed from the driver class comms_return_char: comms_return_char to assign to the channel, see above comms_prompt_search_depth: depth of the buffer to search in for searching for the prompt in \"read_until_prompt\"; smaller number here will generally be faster, though may be less reliable; default value is 1000 timeout_ops: timeout_ops to assign to the channel, see above channel_log: log \"channel\" output -- this would be the output you would normally see on a terminal. If `True` logs to `scrapli_channel.log`, if a string is provided, logs to wherever that string points channel_log_mode: \"write\"|\"append\", all other values will raise ValueError, does what it sounds like it should by setting the channel log to the provided mode channel_lock: bool indicated if channel lock should be used for all read/write operations Returns: None Raises: N/A \"\"\" comms_prompt_pattern: str = r\"^[a-z0-9.\\-@()/:]{1,32}[#>$]$\" comms_return_char: str = \"\\n\" comms_prompt_search_depth: int = 1000 timeout_ops: float = 30.0 channel_log: Union[str, bool, BytesIO] = False channel_log_mode: str = \"write\" channel_lock: bool = False def __post_init__(self) -> None: \"\"\" Validate dataclass arguments at end of initialization Args: N/A Returns: None Raises: ScrapliValueError: if invalid channel_log_mode provided \"\"\" if self.channel_log_mode.lower() not in ( \"write\", \"append\", ): raise ScrapliValueError( f\"provided channel_log_mode '{self.channel_log_mode}' is not valid, mode must be \" f\"one of: 'write', 'append'\" ) if self.channel_log_mode.lower() == \"write\": self.channel_log_mode = \"w\" else: self.channel_log_mode = \"a\" Class variables \u00b6 channel_lock: bool channel_log: Union[str, bool, _io.BytesIO] channel_log_mode: str comms_prompt_pattern: str comms_prompt_search_depth: int comms_return_char: str timeout_ops: float","title":"Base Channel"},{"location":"api_docs/channel/base_channel/#module-scraplichannelbase_channel","text":"scrapli.channel.base_channel Expand source code \"\"\"scrapli.channel.base_channel\"\"\" import re from dataclasses import dataclass from datetime import datetime from functools import lru_cache from io import SEEK_END, BytesIO from typing import BinaryIO, List, Optional, Pattern, Tuple, Union from scrapli.exceptions import ScrapliAuthenticationFailed, ScrapliTypeError, ScrapliValueError from scrapli.logging import get_instance_logger from scrapli.transport.base import AsyncTransport, Transport ANSI_ESCAPE_PATTERN = re.compile(rb\"\\x1b(\\[.*?[@-~]|\\].*?(\\x07|\\x1b\\\\))\") @dataclass() class BaseChannelArgs: \"\"\" Dataclass for all base Channel arguments Args: comms_prompt_pattern: comms_prompt_pattern to assign to the channel; should generally be created/passed from the driver class comms_return_char: comms_return_char to assign to the channel, see above comms_prompt_search_depth: depth of the buffer to search in for searching for the prompt in \"read_until_prompt\"; smaller number here will generally be faster, though may be less reliable; default value is 1000 timeout_ops: timeout_ops to assign to the channel, see above channel_log: log \"channel\" output -- this would be the output you would normally see on a terminal. If `True` logs to `scrapli_channel.log`, if a string is provided, logs to wherever that string points channel_log_mode: \"write\"|\"append\", all other values will raise ValueError, does what it sounds like it should by setting the channel log to the provided mode channel_lock: bool indicated if channel lock should be used for all read/write operations Returns: None Raises: N/A \"\"\" comms_prompt_pattern: str = r\"^[a-z0-9.\\-@()/:]{1,32}[#>$]$\" comms_return_char: str = \"\\n\" comms_prompt_search_depth: int = 1000 timeout_ops: float = 30.0 channel_log: Union[str, bool, BytesIO] = False channel_log_mode: str = \"write\" channel_lock: bool = False def __post_init__(self) -> None: \"\"\" Validate dataclass arguments at end of initialization Args: N/A Returns: None Raises: ScrapliValueError: if invalid channel_log_mode provided \"\"\" if self.channel_log_mode.lower() not in ( \"write\", \"append\", ): raise ScrapliValueError( f\"provided channel_log_mode '{self.channel_log_mode}' is not valid, mode must be \" f\"one of: 'write', 'append'\" ) if self.channel_log_mode.lower() == \"write\": self.channel_log_mode = \"w\" else: self.channel_log_mode = \"a\" class BaseChannel: def __init__( self, transport: Union[AsyncTransport, Transport], base_channel_args: BaseChannelArgs, ): \"\"\" BaseChannel Object -- provides convenience methods to both sync and async Channels Args: transport: initialized scrapli Transport/AsyncTransport object base_channel_args: BaseChannelArgs object Returns: None Raises: N/A \"\"\" self.transport = transport self._base_channel_args = base_channel_args self.logger = get_instance_logger( instance_name=\"scrapli.channel\", host=self.transport._base_transport_args.host, port=self.transport._base_transport_args.port, uid=self.transport._base_transport_args.logging_uid, ) self.channel_log: Optional[BinaryIO] = None self._auth_telnet_login_pattern = r\"^(.*username:)|(.*login:)\\s?$\" self._auth_password_pattern = r\"(.*@.*)?password:\\s?$\" self._auth_passphrase_pattern = r\"enter passphrase for key\" @property def auth_telnet_login_pattern(self) -> Pattern[bytes]: \"\"\" Getter for `auth_telnet_login_pattern` attribute Args: N/A Returns: Pattern: compiled pattern of the set auth_telnet_login_pattern value Raises: N/A \"\"\" return re.compile(self._auth_telnet_login_pattern.encode(), flags=re.I | re.M) @auth_telnet_login_pattern.setter def auth_telnet_login_pattern(self, value: str) -> None: \"\"\" Setter for `auth_telnet_login_pattern` attribute Args: value: str value for auth_telnet_login_pattern; this value will be compiled withe re.I and re.M flags when the getter is called. Returns: None Raises: ScrapliTypeError: if value is not of type str \"\"\" self.logger.debug(f\"setting 'auth_telnet_login_pattern' value to '{value}'\") if not isinstance(value, str): raise ScrapliTypeError self._auth_telnet_login_pattern = value @property def auth_password_pattern(self) -> Pattern[bytes]: \"\"\" Getter for `auth_password_pattern` attribute Args: N/A Returns: Pattern: compiled pattern of the set auth_password_pattern value Raises: N/A \"\"\" return re.compile(self._auth_password_pattern.encode(), flags=re.I | re.M) @auth_password_pattern.setter def auth_password_pattern(self, value: str) -> None: \"\"\" Setter for `auth_password_pattern` attribute Args: value: str value for auth_password_pattern; this value will be compiled withe re.I and re.M flags when the getter is called. Returns: None Raises: ScrapliTypeError: if value is not of type str \"\"\" self.logger.debug(f\"setting 'auth_password_pattern' value to '{value}'\") if not isinstance(value, str): raise ScrapliTypeError self._auth_password_pattern = value @property def auth_passphrase_pattern(self) -> Pattern[bytes]: \"\"\" Getter for `auth_passphrase_pattern` attribute Args: N/A Returns: Pattern: compiled pattern of the set auth_passphrase_pattern value Raises: N/A \"\"\" return re.compile(self._auth_passphrase_pattern.encode(), flags=re.I | re.M) @auth_passphrase_pattern.setter def auth_passphrase_pattern(self, value: str) -> None: \"\"\" Setter for `auth_passphrase_pattern` attribute Args: value: str value for auth_passphrase_pattern; this value will be compiled withe re.I and re.M flags when the getter is called. Returns: None Raises: ScrapliTypeError: if value is not of type str \"\"\" self.logger.debug(f\"setting '_auth_passphrase_pattern' value to '{value}'\") if not isinstance(value, str): raise ScrapliTypeError self._auth_passphrase_pattern = value def open(self) -> None: \"\"\" Channel open method Args: N/A Returns: None Raises: N/A \"\"\" if self._base_channel_args.channel_log: if isinstance(self._base_channel_args.channel_log, BytesIO): self.channel_log = self._base_channel_args.channel_log else: channel_log_destination = \"scrapli_channel.log\" if isinstance(self._base_channel_args.channel_log, str): channel_log_destination = self._base_channel_args.channel_log self.logger.info( f\"channel log enabled, logging channel output to '{channel_log_destination}'\" ) # have to ignore type due to mypy not wanting to read the mode from formatted string # if you change the mode --> \"wb\" or \"ab\" it works as you would hope/expect; those # are the only values it can possibly be at this point though so we can safely # ignore here # note that this will *always* be binary mode, so there doesn't need to be any # encoding, hence ignoring that pylint message! self.channel_log = open( # pylint: disable=W1514,R1732 channel_log_destination, mode=f\"{self._base_channel_args.channel_log_mode}b\", # type: ignore ) def close(self) -> None: \"\"\" Channel close method Args: N/A Returns: None Raises: N/A \"\"\" if self.channel_log: self.channel_log.close() def _process_read_buf(self, read_buf: BytesIO) -> bytes: \"\"\" Process the read buffer Seeks backwards up to search depth then partitions on newlines. Partition is to ensure that the resulting search_buf does not end up with partial lines in the output which can cause prompt patterns to match places they should not match! Args: read_buf: bytesio object read from the transport Returns: bytes: cleaned up search buffer Raises: N/A \"\"\" read_buf.seek(-self._base_channel_args.comms_prompt_search_depth, SEEK_END) search_buf = read_buf.read() before, _, search_buf = search_buf.partition(b\"\\n\") if not search_buf: # didn't split on anything or nothing after partition search_buf = before return search_buf def write(self, channel_input: str, redacted: bool = False) -> None: \"\"\" Write input to the underlying Transport session Args: channel_input: string of input to send redacted: redact channel input from log or not Returns: None Raises: N/A \"\"\" log_output = \"REDACTED\" if redacted else repr(channel_input) self.logger.debug(f\"write: {log_output}\") self.transport.write(channel_input=channel_input.encode()) def send_return(self) -> None: \"\"\" Convenience method to send return char Args: N/A Returns: None Raises: N/A \"\"\" self.write(channel_input=self._base_channel_args.comms_return_char) @staticmethod def _join_and_compile(channel_outputs: Optional[List[bytes]]) -> Pattern[bytes]: \"\"\" Convenience method for read_until_prompt_or_time to join channel inputs into a regex pattern Args: channel_outputs: list of bytes channel inputs to join into a regex pattern Returns: Pattern: joined regex pattern or an empty pattern (empty bytes) Raises: N/A \"\"\" regex_channel_outputs = b\"\" if channel_outputs: regex_channel_outputs = b\"|\".join( [b\"(\" + channel_output + b\")\" for channel_output in channel_outputs] ) regex_channel_outputs_pattern = re.compile(pattern=regex_channel_outputs, flags=re.I | re.M) return regex_channel_outputs_pattern def _ssh_message_handler(self, output: bytes) -> None: # noqa: C901 \"\"\" Parse EOF messages from _pty_authenticate and create log/stack exception message Args: output: bytes output from _pty_authenticate Returns: N/A # noqa: DAR202 Raises: ScrapliAuthenticationFailed: if any errors are read in the output \"\"\" msg = \"\" if b\"host key verification failed\" in output.lower(): msg = \"Host key verification failed\" elif b\"operation timed out\" in output.lower() or b\"connection timed out\" in output.lower(): msg = \"Timed out connecting to host\" elif b\"no route to host\" in output.lower(): msg = \"No route to host\" elif b\"no matching key exchange\" in output.lower(): msg = \"No matching key exchange found for host\" key_exchange_pattern = re.compile( pattern=rb\"their offer: ([a-z0-9\\-,]*)\", flags=re.M | re.I ) offered_key_exchanges_match = re.search(pattern=key_exchange_pattern, string=output) if offered_key_exchanges_match: offered_key_exchanges = offered_key_exchanges_match.group(1).decode() msg += f\", their offer: {offered_key_exchanges}\" elif b\"no matching cipher\" in output.lower(): msg = \"No matching cipher found for host\" ciphers_pattern = re.compile(pattern=rb\"their offer: ([a-z0-9\\-,]*)\", flags=re.M | re.I) offered_ciphers_match = re.search(pattern=ciphers_pattern, string=output) if offered_ciphers_match: offered_ciphers = offered_ciphers_match.group(1).decode() msg += f\", their offer: {offered_ciphers}\" elif b\"bad configuration\" in output.lower(): msg = \"Bad SSH configuration option(s) for host\" configuration_pattern = re.compile( pattern=rb\"bad configuration option: ([a-z0-9\\+\\=,]*)\", flags=re.M | re.I ) configuration_issue_match = re.search(pattern=configuration_pattern, string=output) if configuration_issue_match: configuration_issues = configuration_issue_match.group(1).decode() msg += f\", bad option(s): {configuration_issues}\" elif b\"WARNING: UNPROTECTED PRIVATE KEY FILE!\" in output: msg = \"Permissions for private key are too open, authentication failed!\" elif b\"could not resolve hostname\" in output.lower(): msg = \"Could not resolve address for host\" elif b\"permission denied\" in output.lower(): msg = str(output) if msg: self.logger.critical(msg) raise ScrapliAuthenticationFailed(msg) @staticmethod @lru_cache() def _get_prompt_pattern(class_pattern: str, pattern: Optional[str] = None) -> Pattern[bytes]: \"\"\" Return compiled prompt pattern Given a potential prompt and the Channel class' prompt, return compiled prompt pattern Args: class_pattern: comms_prompt_pattern from the class itself; must be passed so that the arguments are recognized in lru cache; this way if a user changes the pattern during normal scrapli operations the lru cache can \"notice\" the pattern changed! pattern: optional regex pattern to compile, if not provided we use the class' pattern Returns: pattern: compiled regex pattern to use to search for a prompt in output data Raises: N/A \"\"\" if not pattern: return re.compile(class_pattern.encode(), flags=re.M | re.I) bytes_pattern = pattern.encode() if bytes_pattern.startswith(b\"^\") and bytes_pattern.endswith(b\"$\"): return re.compile(bytes_pattern, flags=re.M | re.I) return re.compile(re.escape(bytes_pattern)) def _pre_channel_authenticate_ssh( self, ) -> Tuple[Pattern[bytes], Pattern[bytes], Pattern[bytes]]: \"\"\" Handle pre ssh authentication work for parity between sync and sync versions. Args: N/A Returns: tuple: tuple of pass/passphrase/prompt patterns Raises: N/A \"\"\" prompt_pattern = self._get_prompt_pattern( class_pattern=self._base_channel_args.comms_prompt_pattern ) return self.auth_password_pattern, self.auth_passphrase_pattern, prompt_pattern def _pre_channel_authenticate_telnet( self, ) -> Tuple[Pattern[bytes], Pattern[bytes], Pattern[bytes], float, float]: \"\"\" Handle pre telnet authentication work for parity between sync and sync versions. Args: N/A Returns: tuple: tuple of user/pass/prompt patterns, start timestamp and return interval Raises: N/A \"\"\" prompt_pattern = self._get_prompt_pattern( class_pattern=self._base_channel_args.comms_prompt_pattern ) # capture the start time of the authentication event; we also set a \"return_interval\" which # is 1/10 the timout_ops value, we will send a return character at roughly this interval if # there is no output on the channel. we do this because sometimes telnet needs a kick to get # it to prompt for auth -- particularity when connecting to terminal server/console port auth_start_time = datetime.now().timestamp() return_interval = self._base_channel_args.timeout_ops / 10 return ( self.auth_telnet_login_pattern, self.auth_password_pattern, prompt_pattern, auth_start_time, return_interval, ) def _process_output(self, buf: bytes, strip_prompt: bool) -> bytes: \"\"\" Process output received form the device Remove inputs and prompts if desired Args: buf: bytes output from the device strip_prompt: True/False strip the prompt from the device output Returns: bytes: cleaned up byte string Raises: N/A \"\"\" buf = b\"\\n\".join([line.rstrip() for line in buf.splitlines()]) if strip_prompt: prompt_pattern = self._get_prompt_pattern( class_pattern=self._base_channel_args.comms_prompt_pattern ) buf = re.sub(pattern=prompt_pattern, repl=b\"\", string=buf) buf = buf.lstrip(self._base_channel_args.comms_return_char.encode()).rstrip() return buf @staticmethod def _strip_ansi(buf: bytes) -> bytes: \"\"\" Strip ansi characters from output Args: buf: bytes from previous reads if needed Returns: bytes: bytes output read from channel with ansi characters removed Raises: N/A \"\"\" buf = re.sub(pattern=ANSI_ESCAPE_PATTERN, repl=b\"\", string=buf) return buf @staticmethod def _pre_send_input(channel_input: str) -> None: \"\"\" Handle pre \"send_input\" tasks for consistency between sync/async versions Args: channel_input: string input to send to channel Returns: bytes: current channel buffer Raises: ScrapliTypeError: if input is anything but a string \"\"\" if not isinstance(channel_input, str): raise ScrapliTypeError( f\"`send_input` expects a single string, got {type(channel_input)}.\" ) @staticmethod def _pre_send_inputs_interact(interact_events: List[Tuple[str, str, Optional[bool]]]) -> None: \"\"\" Handle pre \"send_inputs_interact\" tasks for consistency between sync/async versions Args: interact_events: interact events passed to `send_inputs_interact` Returns: None Raises: ScrapliTypeError: if input is anything but a string \"\"\" if not isinstance(interact_events, list): raise ScrapliTypeError(f\"`interact_events` expects a List, got {type(interact_events)}\")","title":"Module scrapli.channel.base_channel"},{"location":"api_docs/channel/base_channel/#classes","text":"","title":"Classes"},{"location":"api_docs/channel/base_channel/#basechannel","text":"1 2 3 4 5 6 7 8 9 10 11 BaseChannel Object -- provides convenience methods to both sync and async Channels Args: transport: initialized scrapli Transport/AsyncTransport object base_channel_args: BaseChannelArgs object Returns: None Raises: N/A Expand source code class BaseChannel: def __init__( self, transport: Union[AsyncTransport, Transport], base_channel_args: BaseChannelArgs, ): \"\"\" BaseChannel Object -- provides convenience methods to both sync and async Channels Args: transport: initialized scrapli Transport/AsyncTransport object base_channel_args: BaseChannelArgs object Returns: None Raises: N/A \"\"\" self.transport = transport self._base_channel_args = base_channel_args self.logger = get_instance_logger( instance_name=\"scrapli.channel\", host=self.transport._base_transport_args.host, port=self.transport._base_transport_args.port, uid=self.transport._base_transport_args.logging_uid, ) self.channel_log: Optional[BinaryIO] = None self._auth_telnet_login_pattern = r\"^(.*username:)|(.*login:)\\s?$\" self._auth_password_pattern = r\"(.*@.*)?password:\\s?$\" self._auth_passphrase_pattern = r\"enter passphrase for key\" @property def auth_telnet_login_pattern(self) -> Pattern[bytes]: \"\"\" Getter for `auth_telnet_login_pattern` attribute Args: N/A Returns: Pattern: compiled pattern of the set auth_telnet_login_pattern value Raises: N/A \"\"\" return re.compile(self._auth_telnet_login_pattern.encode(), flags=re.I | re.M) @auth_telnet_login_pattern.setter def auth_telnet_login_pattern(self, value: str) -> None: \"\"\" Setter for `auth_telnet_login_pattern` attribute Args: value: str value for auth_telnet_login_pattern; this value will be compiled withe re.I and re.M flags when the getter is called. Returns: None Raises: ScrapliTypeError: if value is not of type str \"\"\" self.logger.debug(f\"setting 'auth_telnet_login_pattern' value to '{value}'\") if not isinstance(value, str): raise ScrapliTypeError self._auth_telnet_login_pattern = value @property def auth_password_pattern(self) -> Pattern[bytes]: \"\"\" Getter for `auth_password_pattern` attribute Args: N/A Returns: Pattern: compiled pattern of the set auth_password_pattern value Raises: N/A \"\"\" return re.compile(self._auth_password_pattern.encode(), flags=re.I | re.M) @auth_password_pattern.setter def auth_password_pattern(self, value: str) -> None: \"\"\" Setter for `auth_password_pattern` attribute Args: value: str value for auth_password_pattern; this value will be compiled withe re.I and re.M flags when the getter is called. Returns: None Raises: ScrapliTypeError: if value is not of type str \"\"\" self.logger.debug(f\"setting 'auth_password_pattern' value to '{value}'\") if not isinstance(value, str): raise ScrapliTypeError self._auth_password_pattern = value @property def auth_passphrase_pattern(self) -> Pattern[bytes]: \"\"\" Getter for `auth_passphrase_pattern` attribute Args: N/A Returns: Pattern: compiled pattern of the set auth_passphrase_pattern value Raises: N/A \"\"\" return re.compile(self._auth_passphrase_pattern.encode(), flags=re.I | re.M) @auth_passphrase_pattern.setter def auth_passphrase_pattern(self, value: str) -> None: \"\"\" Setter for `auth_passphrase_pattern` attribute Args: value: str value for auth_passphrase_pattern; this value will be compiled withe re.I and re.M flags when the getter is called. Returns: None Raises: ScrapliTypeError: if value is not of type str \"\"\" self.logger.debug(f\"setting '_auth_passphrase_pattern' value to '{value}'\") if not isinstance(value, str): raise ScrapliTypeError self._auth_passphrase_pattern = value def open(self) -> None: \"\"\" Channel open method Args: N/A Returns: None Raises: N/A \"\"\" if self._base_channel_args.channel_log: if isinstance(self._base_channel_args.channel_log, BytesIO): self.channel_log = self._base_channel_args.channel_log else: channel_log_destination = \"scrapli_channel.log\" if isinstance(self._base_channel_args.channel_log, str): channel_log_destination = self._base_channel_args.channel_log self.logger.info( f\"channel log enabled, logging channel output to '{channel_log_destination}'\" ) # have to ignore type due to mypy not wanting to read the mode from formatted string # if you change the mode --> \"wb\" or \"ab\" it works as you would hope/expect; those # are the only values it can possibly be at this point though so we can safely # ignore here # note that this will *always* be binary mode, so there doesn't need to be any # encoding, hence ignoring that pylint message! self.channel_log = open( # pylint: disable=W1514,R1732 channel_log_destination, mode=f\"{self._base_channel_args.channel_log_mode}b\", # type: ignore ) def close(self) -> None: \"\"\" Channel close method Args: N/A Returns: None Raises: N/A \"\"\" if self.channel_log: self.channel_log.close() def _process_read_buf(self, read_buf: BytesIO) -> bytes: \"\"\" Process the read buffer Seeks backwards up to search depth then partitions on newlines. Partition is to ensure that the resulting search_buf does not end up with partial lines in the output which can cause prompt patterns to match places they should not match! Args: read_buf: bytesio object read from the transport Returns: bytes: cleaned up search buffer Raises: N/A \"\"\" read_buf.seek(-self._base_channel_args.comms_prompt_search_depth, SEEK_END) search_buf = read_buf.read() before, _, search_buf = search_buf.partition(b\"\\n\") if not search_buf: # didn't split on anything or nothing after partition search_buf = before return search_buf def write(self, channel_input: str, redacted: bool = False) -> None: \"\"\" Write input to the underlying Transport session Args: channel_input: string of input to send redacted: redact channel input from log or not Returns: None Raises: N/A \"\"\" log_output = \"REDACTED\" if redacted else repr(channel_input) self.logger.debug(f\"write: {log_output}\") self.transport.write(channel_input=channel_input.encode()) def send_return(self) -> None: \"\"\" Convenience method to send return char Args: N/A Returns: None Raises: N/A \"\"\" self.write(channel_input=self._base_channel_args.comms_return_char) @staticmethod def _join_and_compile(channel_outputs: Optional[List[bytes]]) -> Pattern[bytes]: \"\"\" Convenience method for read_until_prompt_or_time to join channel inputs into a regex pattern Args: channel_outputs: list of bytes channel inputs to join into a regex pattern Returns: Pattern: joined regex pattern or an empty pattern (empty bytes) Raises: N/A \"\"\" regex_channel_outputs = b\"\" if channel_outputs: regex_channel_outputs = b\"|\".join( [b\"(\" + channel_output + b\")\" for channel_output in channel_outputs] ) regex_channel_outputs_pattern = re.compile(pattern=regex_channel_outputs, flags=re.I | re.M) return regex_channel_outputs_pattern def _ssh_message_handler(self, output: bytes) -> None: # noqa: C901 \"\"\" Parse EOF messages from _pty_authenticate and create log/stack exception message Args: output: bytes output from _pty_authenticate Returns: N/A # noqa: DAR202 Raises: ScrapliAuthenticationFailed: if any errors are read in the output \"\"\" msg = \"\" if b\"host key verification failed\" in output.lower(): msg = \"Host key verification failed\" elif b\"operation timed out\" in output.lower() or b\"connection timed out\" in output.lower(): msg = \"Timed out connecting to host\" elif b\"no route to host\" in output.lower(): msg = \"No route to host\" elif b\"no matching key exchange\" in output.lower(): msg = \"No matching key exchange found for host\" key_exchange_pattern = re.compile( pattern=rb\"their offer: ([a-z0-9\\-,]*)\", flags=re.M | re.I ) offered_key_exchanges_match = re.search(pattern=key_exchange_pattern, string=output) if offered_key_exchanges_match: offered_key_exchanges = offered_key_exchanges_match.group(1).decode() msg += f\", their offer: {offered_key_exchanges}\" elif b\"no matching cipher\" in output.lower(): msg = \"No matching cipher found for host\" ciphers_pattern = re.compile(pattern=rb\"their offer: ([a-z0-9\\-,]*)\", flags=re.M | re.I) offered_ciphers_match = re.search(pattern=ciphers_pattern, string=output) if offered_ciphers_match: offered_ciphers = offered_ciphers_match.group(1).decode() msg += f\", their offer: {offered_ciphers}\" elif b\"bad configuration\" in output.lower(): msg = \"Bad SSH configuration option(s) for host\" configuration_pattern = re.compile( pattern=rb\"bad configuration option: ([a-z0-9\\+\\=,]*)\", flags=re.M | re.I ) configuration_issue_match = re.search(pattern=configuration_pattern, string=output) if configuration_issue_match: configuration_issues = configuration_issue_match.group(1).decode() msg += f\", bad option(s): {configuration_issues}\" elif b\"WARNING: UNPROTECTED PRIVATE KEY FILE!\" in output: msg = \"Permissions for private key are too open, authentication failed!\" elif b\"could not resolve hostname\" in output.lower(): msg = \"Could not resolve address for host\" elif b\"permission denied\" in output.lower(): msg = str(output) if msg: self.logger.critical(msg) raise ScrapliAuthenticationFailed(msg) @staticmethod @lru_cache() def _get_prompt_pattern(class_pattern: str, pattern: Optional[str] = None) -> Pattern[bytes]: \"\"\" Return compiled prompt pattern Given a potential prompt and the Channel class' prompt, return compiled prompt pattern Args: class_pattern: comms_prompt_pattern from the class itself; must be passed so that the arguments are recognized in lru cache; this way if a user changes the pattern during normal scrapli operations the lru cache can \"notice\" the pattern changed! pattern: optional regex pattern to compile, if not provided we use the class' pattern Returns: pattern: compiled regex pattern to use to search for a prompt in output data Raises: N/A \"\"\" if not pattern: return re.compile(class_pattern.encode(), flags=re.M | re.I) bytes_pattern = pattern.encode() if bytes_pattern.startswith(b\"^\") and bytes_pattern.endswith(b\"$\"): return re.compile(bytes_pattern, flags=re.M | re.I) return re.compile(re.escape(bytes_pattern)) def _pre_channel_authenticate_ssh( self, ) -> Tuple[Pattern[bytes], Pattern[bytes], Pattern[bytes]]: \"\"\" Handle pre ssh authentication work for parity between sync and sync versions. Args: N/A Returns: tuple: tuple of pass/passphrase/prompt patterns Raises: N/A \"\"\" prompt_pattern = self._get_prompt_pattern( class_pattern=self._base_channel_args.comms_prompt_pattern ) return self.auth_password_pattern, self.auth_passphrase_pattern, prompt_pattern def _pre_channel_authenticate_telnet( self, ) -> Tuple[Pattern[bytes], Pattern[bytes], Pattern[bytes], float, float]: \"\"\" Handle pre telnet authentication work for parity between sync and sync versions. Args: N/A Returns: tuple: tuple of user/pass/prompt patterns, start timestamp and return interval Raises: N/A \"\"\" prompt_pattern = self._get_prompt_pattern( class_pattern=self._base_channel_args.comms_prompt_pattern ) # capture the start time of the authentication event; we also set a \"return_interval\" which # is 1/10 the timout_ops value, we will send a return character at roughly this interval if # there is no output on the channel. we do this because sometimes telnet needs a kick to get # it to prompt for auth -- particularity when connecting to terminal server/console port auth_start_time = datetime.now().timestamp() return_interval = self._base_channel_args.timeout_ops / 10 return ( self.auth_telnet_login_pattern, self.auth_password_pattern, prompt_pattern, auth_start_time, return_interval, ) def _process_output(self, buf: bytes, strip_prompt: bool) -> bytes: \"\"\" Process output received form the device Remove inputs and prompts if desired Args: buf: bytes output from the device strip_prompt: True/False strip the prompt from the device output Returns: bytes: cleaned up byte string Raises: N/A \"\"\" buf = b\"\\n\".join([line.rstrip() for line in buf.splitlines()]) if strip_prompt: prompt_pattern = self._get_prompt_pattern( class_pattern=self._base_channel_args.comms_prompt_pattern ) buf = re.sub(pattern=prompt_pattern, repl=b\"\", string=buf) buf = buf.lstrip(self._base_channel_args.comms_return_char.encode()).rstrip() return buf @staticmethod def _strip_ansi(buf: bytes) -> bytes: \"\"\" Strip ansi characters from output Args: buf: bytes from previous reads if needed Returns: bytes: bytes output read from channel with ansi characters removed Raises: N/A \"\"\" buf = re.sub(pattern=ANSI_ESCAPE_PATTERN, repl=b\"\", string=buf) return buf @staticmethod def _pre_send_input(channel_input: str) -> None: \"\"\" Handle pre \"send_input\" tasks for consistency between sync/async versions Args: channel_input: string input to send to channel Returns: bytes: current channel buffer Raises: ScrapliTypeError: if input is anything but a string \"\"\" if not isinstance(channel_input, str): raise ScrapliTypeError( f\"`send_input` expects a single string, got {type(channel_input)}.\" ) @staticmethod def _pre_send_inputs_interact(interact_events: List[Tuple[str, str, Optional[bool]]]) -> None: \"\"\" Handle pre \"send_inputs_interact\" tasks for consistency between sync/async versions Args: interact_events: interact events passed to `send_inputs_interact` Returns: None Raises: ScrapliTypeError: if input is anything but a string \"\"\" if not isinstance(interact_events, list): raise ScrapliTypeError(f\"`interact_events` expects a List, got {type(interact_events)}\")","title":"BaseChannel"},{"location":"api_docs/channel/base_channel/#descendants","text":"scrapli.channel.async_channel.AsyncChannel scrapli.channel.sync_channel.Channel","title":"Descendants"},{"location":"api_docs/channel/base_channel/#instance-variables","text":"auth_passphrase_pattern: Pattern[bytes] 1 2 3 4 5 6 7 8 9 10 Getter for `auth_passphrase_pattern` attribute Args: N/A Returns: Pattern: compiled pattern of the set auth_passphrase_pattern value Raises: N/A auth_password_pattern: Pattern[bytes] 1 2 3 4 5 6 7 8 9 10 Getter for `auth_password_pattern` attribute Args: N/A Returns: Pattern: compiled pattern of the set auth_password_pattern value Raises: N/A auth_telnet_login_pattern: Pattern[bytes] 1 2 3 4 5 6 7 8 9 10 Getter for `auth_telnet_login_pattern` attribute Args: N/A Returns: Pattern: compiled pattern of the set auth_telnet_login_pattern value Raises: N/A","title":"Instance variables"},{"location":"api_docs/channel/base_channel/#methods","text":"","title":"Methods"},{"location":"api_docs/channel/base_channel/#close","text":"close(self) \u2011> None 1 2 3 4 5 6 7 8 9 10 Channel close method Args: N/A Returns: None Raises: N/A","title":"close"},{"location":"api_docs/channel/base_channel/#open","text":"open(self) \u2011> None 1 2 3 4 5 6 7 8 9 10 Channel open method Args: N/A Returns: None Raises: N/A","title":"open"},{"location":"api_docs/channel/base_channel/#send_return","text":"send_return(self) \u2011> None 1 2 3 4 5 6 7 8 9 10 Convenience method to send return char Args: N/A Returns: None Raises: N/A","title":"send_return"},{"location":"api_docs/channel/base_channel/#write","text":"write(self, channel_input: str, redacted: bool = False) \u2011> None 1 2 3 4 5 6 7 8 9 10 11 Write input to the underlying Transport session Args: channel_input: string of input to send redacted: redact channel input from log or not Returns: None Raises: N/A","title":"write"},{"location":"api_docs/channel/base_channel/#basechannelargs","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 Dataclass for all base Channel arguments Args: comms_prompt_pattern: comms_prompt_pattern to assign to the channel; should generally be created/passed from the driver class comms_return_char: comms_return_char to assign to the channel, see above comms_prompt_search_depth: depth of the buffer to search in for searching for the prompt in \"read_until_prompt\"; smaller number here will generally be faster, though may be less reliable; default value is 1000 timeout_ops: timeout_ops to assign to the channel, see above channel_log: log \"channel\" output -- this would be the output you would normally see on a terminal. If `True` logs to `scrapli_channel.log`, if a string is provided, logs to wherever that string points channel_log_mode: \"write\"|\"append\", all other values will raise ValueError, does what it sounds like it should by setting the channel log to the provided mode channel_lock: bool indicated if channel lock should be used for all read/write operations Returns: None Raises: N/A Expand source code @dataclass() class BaseChannelArgs: \"\"\" Dataclass for all base Channel arguments Args: comms_prompt_pattern: comms_prompt_pattern to assign to the channel; should generally be created/passed from the driver class comms_return_char: comms_return_char to assign to the channel, see above comms_prompt_search_depth: depth of the buffer to search in for searching for the prompt in \"read_until_prompt\"; smaller number here will generally be faster, though may be less reliable; default value is 1000 timeout_ops: timeout_ops to assign to the channel, see above channel_log: log \"channel\" output -- this would be the output you would normally see on a terminal. If `True` logs to `scrapli_channel.log`, if a string is provided, logs to wherever that string points channel_log_mode: \"write\"|\"append\", all other values will raise ValueError, does what it sounds like it should by setting the channel log to the provided mode channel_lock: bool indicated if channel lock should be used for all read/write operations Returns: None Raises: N/A \"\"\" comms_prompt_pattern: str = r\"^[a-z0-9.\\-@()/:]{1,32}[#>$]$\" comms_return_char: str = \"\\n\" comms_prompt_search_depth: int = 1000 timeout_ops: float = 30.0 channel_log: Union[str, bool, BytesIO] = False channel_log_mode: str = \"write\" channel_lock: bool = False def __post_init__(self) -> None: \"\"\" Validate dataclass arguments at end of initialization Args: N/A Returns: None Raises: ScrapliValueError: if invalid channel_log_mode provided \"\"\" if self.channel_log_mode.lower() not in ( \"write\", \"append\", ): raise ScrapliValueError( f\"provided channel_log_mode '{self.channel_log_mode}' is not valid, mode must be \" f\"one of: 'write', 'append'\" ) if self.channel_log_mode.lower() == \"write\": self.channel_log_mode = \"w\" else: self.channel_log_mode = \"a\"","title":"BaseChannelArgs"},{"location":"api_docs/channel/base_channel/#class-variables","text":"channel_lock: bool channel_log: Union[str, bool, _io.BytesIO] channel_log_mode: str comms_prompt_pattern: str comms_prompt_search_depth: int comms_return_char: str timeout_ops: float","title":"Class variables"},{"location":"api_docs/channel/sync_channel/","text":"window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting()) Module scrapli.channel.sync_channel \u00b6 scrapli.channel.sync_channel Expand source code \"\"\"scrapli.channel.sync_channel\"\"\" import re import time from contextlib import contextmanager from datetime import datetime from io import BytesIO from threading import Lock from typing import Iterator, List, Optional, Tuple from scrapli.channel.base_channel import BaseChannel, BaseChannelArgs from scrapli.decorators import timeout_wrapper from scrapli.exceptions import ScrapliAuthenticationFailed, ScrapliTimeout from scrapli.transport.base import Transport class Channel(BaseChannel): def __init__( self, transport: Transport, base_channel_args: BaseChannelArgs, ) -> None: super().__init__( transport=transport, base_channel_args=base_channel_args, ) self.transport: Transport self.channel_lock: Optional[Lock] = None if self._base_channel_args.channel_lock: self.channel_lock = Lock() @contextmanager def _channel_lock(self) -> Iterator[None]: \"\"\" Lock the channel during public channel operations if channel_lock is enabled Args: N/A Yields: None Raises: N/A \"\"\" if self.channel_lock: with self.channel_lock: yield else: yield def read(self) -> bytes: \"\"\" Read chunks of output from the channel Replaces any r\"\\r\" characters that sometimes get stuffed into the output from the devices Args: N/A Returns: bytes: output read from channel Raises: N/A \"\"\" buf = self.transport.read() buf = buf.replace(b\"\\r\", b\"\") self.logger.debug(f\"read: {repr(buf)}\") if self.channel_log: self.channel_log.write(buf) if b\"\\x1b\" in buf.lower(): buf = self._strip_ansi(buf=buf) return buf def _read_until_input(self, channel_input: bytes) -> bytes: \"\"\" Read until all channel_input has been read on the channel Args: channel_input: bytes that should have been written to the channel Returns: bytes: output read from channel while checking for the input in the channel stream Raises: N/A \"\"\" buf = b\"\" if not channel_input: return buf # squish all channel input words together and cast to lower to make comparison easier processed_channel_input = b\"\".join(channel_input.lower().split()) while True: buf += self.read() # replace any backspace chars (particular problem w/ junos), and remove any added spaces # this is just for comparison of the inputs to what was read from channel if processed_channel_input in b\"\".join(buf.lower().replace(b\"\\x08\", b\"\").split()): return buf def _read_until_prompt(self, buf: bytes = b\"\") -> bytes: \"\"\" Read until expected prompt is seen. This reads until the \"normal\" `_base_channel_args.comms_prompt_pattern` is seen. The `_read_until_explicit_prompt` method can be used to read until some pattern in an arbitrary list of patterns is seen. Args: buf: output from previous reads if needed (used by scrapli netconf) Returns: bytes: output read from channel Raises: N/A \"\"\" search_pattern = self._get_prompt_pattern( class_pattern=self._base_channel_args.comms_prompt_pattern ) read_buf = BytesIO(buf) while True: read_buf.write(self.read()) search_buf = self._process_read_buf(read_buf=read_buf) channel_match = re.search( pattern=search_pattern, string=search_buf, ) if channel_match: return read_buf.getvalue() def _read_until_explicit_prompt(self, prompts: List[str]) -> bytes: \"\"\" Read until expected prompt is seen. This method is for *explicit* prompt patterns instead of the \"standard\" prompt patterns contained in the `_base_channel_args.comms_prompt_pattern` attribute. Generally this is only used for `send_interactive` though it could be used elsewhere as well. Args: prompts: list of prompt patterns to look for, will return upon seeing any match Returns: bytes: output read from channel Raises: N/A \"\"\" search_patterns = [ self._get_prompt_pattern( class_pattern=self._base_channel_args.comms_prompt_pattern, pattern=prompt ) for prompt in prompts ] read_buf = BytesIO(b\"\") while True: read_buf.write(self.read()) search_buf = self._process_read_buf(read_buf=read_buf) for search_pattern in search_patterns: channel_match = re.search( pattern=search_pattern, string=search_buf, ) if channel_match: return read_buf.getvalue() def _read_until_prompt_or_time( self, buf: bytes = b\"\", channel_outputs: Optional[List[bytes]] = None, read_duration: Optional[float] = None, ) -> bytes: \"\"\" Read until expected prompt is seen, outputs are seen, for duration, whichever comes first. As transport reading may block, transport timeout is temporarily set to the read_duration and any `ScrapliTimeout` that is raised while reading is ignored. Args: buf: bytes from previous reads if needed channel_outputs: List of bytes to search for in channel output, if any are seen, return read output read_duration: duration to read from channel for Returns: bytes: output read from channel Raises: N/A \"\"\" search_pattern = self._get_prompt_pattern( class_pattern=self._base_channel_args.comms_prompt_pattern, ) if channel_outputs is None: channel_outputs = [] if read_duration is None: read_duration = 2.5 regex_channel_outputs_pattern = self._join_and_compile(channel_outputs=channel_outputs) _transport_args = self.transport._base_transport_args # pylint: disable=W0212 previous_timeout_transport = _transport_args.timeout_transport _transport_args.timeout_transport = int(read_duration) read_buf = BytesIO(buf) start = time.time() while True: try: read_buf.write(self.read()) except ScrapliTimeout: pass search_buf = self._process_read_buf(read_buf=read_buf) if (time.time() - start) > read_duration: break if any((channel_output in search_buf for channel_output in channel_outputs)): break if re.search(pattern=regex_channel_outputs_pattern, string=search_buf): break if re.search(pattern=search_pattern, string=search_buf): break _transport_args.timeout_transport = previous_timeout_transport return read_buf.getvalue() @timeout_wrapper def channel_authenticate_ssh( self, auth_password: str, auth_private_key_passphrase: str ) -> None: \"\"\" Handle SSH Authentication for transports that only operate \"in the channel\" (i.e. system) Args: auth_password: password to authenticate with auth_private_key_passphrase: passphrase for ssh key if necessary Returns: None Raises: ScrapliAuthenticationFailed: if password prompt seen more than twice ScrapliAuthenticationFailed: if passphrase prompt seen more than twice \"\"\" self.logger.debug(\"attempting in channel ssh authentication\") password_count = 0 passphrase_count = 0 authenticate_buf = b\"\" ( password_pattern, passphrase_pattern, prompt_pattern, ) = self._pre_channel_authenticate_ssh() with self._channel_lock(): while True: buf = self.read() authenticate_buf += buf.lower() self._ssh_message_handler(output=authenticate_buf) if re.search( pattern=password_pattern, string=authenticate_buf, ): # clear the authentication buffer so we don't re-read the password prompt authenticate_buf = b\"\" password_count += 1 if password_count > 2: msg = \"password prompt seen more than once, assuming auth failed\" self.logger.critical(msg) raise ScrapliAuthenticationFailed(msg) self.write(channel_input=auth_password, redacted=True) self.send_return() if re.search( pattern=passphrase_pattern, string=authenticate_buf, ): # clear the authentication buffer so we don't re-read the passphrase prompt authenticate_buf = b\"\" passphrase_count += 1 if passphrase_count > 2: msg = \"passphrase prompt seen more than once, assuming auth failed\" self.logger.critical(msg) raise ScrapliAuthenticationFailed(msg) self.write(channel_input=auth_private_key_passphrase, redacted=True) self.send_return() if re.search( pattern=prompt_pattern, string=authenticate_buf, ): return @timeout_wrapper def channel_authenticate_telnet(self, auth_username: str = \"\", auth_password: str = \"\") -> None: \"\"\" Handle Telnet Authentication Args: auth_username: username to use for telnet authentication auth_password: password to use for telnet authentication Returns: None Raises: ScrapliAuthenticationFailed: if password prompt seen more than twice ScrapliAuthenticationFailed: if login prompt seen more than twice \"\"\" self.logger.debug(\"attempting in channel telnet authentication\") username_count = 0 password_count = 0 authenticate_buf = b\"\" ( username_pattern, password_pattern, prompt_pattern, auth_start_time, return_interval, ) = self._pre_channel_authenticate_telnet() return_attempts = 1 with self._channel_lock(): while True: buf = self.read() if not buf: current_iteration_time = datetime.now().timestamp() if (current_iteration_time - auth_start_time) > ( return_interval * return_attempts ): self.send_return() return_attempts += 1 authenticate_buf += buf.lower() if re.search( pattern=username_pattern, string=authenticate_buf, ): # clear the authentication buffer so we don't re-read the username prompt authenticate_buf = b\"\" username_count += 1 if username_count > 2: msg = \"username/login prompt seen more than once, assuming auth failed\" self.logger.critical(msg) raise ScrapliAuthenticationFailed(msg) self.write(channel_input=auth_username) self.send_return() if re.search( pattern=password_pattern, string=authenticate_buf, ): # clear the authentication buffer so we don't re-read the password prompt authenticate_buf = b\"\" password_count += 1 if password_count > 2: msg = \"password prompt seen more than once, assuming auth failed\" self.logger.critical(msg) raise ScrapliAuthenticationFailed(msg) self.write(channel_input=auth_password, redacted=True) self.send_return() if re.search( pattern=prompt_pattern, string=authenticate_buf, ): return @timeout_wrapper def get_prompt(self) -> str: \"\"\" Get current channel prompt Args: N/A Returns: str: string of the current prompt Raises: N/A \"\"\" buf = b\"\" search_pattern = self._get_prompt_pattern( class_pattern=self._base_channel_args.comms_prompt_pattern ) with self._channel_lock(): self.send_return() while True: buf += self.read() channel_match = re.search( pattern=search_pattern, string=buf, ) if channel_match: current_prompt = channel_match.group(0) return current_prompt.decode().strip() @timeout_wrapper def send_input( self, channel_input: str, *, strip_prompt: bool = True, eager: bool = False, ) -> Tuple[bytes, bytes]: \"\"\" Primary entry point to send data to devices in shell mode; accept input and returns result Args: channel_input: string input to send to channel strip_prompt: strip prompt or not, defaults to True (yes, strip the prompt) eager: eager mode reads and returns the `_read_until_input` value, but does not attempt to read to the prompt pattern -- this should not be used manually! (only used by `send_configs` with the eager flag set) Returns: Tuple[bytes, bytes]: tuple of \"raw\" output and \"processed\" (cleaned up/stripped) output Raises: N/A \"\"\" self._pre_send_input(channel_input=channel_input) buf = b\"\" bytes_channel_input = channel_input.encode() self.logger.info( f\"sending channel input: {channel_input}; strip_prompt: {strip_prompt}; eager: {eager}\" ) with self._channel_lock(): self.write(channel_input=channel_input) _buf_until_input = self._read_until_input(channel_input=bytes_channel_input) self.send_return() if not eager: buf += self._read_until_prompt() processed_buf = self._process_output( buf=buf, strip_prompt=strip_prompt, ) return buf, processed_buf @timeout_wrapper def send_input_and_read( self, channel_input: str, *, strip_prompt: bool = True, expected_outputs: Optional[List[str]] = None, read_duration: Optional[float] = None, ) -> Tuple[bytes, bytes]: \"\"\" Send a command and read until expected prompt is seen, outputs are seen, or for duration Args: channel_input: string input to send to channel strip_prompt: strip prompt or not, defaults to True (yes, strip the prompt) expected_outputs: list of strings to look for in output; if any of these are seen, return output read up till that read read_duration: float duration to read for Returns: Tuple[bytes, bytes]: tuple of \"raw\" output and \"processed\" (cleaned up/stripped) output Raises: N/A \"\"\" self._pre_send_input(channel_input=channel_input) buf = b\"\" bytes_channel_input = channel_input.encode() bytes_channel_outputs = [ channel_output.encode() for channel_output in expected_outputs or [] ] self.logger.info( f\"sending channel input and read: {channel_input}; strip_prompt: {strip_prompt}; \" f\"expected_outputs: {expected_outputs}; read_duration: {read_duration}\" ) with self._channel_lock(): self.write(channel_input=channel_input) _buf_until_input = self._read_until_input(channel_input=bytes_channel_input) self.send_return() buf += self._read_until_prompt_or_time( channel_outputs=bytes_channel_outputs, read_duration=read_duration ) processed_buf = self._process_output( buf=buf, strip_prompt=strip_prompt, ) return buf, processed_buf @timeout_wrapper def send_inputs_interact( self, interact_events: List[Tuple[str, str, Optional[bool]]], *, interaction_complete_patterns: Optional[List[str]] = None, ) -> Tuple[bytes, bytes]: \"\"\" Interact with a device with changing prompts per input. Used to interact with devices where prompts change per input, and where inputs may be hidden such as in the case of a password input. This can be used to respond to challenges from devices such as the confirmation for the command \"clear logging\" on IOSXE devices for example. You may have as many elements in the \"interact_events\" list as needed, and each element of that list should be a tuple of two or three elements. The first element is always the input to send as a string, the second should be the expected response as a string, and the optional third a bool for whether or not the input is \"hidden\" (i.e. password input) An example where we need this sort of capability: ''' 3560CX#copy flash: scp: Source filename []? test1.txt Address or name of remote host []? 172.31.254.100 Destination username [carl]? Writing test1.txt Password: Password: Sink: C0644 639 test1.txt ! 639 bytes copied in 12.066 secs (53 bytes/sec) 3560CX# ''' To accomplish this we can use the following: ''' interact = conn.channel.send_inputs_interact( [ (\"copy flash: scp:\", \"Source filename []?\", False), (\"test1.txt\", \"Address or name of remote host []?\", False), (\"172.31.254.100\", \"Destination username [carl]?\", False), (\"carl\", \"Password:\", False), (\"super_secure_password\", prompt, True), ] ) ''' If we needed to deal with more prompts we could simply continue adding tuples to the list of interact \"events\". Args: interact_events: list of tuples containing the \"interactions\" with the device each list element must have an input and an expected response, and may have an optional bool for the third and final element -- the optional bool specifies if the input that is sent to the device is \"hidden\" (ex: password), if the hidden param is not provided it is assumed the input is \"normal\" (not hidden) interaction_complete_patterns: list of patterns, that if seen, indicate the interactive \"session\" has ended and we should exit the interactive session. Returns: Tuple[bytes, bytes]: output read from the channel with no whitespace trimming/cleaning, and the output read from the channel that has been \"cleaned up\" Raises: N/A \"\"\" self._pre_send_inputs_interact(interact_events=interact_events) buf = b\"\" processed_buf = b\"\" with self._channel_lock(): for interact_event in interact_events: channel_input = interact_event[0] bytes_channel_input = channel_input.encode() channel_response = interact_event[1] prompts = [channel_response] if interaction_complete_patterns is not None: prompts.extend(interaction_complete_patterns) try: hidden_input = interact_event[2] except IndexError: hidden_input = False _channel_input = channel_input if not hidden_input else \"REDACTED\" self.logger.info( f\"sending interactive input: {_channel_input}; \" f\"expecting: {channel_response}; \" f\"hidden_input: {hidden_input}\" ) self.write(channel_input=channel_input, redacted=bool(hidden_input)) if channel_response and hidden_input is not True: buf += self._read_until_input(channel_input=bytes_channel_input) self.send_return() buf += self._read_until_explicit_prompt(prompts=prompts) processed_buf += self._process_output( buf=buf, strip_prompt=False, ) return buf, processed_buf Classes \u00b6 Channel \u00b6 1 2 3 4 5 6 7 8 9 10 11 BaseChannel Object -- provides convenience methods to both sync and async Channels Args: transport: initialized scrapli Transport/AsyncTransport object base_channel_args: BaseChannelArgs object Returns: None Raises: N/A Expand source code class Channel(BaseChannel): def __init__( self, transport: Transport, base_channel_args: BaseChannelArgs, ) -> None: super().__init__( transport=transport, base_channel_args=base_channel_args, ) self.transport: Transport self.channel_lock: Optional[Lock] = None if self._base_channel_args.channel_lock: self.channel_lock = Lock() @contextmanager def _channel_lock(self) -> Iterator[None]: \"\"\" Lock the channel during public channel operations if channel_lock is enabled Args: N/A Yields: None Raises: N/A \"\"\" if self.channel_lock: with self.channel_lock: yield else: yield def read(self) -> bytes: \"\"\" Read chunks of output from the channel Replaces any r\"\\r\" characters that sometimes get stuffed into the output from the devices Args: N/A Returns: bytes: output read from channel Raises: N/A \"\"\" buf = self.transport.read() buf = buf.replace(b\"\\r\", b\"\") self.logger.debug(f\"read: {repr(buf)}\") if self.channel_log: self.channel_log.write(buf) if b\"\\x1b\" in buf.lower(): buf = self._strip_ansi(buf=buf) return buf def _read_until_input(self, channel_input: bytes) -> bytes: \"\"\" Read until all channel_input has been read on the channel Args: channel_input: bytes that should have been written to the channel Returns: bytes: output read from channel while checking for the input in the channel stream Raises: N/A \"\"\" buf = b\"\" if not channel_input: return buf # squish all channel input words together and cast to lower to make comparison easier processed_channel_input = b\"\".join(channel_input.lower().split()) while True: buf += self.read() # replace any backspace chars (particular problem w/ junos), and remove any added spaces # this is just for comparison of the inputs to what was read from channel if processed_channel_input in b\"\".join(buf.lower().replace(b\"\\x08\", b\"\").split()): return buf def _read_until_prompt(self, buf: bytes = b\"\") -> bytes: \"\"\" Read until expected prompt is seen. This reads until the \"normal\" `_base_channel_args.comms_prompt_pattern` is seen. The `_read_until_explicit_prompt` method can be used to read until some pattern in an arbitrary list of patterns is seen. Args: buf: output from previous reads if needed (used by scrapli netconf) Returns: bytes: output read from channel Raises: N/A \"\"\" search_pattern = self._get_prompt_pattern( class_pattern=self._base_channel_args.comms_prompt_pattern ) read_buf = BytesIO(buf) while True: read_buf.write(self.read()) search_buf = self._process_read_buf(read_buf=read_buf) channel_match = re.search( pattern=search_pattern, string=search_buf, ) if channel_match: return read_buf.getvalue() def _read_until_explicit_prompt(self, prompts: List[str]) -> bytes: \"\"\" Read until expected prompt is seen. This method is for *explicit* prompt patterns instead of the \"standard\" prompt patterns contained in the `_base_channel_args.comms_prompt_pattern` attribute. Generally this is only used for `send_interactive` though it could be used elsewhere as well. Args: prompts: list of prompt patterns to look for, will return upon seeing any match Returns: bytes: output read from channel Raises: N/A \"\"\" search_patterns = [ self._get_prompt_pattern( class_pattern=self._base_channel_args.comms_prompt_pattern, pattern=prompt ) for prompt in prompts ] read_buf = BytesIO(b\"\") while True: read_buf.write(self.read()) search_buf = self._process_read_buf(read_buf=read_buf) for search_pattern in search_patterns: channel_match = re.search( pattern=search_pattern, string=search_buf, ) if channel_match: return read_buf.getvalue() def _read_until_prompt_or_time( self, buf: bytes = b\"\", channel_outputs: Optional[List[bytes]] = None, read_duration: Optional[float] = None, ) -> bytes: \"\"\" Read until expected prompt is seen, outputs are seen, for duration, whichever comes first. As transport reading may block, transport timeout is temporarily set to the read_duration and any `ScrapliTimeout` that is raised while reading is ignored. Args: buf: bytes from previous reads if needed channel_outputs: List of bytes to search for in channel output, if any are seen, return read output read_duration: duration to read from channel for Returns: bytes: output read from channel Raises: N/A \"\"\" search_pattern = self._get_prompt_pattern( class_pattern=self._base_channel_args.comms_prompt_pattern, ) if channel_outputs is None: channel_outputs = [] if read_duration is None: read_duration = 2.5 regex_channel_outputs_pattern = self._join_and_compile(channel_outputs=channel_outputs) _transport_args = self.transport._base_transport_args # pylint: disable=W0212 previous_timeout_transport = _transport_args.timeout_transport _transport_args.timeout_transport = int(read_duration) read_buf = BytesIO(buf) start = time.time() while True: try: read_buf.write(self.read()) except ScrapliTimeout: pass search_buf = self._process_read_buf(read_buf=read_buf) if (time.time() - start) > read_duration: break if any((channel_output in search_buf for channel_output in channel_outputs)): break if re.search(pattern=regex_channel_outputs_pattern, string=search_buf): break if re.search(pattern=search_pattern, string=search_buf): break _transport_args.timeout_transport = previous_timeout_transport return read_buf.getvalue() @timeout_wrapper def channel_authenticate_ssh( self, auth_password: str, auth_private_key_passphrase: str ) -> None: \"\"\" Handle SSH Authentication for transports that only operate \"in the channel\" (i.e. system) Args: auth_password: password to authenticate with auth_private_key_passphrase: passphrase for ssh key if necessary Returns: None Raises: ScrapliAuthenticationFailed: if password prompt seen more than twice ScrapliAuthenticationFailed: if passphrase prompt seen more than twice \"\"\" self.logger.debug(\"attempting in channel ssh authentication\") password_count = 0 passphrase_count = 0 authenticate_buf = b\"\" ( password_pattern, passphrase_pattern, prompt_pattern, ) = self._pre_channel_authenticate_ssh() with self._channel_lock(): while True: buf = self.read() authenticate_buf += buf.lower() self._ssh_message_handler(output=authenticate_buf) if re.search( pattern=password_pattern, string=authenticate_buf, ): # clear the authentication buffer so we don't re-read the password prompt authenticate_buf = b\"\" password_count += 1 if password_count > 2: msg = \"password prompt seen more than once, assuming auth failed\" self.logger.critical(msg) raise ScrapliAuthenticationFailed(msg) self.write(channel_input=auth_password, redacted=True) self.send_return() if re.search( pattern=passphrase_pattern, string=authenticate_buf, ): # clear the authentication buffer so we don't re-read the passphrase prompt authenticate_buf = b\"\" passphrase_count += 1 if passphrase_count > 2: msg = \"passphrase prompt seen more than once, assuming auth failed\" self.logger.critical(msg) raise ScrapliAuthenticationFailed(msg) self.write(channel_input=auth_private_key_passphrase, redacted=True) self.send_return() if re.search( pattern=prompt_pattern, string=authenticate_buf, ): return @timeout_wrapper def channel_authenticate_telnet(self, auth_username: str = \"\", auth_password: str = \"\") -> None: \"\"\" Handle Telnet Authentication Args: auth_username: username to use for telnet authentication auth_password: password to use for telnet authentication Returns: None Raises: ScrapliAuthenticationFailed: if password prompt seen more than twice ScrapliAuthenticationFailed: if login prompt seen more than twice \"\"\" self.logger.debug(\"attempting in channel telnet authentication\") username_count = 0 password_count = 0 authenticate_buf = b\"\" ( username_pattern, password_pattern, prompt_pattern, auth_start_time, return_interval, ) = self._pre_channel_authenticate_telnet() return_attempts = 1 with self._channel_lock(): while True: buf = self.read() if not buf: current_iteration_time = datetime.now().timestamp() if (current_iteration_time - auth_start_time) > ( return_interval * return_attempts ): self.send_return() return_attempts += 1 authenticate_buf += buf.lower() if re.search( pattern=username_pattern, string=authenticate_buf, ): # clear the authentication buffer so we don't re-read the username prompt authenticate_buf = b\"\" username_count += 1 if username_count > 2: msg = \"username/login prompt seen more than once, assuming auth failed\" self.logger.critical(msg) raise ScrapliAuthenticationFailed(msg) self.write(channel_input=auth_username) self.send_return() if re.search( pattern=password_pattern, string=authenticate_buf, ): # clear the authentication buffer so we don't re-read the password prompt authenticate_buf = b\"\" password_count += 1 if password_count > 2: msg = \"password prompt seen more than once, assuming auth failed\" self.logger.critical(msg) raise ScrapliAuthenticationFailed(msg) self.write(channel_input=auth_password, redacted=True) self.send_return() if re.search( pattern=prompt_pattern, string=authenticate_buf, ): return @timeout_wrapper def get_prompt(self) -> str: \"\"\" Get current channel prompt Args: N/A Returns: str: string of the current prompt Raises: N/A \"\"\" buf = b\"\" search_pattern = self._get_prompt_pattern( class_pattern=self._base_channel_args.comms_prompt_pattern ) with self._channel_lock(): self.send_return() while True: buf += self.read() channel_match = re.search( pattern=search_pattern, string=buf, ) if channel_match: current_prompt = channel_match.group(0) return current_prompt.decode().strip() @timeout_wrapper def send_input( self, channel_input: str, *, strip_prompt: bool = True, eager: bool = False, ) -> Tuple[bytes, bytes]: \"\"\" Primary entry point to send data to devices in shell mode; accept input and returns result Args: channel_input: string input to send to channel strip_prompt: strip prompt or not, defaults to True (yes, strip the prompt) eager: eager mode reads and returns the `_read_until_input` value, but does not attempt to read to the prompt pattern -- this should not be used manually! (only used by `send_configs` with the eager flag set) Returns: Tuple[bytes, bytes]: tuple of \"raw\" output and \"processed\" (cleaned up/stripped) output Raises: N/A \"\"\" self._pre_send_input(channel_input=channel_input) buf = b\"\" bytes_channel_input = channel_input.encode() self.logger.info( f\"sending channel input: {channel_input}; strip_prompt: {strip_prompt}; eager: {eager}\" ) with self._channel_lock(): self.write(channel_input=channel_input) _buf_until_input = self._read_until_input(channel_input=bytes_channel_input) self.send_return() if not eager: buf += self._read_until_prompt() processed_buf = self._process_output( buf=buf, strip_prompt=strip_prompt, ) return buf, processed_buf @timeout_wrapper def send_input_and_read( self, channel_input: str, *, strip_prompt: bool = True, expected_outputs: Optional[List[str]] = None, read_duration: Optional[float] = None, ) -> Tuple[bytes, bytes]: \"\"\" Send a command and read until expected prompt is seen, outputs are seen, or for duration Args: channel_input: string input to send to channel strip_prompt: strip prompt or not, defaults to True (yes, strip the prompt) expected_outputs: list of strings to look for in output; if any of these are seen, return output read up till that read read_duration: float duration to read for Returns: Tuple[bytes, bytes]: tuple of \"raw\" output and \"processed\" (cleaned up/stripped) output Raises: N/A \"\"\" self._pre_send_input(channel_input=channel_input) buf = b\"\" bytes_channel_input = channel_input.encode() bytes_channel_outputs = [ channel_output.encode() for channel_output in expected_outputs or [] ] self.logger.info( f\"sending channel input and read: {channel_input}; strip_prompt: {strip_prompt}; \" f\"expected_outputs: {expected_outputs}; read_duration: {read_duration}\" ) with self._channel_lock(): self.write(channel_input=channel_input) _buf_until_input = self._read_until_input(channel_input=bytes_channel_input) self.send_return() buf += self._read_until_prompt_or_time( channel_outputs=bytes_channel_outputs, read_duration=read_duration ) processed_buf = self._process_output( buf=buf, strip_prompt=strip_prompt, ) return buf, processed_buf @timeout_wrapper def send_inputs_interact( self, interact_events: List[Tuple[str, str, Optional[bool]]], *, interaction_complete_patterns: Optional[List[str]] = None, ) -> Tuple[bytes, bytes]: \"\"\" Interact with a device with changing prompts per input. Used to interact with devices where prompts change per input, and where inputs may be hidden such as in the case of a password input. This can be used to respond to challenges from devices such as the confirmation for the command \"clear logging\" on IOSXE devices for example. You may have as many elements in the \"interact_events\" list as needed, and each element of that list should be a tuple of two or three elements. The first element is always the input to send as a string, the second should be the expected response as a string, and the optional third a bool for whether or not the input is \"hidden\" (i.e. password input) An example where we need this sort of capability: ''' 3560CX#copy flash: scp: Source filename []? test1.txt Address or name of remote host []? 172.31.254.100 Destination username [carl]? Writing test1.txt Password: Password: Sink: C0644 639 test1.txt ! 639 bytes copied in 12.066 secs (53 bytes/sec) 3560CX# ''' To accomplish this we can use the following: ''' interact = conn.channel.send_inputs_interact( [ (\"copy flash: scp:\", \"Source filename []?\", False), (\"test1.txt\", \"Address or name of remote host []?\", False), (\"172.31.254.100\", \"Destination username [carl]?\", False), (\"carl\", \"Password:\", False), (\"super_secure_password\", prompt, True), ] ) ''' If we needed to deal with more prompts we could simply continue adding tuples to the list of interact \"events\". Args: interact_events: list of tuples containing the \"interactions\" with the device each list element must have an input and an expected response, and may have an optional bool for the third and final element -- the optional bool specifies if the input that is sent to the device is \"hidden\" (ex: password), if the hidden param is not provided it is assumed the input is \"normal\" (not hidden) interaction_complete_patterns: list of patterns, that if seen, indicate the interactive \"session\" has ended and we should exit the interactive session. Returns: Tuple[bytes, bytes]: output read from the channel with no whitespace trimming/cleaning, and the output read from the channel that has been \"cleaned up\" Raises: N/A \"\"\" self._pre_send_inputs_interact(interact_events=interact_events) buf = b\"\" processed_buf = b\"\" with self._channel_lock(): for interact_event in interact_events: channel_input = interact_event[0] bytes_channel_input = channel_input.encode() channel_response = interact_event[1] prompts = [channel_response] if interaction_complete_patterns is not None: prompts.extend(interaction_complete_patterns) try: hidden_input = interact_event[2] except IndexError: hidden_input = False _channel_input = channel_input if not hidden_input else \"REDACTED\" self.logger.info( f\"sending interactive input: {_channel_input}; \" f\"expecting: {channel_response}; \" f\"hidden_input: {hidden_input}\" ) self.write(channel_input=channel_input, redacted=bool(hidden_input)) if channel_response and hidden_input is not True: buf += self._read_until_input(channel_input=bytes_channel_input) self.send_return() buf += self._read_until_explicit_prompt(prompts=prompts) processed_buf += self._process_output( buf=buf, strip_prompt=False, ) return buf, processed_buf Ancestors (in MRO) \u00b6 scrapli.channel.base_channel.BaseChannel Methods \u00b6 channel_authenticate_ssh \u00b6 channel_authenticate_ssh(self, auth_password: str, auth_private_key_passphrase: str) \u2011> None 1 2 3 4 5 6 7 8 9 10 11 12 Handle SSH Authentication for transports that only operate \"in the channel\" (i.e. system) Args: auth_password: password to authenticate with auth_private_key_passphrase: passphrase for ssh key if necessary Returns: None Raises: ScrapliAuthenticationFailed: if password prompt seen more than twice ScrapliAuthenticationFailed: if passphrase prompt seen more than twice channel_authenticate_telnet \u00b6 channel_authenticate_telnet(self, auth_username: str = '', auth_password: str = '') \u2011> None 1 2 3 4 5 6 7 8 9 10 11 12 Handle Telnet Authentication Args: auth_username: username to use for telnet authentication auth_password: password to use for telnet authentication Returns: None Raises: ScrapliAuthenticationFailed: if password prompt seen more than twice ScrapliAuthenticationFailed: if login prompt seen more than twice get_prompt \u00b6 get_prompt(self) \u2011> str 1 2 3 4 5 6 7 8 9 10 Get current channel prompt Args: N/A Returns: str: string of the current prompt Raises: N/A read \u00b6 read(self) \u2011> bytes 1 2 3 4 5 6 7 8 9 10 11 12 13 Read chunks of output from the channel Replaces any r\" \" characters that sometimes get stuffed into the output from the devices Args: N/A Returns: bytes: output read from channel Raises: N/A send_input \u00b6 send_input(self, channel_input: str, *, strip_prompt: bool = True, eager: bool = False) \u2011> Tuple[bytes, bytes] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 Primary entry point to send data to devices in shell mode; accept input and returns result Args: channel_input: string input to send to channel strip_prompt: strip prompt or not, defaults to True (yes, strip the prompt) eager: eager mode reads and returns the `_read_until_input` value, but does not attempt to read to the prompt pattern -- this should not be used manually! (only used by `send_configs` with the eager flag set) Returns: Tuple[bytes, bytes]: tuple of \"raw\" output and \"processed\" (cleaned up/stripped) output Raises: N/A send_input_and_read \u00b6 send_input_and_read(self, channel_input: str, *, strip_prompt: bool = True, expected_outputs: Optional[List[str]] = None, read_duration: Optional[float] = None) \u2011> Tuple[bytes, bytes] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 Send a command and read until expected prompt is seen, outputs are seen, or for duration Args: channel_input: string input to send to channel strip_prompt: strip prompt or not, defaults to True (yes, strip the prompt) expected_outputs: list of strings to look for in output; if any of these are seen, return output read up till that read read_duration: float duration to read for Returns: Tuple[bytes, bytes]: tuple of \"raw\" output and \"processed\" (cleaned up/stripped) output Raises: N/A send_inputs_interact \u00b6 send_inputs_interact(self, interact_events: List[Tuple[str, str, Optional[bool]]], *, interaction_complete_patterns: Optional[List[str]] = None) \u2011> Tuple[bytes, bytes] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 Interact with a device with changing prompts per input. Used to interact with devices where prompts change per input, and where inputs may be hidden such as in the case of a password input. This can be used to respond to challenges from devices such as the confirmation for the command \"clear logging\" on IOSXE devices for example. You may have as many elements in the \"interact_events\" list as needed, and each element of that list should be a tuple of two or three elements. The first element is always the input to send as a string, the second should be the expected response as a string, and the optional third a bool for whether or not the input is \"hidden\" (i.e. password input) An example where we need this sort of capability: ''' 3560CX#copy flash: scp: Source filename []? test1.txt Address or name of remote host []? 172.31.254.100 Destination username [carl]? Writing test1.txt Password: Password: Sink: C0644 639 test1.txt ! 639 bytes copied in 12.066 secs (53 bytes/sec) 3560CX# ''' To accomplish this we can use the following: ''' interact = conn.channel.send_inputs_interact( [ (\"copy flash: scp:\", \"Source filename []?\", False), (\"test1.txt\", \"Address or name of remote host []?\", False), (\"172.31.254.100\", \"Destination username [carl]?\", False), (\"carl\", \"Password:\", False), (\"super_secure_password\", prompt, True), ] ) ''' If we needed to deal with more prompts we could simply continue adding tuples to the list of interact \"events\". Args: interact_events: list of tuples containing the \"interactions\" with the device each list element must have an input and an expected response, and may have an optional bool for the third and final element -- the optional bool specifies if the input that is sent to the device is \"hidden\" (ex: password), if the hidden param is not provided it is assumed the input is \"normal\" (not hidden) interaction_complete_patterns: list of patterns, that if seen, indicate the interactive \"session\" has ended and we should exit the interactive session. Returns: Tuple[bytes, bytes]: output read from the channel with no whitespace trimming/cleaning, and the output read from the channel that has been \"cleaned up\" Raises: N/A","title":"Sync Channel"},{"location":"api_docs/channel/sync_channel/#module-scraplichannelsync_channel","text":"scrapli.channel.sync_channel Expand source code \"\"\"scrapli.channel.sync_channel\"\"\" import re import time from contextlib import contextmanager from datetime import datetime from io import BytesIO from threading import Lock from typing import Iterator, List, Optional, Tuple from scrapli.channel.base_channel import BaseChannel, BaseChannelArgs from scrapli.decorators import timeout_wrapper from scrapli.exceptions import ScrapliAuthenticationFailed, ScrapliTimeout from scrapli.transport.base import Transport class Channel(BaseChannel): def __init__( self, transport: Transport, base_channel_args: BaseChannelArgs, ) -> None: super().__init__( transport=transport, base_channel_args=base_channel_args, ) self.transport: Transport self.channel_lock: Optional[Lock] = None if self._base_channel_args.channel_lock: self.channel_lock = Lock() @contextmanager def _channel_lock(self) -> Iterator[None]: \"\"\" Lock the channel during public channel operations if channel_lock is enabled Args: N/A Yields: None Raises: N/A \"\"\" if self.channel_lock: with self.channel_lock: yield else: yield def read(self) -> bytes: \"\"\" Read chunks of output from the channel Replaces any r\"\\r\" characters that sometimes get stuffed into the output from the devices Args: N/A Returns: bytes: output read from channel Raises: N/A \"\"\" buf = self.transport.read() buf = buf.replace(b\"\\r\", b\"\") self.logger.debug(f\"read: {repr(buf)}\") if self.channel_log: self.channel_log.write(buf) if b\"\\x1b\" in buf.lower(): buf = self._strip_ansi(buf=buf) return buf def _read_until_input(self, channel_input: bytes) -> bytes: \"\"\" Read until all channel_input has been read on the channel Args: channel_input: bytes that should have been written to the channel Returns: bytes: output read from channel while checking for the input in the channel stream Raises: N/A \"\"\" buf = b\"\" if not channel_input: return buf # squish all channel input words together and cast to lower to make comparison easier processed_channel_input = b\"\".join(channel_input.lower().split()) while True: buf += self.read() # replace any backspace chars (particular problem w/ junos), and remove any added spaces # this is just for comparison of the inputs to what was read from channel if processed_channel_input in b\"\".join(buf.lower().replace(b\"\\x08\", b\"\").split()): return buf def _read_until_prompt(self, buf: bytes = b\"\") -> bytes: \"\"\" Read until expected prompt is seen. This reads until the \"normal\" `_base_channel_args.comms_prompt_pattern` is seen. The `_read_until_explicit_prompt` method can be used to read until some pattern in an arbitrary list of patterns is seen. Args: buf: output from previous reads if needed (used by scrapli netconf) Returns: bytes: output read from channel Raises: N/A \"\"\" search_pattern = self._get_prompt_pattern( class_pattern=self._base_channel_args.comms_prompt_pattern ) read_buf = BytesIO(buf) while True: read_buf.write(self.read()) search_buf = self._process_read_buf(read_buf=read_buf) channel_match = re.search( pattern=search_pattern, string=search_buf, ) if channel_match: return read_buf.getvalue() def _read_until_explicit_prompt(self, prompts: List[str]) -> bytes: \"\"\" Read until expected prompt is seen. This method is for *explicit* prompt patterns instead of the \"standard\" prompt patterns contained in the `_base_channel_args.comms_prompt_pattern` attribute. Generally this is only used for `send_interactive` though it could be used elsewhere as well. Args: prompts: list of prompt patterns to look for, will return upon seeing any match Returns: bytes: output read from channel Raises: N/A \"\"\" search_patterns = [ self._get_prompt_pattern( class_pattern=self._base_channel_args.comms_prompt_pattern, pattern=prompt ) for prompt in prompts ] read_buf = BytesIO(b\"\") while True: read_buf.write(self.read()) search_buf = self._process_read_buf(read_buf=read_buf) for search_pattern in search_patterns: channel_match = re.search( pattern=search_pattern, string=search_buf, ) if channel_match: return read_buf.getvalue() def _read_until_prompt_or_time( self, buf: bytes = b\"\", channel_outputs: Optional[List[bytes]] = None, read_duration: Optional[float] = None, ) -> bytes: \"\"\" Read until expected prompt is seen, outputs are seen, for duration, whichever comes first. As transport reading may block, transport timeout is temporarily set to the read_duration and any `ScrapliTimeout` that is raised while reading is ignored. Args: buf: bytes from previous reads if needed channel_outputs: List of bytes to search for in channel output, if any are seen, return read output read_duration: duration to read from channel for Returns: bytes: output read from channel Raises: N/A \"\"\" search_pattern = self._get_prompt_pattern( class_pattern=self._base_channel_args.comms_prompt_pattern, ) if channel_outputs is None: channel_outputs = [] if read_duration is None: read_duration = 2.5 regex_channel_outputs_pattern = self._join_and_compile(channel_outputs=channel_outputs) _transport_args = self.transport._base_transport_args # pylint: disable=W0212 previous_timeout_transport = _transport_args.timeout_transport _transport_args.timeout_transport = int(read_duration) read_buf = BytesIO(buf) start = time.time() while True: try: read_buf.write(self.read()) except ScrapliTimeout: pass search_buf = self._process_read_buf(read_buf=read_buf) if (time.time() - start) > read_duration: break if any((channel_output in search_buf for channel_output in channel_outputs)): break if re.search(pattern=regex_channel_outputs_pattern, string=search_buf): break if re.search(pattern=search_pattern, string=search_buf): break _transport_args.timeout_transport = previous_timeout_transport return read_buf.getvalue() @timeout_wrapper def channel_authenticate_ssh( self, auth_password: str, auth_private_key_passphrase: str ) -> None: \"\"\" Handle SSH Authentication for transports that only operate \"in the channel\" (i.e. system) Args: auth_password: password to authenticate with auth_private_key_passphrase: passphrase for ssh key if necessary Returns: None Raises: ScrapliAuthenticationFailed: if password prompt seen more than twice ScrapliAuthenticationFailed: if passphrase prompt seen more than twice \"\"\" self.logger.debug(\"attempting in channel ssh authentication\") password_count = 0 passphrase_count = 0 authenticate_buf = b\"\" ( password_pattern, passphrase_pattern, prompt_pattern, ) = self._pre_channel_authenticate_ssh() with self._channel_lock(): while True: buf = self.read() authenticate_buf += buf.lower() self._ssh_message_handler(output=authenticate_buf) if re.search( pattern=password_pattern, string=authenticate_buf, ): # clear the authentication buffer so we don't re-read the password prompt authenticate_buf = b\"\" password_count += 1 if password_count > 2: msg = \"password prompt seen more than once, assuming auth failed\" self.logger.critical(msg) raise ScrapliAuthenticationFailed(msg) self.write(channel_input=auth_password, redacted=True) self.send_return() if re.search( pattern=passphrase_pattern, string=authenticate_buf, ): # clear the authentication buffer so we don't re-read the passphrase prompt authenticate_buf = b\"\" passphrase_count += 1 if passphrase_count > 2: msg = \"passphrase prompt seen more than once, assuming auth failed\" self.logger.critical(msg) raise ScrapliAuthenticationFailed(msg) self.write(channel_input=auth_private_key_passphrase, redacted=True) self.send_return() if re.search( pattern=prompt_pattern, string=authenticate_buf, ): return @timeout_wrapper def channel_authenticate_telnet(self, auth_username: str = \"\", auth_password: str = \"\") -> None: \"\"\" Handle Telnet Authentication Args: auth_username: username to use for telnet authentication auth_password: password to use for telnet authentication Returns: None Raises: ScrapliAuthenticationFailed: if password prompt seen more than twice ScrapliAuthenticationFailed: if login prompt seen more than twice \"\"\" self.logger.debug(\"attempting in channel telnet authentication\") username_count = 0 password_count = 0 authenticate_buf = b\"\" ( username_pattern, password_pattern, prompt_pattern, auth_start_time, return_interval, ) = self._pre_channel_authenticate_telnet() return_attempts = 1 with self._channel_lock(): while True: buf = self.read() if not buf: current_iteration_time = datetime.now().timestamp() if (current_iteration_time - auth_start_time) > ( return_interval * return_attempts ): self.send_return() return_attempts += 1 authenticate_buf += buf.lower() if re.search( pattern=username_pattern, string=authenticate_buf, ): # clear the authentication buffer so we don't re-read the username prompt authenticate_buf = b\"\" username_count += 1 if username_count > 2: msg = \"username/login prompt seen more than once, assuming auth failed\" self.logger.critical(msg) raise ScrapliAuthenticationFailed(msg) self.write(channel_input=auth_username) self.send_return() if re.search( pattern=password_pattern, string=authenticate_buf, ): # clear the authentication buffer so we don't re-read the password prompt authenticate_buf = b\"\" password_count += 1 if password_count > 2: msg = \"password prompt seen more than once, assuming auth failed\" self.logger.critical(msg) raise ScrapliAuthenticationFailed(msg) self.write(channel_input=auth_password, redacted=True) self.send_return() if re.search( pattern=prompt_pattern, string=authenticate_buf, ): return @timeout_wrapper def get_prompt(self) -> str: \"\"\" Get current channel prompt Args: N/A Returns: str: string of the current prompt Raises: N/A \"\"\" buf = b\"\" search_pattern = self._get_prompt_pattern( class_pattern=self._base_channel_args.comms_prompt_pattern ) with self._channel_lock(): self.send_return() while True: buf += self.read() channel_match = re.search( pattern=search_pattern, string=buf, ) if channel_match: current_prompt = channel_match.group(0) return current_prompt.decode().strip() @timeout_wrapper def send_input( self, channel_input: str, *, strip_prompt: bool = True, eager: bool = False, ) -> Tuple[bytes, bytes]: \"\"\" Primary entry point to send data to devices in shell mode; accept input and returns result Args: channel_input: string input to send to channel strip_prompt: strip prompt or not, defaults to True (yes, strip the prompt) eager: eager mode reads and returns the `_read_until_input` value, but does not attempt to read to the prompt pattern -- this should not be used manually! (only used by `send_configs` with the eager flag set) Returns: Tuple[bytes, bytes]: tuple of \"raw\" output and \"processed\" (cleaned up/stripped) output Raises: N/A \"\"\" self._pre_send_input(channel_input=channel_input) buf = b\"\" bytes_channel_input = channel_input.encode() self.logger.info( f\"sending channel input: {channel_input}; strip_prompt: {strip_prompt}; eager: {eager}\" ) with self._channel_lock(): self.write(channel_input=channel_input) _buf_until_input = self._read_until_input(channel_input=bytes_channel_input) self.send_return() if not eager: buf += self._read_until_prompt() processed_buf = self._process_output( buf=buf, strip_prompt=strip_prompt, ) return buf, processed_buf @timeout_wrapper def send_input_and_read( self, channel_input: str, *, strip_prompt: bool = True, expected_outputs: Optional[List[str]] = None, read_duration: Optional[float] = None, ) -> Tuple[bytes, bytes]: \"\"\" Send a command and read until expected prompt is seen, outputs are seen, or for duration Args: channel_input: string input to send to channel strip_prompt: strip prompt or not, defaults to True (yes, strip the prompt) expected_outputs: list of strings to look for in output; if any of these are seen, return output read up till that read read_duration: float duration to read for Returns: Tuple[bytes, bytes]: tuple of \"raw\" output and \"processed\" (cleaned up/stripped) output Raises: N/A \"\"\" self._pre_send_input(channel_input=channel_input) buf = b\"\" bytes_channel_input = channel_input.encode() bytes_channel_outputs = [ channel_output.encode() for channel_output in expected_outputs or [] ] self.logger.info( f\"sending channel input and read: {channel_input}; strip_prompt: {strip_prompt}; \" f\"expected_outputs: {expected_outputs}; read_duration: {read_duration}\" ) with self._channel_lock(): self.write(channel_input=channel_input) _buf_until_input = self._read_until_input(channel_input=bytes_channel_input) self.send_return() buf += self._read_until_prompt_or_time( channel_outputs=bytes_channel_outputs, read_duration=read_duration ) processed_buf = self._process_output( buf=buf, strip_prompt=strip_prompt, ) return buf, processed_buf @timeout_wrapper def send_inputs_interact( self, interact_events: List[Tuple[str, str, Optional[bool]]], *, interaction_complete_patterns: Optional[List[str]] = None, ) -> Tuple[bytes, bytes]: \"\"\" Interact with a device with changing prompts per input. Used to interact with devices where prompts change per input, and where inputs may be hidden such as in the case of a password input. This can be used to respond to challenges from devices such as the confirmation for the command \"clear logging\" on IOSXE devices for example. You may have as many elements in the \"interact_events\" list as needed, and each element of that list should be a tuple of two or three elements. The first element is always the input to send as a string, the second should be the expected response as a string, and the optional third a bool for whether or not the input is \"hidden\" (i.e. password input) An example where we need this sort of capability: ''' 3560CX#copy flash: scp: Source filename []? test1.txt Address or name of remote host []? 172.31.254.100 Destination username [carl]? Writing test1.txt Password: Password: Sink: C0644 639 test1.txt ! 639 bytes copied in 12.066 secs (53 bytes/sec) 3560CX# ''' To accomplish this we can use the following: ''' interact = conn.channel.send_inputs_interact( [ (\"copy flash: scp:\", \"Source filename []?\", False), (\"test1.txt\", \"Address or name of remote host []?\", False), (\"172.31.254.100\", \"Destination username [carl]?\", False), (\"carl\", \"Password:\", False), (\"super_secure_password\", prompt, True), ] ) ''' If we needed to deal with more prompts we could simply continue adding tuples to the list of interact \"events\". Args: interact_events: list of tuples containing the \"interactions\" with the device each list element must have an input and an expected response, and may have an optional bool for the third and final element -- the optional bool specifies if the input that is sent to the device is \"hidden\" (ex: password), if the hidden param is not provided it is assumed the input is \"normal\" (not hidden) interaction_complete_patterns: list of patterns, that if seen, indicate the interactive \"session\" has ended and we should exit the interactive session. Returns: Tuple[bytes, bytes]: output read from the channel with no whitespace trimming/cleaning, and the output read from the channel that has been \"cleaned up\" Raises: N/A \"\"\" self._pre_send_inputs_interact(interact_events=interact_events) buf = b\"\" processed_buf = b\"\" with self._channel_lock(): for interact_event in interact_events: channel_input = interact_event[0] bytes_channel_input = channel_input.encode() channel_response = interact_event[1] prompts = [channel_response] if interaction_complete_patterns is not None: prompts.extend(interaction_complete_patterns) try: hidden_input = interact_event[2] except IndexError: hidden_input = False _channel_input = channel_input if not hidden_input else \"REDACTED\" self.logger.info( f\"sending interactive input: {_channel_input}; \" f\"expecting: {channel_response}; \" f\"hidden_input: {hidden_input}\" ) self.write(channel_input=channel_input, redacted=bool(hidden_input)) if channel_response and hidden_input is not True: buf += self._read_until_input(channel_input=bytes_channel_input) self.send_return() buf += self._read_until_explicit_prompt(prompts=prompts) processed_buf += self._process_output( buf=buf, strip_prompt=False, ) return buf, processed_buf","title":"Module scrapli.channel.sync_channel"},{"location":"api_docs/channel/sync_channel/#classes","text":"","title":"Classes"},{"location":"api_docs/channel/sync_channel/#channel","text":"1 2 3 4 5 6 7 8 9 10 11 BaseChannel Object -- provides convenience methods to both sync and async Channels Args: transport: initialized scrapli Transport/AsyncTransport object base_channel_args: BaseChannelArgs object Returns: None Raises: N/A Expand source code class Channel(BaseChannel): def __init__( self, transport: Transport, base_channel_args: BaseChannelArgs, ) -> None: super().__init__( transport=transport, base_channel_args=base_channel_args, ) self.transport: Transport self.channel_lock: Optional[Lock] = None if self._base_channel_args.channel_lock: self.channel_lock = Lock() @contextmanager def _channel_lock(self) -> Iterator[None]: \"\"\" Lock the channel during public channel operations if channel_lock is enabled Args: N/A Yields: None Raises: N/A \"\"\" if self.channel_lock: with self.channel_lock: yield else: yield def read(self) -> bytes: \"\"\" Read chunks of output from the channel Replaces any r\"\\r\" characters that sometimes get stuffed into the output from the devices Args: N/A Returns: bytes: output read from channel Raises: N/A \"\"\" buf = self.transport.read() buf = buf.replace(b\"\\r\", b\"\") self.logger.debug(f\"read: {repr(buf)}\") if self.channel_log: self.channel_log.write(buf) if b\"\\x1b\" in buf.lower(): buf = self._strip_ansi(buf=buf) return buf def _read_until_input(self, channel_input: bytes) -> bytes: \"\"\" Read until all channel_input has been read on the channel Args: channel_input: bytes that should have been written to the channel Returns: bytes: output read from channel while checking for the input in the channel stream Raises: N/A \"\"\" buf = b\"\" if not channel_input: return buf # squish all channel input words together and cast to lower to make comparison easier processed_channel_input = b\"\".join(channel_input.lower().split()) while True: buf += self.read() # replace any backspace chars (particular problem w/ junos), and remove any added spaces # this is just for comparison of the inputs to what was read from channel if processed_channel_input in b\"\".join(buf.lower().replace(b\"\\x08\", b\"\").split()): return buf def _read_until_prompt(self, buf: bytes = b\"\") -> bytes: \"\"\" Read until expected prompt is seen. This reads until the \"normal\" `_base_channel_args.comms_prompt_pattern` is seen. The `_read_until_explicit_prompt` method can be used to read until some pattern in an arbitrary list of patterns is seen. Args: buf: output from previous reads if needed (used by scrapli netconf) Returns: bytes: output read from channel Raises: N/A \"\"\" search_pattern = self._get_prompt_pattern( class_pattern=self._base_channel_args.comms_prompt_pattern ) read_buf = BytesIO(buf) while True: read_buf.write(self.read()) search_buf = self._process_read_buf(read_buf=read_buf) channel_match = re.search( pattern=search_pattern, string=search_buf, ) if channel_match: return read_buf.getvalue() def _read_until_explicit_prompt(self, prompts: List[str]) -> bytes: \"\"\" Read until expected prompt is seen. This method is for *explicit* prompt patterns instead of the \"standard\" prompt patterns contained in the `_base_channel_args.comms_prompt_pattern` attribute. Generally this is only used for `send_interactive` though it could be used elsewhere as well. Args: prompts: list of prompt patterns to look for, will return upon seeing any match Returns: bytes: output read from channel Raises: N/A \"\"\" search_patterns = [ self._get_prompt_pattern( class_pattern=self._base_channel_args.comms_prompt_pattern, pattern=prompt ) for prompt in prompts ] read_buf = BytesIO(b\"\") while True: read_buf.write(self.read()) search_buf = self._process_read_buf(read_buf=read_buf) for search_pattern in search_patterns: channel_match = re.search( pattern=search_pattern, string=search_buf, ) if channel_match: return read_buf.getvalue() def _read_until_prompt_or_time( self, buf: bytes = b\"\", channel_outputs: Optional[List[bytes]] = None, read_duration: Optional[float] = None, ) -> bytes: \"\"\" Read until expected prompt is seen, outputs are seen, for duration, whichever comes first. As transport reading may block, transport timeout is temporarily set to the read_duration and any `ScrapliTimeout` that is raised while reading is ignored. Args: buf: bytes from previous reads if needed channel_outputs: List of bytes to search for in channel output, if any are seen, return read output read_duration: duration to read from channel for Returns: bytes: output read from channel Raises: N/A \"\"\" search_pattern = self._get_prompt_pattern( class_pattern=self._base_channel_args.comms_prompt_pattern, ) if channel_outputs is None: channel_outputs = [] if read_duration is None: read_duration = 2.5 regex_channel_outputs_pattern = self._join_and_compile(channel_outputs=channel_outputs) _transport_args = self.transport._base_transport_args # pylint: disable=W0212 previous_timeout_transport = _transport_args.timeout_transport _transport_args.timeout_transport = int(read_duration) read_buf = BytesIO(buf) start = time.time() while True: try: read_buf.write(self.read()) except ScrapliTimeout: pass search_buf = self._process_read_buf(read_buf=read_buf) if (time.time() - start) > read_duration: break if any((channel_output in search_buf for channel_output in channel_outputs)): break if re.search(pattern=regex_channel_outputs_pattern, string=search_buf): break if re.search(pattern=search_pattern, string=search_buf): break _transport_args.timeout_transport = previous_timeout_transport return read_buf.getvalue() @timeout_wrapper def channel_authenticate_ssh( self, auth_password: str, auth_private_key_passphrase: str ) -> None: \"\"\" Handle SSH Authentication for transports that only operate \"in the channel\" (i.e. system) Args: auth_password: password to authenticate with auth_private_key_passphrase: passphrase for ssh key if necessary Returns: None Raises: ScrapliAuthenticationFailed: if password prompt seen more than twice ScrapliAuthenticationFailed: if passphrase prompt seen more than twice \"\"\" self.logger.debug(\"attempting in channel ssh authentication\") password_count = 0 passphrase_count = 0 authenticate_buf = b\"\" ( password_pattern, passphrase_pattern, prompt_pattern, ) = self._pre_channel_authenticate_ssh() with self._channel_lock(): while True: buf = self.read() authenticate_buf += buf.lower() self._ssh_message_handler(output=authenticate_buf) if re.search( pattern=password_pattern, string=authenticate_buf, ): # clear the authentication buffer so we don't re-read the password prompt authenticate_buf = b\"\" password_count += 1 if password_count > 2: msg = \"password prompt seen more than once, assuming auth failed\" self.logger.critical(msg) raise ScrapliAuthenticationFailed(msg) self.write(channel_input=auth_password, redacted=True) self.send_return() if re.search( pattern=passphrase_pattern, string=authenticate_buf, ): # clear the authentication buffer so we don't re-read the passphrase prompt authenticate_buf = b\"\" passphrase_count += 1 if passphrase_count > 2: msg = \"passphrase prompt seen more than once, assuming auth failed\" self.logger.critical(msg) raise ScrapliAuthenticationFailed(msg) self.write(channel_input=auth_private_key_passphrase, redacted=True) self.send_return() if re.search( pattern=prompt_pattern, string=authenticate_buf, ): return @timeout_wrapper def channel_authenticate_telnet(self, auth_username: str = \"\", auth_password: str = \"\") -> None: \"\"\" Handle Telnet Authentication Args: auth_username: username to use for telnet authentication auth_password: password to use for telnet authentication Returns: None Raises: ScrapliAuthenticationFailed: if password prompt seen more than twice ScrapliAuthenticationFailed: if login prompt seen more than twice \"\"\" self.logger.debug(\"attempting in channel telnet authentication\") username_count = 0 password_count = 0 authenticate_buf = b\"\" ( username_pattern, password_pattern, prompt_pattern, auth_start_time, return_interval, ) = self._pre_channel_authenticate_telnet() return_attempts = 1 with self._channel_lock(): while True: buf = self.read() if not buf: current_iteration_time = datetime.now().timestamp() if (current_iteration_time - auth_start_time) > ( return_interval * return_attempts ): self.send_return() return_attempts += 1 authenticate_buf += buf.lower() if re.search( pattern=username_pattern, string=authenticate_buf, ): # clear the authentication buffer so we don't re-read the username prompt authenticate_buf = b\"\" username_count += 1 if username_count > 2: msg = \"username/login prompt seen more than once, assuming auth failed\" self.logger.critical(msg) raise ScrapliAuthenticationFailed(msg) self.write(channel_input=auth_username) self.send_return() if re.search( pattern=password_pattern, string=authenticate_buf, ): # clear the authentication buffer so we don't re-read the password prompt authenticate_buf = b\"\" password_count += 1 if password_count > 2: msg = \"password prompt seen more than once, assuming auth failed\" self.logger.critical(msg) raise ScrapliAuthenticationFailed(msg) self.write(channel_input=auth_password, redacted=True) self.send_return() if re.search( pattern=prompt_pattern, string=authenticate_buf, ): return @timeout_wrapper def get_prompt(self) -> str: \"\"\" Get current channel prompt Args: N/A Returns: str: string of the current prompt Raises: N/A \"\"\" buf = b\"\" search_pattern = self._get_prompt_pattern( class_pattern=self._base_channel_args.comms_prompt_pattern ) with self._channel_lock(): self.send_return() while True: buf += self.read() channel_match = re.search( pattern=search_pattern, string=buf, ) if channel_match: current_prompt = channel_match.group(0) return current_prompt.decode().strip() @timeout_wrapper def send_input( self, channel_input: str, *, strip_prompt: bool = True, eager: bool = False, ) -> Tuple[bytes, bytes]: \"\"\" Primary entry point to send data to devices in shell mode; accept input and returns result Args: channel_input: string input to send to channel strip_prompt: strip prompt or not, defaults to True (yes, strip the prompt) eager: eager mode reads and returns the `_read_until_input` value, but does not attempt to read to the prompt pattern -- this should not be used manually! (only used by `send_configs` with the eager flag set) Returns: Tuple[bytes, bytes]: tuple of \"raw\" output and \"processed\" (cleaned up/stripped) output Raises: N/A \"\"\" self._pre_send_input(channel_input=channel_input) buf = b\"\" bytes_channel_input = channel_input.encode() self.logger.info( f\"sending channel input: {channel_input}; strip_prompt: {strip_prompt}; eager: {eager}\" ) with self._channel_lock(): self.write(channel_input=channel_input) _buf_until_input = self._read_until_input(channel_input=bytes_channel_input) self.send_return() if not eager: buf += self._read_until_prompt() processed_buf = self._process_output( buf=buf, strip_prompt=strip_prompt, ) return buf, processed_buf @timeout_wrapper def send_input_and_read( self, channel_input: str, *, strip_prompt: bool = True, expected_outputs: Optional[List[str]] = None, read_duration: Optional[float] = None, ) -> Tuple[bytes, bytes]: \"\"\" Send a command and read until expected prompt is seen, outputs are seen, or for duration Args: channel_input: string input to send to channel strip_prompt: strip prompt or not, defaults to True (yes, strip the prompt) expected_outputs: list of strings to look for in output; if any of these are seen, return output read up till that read read_duration: float duration to read for Returns: Tuple[bytes, bytes]: tuple of \"raw\" output and \"processed\" (cleaned up/stripped) output Raises: N/A \"\"\" self._pre_send_input(channel_input=channel_input) buf = b\"\" bytes_channel_input = channel_input.encode() bytes_channel_outputs = [ channel_output.encode() for channel_output in expected_outputs or [] ] self.logger.info( f\"sending channel input and read: {channel_input}; strip_prompt: {strip_prompt}; \" f\"expected_outputs: {expected_outputs}; read_duration: {read_duration}\" ) with self._channel_lock(): self.write(channel_input=channel_input) _buf_until_input = self._read_until_input(channel_input=bytes_channel_input) self.send_return() buf += self._read_until_prompt_or_time( channel_outputs=bytes_channel_outputs, read_duration=read_duration ) processed_buf = self._process_output( buf=buf, strip_prompt=strip_prompt, ) return buf, processed_buf @timeout_wrapper def send_inputs_interact( self, interact_events: List[Tuple[str, str, Optional[bool]]], *, interaction_complete_patterns: Optional[List[str]] = None, ) -> Tuple[bytes, bytes]: \"\"\" Interact with a device with changing prompts per input. Used to interact with devices where prompts change per input, and where inputs may be hidden such as in the case of a password input. This can be used to respond to challenges from devices such as the confirmation for the command \"clear logging\" on IOSXE devices for example. You may have as many elements in the \"interact_events\" list as needed, and each element of that list should be a tuple of two or three elements. The first element is always the input to send as a string, the second should be the expected response as a string, and the optional third a bool for whether or not the input is \"hidden\" (i.e. password input) An example where we need this sort of capability: ''' 3560CX#copy flash: scp: Source filename []? test1.txt Address or name of remote host []? 172.31.254.100 Destination username [carl]? Writing test1.txt Password: Password: Sink: C0644 639 test1.txt ! 639 bytes copied in 12.066 secs (53 bytes/sec) 3560CX# ''' To accomplish this we can use the following: ''' interact = conn.channel.send_inputs_interact( [ (\"copy flash: scp:\", \"Source filename []?\", False), (\"test1.txt\", \"Address or name of remote host []?\", False), (\"172.31.254.100\", \"Destination username [carl]?\", False), (\"carl\", \"Password:\", False), (\"super_secure_password\", prompt, True), ] ) ''' If we needed to deal with more prompts we could simply continue adding tuples to the list of interact \"events\". Args: interact_events: list of tuples containing the \"interactions\" with the device each list element must have an input and an expected response, and may have an optional bool for the third and final element -- the optional bool specifies if the input that is sent to the device is \"hidden\" (ex: password), if the hidden param is not provided it is assumed the input is \"normal\" (not hidden) interaction_complete_patterns: list of patterns, that if seen, indicate the interactive \"session\" has ended and we should exit the interactive session. Returns: Tuple[bytes, bytes]: output read from the channel with no whitespace trimming/cleaning, and the output read from the channel that has been \"cleaned up\" Raises: N/A \"\"\" self._pre_send_inputs_interact(interact_events=interact_events) buf = b\"\" processed_buf = b\"\" with self._channel_lock(): for interact_event in interact_events: channel_input = interact_event[0] bytes_channel_input = channel_input.encode() channel_response = interact_event[1] prompts = [channel_response] if interaction_complete_patterns is not None: prompts.extend(interaction_complete_patterns) try: hidden_input = interact_event[2] except IndexError: hidden_input = False _channel_input = channel_input if not hidden_input else \"REDACTED\" self.logger.info( f\"sending interactive input: {_channel_input}; \" f\"expecting: {channel_response}; \" f\"hidden_input: {hidden_input}\" ) self.write(channel_input=channel_input, redacted=bool(hidden_input)) if channel_response and hidden_input is not True: buf += self._read_until_input(channel_input=bytes_channel_input) self.send_return() buf += self._read_until_explicit_prompt(prompts=prompts) processed_buf += self._process_output( buf=buf, strip_prompt=False, ) return buf, processed_buf","title":"Channel"},{"location":"api_docs/channel/sync_channel/#ancestors-in-mro","text":"scrapli.channel.base_channel.BaseChannel","title":"Ancestors (in MRO)"},{"location":"api_docs/channel/sync_channel/#methods","text":"","title":"Methods"},{"location":"api_docs/channel/sync_channel/#channel_authenticate_ssh","text":"channel_authenticate_ssh(self, auth_password: str, auth_private_key_passphrase: str) \u2011> None 1 2 3 4 5 6 7 8 9 10 11 12 Handle SSH Authentication for transports that only operate \"in the channel\" (i.e. system) Args: auth_password: password to authenticate with auth_private_key_passphrase: passphrase for ssh key if necessary Returns: None Raises: ScrapliAuthenticationFailed: if password prompt seen more than twice ScrapliAuthenticationFailed: if passphrase prompt seen more than twice","title":"channel_authenticate_ssh"},{"location":"api_docs/channel/sync_channel/#channel_authenticate_telnet","text":"channel_authenticate_telnet(self, auth_username: str = '', auth_password: str = '') \u2011> None 1 2 3 4 5 6 7 8 9 10 11 12 Handle Telnet Authentication Args: auth_username: username to use for telnet authentication auth_password: password to use for telnet authentication Returns: None Raises: ScrapliAuthenticationFailed: if password prompt seen more than twice ScrapliAuthenticationFailed: if login prompt seen more than twice","title":"channel_authenticate_telnet"},{"location":"api_docs/channel/sync_channel/#get_prompt","text":"get_prompt(self) \u2011> str 1 2 3 4 5 6 7 8 9 10 Get current channel prompt Args: N/A Returns: str: string of the current prompt Raises: N/A","title":"get_prompt"},{"location":"api_docs/channel/sync_channel/#read","text":"read(self) \u2011> bytes 1 2 3 4 5 6 7 8 9 10 11 12 13 Read chunks of output from the channel Replaces any r\" \" characters that sometimes get stuffed into the output from the devices Args: N/A Returns: bytes: output read from channel Raises: N/A","title":"read"},{"location":"api_docs/channel/sync_channel/#send_input","text":"send_input(self, channel_input: str, *, strip_prompt: bool = True, eager: bool = False) \u2011> Tuple[bytes, bytes] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 Primary entry point to send data to devices in shell mode; accept input and returns result Args: channel_input: string input to send to channel strip_prompt: strip prompt or not, defaults to True (yes, strip the prompt) eager: eager mode reads and returns the `_read_until_input` value, but does not attempt to read to the prompt pattern -- this should not be used manually! (only used by `send_configs` with the eager flag set) Returns: Tuple[bytes, bytes]: tuple of \"raw\" output and \"processed\" (cleaned up/stripped) output Raises: N/A","title":"send_input"},{"location":"api_docs/channel/sync_channel/#send_input_and_read","text":"send_input_and_read(self, channel_input: str, *, strip_prompt: bool = True, expected_outputs: Optional[List[str]] = None, read_duration: Optional[float] = None) \u2011> Tuple[bytes, bytes] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 Send a command and read until expected prompt is seen, outputs are seen, or for duration Args: channel_input: string input to send to channel strip_prompt: strip prompt or not, defaults to True (yes, strip the prompt) expected_outputs: list of strings to look for in output; if any of these are seen, return output read up till that read read_duration: float duration to read for Returns: Tuple[bytes, bytes]: tuple of \"raw\" output and \"processed\" (cleaned up/stripped) output Raises: N/A","title":"send_input_and_read"},{"location":"api_docs/channel/sync_channel/#send_inputs_interact","text":"send_inputs_interact(self, interact_events: List[Tuple[str, str, Optional[bool]]], *, interaction_complete_patterns: Optional[List[str]] = None) \u2011> Tuple[bytes, bytes] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 Interact with a device with changing prompts per input. Used to interact with devices where prompts change per input, and where inputs may be hidden such as in the case of a password input. This can be used to respond to challenges from devices such as the confirmation for the command \"clear logging\" on IOSXE devices for example. You may have as many elements in the \"interact_events\" list as needed, and each element of that list should be a tuple of two or three elements. The first element is always the input to send as a string, the second should be the expected response as a string, and the optional third a bool for whether or not the input is \"hidden\" (i.e. password input) An example where we need this sort of capability: ''' 3560CX#copy flash: scp: Source filename []? test1.txt Address or name of remote host []? 172.31.254.100 Destination username [carl]? Writing test1.txt Password: Password: Sink: C0644 639 test1.txt ! 639 bytes copied in 12.066 secs (53 bytes/sec) 3560CX# ''' To accomplish this we can use the following: ''' interact = conn.channel.send_inputs_interact( [ (\"copy flash: scp:\", \"Source filename []?\", False), (\"test1.txt\", \"Address or name of remote host []?\", False), (\"172.31.254.100\", \"Destination username [carl]?\", False), (\"carl\", \"Password:\", False), (\"super_secure_password\", prompt, True), ] ) ''' If we needed to deal with more prompts we could simply continue adding tuples to the list of interact \"events\". Args: interact_events: list of tuples containing the \"interactions\" with the device each list element must have an input and an expected response, and may have an optional bool for the third and final element -- the optional bool specifies if the input that is sent to the device is \"hidden\" (ex: password), if the hidden param is not provided it is assumed the input is \"normal\" (not hidden) interaction_complete_patterns: list of patterns, that if seen, indicate the interactive \"session\" has ended and we should exit the interactive session. Returns: Tuple[bytes, bytes]: output read from the channel with no whitespace trimming/cleaning, and the output read from the channel that has been \"cleaned up\" Raises: N/A","title":"send_inputs_interact"},{"location":"api_docs/driver/base_driver/","text":"BaseDriver Object \u00b6 BaseDriver is the root for all Scrapli driver classes. The synchronous and asyncio driver base driver classes can be used to provide a semi-pexpect like experience over top of whatever transport a user prefers. Generally, however, the base driver classes should not be used directly. It is best to use the GenericDriver (or AsyncGenericDriver) or NetworkDriver (or AsyncNetworkDriver) sub-classes of the base drivers. Args \u00b6 host : host ip/name to connect to port : port to connect to auth_username : username for authentication auth_private_key : path to private key for authentication auth_private_key_passphrase : passphrase for decrypting ssh key if necessary auth_password : password for authentication auth_strict_key : strict host checking or not auth_bypass : bypass \"in channel\" authentication -- only supported with telnet, asynctelnet, and system transport plugins timeout_socket : timeout for establishing socket/initial connection in seconds timeout_transport : timeout for ssh|telnet transport in seconds timeout_ops : timeout for ssh channel operations comms_prompt_pattern : raw string regex pattern -- preferably use ^ and $ anchors! this is the single most important attribute here! if this does not match a prompt, scrapli will not work! IMPORTANT : regex search uses multi-line + case-insensitive flags. multi-line allows for highly reliably matching for prompts however we do NOT strip trailing whitespace for each line, so be sure to add '\\s?' or similar if your device needs that. This should be mostly sorted for you if using network drivers (i.e. IOSXEDriver ). comms_return_char : character to used to send returns to host ssh_config_file : string to path for ssh config file, True to use default ssh config file or False to ignore default ssh config file ssh_known_hosts_file : string to path for ssh known hosts file, True to use default known file locations. Only applicable/needed if auth_strict_key is set to True on_init : callable that accepts the class instance as its only argument. this callable, if provided, is executed as the last step of object instantiation -- its purpose is primarily to provide a mechanism for scrapli community platforms to have an easy way to modify initialization arguments/object attributes without needing to create a class that extends the driver, instead allowing the community platforms to simply build from the GenericDriver or NetworkDriver classes, and pass this callable to do things such as appending to a username (looking at you RouterOS!!). Note that this is always a synchronous function (even for asyncio drivers)! on_open : callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close : callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar transport : name of the transport plugin to use for the actual telnet/ssh/netconf connection. Available \"core\" transports are: system telnet asynctelnet ssh2 paramiko asyncssh Please see relevant transport plugin section for details. Additionally, third party transport plugins may be available. transport_options : dictionary of options to pass to selected transport class; see docs for given transport class for details of what to pass here channel_lock : True/False to lock the channel (threading.Lock/asyncio.Lock) during any channel operations, defaults to False channel_log : True/False, a string path to a file of where to write out channel logs, or a BytesIO object to write to -- these are not \"logs\" in the normal logging module sense, but only the output that is read from the channel. In other words, the output of the channel log should look similar to what you would see as a human connecting to a device channel_log_mode : \"write\"|\"append\", all other values will raise ValueError, does what it sounds like it should by setting the channel log to the provided mode logging_uid : unique identifier (string) to associate to log messages; useful if you have multiple connections to the same device (i.e. one console, one ssh, or one to each supervisor module, etc.) Returns \u00b6 None Raises \u00b6 N/A","title":"Base Driver Arguments"},{"location":"api_docs/driver/base_driver/#basedriver-object","text":"BaseDriver is the root for all Scrapli driver classes. The synchronous and asyncio driver base driver classes can be used to provide a semi-pexpect like experience over top of whatever transport a user prefers. Generally, however, the base driver classes should not be used directly. It is best to use the GenericDriver (or AsyncGenericDriver) or NetworkDriver (or AsyncNetworkDriver) sub-classes of the base drivers.","title":"BaseDriver Object"},{"location":"api_docs/driver/base_driver/#args","text":"host : host ip/name to connect to port : port to connect to auth_username : username for authentication auth_private_key : path to private key for authentication auth_private_key_passphrase : passphrase for decrypting ssh key if necessary auth_password : password for authentication auth_strict_key : strict host checking or not auth_bypass : bypass \"in channel\" authentication -- only supported with telnet, asynctelnet, and system transport plugins timeout_socket : timeout for establishing socket/initial connection in seconds timeout_transport : timeout for ssh|telnet transport in seconds timeout_ops : timeout for ssh channel operations comms_prompt_pattern : raw string regex pattern -- preferably use ^ and $ anchors! this is the single most important attribute here! if this does not match a prompt, scrapli will not work! IMPORTANT : regex search uses multi-line + case-insensitive flags. multi-line allows for highly reliably matching for prompts however we do NOT strip trailing whitespace for each line, so be sure to add '\\s?' or similar if your device needs that. This should be mostly sorted for you if using network drivers (i.e. IOSXEDriver ). comms_return_char : character to used to send returns to host ssh_config_file : string to path for ssh config file, True to use default ssh config file or False to ignore default ssh config file ssh_known_hosts_file : string to path for ssh known hosts file, True to use default known file locations. Only applicable/needed if auth_strict_key is set to True on_init : callable that accepts the class instance as its only argument. this callable, if provided, is executed as the last step of object instantiation -- its purpose is primarily to provide a mechanism for scrapli community platforms to have an easy way to modify initialization arguments/object attributes without needing to create a class that extends the driver, instead allowing the community platforms to simply build from the GenericDriver or NetworkDriver classes, and pass this callable to do things such as appending to a username (looking at you RouterOS!!). Note that this is always a synchronous function (even for asyncio drivers)! on_open : callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close : callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar transport : name of the transport plugin to use for the actual telnet/ssh/netconf connection. Available \"core\" transports are: system telnet asynctelnet ssh2 paramiko asyncssh Please see relevant transport plugin section for details. Additionally, third party transport plugins may be available. transport_options : dictionary of options to pass to selected transport class; see docs for given transport class for details of what to pass here channel_lock : True/False to lock the channel (threading.Lock/asyncio.Lock) during any channel operations, defaults to False channel_log : True/False, a string path to a file of where to write out channel logs, or a BytesIO object to write to -- these are not \"logs\" in the normal logging module sense, but only the output that is read from the channel. In other words, the output of the channel log should look similar to what you would see as a human connecting to a device channel_log_mode : \"write\"|\"append\", all other values will raise ValueError, does what it sounds like it should by setting the channel log to the provided mode logging_uid : unique identifier (string) to associate to log messages; useful if you have multiple connections to the same device (i.e. one console, one ssh, or one to each supervisor module, etc.)","title":"Args"},{"location":"api_docs/driver/base_driver/#returns","text":"None","title":"Returns"},{"location":"api_docs/driver/base_driver/#raises","text":"N/A","title":"Raises"},{"location":"api_docs/driver/generic_driver/","text":"GenericDriver Object \u00b6 The GenericDriver objects (sync and async versions) extend the BaseDriver class. The GenericDriver objects provide a \"friendly\" telnet/ssh interface with methods available to get_prompt , send_input , and write and read from the underlying connection. The GenericDriver objects have no concept of \"commands\" or \"configurations\", or of \"privilege levels\" -- things that are common place in most network operating systems. As such, the GenericDriver is generally not the \"right\" fit to use when interacting with network devices, and is instead more suited to working with linux-like devices without the concept of privilege levels or config modes. The GenericDriver objects accept all the same arguments that the BaseDriver accepts and nothing else. Args \u00b6 All BaseDriver arguments Returns \u00b6 None Raises \u00b6 N/A","title":"Generic Driver Arguments"},{"location":"api_docs/driver/generic_driver/#genericdriver-object","text":"The GenericDriver objects (sync and async versions) extend the BaseDriver class. The GenericDriver objects provide a \"friendly\" telnet/ssh interface with methods available to get_prompt , send_input , and write and read from the underlying connection. The GenericDriver objects have no concept of \"commands\" or \"configurations\", or of \"privilege levels\" -- things that are common place in most network operating systems. As such, the GenericDriver is generally not the \"right\" fit to use when interacting with network devices, and is instead more suited to working with linux-like devices without the concept of privilege levels or config modes. The GenericDriver objects accept all the same arguments that the BaseDriver accepts and nothing else.","title":"GenericDriver Object"},{"location":"api_docs/driver/generic_driver/#args","text":"All BaseDriver arguments","title":"Args"},{"location":"api_docs/driver/generic_driver/#returns","text":"None","title":"Returns"},{"location":"api_docs/driver/generic_driver/#raises","text":"N/A","title":"Raises"},{"location":"api_docs/driver/network_driver/","text":"NetworkDriver Object \u00b6 The NetworkDriver further extends the GenericDriver objects and adds \"network device\" specific logic. Chiefly, the NetworkDrivers have the concept of \"privilege levels\" -- levels such as \"exec\", \"privilege-exec\", and \"configuration\" in Cisco parlance. Args \u00b6 All BaseDriver/GenericDriver arguments plus... privilege_levels : Dict of privilege levels for a given platform default_desired_privilege_level : string of name of default desired priv, this is the priv level that is generally used to disable paging/set terminal width and things like that upon first login, and is also the priv level scrapli will try to acquire for normal \"command\" operations ( send_command , send_commands ) auth_secondary : password to use for secondary authentication (enable) failed_when_contains : list of strings that indicate a command/configuration has failed textfsm_platform : string name of platform to use for textfsm parsing genie_platform : string name of platform to use for genie parsing Returns \u00b6 None Raises \u00b6 N/A","title":"Network Driver Arguments"},{"location":"api_docs/driver/network_driver/#networkdriver-object","text":"The NetworkDriver further extends the GenericDriver objects and adds \"network device\" specific logic. Chiefly, the NetworkDrivers have the concept of \"privilege levels\" -- levels such as \"exec\", \"privilege-exec\", and \"configuration\" in Cisco parlance.","title":"NetworkDriver Object"},{"location":"api_docs/driver/network_driver/#args","text":"All BaseDriver/GenericDriver arguments plus... privilege_levels : Dict of privilege levels for a given platform default_desired_privilege_level : string of name of default desired priv, this is the priv level that is generally used to disable paging/set terminal width and things like that upon first login, and is also the priv level scrapli will try to acquire for normal \"command\" operations ( send_command , send_commands ) auth_secondary : password to use for secondary authentication (enable) failed_when_contains : list of strings that indicate a command/configuration has failed textfsm_platform : string name of platform to use for textfsm parsing genie_platform : string name of platform to use for genie parsing","title":"Args"},{"location":"api_docs/driver/network_driver/#returns","text":"None","title":"Returns"},{"location":"api_docs/driver/network_driver/#raises","text":"N/A","title":"Raises"},{"location":"api_docs/driver/base/async_driver/","text":"window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting()) Module scrapli.driver.base.async_driver \u00b6 scrapli.driver.base.async_driver Expand source code \"\"\"scrapli.driver.base.async_driver\"\"\" from types import TracebackType from typing import Any, Optional, Type, TypeVar from scrapli.channel import AsyncChannel from scrapli.driver.base.base_driver import BaseDriver from scrapli.exceptions import ScrapliValueError from scrapli.transport import ASYNCIO_TRANSPORTS _T = TypeVar(\"_T\", bound=\"AsyncDriver\") class AsyncDriver(BaseDriver): def __init__(self, **kwargs: Any): super().__init__(**kwargs) if self.transport_name not in ASYNCIO_TRANSPORTS: raise ScrapliValueError( \"provided transport is *not* an asyncio transport, must use an async transport with\" \" the AsyncDriver(s)\" ) self.channel = AsyncChannel( transport=self.transport, base_channel_args=self._base_channel_args, ) async def __aenter__(self: _T) -> _T: \"\"\" Enter method for context manager Args: N/A Returns: _T: a concrete implementation of the opened AsyncDriver object Raises: N/A \"\"\" await self.open() return self async def __aexit__( self, exception_type: Optional[Type[BaseException]], exception_value: Optional[BaseException], traceback: Optional[TracebackType], ) -> None: \"\"\" Exit method to cleanup for context manager Args: exception_type: exception type being raised exception_value: message from exception being raised traceback: traceback from exception being raised Returns: None Raises: N/A \"\"\" await self.close() async def open(self) -> None: \"\"\" Open the scrapli connection Args: N/A Returns: None Raises: N/A \"\"\" self._pre_open_closing_log(closing=False) await self.transport.open() self.channel.open() if ( self.transport_name in ( \"telnet\", \"asynctelnet\", ) and not self.auth_bypass ): await self.channel.channel_authenticate_telnet( auth_username=self.auth_username, auth_password=self.auth_password ) if self.on_open: await self.on_open(self) self._post_open_closing_log(closing=False) async def close(self) -> None: \"\"\" Close the scrapli connection Args: N/A Returns: None Raises: N/A \"\"\" self._post_open_closing_log(closing=True) if self.on_close: await self.on_close(self) self.transport.close() self.channel.close() self._post_open_closing_log(closing=True) async def commandeer(self, conn: \"AsyncDriver\", execute_on_open: bool = True) -> None: \"\"\" Commandeer an existing connection See docstring in sync version for more details: `scrapli.driver.base.sync_driver.commandeer` Args: conn: connection to commandeer execute_on_open: execute the `on_open` function of the current object once the existing connection has been commandeered Returns: None Raises: N/A \"\"\" original_logger = conn.logger original_transport = conn.transport original_transport_logger = conn.transport.logger original_channel_logger = conn.channel.logger original_channel_channel_log = conn.channel.channel_log self.logger = original_logger self.channel.logger = original_channel_logger self.channel.transport = original_transport self.transport = original_transport self.transport.logger = original_transport_logger if original_channel_channel_log is not None: # if the original connection had a channel log we also commandeer that; note that when # the new connection is closed this will also close the channel log; see docstring. self.channel.channel_log = original_channel_channel_log if execute_on_open and self.on_open is not None: await self.on_open(self) @staticmethod def ___getwide___() -> None: # pragma: no cover \"\"\" Dumb inside joke easter egg :) Args: N/A Returns: None Raises: N/A \"\"\" wide = r\"\"\" KKKXXXXXXXXXXNNNNNNNNNNNNNNNWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWW 000000000000KKKKKKKKKKXXXXXXXXXXXXXXXXXNNXXK0Okxdoolllloodxk0KXNNWWNWWWWWWWWWWWWWWWWWWWWWWWWWWWWNNNN kkkkkkkOOOOOOOOOOO00000000000000000000kdl:,... ..';coxOKKKKKKKKKKKKXKKXXKKKXXXXXKKKK000 kkkkkkkOOOOOOOOOOOO000000000000000Od:,. .,cdOKKKKKKKKKKKK0000OOOOOOOOOOOO kkkkkkkkOOOOOOOOOOO0000000000000kc' .:d0KKKKKKKKK0KKOkOOOOOOOOOO0 kkkkkkkkOOOOOOOOOOOO00000000000o' ,o0KKKKKKKKKKOkOOOOOOOOO00 kkkkkkkkOOOOOOOOOOOOO000000000o. ;kKKKKKKKKKOkOOOOOOOOO00 OOOOOOOOOO0000000000000000K0Kk' 'xKKKKKKKKOkOOOOOOOOO00 KKKKKKKKKXXXXXXXXXXXXXXNNNNNNd. cXNNNNNNNK0000O00O0000 KKKKKKKKKXXXXXXXXXXXXNNNNNNNXl ............... :XWWWWWWWX000000000000 KKKKKKKKKXXXXXXXXXXXXXXNNNNNXc ...''',,,,,,;;,,,,,,'''...... .xWWWWWWWWX000000000000 KKKKKKKKKKKXXXXXXXXXXXXXNNNNK; ...',,,,;;;;;;;:::::::;;;;;;,,'. .oNWWWWWWWNK000000OOOO00 KKKKKKKKKKKKXXXXXXXXXXXXXXXN0, ...'',,,;;;;;;:::::::::::::::;;;;,'. .dNWWWWWWWWNK0000OOOOOOOO 0000KKKKKKKKKKKKKXXXXXXXXXXN0, ..'',,,,;;;;;;:::::::::::::::::;;;;,,.. ;ONNNNNWWWWWNK00OOOOOOOOOO kkkkkkOOOOOOOOOOOOOOOOOOO000k; ..,,,,,,'',,;;::::::::::::::::;;;;;;,'. .lOKKKKXXKXXKK0OOOOOOOOOOOOO xxxkkkkkkkkkkkkkkkkkkOOOOkdll;..',,,,,,,''...';::ccccc:::::::::;;;;;,...o0000000000000OkkOOOkkOOOOOO xxxxxxkkkkkkkkkkkkkkkkkkOd:;;,..,;;;;;;;;;;,'',,;:ccccccccc:::;;;;;;,..cO0000000000000Oxkkkkkkkkkkkk xxxxxxxxkkkkkkkkkkkkkkkkkl:;;,'';;;;;,'''''',,,,,;::ccc::;,,'.'''',;,,lO00000000000000kxkkkkkkkkkkkk xxxxxxxxkkkkkkkkkkkkkkkkko::;'';;;;;;,''....,'',,,,;:c:;,,'''',,;;;;,:x00000000000000Okxkkkkkkkkkkkk xxxxxxxxxxkkkkkkkkkkkkkkkxl;,,;;;;:::;;;,,,,,,,,,,,,:c:;,'....''',;;,;cxO000000000000Okxkkkkkkkkkkkk kkkkOOOOOOOOOOOOOO00000000x:;;;;;:::c::::::;;;;;;;;;:c:;,,,,'',,',;:::lOKKKKKKXXXXXXKKOkkkkkkkkkkkkk 000000000000000KKKKKKKKKKK0dc;,;;:::ccccccc::::;;;;;:cc:;;;;:::::::::lOXXXXXNNNNNNNNXX0Okkkkkkkkkkkk OO00000000000000000KKKKKKKK0d::;;;::ccccccccc:;;;;;;;:c:;::ccccccc::cOXXXXXXXXXNNNNNXX0kkkkkkkkkkkkk OOO00000000000000000000KKKKKOxxc;;;::ccccccc:;;;;;;;:ccc:::cccllcc;:kKXXXXXXXXXXXXXXXKOkkkkkkkkkkkkk OOOOO00000000000000000000KKK0kdl;;;;;:ccccc::;,,,,;;:clc:::cclllcc:oKXXXXXXXXXXXXXXXXKOkkkkkkkkkkkkk OOOOOOO0000000000000000Okxdlc;,,;;::;;::cc::;;,,,,,;:::;;:cccccc::clxkO00KKKKKKKKKXKK0kkkkkkkkkkkxkk kkkkkkkkkkkkkkkkkkkxdoc:,''.....,;:::;;;::;;;;;;;;;;;;;;;:ccc:::;,',;;:clodxkOOOOOOOOkxxxxxxxxxxxxxx ddddddddddddddoolc;,'''..........,;;:;;;::;,,,,,;;;;;::::::c:::;'.',,;;;;;::clodxkkkkxdxxxxxxxxxxxxx dddddddoolc::;,'''....... ..',;;;;;;;;,'........',;::::::;;,,;;;;;;;;:::::ccloddddxxxxxxxxxxxxx dollc:;,,''......... ..'''',,,,;;;;;,'''.....'',::::;,,;;;::::;;,,;;;;;;;;;::cldxxxxxxdxxdxx l;'''.''...... ..'',,''',,,,;;;::;;,,,,,,;;::;;'.....',;;,,''',,,,,,'',,,',:odxddddddddd ............. .'',,,,,''',,,;;;;::::;::::::;;;........'''''''..'.....,,'...';cdddddddddd . ....... .',,,,,;,,'',,,,;;;::::::::::;;cc. .....''...'''.......','......':odxdddddd ... .',,;;;;;;,'',;;,,,;;;::::::::;cxo....................''''.......'';lddddddd .. .,;,;;;;;;,,,',;;;,,,,;;;;;;;;:dKO:..................''''.. .......',cdddddd ,:;;;;;,,,,;,,;::;,,,,,;::::::dK0c..................'''.. ........',codddd .;:;;;;;,,;;;,,;:;;:;,,;:::::clc,... ...........'''.... .... .....':oddd .',;;;;;;;;;,,;:;;;;,;::::::;'...... ......'......... .....'',cood ..,;;;;;;;;;;;:;;;;:::::;'. . .............. ...''',:od ..',;;;;:;;;:::::::,,'. ............... ....''.':o ...',,;;,,;,,'.. ............... .. .....'c __ _ __.... ................ .... ......' ____ ____ / /_ _ __(_)___/ /__ .............. .. ... ....... / __ `/ _ \\/ __/ | | /| / / / __ / _ \\ ................ . ...... / /_/ / __/ /_ | |/ |/ / / /_/ / __/ ................. ...... \\__, /\\___/\\__/ |__/|__/_/\\__,_/\\___/ ............... ...... /____/ ............... .. ........ \"\"\" print(wide) Classes \u00b6 AsyncDriver \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 BaseDriver Object BaseDriver is the root for all Scrapli driver classes. The synchronous and asyncio driver base driver classes can be used to provide a semi-pexpect like experience over top of whatever transport a user prefers. Generally, however, the base driver classes should not be used directly. It is best to use the GenericDriver (or AsyncGenericDriver) or NetworkDriver (or AsyncNetworkDriver) sub-classes of the base drivers. Args: host: host ip/name to connect to port: port to connect to auth_username: username for authentication auth_private_key: path to private key for authentication auth_private_key_passphrase: passphrase for decrypting ssh key if necessary auth_password: password for authentication auth_strict_key: strict host checking or not auth_bypass: bypass \"in channel\" authentication -- only supported with telnet, asynctelnet, and system transport plugins timeout_socket: timeout for establishing socket/initial connection in seconds timeout_transport: timeout for ssh|telnet transport in seconds timeout_ops: timeout for ssh channel operations comms_prompt_pattern: raw string regex pattern -- preferably use `^` and `$` anchors! this is the single most important attribute here! if this does not match a prompt, scrapli will not work! IMPORTANT: regex search uses multi-line + case insensitive flags. multi-line allows for highly reliably matching for prompts however we do NOT strip trailing whitespace for each line, so be sure to add '\\\\s?' or similar if your device needs that. This should be mostly sorted for you if using network drivers (i.e. `IOSXEDriver`). Lastly, the case insensitive is just a convenience factor so i can be lazy. comms_return_char: character to use to send returns to host ssh_config_file: string to path for ssh config file, True to use default ssh config file or False to ignore default ssh config file ssh_known_hosts_file: string to path for ssh known hosts file, True to use default known file locations. Only applicable/needed if `auth_strict_key` is set to True on_init: callable that accepts the class instance as its only argument. this callable, if provided, is executed as the last step of object instantiation -- its purpose is primarily to provide a mechanism for scrapli community platforms to have an easy way to modify initialization arguments/object attributes without needing to create a class that extends the driver, instead allowing the community platforms to simply build from the GenericDriver or NetworkDriver classes, and pass this callable to do things such as appending to a username (looking at you RouterOS!!). Note that this is *always* a synchronous function (even for asyncio drivers)! on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar transport: name of the transport plugin to use for the actual telnet/ssh/netconf connection. Available \"core\" transports are: - system - telnet - asynctelnet - ssh2 - paramiko - asyncssh Please see relevant transport plugin section for details. Additionally third party transport plugins may be available. transport_options: dictionary of options to pass to selected transport class; see docs for given transport class for details of what to pass here channel_lock: True/False to lock the channel (threading.Lock/asyncio.Lock) during any channel operations, defaults to False channel_log: True/False or a string path to a file of where to write out channel logs -- these are not \"logs\" in the normal logging module sense, but only the output that is read from the channel. In other words, the output of the channel log should look similar to what you would see as a human connecting to a device channel_log_mode: \"write\"|\"append\", all other values will raise ValueError, does what it sounds like it should by setting the channel log to the provided mode logging_uid: unique identifier (string) to associate to log messages; useful if you have multiple connections to the same device (i.e. one console, one ssh, or one to each supervisor module, etc.) Returns: None Raises: N/A Expand source code class AsyncDriver(BaseDriver): def __init__(self, **kwargs: Any): super().__init__(**kwargs) if self.transport_name not in ASYNCIO_TRANSPORTS: raise ScrapliValueError( \"provided transport is *not* an asyncio transport, must use an async transport with\" \" the AsyncDriver(s)\" ) self.channel = AsyncChannel( transport=self.transport, base_channel_args=self._base_channel_args, ) async def __aenter__(self: _T) -> _T: \"\"\" Enter method for context manager Args: N/A Returns: _T: a concrete implementation of the opened AsyncDriver object Raises: N/A \"\"\" await self.open() return self async def __aexit__( self, exception_type: Optional[Type[BaseException]], exception_value: Optional[BaseException], traceback: Optional[TracebackType], ) -> None: \"\"\" Exit method to cleanup for context manager Args: exception_type: exception type being raised exception_value: message from exception being raised traceback: traceback from exception being raised Returns: None Raises: N/A \"\"\" await self.close() async def open(self) -> None: \"\"\" Open the scrapli connection Args: N/A Returns: None Raises: N/A \"\"\" self._pre_open_closing_log(closing=False) await self.transport.open() self.channel.open() if ( self.transport_name in ( \"telnet\", \"asynctelnet\", ) and not self.auth_bypass ): await self.channel.channel_authenticate_telnet( auth_username=self.auth_username, auth_password=self.auth_password ) if self.on_open: await self.on_open(self) self._post_open_closing_log(closing=False) async def close(self) -> None: \"\"\" Close the scrapli connection Args: N/A Returns: None Raises: N/A \"\"\" self._post_open_closing_log(closing=True) if self.on_close: await self.on_close(self) self.transport.close() self.channel.close() self._post_open_closing_log(closing=True) async def commandeer(self, conn: \"AsyncDriver\", execute_on_open: bool = True) -> None: \"\"\" Commandeer an existing connection See docstring in sync version for more details: `scrapli.driver.base.sync_driver.commandeer` Args: conn: connection to commandeer execute_on_open: execute the `on_open` function of the current object once the existing connection has been commandeered Returns: None Raises: N/A \"\"\" original_logger = conn.logger original_transport = conn.transport original_transport_logger = conn.transport.logger original_channel_logger = conn.channel.logger original_channel_channel_log = conn.channel.channel_log self.logger = original_logger self.channel.logger = original_channel_logger self.channel.transport = original_transport self.transport = original_transport self.transport.logger = original_transport_logger if original_channel_channel_log is not None: # if the original connection had a channel log we also commandeer that; note that when # the new connection is closed this will also close the channel log; see docstring. self.channel.channel_log = original_channel_channel_log if execute_on_open and self.on_open is not None: await self.on_open(self) @staticmethod def ___getwide___() -> None: # pragma: no cover \"\"\" Dumb inside joke easter egg :) Args: N/A Returns: None Raises: N/A \"\"\" wide = r\"\"\" KKKXXXXXXXXXXNNNNNNNNNNNNNNNWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWW 000000000000KKKKKKKKKKXXXXXXXXXXXXXXXXXNNXXK0Okxdoolllloodxk0KXNNWWNWWWWWWWWWWWWWWWWWWWWWWWWWWWWNNNN kkkkkkkOOOOOOOOOOO00000000000000000000kdl:,... ..';coxOKKKKKKKKKKKKXKKXXKKKXXXXXKKKK000 kkkkkkkOOOOOOOOOOOO000000000000000Od:,. .,cdOKKKKKKKKKKKK0000OOOOOOOOOOOO kkkkkkkkOOOOOOOOOOO0000000000000kc' .:d0KKKKKKKKK0KKOkOOOOOOOOOO0 kkkkkkkkOOOOOOOOOOOO00000000000o' ,o0KKKKKKKKKKOkOOOOOOOOO00 kkkkkkkkOOOOOOOOOOOOO000000000o. ;kKKKKKKKKKOkOOOOOOOOO00 OOOOOOOOOO0000000000000000K0Kk' 'xKKKKKKKKOkOOOOOOOOO00 KKKKKKKKKXXXXXXXXXXXXXXNNNNNNd. cXNNNNNNNK0000O00O0000 KKKKKKKKKXXXXXXXXXXXXNNNNNNNXl ............... :XWWWWWWWX000000000000 KKKKKKKKKXXXXXXXXXXXXXXNNNNNXc ...''',,,,,,;;,,,,,,'''...... .xWWWWWWWWX000000000000 KKKKKKKKKKKXXXXXXXXXXXXXNNNNK; ...',,,,;;;;;;;:::::::;;;;;;,,'. .oNWWWWWWWNK000000OOOO00 KKKKKKKKKKKKXXXXXXXXXXXXXXXN0, ...'',,,;;;;;;:::::::::::::::;;;;,'. .dNWWWWWWWWNK0000OOOOOOOO 0000KKKKKKKKKKKKKXXXXXXXXXXN0, ..'',,,,;;;;;;:::::::::::::::::;;;;,,.. ;ONNNNNWWWWWNK00OOOOOOOOOO kkkkkkOOOOOOOOOOOOOOOOOOO000k; ..,,,,,,'',,;;::::::::::::::::;;;;;;,'. .lOKKKKXXKXXKK0OOOOOOOOOOOOO xxxkkkkkkkkkkkkkkkkkkOOOOkdll;..',,,,,,,''...';::ccccc:::::::::;;;;;,...o0000000000000OkkOOOkkOOOOOO xxxxxxkkkkkkkkkkkkkkkkkkOd:;;,..,;;;;;;;;;;,'',,;:ccccccccc:::;;;;;;,..cO0000000000000Oxkkkkkkkkkkkk xxxxxxxxkkkkkkkkkkkkkkkkkl:;;,'';;;;;,'''''',,,,,;::ccc::;,,'.'''',;,,lO00000000000000kxkkkkkkkkkkkk xxxxxxxxkkkkkkkkkkkkkkkkko::;'';;;;;;,''....,'',,,,;:c:;,,'''',,;;;;,:x00000000000000Okxkkkkkkkkkkkk xxxxxxxxxxkkkkkkkkkkkkkkkxl;,,;;;;:::;;;,,,,,,,,,,,,:c:;,'....''',;;,;cxO000000000000Okxkkkkkkkkkkkk kkkkOOOOOOOOOOOOOO00000000x:;;;;;:::c::::::;;;;;;;;;:c:;,,,,'',,',;:::lOKKKKKKXXXXXXKKOkkkkkkkkkkkkk 000000000000000KKKKKKKKKKK0dc;,;;:::ccccccc::::;;;;;:cc:;;;;:::::::::lOXXXXXNNNNNNNNXX0Okkkkkkkkkkkk OO00000000000000000KKKKKKKK0d::;;;::ccccccccc:;;;;;;;:c:;::ccccccc::cOXXXXXXXXXNNNNNXX0kkkkkkkkkkkkk OOO00000000000000000000KKKKKOxxc;;;::ccccccc:;;;;;;;:ccc:::cccllcc;:kKXXXXXXXXXXXXXXXKOkkkkkkkkkkkkk OOOOO00000000000000000000KKK0kdl;;;;;:ccccc::;,,,,;;:clc:::cclllcc:oKXXXXXXXXXXXXXXXXKOkkkkkkkkkkkkk OOOOOOO0000000000000000Okxdlc;,,;;::;;::cc::;;,,,,,;:::;;:cccccc::clxkO00KKKKKKKKKXKK0kkkkkkkkkkkxkk kkkkkkkkkkkkkkkkkkkxdoc:,''.....,;:::;;;::;;;;;;;;;;;;;;;:ccc:::;,',;;:clodxkOOOOOOOOkxxxxxxxxxxxxxx ddddddddddddddoolc;,'''..........,;;:;;;::;,,,,,;;;;;::::::c:::;'.',,;;;;;::clodxkkkkxdxxxxxxxxxxxxx dddddddoolc::;,'''....... ..',;;;;;;;;,'........',;::::::;;,,;;;;;;;;:::::ccloddddxxxxxxxxxxxxx dollc:;,,''......... ..'''',,,,;;;;;,'''.....'',::::;,,;;;::::;;,,;;;;;;;;;::cldxxxxxxdxxdxx l;'''.''...... ..'',,''',,,,;;;::;;,,,,,,;;::;;'.....',;;,,''',,,,,,'',,,',:odxddddddddd ............. .'',,,,,''',,,;;;;::::;::::::;;;........'''''''..'.....,,'...';cdddddddddd . ....... .',,,,,;,,'',,,,;;;::::::::::;;cc. .....''...'''.......','......':odxdddddd ... .',,;;;;;;,'',;;,,,;;;::::::::;cxo....................''''.......'';lddddddd .. .,;,;;;;;;,,,',;;;,,,,;;;;;;;;:dKO:..................''''.. .......',cdddddd ,:;;;;;,,,,;,,;::;,,,,,;::::::dK0c..................'''.. ........',codddd .;:;;;;;,,;;;,,;:;;:;,,;:::::clc,... ...........'''.... .... .....':oddd .',;;;;;;;;;,,;:;;;;,;::::::;'...... ......'......... .....'',cood ..,;;;;;;;;;;;:;;;;:::::;'. . .............. ...''',:od ..',;;;;:;;;:::::::,,'. ............... ....''.':o ...',,;;,,;,,'.. ............... .. .....'c __ _ __.... ................ .... ......' ____ ____ / /_ _ __(_)___/ /__ .............. .. ... ....... / __ `/ _ \\/ __/ | | /| / / / __ / _ \\ ................ . ...... / /_/ / __/ /_ | |/ |/ / / /_/ / __/ ................. ...... \\__, /\\___/\\__/ |__/|__/_/\\__,_/\\___/ ............... ...... /____/ ............... .. ........ \"\"\" print(wide) Ancestors (in MRO) \u00b6 scrapli.driver.base.base_driver.BaseDriver Descendants \u00b6 scrapli.driver.generic.async_driver.AsyncGenericDriver Methods \u00b6 close \u00b6 close(self) \u2011> None 1 2 3 4 5 6 7 8 9 10 Close the scrapli connection Args: N/A Returns: None Raises: N/A commandeer \u00b6 commandeer(self, conn: AsyncDriver, execute_on_open: bool = True) \u2011> None 1 2 3 4 5 6 7 8 9 10 11 12 13 14 Commandeer an existing connection See docstring in sync version for more details: `scrapli.driver.base.sync_driver.commandeer` Args: conn: connection to commandeer execute_on_open: execute the `on_open` function of the current object once the existing connection has been commandeered Returns: None Raises: N/A open \u00b6 open(self) \u2011> None 1 2 3 4 5 6 7 8 9 10 Open the scrapli connection Args: N/A Returns: None Raises: N/A","title":"Async Driver"},{"location":"api_docs/driver/base/async_driver/#module-scraplidriverbaseasync_driver","text":"scrapli.driver.base.async_driver Expand source code \"\"\"scrapli.driver.base.async_driver\"\"\" from types import TracebackType from typing import Any, Optional, Type, TypeVar from scrapli.channel import AsyncChannel from scrapli.driver.base.base_driver import BaseDriver from scrapli.exceptions import ScrapliValueError from scrapli.transport import ASYNCIO_TRANSPORTS _T = TypeVar(\"_T\", bound=\"AsyncDriver\") class AsyncDriver(BaseDriver): def __init__(self, **kwargs: Any): super().__init__(**kwargs) if self.transport_name not in ASYNCIO_TRANSPORTS: raise ScrapliValueError( \"provided transport is *not* an asyncio transport, must use an async transport with\" \" the AsyncDriver(s)\" ) self.channel = AsyncChannel( transport=self.transport, base_channel_args=self._base_channel_args, ) async def __aenter__(self: _T) -> _T: \"\"\" Enter method for context manager Args: N/A Returns: _T: a concrete implementation of the opened AsyncDriver object Raises: N/A \"\"\" await self.open() return self async def __aexit__( self, exception_type: Optional[Type[BaseException]], exception_value: Optional[BaseException], traceback: Optional[TracebackType], ) -> None: \"\"\" Exit method to cleanup for context manager Args: exception_type: exception type being raised exception_value: message from exception being raised traceback: traceback from exception being raised Returns: None Raises: N/A \"\"\" await self.close() async def open(self) -> None: \"\"\" Open the scrapli connection Args: N/A Returns: None Raises: N/A \"\"\" self._pre_open_closing_log(closing=False) await self.transport.open() self.channel.open() if ( self.transport_name in ( \"telnet\", \"asynctelnet\", ) and not self.auth_bypass ): await self.channel.channel_authenticate_telnet( auth_username=self.auth_username, auth_password=self.auth_password ) if self.on_open: await self.on_open(self) self._post_open_closing_log(closing=False) async def close(self) -> None: \"\"\" Close the scrapli connection Args: N/A Returns: None Raises: N/A \"\"\" self._post_open_closing_log(closing=True) if self.on_close: await self.on_close(self) self.transport.close() self.channel.close() self._post_open_closing_log(closing=True) async def commandeer(self, conn: \"AsyncDriver\", execute_on_open: bool = True) -> None: \"\"\" Commandeer an existing connection See docstring in sync version for more details: `scrapli.driver.base.sync_driver.commandeer` Args: conn: connection to commandeer execute_on_open: execute the `on_open` function of the current object once the existing connection has been commandeered Returns: None Raises: N/A \"\"\" original_logger = conn.logger original_transport = conn.transport original_transport_logger = conn.transport.logger original_channel_logger = conn.channel.logger original_channel_channel_log = conn.channel.channel_log self.logger = original_logger self.channel.logger = original_channel_logger self.channel.transport = original_transport self.transport = original_transport self.transport.logger = original_transport_logger if original_channel_channel_log is not None: # if the original connection had a channel log we also commandeer that; note that when # the new connection is closed this will also close the channel log; see docstring. self.channel.channel_log = original_channel_channel_log if execute_on_open and self.on_open is not None: await self.on_open(self) @staticmethod def ___getwide___() -> None: # pragma: no cover \"\"\" Dumb inside joke easter egg :) Args: N/A Returns: None Raises: N/A \"\"\" wide = r\"\"\" KKKXXXXXXXXXXNNNNNNNNNNNNNNNWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWW 000000000000KKKKKKKKKKXXXXXXXXXXXXXXXXXNNXXK0Okxdoolllloodxk0KXNNWWNWWWWWWWWWWWWWWWWWWWWWWWWWWWWNNNN kkkkkkkOOOOOOOOOOO00000000000000000000kdl:,... ..';coxOKKKKKKKKKKKKXKKXXKKKXXXXXKKKK000 kkkkkkkOOOOOOOOOOOO000000000000000Od:,. .,cdOKKKKKKKKKKKK0000OOOOOOOOOOOO kkkkkkkkOOOOOOOOOOO0000000000000kc' .:d0KKKKKKKKK0KKOkOOOOOOOOOO0 kkkkkkkkOOOOOOOOOOOO00000000000o' ,o0KKKKKKKKKKOkOOOOOOOOO00 kkkkkkkkOOOOOOOOOOOOO000000000o. ;kKKKKKKKKKOkOOOOOOOOO00 OOOOOOOOOO0000000000000000K0Kk' 'xKKKKKKKKOkOOOOOOOOO00 KKKKKKKKKXXXXXXXXXXXXXXNNNNNNd. cXNNNNNNNK0000O00O0000 KKKKKKKKKXXXXXXXXXXXXNNNNNNNXl ............... :XWWWWWWWX000000000000 KKKKKKKKKXXXXXXXXXXXXXXNNNNNXc ...''',,,,,,;;,,,,,,'''...... .xWWWWWWWWX000000000000 KKKKKKKKKKKXXXXXXXXXXXXXNNNNK; ...',,,,;;;;;;;:::::::;;;;;;,,'. .oNWWWWWWWNK000000OOOO00 KKKKKKKKKKKKXXXXXXXXXXXXXXXN0, ...'',,,;;;;;;:::::::::::::::;;;;,'. .dNWWWWWWWWNK0000OOOOOOOO 0000KKKKKKKKKKKKKXXXXXXXXXXN0, ..'',,,,;;;;;;:::::::::::::::::;;;;,,.. ;ONNNNNWWWWWNK00OOOOOOOOOO kkkkkkOOOOOOOOOOOOOOOOOOO000k; ..,,,,,,'',,;;::::::::::::::::;;;;;;,'. .lOKKKKXXKXXKK0OOOOOOOOOOOOO xxxkkkkkkkkkkkkkkkkkkOOOOkdll;..',,,,,,,''...';::ccccc:::::::::;;;;;,...o0000000000000OkkOOOkkOOOOOO xxxxxxkkkkkkkkkkkkkkkkkkOd:;;,..,;;;;;;;;;;,'',,;:ccccccccc:::;;;;;;,..cO0000000000000Oxkkkkkkkkkkkk xxxxxxxxkkkkkkkkkkkkkkkkkl:;;,'';;;;;,'''''',,,,,;::ccc::;,,'.'''',;,,lO00000000000000kxkkkkkkkkkkkk xxxxxxxxkkkkkkkkkkkkkkkkko::;'';;;;;;,''....,'',,,,;:c:;,,'''',,;;;;,:x00000000000000Okxkkkkkkkkkkkk xxxxxxxxxxkkkkkkkkkkkkkkkxl;,,;;;;:::;;;,,,,,,,,,,,,:c:;,'....''',;;,;cxO000000000000Okxkkkkkkkkkkkk kkkkOOOOOOOOOOOOOO00000000x:;;;;;:::c::::::;;;;;;;;;:c:;,,,,'',,',;:::lOKKKKKKXXXXXXKKOkkkkkkkkkkkkk 000000000000000KKKKKKKKKKK0dc;,;;:::ccccccc::::;;;;;:cc:;;;;:::::::::lOXXXXXNNNNNNNNXX0Okkkkkkkkkkkk OO00000000000000000KKKKKKKK0d::;;;::ccccccccc:;;;;;;;:c:;::ccccccc::cOXXXXXXXXXNNNNNXX0kkkkkkkkkkkkk OOO00000000000000000000KKKKKOxxc;;;::ccccccc:;;;;;;;:ccc:::cccllcc;:kKXXXXXXXXXXXXXXXKOkkkkkkkkkkkkk OOOOO00000000000000000000KKK0kdl;;;;;:ccccc::;,,,,;;:clc:::cclllcc:oKXXXXXXXXXXXXXXXXKOkkkkkkkkkkkkk OOOOOOO0000000000000000Okxdlc;,,;;::;;::cc::;;,,,,,;:::;;:cccccc::clxkO00KKKKKKKKKXKK0kkkkkkkkkkkxkk kkkkkkkkkkkkkkkkkkkxdoc:,''.....,;:::;;;::;;;;;;;;;;;;;;;:ccc:::;,',;;:clodxkOOOOOOOOkxxxxxxxxxxxxxx ddddddddddddddoolc;,'''..........,;;:;;;::;,,,,,;;;;;::::::c:::;'.',,;;;;;::clodxkkkkxdxxxxxxxxxxxxx dddddddoolc::;,'''....... ..',;;;;;;;;,'........',;::::::;;,,;;;;;;;;:::::ccloddddxxxxxxxxxxxxx dollc:;,,''......... ..'''',,,,;;;;;,'''.....'',::::;,,;;;::::;;,,;;;;;;;;;::cldxxxxxxdxxdxx l;'''.''...... ..'',,''',,,,;;;::;;,,,,,,;;::;;'.....',;;,,''',,,,,,'',,,',:odxddddddddd ............. .'',,,,,''',,,;;;;::::;::::::;;;........'''''''..'.....,,'...';cdddddddddd . ....... .',,,,,;,,'',,,,;;;::::::::::;;cc. .....''...'''.......','......':odxdddddd ... .',,;;;;;;,'',;;,,,;;;::::::::;cxo....................''''.......'';lddddddd .. .,;,;;;;;;,,,',;;;,,,,;;;;;;;;:dKO:..................''''.. .......',cdddddd ,:;;;;;,,,,;,,;::;,,,,,;::::::dK0c..................'''.. ........',codddd .;:;;;;;,,;;;,,;:;;:;,,;:::::clc,... ...........'''.... .... .....':oddd .',;;;;;;;;;,,;:;;;;,;::::::;'...... ......'......... .....'',cood ..,;;;;;;;;;;;:;;;;:::::;'. . .............. ...''',:od ..',;;;;:;;;:::::::,,'. ............... ....''.':o ...',,;;,,;,,'.. ............... .. .....'c __ _ __.... ................ .... ......' ____ ____ / /_ _ __(_)___/ /__ .............. .. ... ....... / __ `/ _ \\/ __/ | | /| / / / __ / _ \\ ................ . ...... / /_/ / __/ /_ | |/ |/ / / /_/ / __/ ................. ...... \\__, /\\___/\\__/ |__/|__/_/\\__,_/\\___/ ............... ...... /____/ ............... .. ........ \"\"\" print(wide)","title":"Module scrapli.driver.base.async_driver"},{"location":"api_docs/driver/base/async_driver/#classes","text":"","title":"Classes"},{"location":"api_docs/driver/base/async_driver/#asyncdriver","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 BaseDriver Object BaseDriver is the root for all Scrapli driver classes. The synchronous and asyncio driver base driver classes can be used to provide a semi-pexpect like experience over top of whatever transport a user prefers. Generally, however, the base driver classes should not be used directly. It is best to use the GenericDriver (or AsyncGenericDriver) or NetworkDriver (or AsyncNetworkDriver) sub-classes of the base drivers. Args: host: host ip/name to connect to port: port to connect to auth_username: username for authentication auth_private_key: path to private key for authentication auth_private_key_passphrase: passphrase for decrypting ssh key if necessary auth_password: password for authentication auth_strict_key: strict host checking or not auth_bypass: bypass \"in channel\" authentication -- only supported with telnet, asynctelnet, and system transport plugins timeout_socket: timeout for establishing socket/initial connection in seconds timeout_transport: timeout for ssh|telnet transport in seconds timeout_ops: timeout for ssh channel operations comms_prompt_pattern: raw string regex pattern -- preferably use `^` and `$` anchors! this is the single most important attribute here! if this does not match a prompt, scrapli will not work! IMPORTANT: regex search uses multi-line + case insensitive flags. multi-line allows for highly reliably matching for prompts however we do NOT strip trailing whitespace for each line, so be sure to add '\\\\s?' or similar if your device needs that. This should be mostly sorted for you if using network drivers (i.e. `IOSXEDriver`). Lastly, the case insensitive is just a convenience factor so i can be lazy. comms_return_char: character to use to send returns to host ssh_config_file: string to path for ssh config file, True to use default ssh config file or False to ignore default ssh config file ssh_known_hosts_file: string to path for ssh known hosts file, True to use default known file locations. Only applicable/needed if `auth_strict_key` is set to True on_init: callable that accepts the class instance as its only argument. this callable, if provided, is executed as the last step of object instantiation -- its purpose is primarily to provide a mechanism for scrapli community platforms to have an easy way to modify initialization arguments/object attributes without needing to create a class that extends the driver, instead allowing the community platforms to simply build from the GenericDriver or NetworkDriver classes, and pass this callable to do things such as appending to a username (looking at you RouterOS!!). Note that this is *always* a synchronous function (even for asyncio drivers)! on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar transport: name of the transport plugin to use for the actual telnet/ssh/netconf connection. Available \"core\" transports are: - system - telnet - asynctelnet - ssh2 - paramiko - asyncssh Please see relevant transport plugin section for details. Additionally third party transport plugins may be available. transport_options: dictionary of options to pass to selected transport class; see docs for given transport class for details of what to pass here channel_lock: True/False to lock the channel (threading.Lock/asyncio.Lock) during any channel operations, defaults to False channel_log: True/False or a string path to a file of where to write out channel logs -- these are not \"logs\" in the normal logging module sense, but only the output that is read from the channel. In other words, the output of the channel log should look similar to what you would see as a human connecting to a device channel_log_mode: \"write\"|\"append\", all other values will raise ValueError, does what it sounds like it should by setting the channel log to the provided mode logging_uid: unique identifier (string) to associate to log messages; useful if you have multiple connections to the same device (i.e. one console, one ssh, or one to each supervisor module, etc.) Returns: None Raises: N/A Expand source code class AsyncDriver(BaseDriver): def __init__(self, **kwargs: Any): super().__init__(**kwargs) if self.transport_name not in ASYNCIO_TRANSPORTS: raise ScrapliValueError( \"provided transport is *not* an asyncio transport, must use an async transport with\" \" the AsyncDriver(s)\" ) self.channel = AsyncChannel( transport=self.transport, base_channel_args=self._base_channel_args, ) async def __aenter__(self: _T) -> _T: \"\"\" Enter method for context manager Args: N/A Returns: _T: a concrete implementation of the opened AsyncDriver object Raises: N/A \"\"\" await self.open() return self async def __aexit__( self, exception_type: Optional[Type[BaseException]], exception_value: Optional[BaseException], traceback: Optional[TracebackType], ) -> None: \"\"\" Exit method to cleanup for context manager Args: exception_type: exception type being raised exception_value: message from exception being raised traceback: traceback from exception being raised Returns: None Raises: N/A \"\"\" await self.close() async def open(self) -> None: \"\"\" Open the scrapli connection Args: N/A Returns: None Raises: N/A \"\"\" self._pre_open_closing_log(closing=False) await self.transport.open() self.channel.open() if ( self.transport_name in ( \"telnet\", \"asynctelnet\", ) and not self.auth_bypass ): await self.channel.channel_authenticate_telnet( auth_username=self.auth_username, auth_password=self.auth_password ) if self.on_open: await self.on_open(self) self._post_open_closing_log(closing=False) async def close(self) -> None: \"\"\" Close the scrapli connection Args: N/A Returns: None Raises: N/A \"\"\" self._post_open_closing_log(closing=True) if self.on_close: await self.on_close(self) self.transport.close() self.channel.close() self._post_open_closing_log(closing=True) async def commandeer(self, conn: \"AsyncDriver\", execute_on_open: bool = True) -> None: \"\"\" Commandeer an existing connection See docstring in sync version for more details: `scrapli.driver.base.sync_driver.commandeer` Args: conn: connection to commandeer execute_on_open: execute the `on_open` function of the current object once the existing connection has been commandeered Returns: None Raises: N/A \"\"\" original_logger = conn.logger original_transport = conn.transport original_transport_logger = conn.transport.logger original_channel_logger = conn.channel.logger original_channel_channel_log = conn.channel.channel_log self.logger = original_logger self.channel.logger = original_channel_logger self.channel.transport = original_transport self.transport = original_transport self.transport.logger = original_transport_logger if original_channel_channel_log is not None: # if the original connection had a channel log we also commandeer that; note that when # the new connection is closed this will also close the channel log; see docstring. self.channel.channel_log = original_channel_channel_log if execute_on_open and self.on_open is not None: await self.on_open(self) @staticmethod def ___getwide___() -> None: # pragma: no cover \"\"\" Dumb inside joke easter egg :) Args: N/A Returns: None Raises: N/A \"\"\" wide = r\"\"\" KKKXXXXXXXXXXNNNNNNNNNNNNNNNWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWW 000000000000KKKKKKKKKKXXXXXXXXXXXXXXXXXNNXXK0Okxdoolllloodxk0KXNNWWNWWWWWWWWWWWWWWWWWWWWWWWWWWWWNNNN kkkkkkkOOOOOOOOOOO00000000000000000000kdl:,... ..';coxOKKKKKKKKKKKKXKKXXKKKXXXXXKKKK000 kkkkkkkOOOOOOOOOOOO000000000000000Od:,. .,cdOKKKKKKKKKKKK0000OOOOOOOOOOOO kkkkkkkkOOOOOOOOOOO0000000000000kc' .:d0KKKKKKKKK0KKOkOOOOOOOOOO0 kkkkkkkkOOOOOOOOOOOO00000000000o' ,o0KKKKKKKKKKOkOOOOOOOOO00 kkkkkkkkOOOOOOOOOOOOO000000000o. ;kKKKKKKKKKOkOOOOOOOOO00 OOOOOOOOOO0000000000000000K0Kk' 'xKKKKKKKKOkOOOOOOOOO00 KKKKKKKKKXXXXXXXXXXXXXXNNNNNNd. cXNNNNNNNK0000O00O0000 KKKKKKKKKXXXXXXXXXXXXNNNNNNNXl ............... :XWWWWWWWX000000000000 KKKKKKKKKXXXXXXXXXXXXXXNNNNNXc ...''',,,,,,;;,,,,,,'''...... .xWWWWWWWWX000000000000 KKKKKKKKKKKXXXXXXXXXXXXXNNNNK; ...',,,,;;;;;;;:::::::;;;;;;,,'. .oNWWWWWWWNK000000OOOO00 KKKKKKKKKKKKXXXXXXXXXXXXXXXN0, ...'',,,;;;;;;:::::::::::::::;;;;,'. .dNWWWWWWWWNK0000OOOOOOOO 0000KKKKKKKKKKKKKXXXXXXXXXXN0, ..'',,,,;;;;;;:::::::::::::::::;;;;,,.. ;ONNNNNWWWWWNK00OOOOOOOOOO kkkkkkOOOOOOOOOOOOOOOOOOO000k; ..,,,,,,'',,;;::::::::::::::::;;;;;;,'. .lOKKKKXXKXXKK0OOOOOOOOOOOOO xxxkkkkkkkkkkkkkkkkkkOOOOkdll;..',,,,,,,''...';::ccccc:::::::::;;;;;,...o0000000000000OkkOOOkkOOOOOO xxxxxxkkkkkkkkkkkkkkkkkkOd:;;,..,;;;;;;;;;;,'',,;:ccccccccc:::;;;;;;,..cO0000000000000Oxkkkkkkkkkkkk xxxxxxxxkkkkkkkkkkkkkkkkkl:;;,'';;;;;,'''''',,,,,;::ccc::;,,'.'''',;,,lO00000000000000kxkkkkkkkkkkkk xxxxxxxxkkkkkkkkkkkkkkkkko::;'';;;;;;,''....,'',,,,;:c:;,,'''',,;;;;,:x00000000000000Okxkkkkkkkkkkkk xxxxxxxxxxkkkkkkkkkkkkkkkxl;,,;;;;:::;;;,,,,,,,,,,,,:c:;,'....''',;;,;cxO000000000000Okxkkkkkkkkkkkk kkkkOOOOOOOOOOOOOO00000000x:;;;;;:::c::::::;;;;;;;;;:c:;,,,,'',,',;:::lOKKKKKKXXXXXXKKOkkkkkkkkkkkkk 000000000000000KKKKKKKKKKK0dc;,;;:::ccccccc::::;;;;;:cc:;;;;:::::::::lOXXXXXNNNNNNNNXX0Okkkkkkkkkkkk OO00000000000000000KKKKKKKK0d::;;;::ccccccccc:;;;;;;;:c:;::ccccccc::cOXXXXXXXXXNNNNNXX0kkkkkkkkkkkkk OOO00000000000000000000KKKKKOxxc;;;::ccccccc:;;;;;;;:ccc:::cccllcc;:kKXXXXXXXXXXXXXXXKOkkkkkkkkkkkkk OOOOO00000000000000000000KKK0kdl;;;;;:ccccc::;,,,,;;:clc:::cclllcc:oKXXXXXXXXXXXXXXXXKOkkkkkkkkkkkkk OOOOOOO0000000000000000Okxdlc;,,;;::;;::cc::;;,,,,,;:::;;:cccccc::clxkO00KKKKKKKKKXKK0kkkkkkkkkkkxkk kkkkkkkkkkkkkkkkkkkxdoc:,''.....,;:::;;;::;;;;;;;;;;;;;;;:ccc:::;,',;;:clodxkOOOOOOOOkxxxxxxxxxxxxxx ddddddddddddddoolc;,'''..........,;;:;;;::;,,,,,;;;;;::::::c:::;'.',,;;;;;::clodxkkkkxdxxxxxxxxxxxxx dddddddoolc::;,'''....... ..',;;;;;;;;,'........',;::::::;;,,;;;;;;;;:::::ccloddddxxxxxxxxxxxxx dollc:;,,''......... ..'''',,,,;;;;;,'''.....'',::::;,,;;;::::;;,,;;;;;;;;;::cldxxxxxxdxxdxx l;'''.''...... ..'',,''',,,,;;;::;;,,,,,,;;::;;'.....',;;,,''',,,,,,'',,,',:odxddddddddd ............. .'',,,,,''',,,;;;;::::;::::::;;;........'''''''..'.....,,'...';cdddddddddd . ....... .',,,,,;,,'',,,,;;;::::::::::;;cc. .....''...'''.......','......':odxdddddd ... .',,;;;;;;,'',;;,,,;;;::::::::;cxo....................''''.......'';lddddddd .. .,;,;;;;;;,,,',;;;,,,,;;;;;;;;:dKO:..................''''.. .......',cdddddd ,:;;;;;,,,,;,,;::;,,,,,;::::::dK0c..................'''.. ........',codddd .;:;;;;;,,;;;,,;:;;:;,,;:::::clc,... ...........'''.... .... .....':oddd .',;;;;;;;;;,,;:;;;;,;::::::;'...... ......'......... .....'',cood ..,;;;;;;;;;;;:;;;;:::::;'. . .............. ...''',:od ..',;;;;:;;;:::::::,,'. ............... ....''.':o ...',,;;,,;,,'.. ............... .. .....'c __ _ __.... ................ .... ......' ____ ____ / /_ _ __(_)___/ /__ .............. .. ... ....... / __ `/ _ \\/ __/ | | /| / / / __ / _ \\ ................ . ...... / /_/ / __/ /_ | |/ |/ / / /_/ / __/ ................. ...... \\__, /\\___/\\__/ |__/|__/_/\\__,_/\\___/ ............... ...... /____/ ............... .. ........ \"\"\" print(wide)","title":"AsyncDriver"},{"location":"api_docs/driver/base/async_driver/#ancestors-in-mro","text":"scrapli.driver.base.base_driver.BaseDriver","title":"Ancestors (in MRO)"},{"location":"api_docs/driver/base/async_driver/#descendants","text":"scrapli.driver.generic.async_driver.AsyncGenericDriver","title":"Descendants"},{"location":"api_docs/driver/base/async_driver/#methods","text":"","title":"Methods"},{"location":"api_docs/driver/base/async_driver/#close","text":"close(self) \u2011> None 1 2 3 4 5 6 7 8 9 10 Close the scrapli connection Args: N/A Returns: None Raises: N/A","title":"close"},{"location":"api_docs/driver/base/async_driver/#commandeer","text":"commandeer(self, conn: AsyncDriver, execute_on_open: bool = True) \u2011> None 1 2 3 4 5 6 7 8 9 10 11 12 13 14 Commandeer an existing connection See docstring in sync version for more details: `scrapli.driver.base.sync_driver.commandeer` Args: conn: connection to commandeer execute_on_open: execute the `on_open` function of the current object once the existing connection has been commandeered Returns: None Raises: N/A","title":"commandeer"},{"location":"api_docs/driver/base/async_driver/#open","text":"open(self) \u2011> None 1 2 3 4 5 6 7 8 9 10 Open the scrapli connection Args: N/A Returns: None Raises: N/A","title":"open"},{"location":"api_docs/driver/base/base_driver/","text":"window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting()) Module scrapli.driver.base.base_driver \u00b6 scrapli.driver.base.base_driver Expand source code \"\"\"scrapli.driver.base.base_driver\"\"\" import importlib from dataclasses import fields from io import BytesIO from pathlib import Path from types import ModuleType from typing import Any, Callable, Dict, Optional, Tuple, Type, Union from scrapli.channel.base_channel import BaseChannelArgs from scrapli.exceptions import ScrapliTransportPluginError, ScrapliTypeError, ScrapliValueError from scrapli.helper import format_user_warning, resolve_file from scrapli.logging import get_instance_logger from scrapli.ssh_config import ssh_config_factory from scrapli.transport import CORE_TRANSPORTS from scrapli.transport.base import BasePluginTransportArgs, BaseTransportArgs class BaseDriver: def __init__( self, host: str, port: Optional[int] = None, auth_username: str = \"\", auth_password: str = \"\", auth_private_key: str = \"\", auth_private_key_passphrase: str = \"\", auth_strict_key: bool = True, auth_bypass: bool = False, timeout_socket: float = 15.0, timeout_transport: float = 30.0, timeout_ops: float = 30.0, comms_prompt_pattern: str = r\"^[a-z0-9.\\-@()/:]{1,48}[#>$]\\s*$\", comms_return_char: str = \"\\n\", ssh_config_file: Union[str, bool] = False, ssh_known_hosts_file: Union[str, bool] = False, on_init: Optional[Callable[..., Any]] = None, on_open: Optional[Callable[..., Any]] = None, on_close: Optional[Callable[..., Any]] = None, transport: str = \"system\", transport_options: Optional[Dict[str, Any]] = None, channel_log: Union[str, bool, BytesIO] = False, channel_log_mode: str = \"write\", channel_lock: bool = False, logging_uid: str = \"\", ) -> None: r\"\"\" BaseDriver Object BaseDriver is the root for all Scrapli driver classes. The synchronous and asyncio driver base driver classes can be used to provide a semi-pexpect like experience over top of whatever transport a user prefers. Generally, however, the base driver classes should not be used directly. It is best to use the GenericDriver (or AsyncGenericDriver) or NetworkDriver (or AsyncNetworkDriver) sub-classes of the base drivers. Args: host: host ip/name to connect to port: port to connect to auth_username: username for authentication auth_private_key: path to private key for authentication auth_private_key_passphrase: passphrase for decrypting ssh key if necessary auth_password: password for authentication auth_strict_key: strict host checking or not auth_bypass: bypass \"in channel\" authentication -- only supported with telnet, asynctelnet, and system transport plugins timeout_socket: timeout for establishing socket/initial connection in seconds timeout_transport: timeout for ssh|telnet transport in seconds timeout_ops: timeout for ssh channel operations comms_prompt_pattern: raw string regex pattern -- preferably use `^` and `$` anchors! this is the single most important attribute here! if this does not match a prompt, scrapli will not work! IMPORTANT: regex search uses multi-line + case insensitive flags. multi-line allows for highly reliably matching for prompts however we do NOT strip trailing whitespace for each line, so be sure to add '\\\\s?' or similar if your device needs that. This should be mostly sorted for you if using network drivers (i.e. `IOSXEDriver`). Lastly, the case insensitive is just a convenience factor so i can be lazy. comms_return_char: character to use to send returns to host ssh_config_file: string to path for ssh config file, True to use default ssh config file or False to ignore default ssh config file ssh_known_hosts_file: string to path for ssh known hosts file, True to use default known file locations. Only applicable/needed if `auth_strict_key` is set to True on_init: callable that accepts the class instance as its only argument. this callable, if provided, is executed as the last step of object instantiation -- its purpose is primarily to provide a mechanism for scrapli community platforms to have an easy way to modify initialization arguments/object attributes without needing to create a class that extends the driver, instead allowing the community platforms to simply build from the GenericDriver or NetworkDriver classes, and pass this callable to do things such as appending to a username (looking at you RouterOS!!). Note that this is *always* a synchronous function (even for asyncio drivers)! on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar transport: name of the transport plugin to use for the actual telnet/ssh/netconf connection. Available \"core\" transports are: - system - telnet - asynctelnet - ssh2 - paramiko - asyncssh Please see relevant transport plugin section for details. Additionally third party transport plugins may be available. transport_options: dictionary of options to pass to selected transport class; see docs for given transport class for details of what to pass here channel_lock: True/False to lock the channel (threading.Lock/asyncio.Lock) during any channel operations, defaults to False channel_log: True/False or a string path to a file of where to write out channel logs -- these are not \"logs\" in the normal logging module sense, but only the output that is read from the channel. In other words, the output of the channel log should look similar to what you would see as a human connecting to a device channel_log_mode: \"write\"|\"append\", all other values will raise ValueError, does what it sounds like it should by setting the channel log to the provided mode logging_uid: unique identifier (string) to associate to log messages; useful if you have multiple connections to the same device (i.e. one console, one ssh, or one to each supervisor module, etc.) Returns: None Raises: N/A \"\"\" if port is None: port = 22 if \"telnet\" in transport: port = 23 self.logger = get_instance_logger( instance_name=\"scrapli.driver\", host=host, port=port, uid=logging_uid ) self._base_channel_args = BaseChannelArgs( comms_prompt_pattern=comms_prompt_pattern, comms_return_char=comms_return_char, timeout_ops=timeout_ops, channel_log=channel_log, channel_log_mode=channel_log_mode, channel_lock=channel_lock, ) # transport options is unused in most transport plugins, but when used will be a dict of # user provided arguments, defaults to None to not be mutable argument, so if its still # None at this point turn it into an empty dict to pass into the transports transport_options = transport_options or {} self._base_transport_args = BaseTransportArgs( transport_options=transport_options, host=host, port=port, timeout_socket=timeout_socket, timeout_transport=timeout_transport, logging_uid=logging_uid, ) self.host, self.port = self._setup_host(host=host, port=port) self.auth_username = auth_username self.auth_password = auth_password self.auth_private_key_passphrase = auth_private_key_passphrase self.auth_private_key, self.auth_strict_key, self.auth_bypass = self._setup_auth( auth_private_key=auth_private_key, auth_strict_key=auth_strict_key, auth_bypass=auth_bypass, ) self.ssh_config_file, self.ssh_known_hosts_file = self._setup_ssh_file_args( transport=transport, ssh_config_file=ssh_config_file, ssh_known_hosts_file=ssh_known_hosts_file, ) self._setup_callables(on_init=on_init, on_open=on_open, on_close=on_close) self.transport_name = transport if self.transport_name in (\"asyncssh\", \"ssh2\", \"paramiko\"): # for mostly(?) historical reasons these transports use the `ssh_config` module to get # port/username/key file. asyncssh may not need this at all anymore as asyncssh core # has added ssh config file support since scrapli's inception self._update_ssh_args_from_ssh_config() transport_class, self._plugin_transport_args = self._transport_factory() self.transport = transport_class( base_transport_args=self._base_transport_args, plugin_transport_args=self._plugin_transport_args, ) if self.on_init: self.on_init(self) def __str__(self) -> str: \"\"\" Magic str method for Scrape Args: N/A Returns: str: str representation of object Raises: N/A \"\"\" return f\"Scrapli Driver {self.host}:{self.port}\" def __repr__(self) -> str: \"\"\" Magic repr method for Scrape Args: N/A Returns: str: repr for class object Raises: N/A \"\"\" password = \"REDACTED\" if self.auth_password else \"\" passphrase = \"REDACTED\" if self.auth_private_key_passphrase else \"\" return ( f\"{self.__class__.__name__}(\" f\"host={self.host!r}, \" f\"port={self.port!r}, \" f\"auth_username={self.auth_username!r}, \" f\"auth_password={password!r}, \" f\"auth_private_key={self.auth_private_key!r}, \" f\"auth_private_key_passphrase={passphrase!r}, \" f\"auth_strict_key={self.auth_strict_key!r}, \" f\"auth_bypass={self.auth_bypass!r}, \" f\"timeout_socket={self._base_transport_args.timeout_socket!r}, \" f\"timeout_transport={self._base_transport_args.timeout_transport!r}, \" f\"timeout_ops={self._base_channel_args.timeout_ops!r}, \" f\"comms_prompt_pattern={self._base_channel_args.comms_prompt_pattern!r}, \" f\"comms_return_char={self._base_channel_args.comms_return_char!r}, \" f\"ssh_config_file={self.ssh_config_file!r}, \" f\"ssh_known_hosts_file={self.ssh_known_hosts_file!r}, \" f\"on_init={self.on_init!r}, \" f\"on_open={self.on_open!r}, \" f\"on_close={self.on_close!r}, \" f\"transport={self.transport_name!r}, \" f\"transport_options={self._base_transport_args.transport_options!r})\" f\"channel_log={self._base_channel_args.channel_log!r}, \" f\"channel_lock={self._base_channel_args.channel_lock!r})\" ) @staticmethod def _setup_host(host: str, port: int) -> Tuple[str, int]: \"\"\" Parse and setup host attributes Args: host: host to parse/set port: port to parse/set Returns: tuple: host, port -- host is stripped to ensure no weird whitespace floating around Raises: ScrapliValueError: if host is not provided ScrapliTypeError: if port is not an integer \"\"\" if not host: raise ScrapliValueError(\"`host` should be a hostname/ip address, got nothing!\") if not isinstance(port, int): raise ScrapliTypeError(f\"`port` should be int, got {type(port)}\") return host.strip(), port @staticmethod def _setup_auth( auth_private_key: str, auth_strict_key: bool, auth_bypass: bool, ) -> Tuple[str, bool, bool]: \"\"\" Parse and setup auth attributes Args: auth_private_key: ssh key to parse/set auth_strict_key: strict key to parse/set auth_bypass: bypass to parse/set Returns: Tuple[str, bool, bool]: string of private key path, bool for auth_strict_key, and bool for auth_bypass values Raises: ScrapliTypeError: if auth_strict_key is not a bool ScrapliTypeError: if auth_bypass is not a bool \"\"\" if not isinstance(auth_strict_key, bool): raise ScrapliTypeError(f\"`auth_strict_key` should be bool, got {type(auth_strict_key)}\") if not isinstance(auth_bypass, bool): raise ScrapliTypeError(f\"`auth_bypass` should be bool, got {type(auth_bypass)}\") if auth_private_key: auth_private_key_path = resolve_file(file=auth_private_key) else: auth_private_key_path = \"\" return auth_private_key_path, auth_strict_key, auth_bypass def _setup_ssh_file_args( self, transport: str, ssh_config_file: Union[str, bool], ssh_known_hosts_file: Union[str, bool], ) -> Tuple[str, str]: \"\"\" Parse and setup ssh related arguments Args: transport: string name of selected transport (so we can ignore this if transport contains \"telnet\" in the name) ssh_config_file: string to path for ssh config file, True to use default ssh config file or False to ignore default ssh config file ssh_known_hosts_file: string to path for ssh known hosts file, True to use default known file locations. Only applicable/needed if `auth_strict_key` is set to True Returns: Tuple[str, str]: string path to config file, string path to known hosts file Raises: ScrapliTypeError: if invalid config file or known hosts file value provided \"\"\" if \"telnet\" in transport: self.logger.debug(\"telnet-based transport selected, ignoring ssh file arguments\") # the word \"telnet\" should occur in all telnet drivers, always. so this should be safe! return \"\", \"\" if not isinstance(ssh_config_file, (str, bool)): raise ScrapliTypeError( f\"`ssh_config_file` must be str or bool, got {type(ssh_config_file)}\" ) if not isinstance(ssh_known_hosts_file, (str, bool)): raise ScrapliTypeError( \"`ssh_known_hosts_file` must be str or bool, got \" f\"{type(ssh_known_hosts_file)}\" ) if ssh_config_file is not False: if isinstance(ssh_config_file, bool): cfg = \"\" else: cfg = ssh_config_file resolved_ssh_config_file = self._resolve_ssh_config(cfg) else: resolved_ssh_config_file = \"\" if ssh_known_hosts_file is not False: if isinstance(ssh_known_hosts_file, bool): known_hosts = \"\" else: known_hosts = ssh_known_hosts_file resolved_ssh_known_hosts_file = self._resolve_ssh_known_hosts(known_hosts) else: resolved_ssh_known_hosts_file = \"\" return resolved_ssh_config_file, resolved_ssh_known_hosts_file def _update_ssh_args_from_ssh_config(self) -> None: \"\"\" Update ssh args based on ssh config file data Args: N/A Returns: None Raises: N/A \"\"\" ssh = ssh_config_factory(ssh_config_file=self.ssh_config_file) host_config = ssh.lookup(host=self.host) if host_config.port: self.logger.info( f\"found port for host in ssh configuration file, using this value \" f\"'{host_config.port}' for port!\" ) # perhaps this should not override already set port because we dont know if the user # provided the port or we just are accepting the default port value... in any case for # port, if it is in the ssh config file we will override whatever we currently have self.port = host_config.port if host_config.user and not self.auth_username: self.logger.info( f\"found username for host in ssh configuration file, using this value \" f\"'{host_config.user}' for auth_username!\" ) # only override auth_username if it is not truthy self.auth_username = host_config.user if host_config.identity_file and not self.auth_private_key: self.logger.info( f\"found identity file for host in ssh configuration file, using this value \" f\"'{host_config.identity_file}' for auth_private_key!\" ) # only override auth_private_key if it is not truthy self.auth_private_key = host_config.identity_file def _setup_callables( self, on_init: Optional[Callable[..., Any]], on_open: Optional[Callable[..., Any]], on_close: Optional[Callable[..., Any]], ) -> None: \"\"\" Parse and setup callables (on_init/on_open/on_close) Args: on_init: on_init to parse/set on_open: on_open to parse/set on_close: on_close to parse/set Returns: None Raises: ScrapliTypeError: if any of the on_* methods are not callables (or None) \"\"\" if on_init is not None and not callable(on_init): raise ScrapliTypeError(f\"`on_init` must be a callable, got {type(on_init)}\") if on_open is not None and not callable(on_open): raise ScrapliTypeError(f\"`on_open` must be a callable, got {type(on_open)}\") if on_close is not None and not callable(on_close): raise ScrapliTypeError(f\"`on_close` must be a callable, got {type(on_close)}\") self.on_init = on_init self.on_open = on_open self.on_close = on_close def _transport_factory(self) -> Tuple[Callable[..., Any], object]: \"\"\" Determine proper transport class and necessary arguments to initialize that class Args: N/A Returns: Tuple[Callable[..., Any], object]: tuple of transport class and dataclass of transport class specific arguments Raises: N/A \"\"\" if self.transport_name in CORE_TRANSPORTS: transport_class, _plugin_transport_args_class = self._load_core_transport_plugin() else: transport_class, _plugin_transport_args_class = self._load_non_core_transport_plugin() _plugin_transport_args = { field.name: getattr(self, field.name) for field in fields(_plugin_transport_args_class) } # ignore type as we are typing it as the base class to make life simple, because of this # mypy thinks we are passing too many args plugin_transport_args = _plugin_transport_args_class(**_plugin_transport_args) return transport_class, plugin_transport_args def _load_transport_plugin_common( self, transport_plugin_module: ModuleType ) -> Tuple[Any, Type[BasePluginTransportArgs]]: \"\"\" Given transport plugin module, load transport class and transport args Args: transport_plugin_module: loaded importlib module for the given transport Returns: Tuple[Any, Type[BasePluginTransportArgs]]: transport class class and TransportArgs dataclass Raises: N/A \"\"\" transport_class = getattr( transport_plugin_module, f\"{self.transport_name.capitalize()}Transport\" ) plugin_transport_args = getattr(transport_plugin_module, \"PluginTransportArgs\") return transport_class, plugin_transport_args def _load_core_transport_plugin( self, ) -> Tuple[Any, Type[BasePluginTransportArgs]]: \"\"\" Find non-core transport plugins and required plugin arguments Args: N/A Returns: Tuple[Any, Type[BasePluginTransportArgs]]: transport class class and TransportArgs \\ dataclass Raises: ScrapliTransportPluginError: if the transport plugin is unable to be loaded \"\"\" self.logger.debug(\"load core transport requested\") try: transport_plugin_module = importlib.import_module( f\"scrapli.transport.plugins.{self.transport_name}.transport\" ) except ModuleNotFoundError as exc: title = \"Transport Plugin Extra Not Installed!\" message = ( f\"Optional transport plugin '{self.transport_name}' is not installed!\\n\" f\"To resolve this issue, install the transport plugin. You can do this in one of \" \"the following ways:\\n\" f\"1: 'pip install -r requirements-{self.transport_name}.txt'\\n\" f\"2: 'pip install scrapli[{self.transport_name}]'\" ) exception_message = format_user_warning(title=title, message=message) raise ScrapliTransportPluginError(exception_message) from exc transport_class, plugin_transport_args = self._load_transport_plugin_common( transport_plugin_module=transport_plugin_module ) self.logger.debug(f\"core transport '{self.transport_name}' loaded successfully\") return transport_class, plugin_transport_args def _load_non_core_transport_plugin(self) -> Tuple[Any, Type[BasePluginTransportArgs]]: \"\"\" Find non-core transport plugins and required plugin arguments Args: N/A Returns: Tuple[Any, Type[BasePluginTransportArgs]]: transport class class and TransportArgs dataclass Raises: ScrapliTransportPluginError: if non-core transport library is not importable \"\"\" try: transport_plugin_module = importlib.import_module( f\"scrapli_{self.transport_name}.transport\" ) except ModuleNotFoundError as exc: title = \"Transport Plugin Extra Not Installed!\" message = ( f\"Optional third party transport plugin '{self.transport_name}' is not installed!\\n\" f\"To resolve this issue, install the transport plugin. You can do this in one of \" \"the following ways:\\n\" f\"1: 'pip install -r requirements-{self.transport_name}.txt'\\n\" f\"2: 'pip install scrapli[{self.transport_name}]'\" ) exception_message = format_user_warning(title=title, message=message) raise ScrapliTransportPluginError(exception_message) from exc transport_class, plugin_transport_args = self._load_transport_plugin_common( transport_plugin_module=transport_plugin_module ) self.logger.debug(f\"non-core transport '{self.transport_name}' loaded successfully\") return transport_class, plugin_transport_args def _resolve_ssh_config(self, ssh_config_file: str) -> str: \"\"\" Resolve ssh configuration file from provided string If provided string is empty (`\"\"`) try to resolve system ssh config files located at `~/.ssh/config` or `/etc/ssh/ssh_config`. Args: ssh_config_file: string representation of ssh config file to try to use Returns: str: string path to ssh config file or an empty string Raises: N/A \"\"\" self.logger.debug(\"attempting to resolve 'ssh_config_file' file\") resolved_ssh_config_file = \"\" if Path(ssh_config_file).is_file(): resolved_ssh_config_file = str(Path(ssh_config_file)) elif Path(\"~/.ssh/config\").expanduser().is_file(): resolved_ssh_config_file = str(Path(\"~/.ssh/config\").expanduser()) elif Path(\"/etc/ssh/ssh_config\").is_file(): resolved_ssh_config_file = str(Path(\"/etc/ssh/ssh_config\")) if resolved_ssh_config_file: self.logger.debug( f\"using '{resolved_ssh_config_file}' as resolved 'ssh_config_file' file'\" ) else: self.logger.debug(\"unable to resolve 'ssh_config_file' file\") return resolved_ssh_config_file def _resolve_ssh_known_hosts(self, ssh_known_hosts: str) -> str: \"\"\" Resolve ssh known hosts file from provided string If provided string is empty (`\"\"`) try to resolve system known hosts files located at `~/.ssh/known_hosts` or `/etc/ssh/ssh_known_hosts`. Args: ssh_known_hosts: string representation of ssh config file to try to use Returns: str: string path to ssh known hosts file or an empty string Raises: N/A \"\"\" self.logger.debug(\"attempting to resolve 'ssh_known_hosts file'\") resolved_ssh_known_hosts = \"\" if Path(ssh_known_hosts).is_file(): resolved_ssh_known_hosts = str(Path(ssh_known_hosts)) elif Path(\"~/.ssh/known_hosts\").expanduser().is_file(): resolved_ssh_known_hosts = str(Path(\"~/.ssh/known_hosts\").expanduser()) elif Path(\"/etc/ssh/ssh_known_hosts\").is_file(): resolved_ssh_known_hosts = str(Path(\"/etc/ssh/ssh_known_hosts\")) if resolved_ssh_known_hosts: self.logger.debug( f\"using '{resolved_ssh_known_hosts}' as resolved 'ssh_known_hosts' file'\" ) else: self.logger.debug(\"unable to resolve 'ssh_known_hosts' file\") return resolved_ssh_known_hosts @property def comms_prompt_pattern(self) -> str: \"\"\" Getter for `comms_prompt_pattern` attribute Args: N/A Returns: str: comms_prompt_pattern string Raises: N/A \"\"\" return self._base_channel_args.comms_prompt_pattern @comms_prompt_pattern.setter def comms_prompt_pattern(self, value: str) -> None: \"\"\" Setter for `comms_prompt_pattern` attribute Args: value: str value for comms_prompt_pattern Returns: None Raises: ScrapliTypeError: if value is not of type str \"\"\" self.logger.debug(f\"setting 'comms_prompt_pattern' value to '{value}'\") if not isinstance(value, str): raise ScrapliTypeError self._base_channel_args.comms_prompt_pattern = value @property def comms_return_char(self) -> str: \"\"\" Getter for `comms_return_char` attribute Args: N/A Returns: str: comms_return_char string Raises: N/A \"\"\" return self._base_channel_args.comms_return_char @comms_return_char.setter def comms_return_char(self, value: str) -> None: \"\"\" Setter for `comms_return_char` attribute Args: value: str value for comms_return_char Returns: None Raises: ScrapliTypeError: if value is not of type str \"\"\" self.logger.debug(f\"setting 'comms_return_char' value to {repr(value)}\") if not isinstance(value, str): raise ScrapliTypeError self._base_channel_args.comms_return_char = value @property def timeout_socket(self) -> float: \"\"\" Getter for `timeout_socket` attribute Args: N/A Returns: float: timeout_socket value Raises: N/A \"\"\" return self._base_transport_args.timeout_socket @timeout_socket.setter def timeout_socket(self, value: float) -> None: \"\"\" Setter for `timeout_socket` attribute Args: value: float value for timeout_socket Returns: None Raises: ScrapliTypeError: if value is not of type int/float \"\"\" self.logger.debug(f\"setting 'timeout_socket' value to '{value}'\") if not isinstance(value, (int, float)): raise ScrapliTypeError self._base_transport_args.timeout_socket = value @property def timeout_transport(self) -> float: \"\"\" Getter for `timeout_transport` attribute Args: N/A Returns: float: timeout_transport value Raises: N/A \"\"\" return self._base_transport_args.timeout_transport @timeout_transport.setter def timeout_transport(self, value: float) -> None: \"\"\" Setter for `timeout_transport` attribute Args: value: float value for timeout_transport Returns: None Raises: ScrapliTypeError: if value is not of type int/float \"\"\" self.logger.debug(f\"setting 'timeout_transport' value to '{value}'\") if not isinstance(value, (int, float)): raise ScrapliTypeError if value == 0: self.logger.debug(\"'timeout_transport' value is 0, this will disable timeout decorator\") self._base_transport_args.timeout_transport = value if hasattr(self.transport, \"_set_timeout\"): # transports such as paramiko/ssh2 we have to set the transport in the session # object, just updating the _base_transport_args value wont update the session! self.transport._set_timeout(value) # pylint: disable=W0212 @property def timeout_ops(self) -> float: \"\"\" Getter for `timeout_ops` attribute Args: N/A Returns: float: timeout_ops value Raises: N/A \"\"\" return self._base_channel_args.timeout_ops @timeout_ops.setter def timeout_ops(self, value: float) -> None: \"\"\" Setter for `timeout_ops` attribute Args: value: float value for timeout_ops Returns: None Raises: ScrapliTypeError: if value is not of type int/float \"\"\" self.logger.debug(f\"setting 'timeout_ops' value to '{value}'\") if not isinstance(value, (int, float)): raise ScrapliTypeError if value == 0: self.logger.debug(\"'timeout_ops' value is 0, this will disable timeout decorator\") self._base_channel_args.timeout_ops = value def isalive(self) -> bool: \"\"\" Check if underlying transport is \"alive\" Args: N/A Returns: bool: True/False if transport is alive Raises: N/A \"\"\" alive: bool = self.transport.isalive() return alive def _pre_open_closing_log(self, closing: bool = False) -> None: \"\"\" Emit \"pre open\" log message for consistency between sync/async drivers Args: closing: bool indicating if message is for closing not opening Returns: None Raises: N/A \"\"\" operation = \"closing\" if closing else \"opening\" self.logger.info(f\"{operation} connection to '{self.host}' on port '{self.port}'\") def _post_open_closing_log(self, closing: bool = False) -> None: \"\"\" Emit \"post open\" log message for consistency between sync/async drivers Args: closing: bool indicating if message is for closing not opening Returns: None Raises: N/A \"\"\" operation = \"closed\" if closing else \"opened\" self.logger.info( f\"connection to '{self.host}' on port '{self.port}' {operation} successfully\" ) Classes \u00b6 BaseDriver \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 BaseDriver Object BaseDriver is the root for all Scrapli driver classes. The synchronous and asyncio driver base driver classes can be used to provide a semi-pexpect like experience over top of whatever transport a user prefers. Generally, however, the base driver classes should not be used directly. It is best to use the GenericDriver (or AsyncGenericDriver) or NetworkDriver (or AsyncNetworkDriver) sub-classes of the base drivers. Args: host: host ip/name to connect to port: port to connect to auth_username: username for authentication auth_private_key: path to private key for authentication auth_private_key_passphrase: passphrase for decrypting ssh key if necessary auth_password: password for authentication auth_strict_key: strict host checking or not auth_bypass: bypass \"in channel\" authentication -- only supported with telnet, asynctelnet, and system transport plugins timeout_socket: timeout for establishing socket/initial connection in seconds timeout_transport: timeout for ssh|telnet transport in seconds timeout_ops: timeout for ssh channel operations comms_prompt_pattern: raw string regex pattern -- preferably use `^` and `$` anchors! this is the single most important attribute here! if this does not match a prompt, scrapli will not work! IMPORTANT: regex search uses multi-line + case insensitive flags. multi-line allows for highly reliably matching for prompts however we do NOT strip trailing whitespace for each line, so be sure to add '\\\\s?' or similar if your device needs that. This should be mostly sorted for you if using network drivers (i.e. `IOSXEDriver`). Lastly, the case insensitive is just a convenience factor so i can be lazy. comms_return_char: character to use to send returns to host ssh_config_file: string to path for ssh config file, True to use default ssh config file or False to ignore default ssh config file ssh_known_hosts_file: string to path for ssh known hosts file, True to use default known file locations. Only applicable/needed if `auth_strict_key` is set to True on_init: callable that accepts the class instance as its only argument. this callable, if provided, is executed as the last step of object instantiation -- its purpose is primarily to provide a mechanism for scrapli community platforms to have an easy way to modify initialization arguments/object attributes without needing to create a class that extends the driver, instead allowing the community platforms to simply build from the GenericDriver or NetworkDriver classes, and pass this callable to do things such as appending to a username (looking at you RouterOS!!). Note that this is *always* a synchronous function (even for asyncio drivers)! on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar transport: name of the transport plugin to use for the actual telnet/ssh/netconf connection. Available \"core\" transports are: - system - telnet - asynctelnet - ssh2 - paramiko - asyncssh Please see relevant transport plugin section for details. Additionally third party transport plugins may be available. transport_options: dictionary of options to pass to selected transport class; see docs for given transport class for details of what to pass here channel_lock: True/False to lock the channel (threading.Lock/asyncio.Lock) during any channel operations, defaults to False channel_log: True/False or a string path to a file of where to write out channel logs -- these are not \"logs\" in the normal logging module sense, but only the output that is read from the channel. In other words, the output of the channel log should look similar to what you would see as a human connecting to a device channel_log_mode: \"write\"|\"append\", all other values will raise ValueError, does what it sounds like it should by setting the channel log to the provided mode logging_uid: unique identifier (string) to associate to log messages; useful if you have multiple connections to the same device (i.e. one console, one ssh, or one to each supervisor module, etc.) Returns: None Raises: N/A Expand source code class BaseDriver: def __init__( self, host: str, port: Optional[int] = None, auth_username: str = \"\", auth_password: str = \"\", auth_private_key: str = \"\", auth_private_key_passphrase: str = \"\", auth_strict_key: bool = True, auth_bypass: bool = False, timeout_socket: float = 15.0, timeout_transport: float = 30.0, timeout_ops: float = 30.0, comms_prompt_pattern: str = r\"^[a-z0-9.\\-@()/:]{1,48}[#>$]\\s*$\", comms_return_char: str = \"\\n\", ssh_config_file: Union[str, bool] = False, ssh_known_hosts_file: Union[str, bool] = False, on_init: Optional[Callable[..., Any]] = None, on_open: Optional[Callable[..., Any]] = None, on_close: Optional[Callable[..., Any]] = None, transport: str = \"system\", transport_options: Optional[Dict[str, Any]] = None, channel_log: Union[str, bool, BytesIO] = False, channel_log_mode: str = \"write\", channel_lock: bool = False, logging_uid: str = \"\", ) -> None: r\"\"\" BaseDriver Object BaseDriver is the root for all Scrapli driver classes. The synchronous and asyncio driver base driver classes can be used to provide a semi-pexpect like experience over top of whatever transport a user prefers. Generally, however, the base driver classes should not be used directly. It is best to use the GenericDriver (or AsyncGenericDriver) or NetworkDriver (or AsyncNetworkDriver) sub-classes of the base drivers. Args: host: host ip/name to connect to port: port to connect to auth_username: username for authentication auth_private_key: path to private key for authentication auth_private_key_passphrase: passphrase for decrypting ssh key if necessary auth_password: password for authentication auth_strict_key: strict host checking or not auth_bypass: bypass \"in channel\" authentication -- only supported with telnet, asynctelnet, and system transport plugins timeout_socket: timeout for establishing socket/initial connection in seconds timeout_transport: timeout for ssh|telnet transport in seconds timeout_ops: timeout for ssh channel operations comms_prompt_pattern: raw string regex pattern -- preferably use `^` and `$` anchors! this is the single most important attribute here! if this does not match a prompt, scrapli will not work! IMPORTANT: regex search uses multi-line + case insensitive flags. multi-line allows for highly reliably matching for prompts however we do NOT strip trailing whitespace for each line, so be sure to add '\\\\s?' or similar if your device needs that. This should be mostly sorted for you if using network drivers (i.e. `IOSXEDriver`). Lastly, the case insensitive is just a convenience factor so i can be lazy. comms_return_char: character to use to send returns to host ssh_config_file: string to path for ssh config file, True to use default ssh config file or False to ignore default ssh config file ssh_known_hosts_file: string to path for ssh known hosts file, True to use default known file locations. Only applicable/needed if `auth_strict_key` is set to True on_init: callable that accepts the class instance as its only argument. this callable, if provided, is executed as the last step of object instantiation -- its purpose is primarily to provide a mechanism for scrapli community platforms to have an easy way to modify initialization arguments/object attributes without needing to create a class that extends the driver, instead allowing the community platforms to simply build from the GenericDriver or NetworkDriver classes, and pass this callable to do things such as appending to a username (looking at you RouterOS!!). Note that this is *always* a synchronous function (even for asyncio drivers)! on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar transport: name of the transport plugin to use for the actual telnet/ssh/netconf connection. Available \"core\" transports are: - system - telnet - asynctelnet - ssh2 - paramiko - asyncssh Please see relevant transport plugin section for details. Additionally third party transport plugins may be available. transport_options: dictionary of options to pass to selected transport class; see docs for given transport class for details of what to pass here channel_lock: True/False to lock the channel (threading.Lock/asyncio.Lock) during any channel operations, defaults to False channel_log: True/False or a string path to a file of where to write out channel logs -- these are not \"logs\" in the normal logging module sense, but only the output that is read from the channel. In other words, the output of the channel log should look similar to what you would see as a human connecting to a device channel_log_mode: \"write\"|\"append\", all other values will raise ValueError, does what it sounds like it should by setting the channel log to the provided mode logging_uid: unique identifier (string) to associate to log messages; useful if you have multiple connections to the same device (i.e. one console, one ssh, or one to each supervisor module, etc.) Returns: None Raises: N/A \"\"\" if port is None: port = 22 if \"telnet\" in transport: port = 23 self.logger = get_instance_logger( instance_name=\"scrapli.driver\", host=host, port=port, uid=logging_uid ) self._base_channel_args = BaseChannelArgs( comms_prompt_pattern=comms_prompt_pattern, comms_return_char=comms_return_char, timeout_ops=timeout_ops, channel_log=channel_log, channel_log_mode=channel_log_mode, channel_lock=channel_lock, ) # transport options is unused in most transport plugins, but when used will be a dict of # user provided arguments, defaults to None to not be mutable argument, so if its still # None at this point turn it into an empty dict to pass into the transports transport_options = transport_options or {} self._base_transport_args = BaseTransportArgs( transport_options=transport_options, host=host, port=port, timeout_socket=timeout_socket, timeout_transport=timeout_transport, logging_uid=logging_uid, ) self.host, self.port = self._setup_host(host=host, port=port) self.auth_username = auth_username self.auth_password = auth_password self.auth_private_key_passphrase = auth_private_key_passphrase self.auth_private_key, self.auth_strict_key, self.auth_bypass = self._setup_auth( auth_private_key=auth_private_key, auth_strict_key=auth_strict_key, auth_bypass=auth_bypass, ) self.ssh_config_file, self.ssh_known_hosts_file = self._setup_ssh_file_args( transport=transport, ssh_config_file=ssh_config_file, ssh_known_hosts_file=ssh_known_hosts_file, ) self._setup_callables(on_init=on_init, on_open=on_open, on_close=on_close) self.transport_name = transport if self.transport_name in (\"asyncssh\", \"ssh2\", \"paramiko\"): # for mostly(?) historical reasons these transports use the `ssh_config` module to get # port/username/key file. asyncssh may not need this at all anymore as asyncssh core # has added ssh config file support since scrapli's inception self._update_ssh_args_from_ssh_config() transport_class, self._plugin_transport_args = self._transport_factory() self.transport = transport_class( base_transport_args=self._base_transport_args, plugin_transport_args=self._plugin_transport_args, ) if self.on_init: self.on_init(self) def __str__(self) -> str: \"\"\" Magic str method for Scrape Args: N/A Returns: str: str representation of object Raises: N/A \"\"\" return f\"Scrapli Driver {self.host}:{self.port}\" def __repr__(self) -> str: \"\"\" Magic repr method for Scrape Args: N/A Returns: str: repr for class object Raises: N/A \"\"\" password = \"REDACTED\" if self.auth_password else \"\" passphrase = \"REDACTED\" if self.auth_private_key_passphrase else \"\" return ( f\"{self.__class__.__name__}(\" f\"host={self.host!r}, \" f\"port={self.port!r}, \" f\"auth_username={self.auth_username!r}, \" f\"auth_password={password!r}, \" f\"auth_private_key={self.auth_private_key!r}, \" f\"auth_private_key_passphrase={passphrase!r}, \" f\"auth_strict_key={self.auth_strict_key!r}, \" f\"auth_bypass={self.auth_bypass!r}, \" f\"timeout_socket={self._base_transport_args.timeout_socket!r}, \" f\"timeout_transport={self._base_transport_args.timeout_transport!r}, \" f\"timeout_ops={self._base_channel_args.timeout_ops!r}, \" f\"comms_prompt_pattern={self._base_channel_args.comms_prompt_pattern!r}, \" f\"comms_return_char={self._base_channel_args.comms_return_char!r}, \" f\"ssh_config_file={self.ssh_config_file!r}, \" f\"ssh_known_hosts_file={self.ssh_known_hosts_file!r}, \" f\"on_init={self.on_init!r}, \" f\"on_open={self.on_open!r}, \" f\"on_close={self.on_close!r}, \" f\"transport={self.transport_name!r}, \" f\"transport_options={self._base_transport_args.transport_options!r})\" f\"channel_log={self._base_channel_args.channel_log!r}, \" f\"channel_lock={self._base_channel_args.channel_lock!r})\" ) @staticmethod def _setup_host(host: str, port: int) -> Tuple[str, int]: \"\"\" Parse and setup host attributes Args: host: host to parse/set port: port to parse/set Returns: tuple: host, port -- host is stripped to ensure no weird whitespace floating around Raises: ScrapliValueError: if host is not provided ScrapliTypeError: if port is not an integer \"\"\" if not host: raise ScrapliValueError(\"`host` should be a hostname/ip address, got nothing!\") if not isinstance(port, int): raise ScrapliTypeError(f\"`port` should be int, got {type(port)}\") return host.strip(), port @staticmethod def _setup_auth( auth_private_key: str, auth_strict_key: bool, auth_bypass: bool, ) -> Tuple[str, bool, bool]: \"\"\" Parse and setup auth attributes Args: auth_private_key: ssh key to parse/set auth_strict_key: strict key to parse/set auth_bypass: bypass to parse/set Returns: Tuple[str, bool, bool]: string of private key path, bool for auth_strict_key, and bool for auth_bypass values Raises: ScrapliTypeError: if auth_strict_key is not a bool ScrapliTypeError: if auth_bypass is not a bool \"\"\" if not isinstance(auth_strict_key, bool): raise ScrapliTypeError(f\"`auth_strict_key` should be bool, got {type(auth_strict_key)}\") if not isinstance(auth_bypass, bool): raise ScrapliTypeError(f\"`auth_bypass` should be bool, got {type(auth_bypass)}\") if auth_private_key: auth_private_key_path = resolve_file(file=auth_private_key) else: auth_private_key_path = \"\" return auth_private_key_path, auth_strict_key, auth_bypass def _setup_ssh_file_args( self, transport: str, ssh_config_file: Union[str, bool], ssh_known_hosts_file: Union[str, bool], ) -> Tuple[str, str]: \"\"\" Parse and setup ssh related arguments Args: transport: string name of selected transport (so we can ignore this if transport contains \"telnet\" in the name) ssh_config_file: string to path for ssh config file, True to use default ssh config file or False to ignore default ssh config file ssh_known_hosts_file: string to path for ssh known hosts file, True to use default known file locations. Only applicable/needed if `auth_strict_key` is set to True Returns: Tuple[str, str]: string path to config file, string path to known hosts file Raises: ScrapliTypeError: if invalid config file or known hosts file value provided \"\"\" if \"telnet\" in transport: self.logger.debug(\"telnet-based transport selected, ignoring ssh file arguments\") # the word \"telnet\" should occur in all telnet drivers, always. so this should be safe! return \"\", \"\" if not isinstance(ssh_config_file, (str, bool)): raise ScrapliTypeError( f\"`ssh_config_file` must be str or bool, got {type(ssh_config_file)}\" ) if not isinstance(ssh_known_hosts_file, (str, bool)): raise ScrapliTypeError( \"`ssh_known_hosts_file` must be str or bool, got \" f\"{type(ssh_known_hosts_file)}\" ) if ssh_config_file is not False: if isinstance(ssh_config_file, bool): cfg = \"\" else: cfg = ssh_config_file resolved_ssh_config_file = self._resolve_ssh_config(cfg) else: resolved_ssh_config_file = \"\" if ssh_known_hosts_file is not False: if isinstance(ssh_known_hosts_file, bool): known_hosts = \"\" else: known_hosts = ssh_known_hosts_file resolved_ssh_known_hosts_file = self._resolve_ssh_known_hosts(known_hosts) else: resolved_ssh_known_hosts_file = \"\" return resolved_ssh_config_file, resolved_ssh_known_hosts_file def _update_ssh_args_from_ssh_config(self) -> None: \"\"\" Update ssh args based on ssh config file data Args: N/A Returns: None Raises: N/A \"\"\" ssh = ssh_config_factory(ssh_config_file=self.ssh_config_file) host_config = ssh.lookup(host=self.host) if host_config.port: self.logger.info( f\"found port for host in ssh configuration file, using this value \" f\"'{host_config.port}' for port!\" ) # perhaps this should not override already set port because we dont know if the user # provided the port or we just are accepting the default port value... in any case for # port, if it is in the ssh config file we will override whatever we currently have self.port = host_config.port if host_config.user and not self.auth_username: self.logger.info( f\"found username for host in ssh configuration file, using this value \" f\"'{host_config.user}' for auth_username!\" ) # only override auth_username if it is not truthy self.auth_username = host_config.user if host_config.identity_file and not self.auth_private_key: self.logger.info( f\"found identity file for host in ssh configuration file, using this value \" f\"'{host_config.identity_file}' for auth_private_key!\" ) # only override auth_private_key if it is not truthy self.auth_private_key = host_config.identity_file def _setup_callables( self, on_init: Optional[Callable[..., Any]], on_open: Optional[Callable[..., Any]], on_close: Optional[Callable[..., Any]], ) -> None: \"\"\" Parse and setup callables (on_init/on_open/on_close) Args: on_init: on_init to parse/set on_open: on_open to parse/set on_close: on_close to parse/set Returns: None Raises: ScrapliTypeError: if any of the on_* methods are not callables (or None) \"\"\" if on_init is not None and not callable(on_init): raise ScrapliTypeError(f\"`on_init` must be a callable, got {type(on_init)}\") if on_open is not None and not callable(on_open): raise ScrapliTypeError(f\"`on_open` must be a callable, got {type(on_open)}\") if on_close is not None and not callable(on_close): raise ScrapliTypeError(f\"`on_close` must be a callable, got {type(on_close)}\") self.on_init = on_init self.on_open = on_open self.on_close = on_close def _transport_factory(self) -> Tuple[Callable[..., Any], object]: \"\"\" Determine proper transport class and necessary arguments to initialize that class Args: N/A Returns: Tuple[Callable[..., Any], object]: tuple of transport class and dataclass of transport class specific arguments Raises: N/A \"\"\" if self.transport_name in CORE_TRANSPORTS: transport_class, _plugin_transport_args_class = self._load_core_transport_plugin() else: transport_class, _plugin_transport_args_class = self._load_non_core_transport_plugin() _plugin_transport_args = { field.name: getattr(self, field.name) for field in fields(_plugin_transport_args_class) } # ignore type as we are typing it as the base class to make life simple, because of this # mypy thinks we are passing too many args plugin_transport_args = _plugin_transport_args_class(**_plugin_transport_args) return transport_class, plugin_transport_args def _load_transport_plugin_common( self, transport_plugin_module: ModuleType ) -> Tuple[Any, Type[BasePluginTransportArgs]]: \"\"\" Given transport plugin module, load transport class and transport args Args: transport_plugin_module: loaded importlib module for the given transport Returns: Tuple[Any, Type[BasePluginTransportArgs]]: transport class class and TransportArgs dataclass Raises: N/A \"\"\" transport_class = getattr( transport_plugin_module, f\"{self.transport_name.capitalize()}Transport\" ) plugin_transport_args = getattr(transport_plugin_module, \"PluginTransportArgs\") return transport_class, plugin_transport_args def _load_core_transport_plugin( self, ) -> Tuple[Any, Type[BasePluginTransportArgs]]: \"\"\" Find non-core transport plugins and required plugin arguments Args: N/A Returns: Tuple[Any, Type[BasePluginTransportArgs]]: transport class class and TransportArgs \\ dataclass Raises: ScrapliTransportPluginError: if the transport plugin is unable to be loaded \"\"\" self.logger.debug(\"load core transport requested\") try: transport_plugin_module = importlib.import_module( f\"scrapli.transport.plugins.{self.transport_name}.transport\" ) except ModuleNotFoundError as exc: title = \"Transport Plugin Extra Not Installed!\" message = ( f\"Optional transport plugin '{self.transport_name}' is not installed!\\n\" f\"To resolve this issue, install the transport plugin. You can do this in one of \" \"the following ways:\\n\" f\"1: 'pip install -r requirements-{self.transport_name}.txt'\\n\" f\"2: 'pip install scrapli[{self.transport_name}]'\" ) exception_message = format_user_warning(title=title, message=message) raise ScrapliTransportPluginError(exception_message) from exc transport_class, plugin_transport_args = self._load_transport_plugin_common( transport_plugin_module=transport_plugin_module ) self.logger.debug(f\"core transport '{self.transport_name}' loaded successfully\") return transport_class, plugin_transport_args def _load_non_core_transport_plugin(self) -> Tuple[Any, Type[BasePluginTransportArgs]]: \"\"\" Find non-core transport plugins and required plugin arguments Args: N/A Returns: Tuple[Any, Type[BasePluginTransportArgs]]: transport class class and TransportArgs dataclass Raises: ScrapliTransportPluginError: if non-core transport library is not importable \"\"\" try: transport_plugin_module = importlib.import_module( f\"scrapli_{self.transport_name}.transport\" ) except ModuleNotFoundError as exc: title = \"Transport Plugin Extra Not Installed!\" message = ( f\"Optional third party transport plugin '{self.transport_name}' is not installed!\\n\" f\"To resolve this issue, install the transport plugin. You can do this in one of \" \"the following ways:\\n\" f\"1: 'pip install -r requirements-{self.transport_name}.txt'\\n\" f\"2: 'pip install scrapli[{self.transport_name}]'\" ) exception_message = format_user_warning(title=title, message=message) raise ScrapliTransportPluginError(exception_message) from exc transport_class, plugin_transport_args = self._load_transport_plugin_common( transport_plugin_module=transport_plugin_module ) self.logger.debug(f\"non-core transport '{self.transport_name}' loaded successfully\") return transport_class, plugin_transport_args def _resolve_ssh_config(self, ssh_config_file: str) -> str: \"\"\" Resolve ssh configuration file from provided string If provided string is empty (`\"\"`) try to resolve system ssh config files located at `~/.ssh/config` or `/etc/ssh/ssh_config`. Args: ssh_config_file: string representation of ssh config file to try to use Returns: str: string path to ssh config file or an empty string Raises: N/A \"\"\" self.logger.debug(\"attempting to resolve 'ssh_config_file' file\") resolved_ssh_config_file = \"\" if Path(ssh_config_file).is_file(): resolved_ssh_config_file = str(Path(ssh_config_file)) elif Path(\"~/.ssh/config\").expanduser().is_file(): resolved_ssh_config_file = str(Path(\"~/.ssh/config\").expanduser()) elif Path(\"/etc/ssh/ssh_config\").is_file(): resolved_ssh_config_file = str(Path(\"/etc/ssh/ssh_config\")) if resolved_ssh_config_file: self.logger.debug( f\"using '{resolved_ssh_config_file}' as resolved 'ssh_config_file' file'\" ) else: self.logger.debug(\"unable to resolve 'ssh_config_file' file\") return resolved_ssh_config_file def _resolve_ssh_known_hosts(self, ssh_known_hosts: str) -> str: \"\"\" Resolve ssh known hosts file from provided string If provided string is empty (`\"\"`) try to resolve system known hosts files located at `~/.ssh/known_hosts` or `/etc/ssh/ssh_known_hosts`. Args: ssh_known_hosts: string representation of ssh config file to try to use Returns: str: string path to ssh known hosts file or an empty string Raises: N/A \"\"\" self.logger.debug(\"attempting to resolve 'ssh_known_hosts file'\") resolved_ssh_known_hosts = \"\" if Path(ssh_known_hosts).is_file(): resolved_ssh_known_hosts = str(Path(ssh_known_hosts)) elif Path(\"~/.ssh/known_hosts\").expanduser().is_file(): resolved_ssh_known_hosts = str(Path(\"~/.ssh/known_hosts\").expanduser()) elif Path(\"/etc/ssh/ssh_known_hosts\").is_file(): resolved_ssh_known_hosts = str(Path(\"/etc/ssh/ssh_known_hosts\")) if resolved_ssh_known_hosts: self.logger.debug( f\"using '{resolved_ssh_known_hosts}' as resolved 'ssh_known_hosts' file'\" ) else: self.logger.debug(\"unable to resolve 'ssh_known_hosts' file\") return resolved_ssh_known_hosts @property def comms_prompt_pattern(self) -> str: \"\"\" Getter for `comms_prompt_pattern` attribute Args: N/A Returns: str: comms_prompt_pattern string Raises: N/A \"\"\" return self._base_channel_args.comms_prompt_pattern @comms_prompt_pattern.setter def comms_prompt_pattern(self, value: str) -> None: \"\"\" Setter for `comms_prompt_pattern` attribute Args: value: str value for comms_prompt_pattern Returns: None Raises: ScrapliTypeError: if value is not of type str \"\"\" self.logger.debug(f\"setting 'comms_prompt_pattern' value to '{value}'\") if not isinstance(value, str): raise ScrapliTypeError self._base_channel_args.comms_prompt_pattern = value @property def comms_return_char(self) -> str: \"\"\" Getter for `comms_return_char` attribute Args: N/A Returns: str: comms_return_char string Raises: N/A \"\"\" return self._base_channel_args.comms_return_char @comms_return_char.setter def comms_return_char(self, value: str) -> None: \"\"\" Setter for `comms_return_char` attribute Args: value: str value for comms_return_char Returns: None Raises: ScrapliTypeError: if value is not of type str \"\"\" self.logger.debug(f\"setting 'comms_return_char' value to {repr(value)}\") if not isinstance(value, str): raise ScrapliTypeError self._base_channel_args.comms_return_char = value @property def timeout_socket(self) -> float: \"\"\" Getter for `timeout_socket` attribute Args: N/A Returns: float: timeout_socket value Raises: N/A \"\"\" return self._base_transport_args.timeout_socket @timeout_socket.setter def timeout_socket(self, value: float) -> None: \"\"\" Setter for `timeout_socket` attribute Args: value: float value for timeout_socket Returns: None Raises: ScrapliTypeError: if value is not of type int/float \"\"\" self.logger.debug(f\"setting 'timeout_socket' value to '{value}'\") if not isinstance(value, (int, float)): raise ScrapliTypeError self._base_transport_args.timeout_socket = value @property def timeout_transport(self) -> float: \"\"\" Getter for `timeout_transport` attribute Args: N/A Returns: float: timeout_transport value Raises: N/A \"\"\" return self._base_transport_args.timeout_transport @timeout_transport.setter def timeout_transport(self, value: float) -> None: \"\"\" Setter for `timeout_transport` attribute Args: value: float value for timeout_transport Returns: None Raises: ScrapliTypeError: if value is not of type int/float \"\"\" self.logger.debug(f\"setting 'timeout_transport' value to '{value}'\") if not isinstance(value, (int, float)): raise ScrapliTypeError if value == 0: self.logger.debug(\"'timeout_transport' value is 0, this will disable timeout decorator\") self._base_transport_args.timeout_transport = value if hasattr(self.transport, \"_set_timeout\"): # transports such as paramiko/ssh2 we have to set the transport in the session # object, just updating the _base_transport_args value wont update the session! self.transport._set_timeout(value) # pylint: disable=W0212 @property def timeout_ops(self) -> float: \"\"\" Getter for `timeout_ops` attribute Args: N/A Returns: float: timeout_ops value Raises: N/A \"\"\" return self._base_channel_args.timeout_ops @timeout_ops.setter def timeout_ops(self, value: float) -> None: \"\"\" Setter for `timeout_ops` attribute Args: value: float value for timeout_ops Returns: None Raises: ScrapliTypeError: if value is not of type int/float \"\"\" self.logger.debug(f\"setting 'timeout_ops' value to '{value}'\") if not isinstance(value, (int, float)): raise ScrapliTypeError if value == 0: self.logger.debug(\"'timeout_ops' value is 0, this will disable timeout decorator\") self._base_channel_args.timeout_ops = value def isalive(self) -> bool: \"\"\" Check if underlying transport is \"alive\" Args: N/A Returns: bool: True/False if transport is alive Raises: N/A \"\"\" alive: bool = self.transport.isalive() return alive def _pre_open_closing_log(self, closing: bool = False) -> None: \"\"\" Emit \"pre open\" log message for consistency between sync/async drivers Args: closing: bool indicating if message is for closing not opening Returns: None Raises: N/A \"\"\" operation = \"closing\" if closing else \"opening\" self.logger.info(f\"{operation} connection to '{self.host}' on port '{self.port}'\") def _post_open_closing_log(self, closing: bool = False) -> None: \"\"\" Emit \"post open\" log message for consistency between sync/async drivers Args: closing: bool indicating if message is for closing not opening Returns: None Raises: N/A \"\"\" operation = \"closed\" if closing else \"opened\" self.logger.info( f\"connection to '{self.host}' on port '{self.port}' {operation} successfully\" ) Descendants \u00b6 scrapli.driver.base.async_driver.AsyncDriver scrapli.driver.base.sync_driver.Driver Instance variables \u00b6 comms_prompt_pattern: str 1 2 3 4 5 6 7 8 9 10 Getter for `comms_prompt_pattern` attribute Args: N/A Returns: str: comms_prompt_pattern string Raises: N/A comms_return_char: str 1 2 3 4 5 6 7 8 9 10 Getter for `comms_return_char` attribute Args: N/A Returns: str: comms_return_char string Raises: N/A timeout_ops: float 1 2 3 4 5 6 7 8 9 10 Getter for `timeout_ops` attribute Args: N/A Returns: float: timeout_ops value Raises: N/A timeout_socket: float 1 2 3 4 5 6 7 8 9 10 Getter for `timeout_socket` attribute Args: N/A Returns: float: timeout_socket value Raises: N/A timeout_transport: float 1 2 3 4 5 6 7 8 9 10 Getter for `timeout_transport` attribute Args: N/A Returns: float: timeout_transport value Raises: N/A Methods \u00b6 isalive \u00b6 isalive(self) \u2011> bool 1 2 3 4 5 6 7 8 9 10 Check if underlying transport is \"alive\" Args: N/A Returns: bool: True/False if transport is alive Raises: N/A","title":"Base Driver"},{"location":"api_docs/driver/base/base_driver/#module-scraplidriverbasebase_driver","text":"scrapli.driver.base.base_driver Expand source code \"\"\"scrapli.driver.base.base_driver\"\"\" import importlib from dataclasses import fields from io import BytesIO from pathlib import Path from types import ModuleType from typing import Any, Callable, Dict, Optional, Tuple, Type, Union from scrapli.channel.base_channel import BaseChannelArgs from scrapli.exceptions import ScrapliTransportPluginError, ScrapliTypeError, ScrapliValueError from scrapli.helper import format_user_warning, resolve_file from scrapli.logging import get_instance_logger from scrapli.ssh_config import ssh_config_factory from scrapli.transport import CORE_TRANSPORTS from scrapli.transport.base import BasePluginTransportArgs, BaseTransportArgs class BaseDriver: def __init__( self, host: str, port: Optional[int] = None, auth_username: str = \"\", auth_password: str = \"\", auth_private_key: str = \"\", auth_private_key_passphrase: str = \"\", auth_strict_key: bool = True, auth_bypass: bool = False, timeout_socket: float = 15.0, timeout_transport: float = 30.0, timeout_ops: float = 30.0, comms_prompt_pattern: str = r\"^[a-z0-9.\\-@()/:]{1,48}[#>$]\\s*$\", comms_return_char: str = \"\\n\", ssh_config_file: Union[str, bool] = False, ssh_known_hosts_file: Union[str, bool] = False, on_init: Optional[Callable[..., Any]] = None, on_open: Optional[Callable[..., Any]] = None, on_close: Optional[Callable[..., Any]] = None, transport: str = \"system\", transport_options: Optional[Dict[str, Any]] = None, channel_log: Union[str, bool, BytesIO] = False, channel_log_mode: str = \"write\", channel_lock: bool = False, logging_uid: str = \"\", ) -> None: r\"\"\" BaseDriver Object BaseDriver is the root for all Scrapli driver classes. The synchronous and asyncio driver base driver classes can be used to provide a semi-pexpect like experience over top of whatever transport a user prefers. Generally, however, the base driver classes should not be used directly. It is best to use the GenericDriver (or AsyncGenericDriver) or NetworkDriver (or AsyncNetworkDriver) sub-classes of the base drivers. Args: host: host ip/name to connect to port: port to connect to auth_username: username for authentication auth_private_key: path to private key for authentication auth_private_key_passphrase: passphrase for decrypting ssh key if necessary auth_password: password for authentication auth_strict_key: strict host checking or not auth_bypass: bypass \"in channel\" authentication -- only supported with telnet, asynctelnet, and system transport plugins timeout_socket: timeout for establishing socket/initial connection in seconds timeout_transport: timeout for ssh|telnet transport in seconds timeout_ops: timeout for ssh channel operations comms_prompt_pattern: raw string regex pattern -- preferably use `^` and `$` anchors! this is the single most important attribute here! if this does not match a prompt, scrapli will not work! IMPORTANT: regex search uses multi-line + case insensitive flags. multi-line allows for highly reliably matching for prompts however we do NOT strip trailing whitespace for each line, so be sure to add '\\\\s?' or similar if your device needs that. This should be mostly sorted for you if using network drivers (i.e. `IOSXEDriver`). Lastly, the case insensitive is just a convenience factor so i can be lazy. comms_return_char: character to use to send returns to host ssh_config_file: string to path for ssh config file, True to use default ssh config file or False to ignore default ssh config file ssh_known_hosts_file: string to path for ssh known hosts file, True to use default known file locations. Only applicable/needed if `auth_strict_key` is set to True on_init: callable that accepts the class instance as its only argument. this callable, if provided, is executed as the last step of object instantiation -- its purpose is primarily to provide a mechanism for scrapli community platforms to have an easy way to modify initialization arguments/object attributes without needing to create a class that extends the driver, instead allowing the community platforms to simply build from the GenericDriver or NetworkDriver classes, and pass this callable to do things such as appending to a username (looking at you RouterOS!!). Note that this is *always* a synchronous function (even for asyncio drivers)! on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar transport: name of the transport plugin to use for the actual telnet/ssh/netconf connection. Available \"core\" transports are: - system - telnet - asynctelnet - ssh2 - paramiko - asyncssh Please see relevant transport plugin section for details. Additionally third party transport plugins may be available. transport_options: dictionary of options to pass to selected transport class; see docs for given transport class for details of what to pass here channel_lock: True/False to lock the channel (threading.Lock/asyncio.Lock) during any channel operations, defaults to False channel_log: True/False or a string path to a file of where to write out channel logs -- these are not \"logs\" in the normal logging module sense, but only the output that is read from the channel. In other words, the output of the channel log should look similar to what you would see as a human connecting to a device channel_log_mode: \"write\"|\"append\", all other values will raise ValueError, does what it sounds like it should by setting the channel log to the provided mode logging_uid: unique identifier (string) to associate to log messages; useful if you have multiple connections to the same device (i.e. one console, one ssh, or one to each supervisor module, etc.) Returns: None Raises: N/A \"\"\" if port is None: port = 22 if \"telnet\" in transport: port = 23 self.logger = get_instance_logger( instance_name=\"scrapli.driver\", host=host, port=port, uid=logging_uid ) self._base_channel_args = BaseChannelArgs( comms_prompt_pattern=comms_prompt_pattern, comms_return_char=comms_return_char, timeout_ops=timeout_ops, channel_log=channel_log, channel_log_mode=channel_log_mode, channel_lock=channel_lock, ) # transport options is unused in most transport plugins, but when used will be a dict of # user provided arguments, defaults to None to not be mutable argument, so if its still # None at this point turn it into an empty dict to pass into the transports transport_options = transport_options or {} self._base_transport_args = BaseTransportArgs( transport_options=transport_options, host=host, port=port, timeout_socket=timeout_socket, timeout_transport=timeout_transport, logging_uid=logging_uid, ) self.host, self.port = self._setup_host(host=host, port=port) self.auth_username = auth_username self.auth_password = auth_password self.auth_private_key_passphrase = auth_private_key_passphrase self.auth_private_key, self.auth_strict_key, self.auth_bypass = self._setup_auth( auth_private_key=auth_private_key, auth_strict_key=auth_strict_key, auth_bypass=auth_bypass, ) self.ssh_config_file, self.ssh_known_hosts_file = self._setup_ssh_file_args( transport=transport, ssh_config_file=ssh_config_file, ssh_known_hosts_file=ssh_known_hosts_file, ) self._setup_callables(on_init=on_init, on_open=on_open, on_close=on_close) self.transport_name = transport if self.transport_name in (\"asyncssh\", \"ssh2\", \"paramiko\"): # for mostly(?) historical reasons these transports use the `ssh_config` module to get # port/username/key file. asyncssh may not need this at all anymore as asyncssh core # has added ssh config file support since scrapli's inception self._update_ssh_args_from_ssh_config() transport_class, self._plugin_transport_args = self._transport_factory() self.transport = transport_class( base_transport_args=self._base_transport_args, plugin_transport_args=self._plugin_transport_args, ) if self.on_init: self.on_init(self) def __str__(self) -> str: \"\"\" Magic str method for Scrape Args: N/A Returns: str: str representation of object Raises: N/A \"\"\" return f\"Scrapli Driver {self.host}:{self.port}\" def __repr__(self) -> str: \"\"\" Magic repr method for Scrape Args: N/A Returns: str: repr for class object Raises: N/A \"\"\" password = \"REDACTED\" if self.auth_password else \"\" passphrase = \"REDACTED\" if self.auth_private_key_passphrase else \"\" return ( f\"{self.__class__.__name__}(\" f\"host={self.host!r}, \" f\"port={self.port!r}, \" f\"auth_username={self.auth_username!r}, \" f\"auth_password={password!r}, \" f\"auth_private_key={self.auth_private_key!r}, \" f\"auth_private_key_passphrase={passphrase!r}, \" f\"auth_strict_key={self.auth_strict_key!r}, \" f\"auth_bypass={self.auth_bypass!r}, \" f\"timeout_socket={self._base_transport_args.timeout_socket!r}, \" f\"timeout_transport={self._base_transport_args.timeout_transport!r}, \" f\"timeout_ops={self._base_channel_args.timeout_ops!r}, \" f\"comms_prompt_pattern={self._base_channel_args.comms_prompt_pattern!r}, \" f\"comms_return_char={self._base_channel_args.comms_return_char!r}, \" f\"ssh_config_file={self.ssh_config_file!r}, \" f\"ssh_known_hosts_file={self.ssh_known_hosts_file!r}, \" f\"on_init={self.on_init!r}, \" f\"on_open={self.on_open!r}, \" f\"on_close={self.on_close!r}, \" f\"transport={self.transport_name!r}, \" f\"transport_options={self._base_transport_args.transport_options!r})\" f\"channel_log={self._base_channel_args.channel_log!r}, \" f\"channel_lock={self._base_channel_args.channel_lock!r})\" ) @staticmethod def _setup_host(host: str, port: int) -> Tuple[str, int]: \"\"\" Parse and setup host attributes Args: host: host to parse/set port: port to parse/set Returns: tuple: host, port -- host is stripped to ensure no weird whitespace floating around Raises: ScrapliValueError: if host is not provided ScrapliTypeError: if port is not an integer \"\"\" if not host: raise ScrapliValueError(\"`host` should be a hostname/ip address, got nothing!\") if not isinstance(port, int): raise ScrapliTypeError(f\"`port` should be int, got {type(port)}\") return host.strip(), port @staticmethod def _setup_auth( auth_private_key: str, auth_strict_key: bool, auth_bypass: bool, ) -> Tuple[str, bool, bool]: \"\"\" Parse and setup auth attributes Args: auth_private_key: ssh key to parse/set auth_strict_key: strict key to parse/set auth_bypass: bypass to parse/set Returns: Tuple[str, bool, bool]: string of private key path, bool for auth_strict_key, and bool for auth_bypass values Raises: ScrapliTypeError: if auth_strict_key is not a bool ScrapliTypeError: if auth_bypass is not a bool \"\"\" if not isinstance(auth_strict_key, bool): raise ScrapliTypeError(f\"`auth_strict_key` should be bool, got {type(auth_strict_key)}\") if not isinstance(auth_bypass, bool): raise ScrapliTypeError(f\"`auth_bypass` should be bool, got {type(auth_bypass)}\") if auth_private_key: auth_private_key_path = resolve_file(file=auth_private_key) else: auth_private_key_path = \"\" return auth_private_key_path, auth_strict_key, auth_bypass def _setup_ssh_file_args( self, transport: str, ssh_config_file: Union[str, bool], ssh_known_hosts_file: Union[str, bool], ) -> Tuple[str, str]: \"\"\" Parse and setup ssh related arguments Args: transport: string name of selected transport (so we can ignore this if transport contains \"telnet\" in the name) ssh_config_file: string to path for ssh config file, True to use default ssh config file or False to ignore default ssh config file ssh_known_hosts_file: string to path for ssh known hosts file, True to use default known file locations. Only applicable/needed if `auth_strict_key` is set to True Returns: Tuple[str, str]: string path to config file, string path to known hosts file Raises: ScrapliTypeError: if invalid config file or known hosts file value provided \"\"\" if \"telnet\" in transport: self.logger.debug(\"telnet-based transport selected, ignoring ssh file arguments\") # the word \"telnet\" should occur in all telnet drivers, always. so this should be safe! return \"\", \"\" if not isinstance(ssh_config_file, (str, bool)): raise ScrapliTypeError( f\"`ssh_config_file` must be str or bool, got {type(ssh_config_file)}\" ) if not isinstance(ssh_known_hosts_file, (str, bool)): raise ScrapliTypeError( \"`ssh_known_hosts_file` must be str or bool, got \" f\"{type(ssh_known_hosts_file)}\" ) if ssh_config_file is not False: if isinstance(ssh_config_file, bool): cfg = \"\" else: cfg = ssh_config_file resolved_ssh_config_file = self._resolve_ssh_config(cfg) else: resolved_ssh_config_file = \"\" if ssh_known_hosts_file is not False: if isinstance(ssh_known_hosts_file, bool): known_hosts = \"\" else: known_hosts = ssh_known_hosts_file resolved_ssh_known_hosts_file = self._resolve_ssh_known_hosts(known_hosts) else: resolved_ssh_known_hosts_file = \"\" return resolved_ssh_config_file, resolved_ssh_known_hosts_file def _update_ssh_args_from_ssh_config(self) -> None: \"\"\" Update ssh args based on ssh config file data Args: N/A Returns: None Raises: N/A \"\"\" ssh = ssh_config_factory(ssh_config_file=self.ssh_config_file) host_config = ssh.lookup(host=self.host) if host_config.port: self.logger.info( f\"found port for host in ssh configuration file, using this value \" f\"'{host_config.port}' for port!\" ) # perhaps this should not override already set port because we dont know if the user # provided the port or we just are accepting the default port value... in any case for # port, if it is in the ssh config file we will override whatever we currently have self.port = host_config.port if host_config.user and not self.auth_username: self.logger.info( f\"found username for host in ssh configuration file, using this value \" f\"'{host_config.user}' for auth_username!\" ) # only override auth_username if it is not truthy self.auth_username = host_config.user if host_config.identity_file and not self.auth_private_key: self.logger.info( f\"found identity file for host in ssh configuration file, using this value \" f\"'{host_config.identity_file}' for auth_private_key!\" ) # only override auth_private_key if it is not truthy self.auth_private_key = host_config.identity_file def _setup_callables( self, on_init: Optional[Callable[..., Any]], on_open: Optional[Callable[..., Any]], on_close: Optional[Callable[..., Any]], ) -> None: \"\"\" Parse and setup callables (on_init/on_open/on_close) Args: on_init: on_init to parse/set on_open: on_open to parse/set on_close: on_close to parse/set Returns: None Raises: ScrapliTypeError: if any of the on_* methods are not callables (or None) \"\"\" if on_init is not None and not callable(on_init): raise ScrapliTypeError(f\"`on_init` must be a callable, got {type(on_init)}\") if on_open is not None and not callable(on_open): raise ScrapliTypeError(f\"`on_open` must be a callable, got {type(on_open)}\") if on_close is not None and not callable(on_close): raise ScrapliTypeError(f\"`on_close` must be a callable, got {type(on_close)}\") self.on_init = on_init self.on_open = on_open self.on_close = on_close def _transport_factory(self) -> Tuple[Callable[..., Any], object]: \"\"\" Determine proper transport class and necessary arguments to initialize that class Args: N/A Returns: Tuple[Callable[..., Any], object]: tuple of transport class and dataclass of transport class specific arguments Raises: N/A \"\"\" if self.transport_name in CORE_TRANSPORTS: transport_class, _plugin_transport_args_class = self._load_core_transport_plugin() else: transport_class, _plugin_transport_args_class = self._load_non_core_transport_plugin() _plugin_transport_args = { field.name: getattr(self, field.name) for field in fields(_plugin_transport_args_class) } # ignore type as we are typing it as the base class to make life simple, because of this # mypy thinks we are passing too many args plugin_transport_args = _plugin_transport_args_class(**_plugin_transport_args) return transport_class, plugin_transport_args def _load_transport_plugin_common( self, transport_plugin_module: ModuleType ) -> Tuple[Any, Type[BasePluginTransportArgs]]: \"\"\" Given transport plugin module, load transport class and transport args Args: transport_plugin_module: loaded importlib module for the given transport Returns: Tuple[Any, Type[BasePluginTransportArgs]]: transport class class and TransportArgs dataclass Raises: N/A \"\"\" transport_class = getattr( transport_plugin_module, f\"{self.transport_name.capitalize()}Transport\" ) plugin_transport_args = getattr(transport_plugin_module, \"PluginTransportArgs\") return transport_class, plugin_transport_args def _load_core_transport_plugin( self, ) -> Tuple[Any, Type[BasePluginTransportArgs]]: \"\"\" Find non-core transport plugins and required plugin arguments Args: N/A Returns: Tuple[Any, Type[BasePluginTransportArgs]]: transport class class and TransportArgs \\ dataclass Raises: ScrapliTransportPluginError: if the transport plugin is unable to be loaded \"\"\" self.logger.debug(\"load core transport requested\") try: transport_plugin_module = importlib.import_module( f\"scrapli.transport.plugins.{self.transport_name}.transport\" ) except ModuleNotFoundError as exc: title = \"Transport Plugin Extra Not Installed!\" message = ( f\"Optional transport plugin '{self.transport_name}' is not installed!\\n\" f\"To resolve this issue, install the transport plugin. You can do this in one of \" \"the following ways:\\n\" f\"1: 'pip install -r requirements-{self.transport_name}.txt'\\n\" f\"2: 'pip install scrapli[{self.transport_name}]'\" ) exception_message = format_user_warning(title=title, message=message) raise ScrapliTransportPluginError(exception_message) from exc transport_class, plugin_transport_args = self._load_transport_plugin_common( transport_plugin_module=transport_plugin_module ) self.logger.debug(f\"core transport '{self.transport_name}' loaded successfully\") return transport_class, plugin_transport_args def _load_non_core_transport_plugin(self) -> Tuple[Any, Type[BasePluginTransportArgs]]: \"\"\" Find non-core transport plugins and required plugin arguments Args: N/A Returns: Tuple[Any, Type[BasePluginTransportArgs]]: transport class class and TransportArgs dataclass Raises: ScrapliTransportPluginError: if non-core transport library is not importable \"\"\" try: transport_plugin_module = importlib.import_module( f\"scrapli_{self.transport_name}.transport\" ) except ModuleNotFoundError as exc: title = \"Transport Plugin Extra Not Installed!\" message = ( f\"Optional third party transport plugin '{self.transport_name}' is not installed!\\n\" f\"To resolve this issue, install the transport plugin. You can do this in one of \" \"the following ways:\\n\" f\"1: 'pip install -r requirements-{self.transport_name}.txt'\\n\" f\"2: 'pip install scrapli[{self.transport_name}]'\" ) exception_message = format_user_warning(title=title, message=message) raise ScrapliTransportPluginError(exception_message) from exc transport_class, plugin_transport_args = self._load_transport_plugin_common( transport_plugin_module=transport_plugin_module ) self.logger.debug(f\"non-core transport '{self.transport_name}' loaded successfully\") return transport_class, plugin_transport_args def _resolve_ssh_config(self, ssh_config_file: str) -> str: \"\"\" Resolve ssh configuration file from provided string If provided string is empty (`\"\"`) try to resolve system ssh config files located at `~/.ssh/config` or `/etc/ssh/ssh_config`. Args: ssh_config_file: string representation of ssh config file to try to use Returns: str: string path to ssh config file or an empty string Raises: N/A \"\"\" self.logger.debug(\"attempting to resolve 'ssh_config_file' file\") resolved_ssh_config_file = \"\" if Path(ssh_config_file).is_file(): resolved_ssh_config_file = str(Path(ssh_config_file)) elif Path(\"~/.ssh/config\").expanduser().is_file(): resolved_ssh_config_file = str(Path(\"~/.ssh/config\").expanduser()) elif Path(\"/etc/ssh/ssh_config\").is_file(): resolved_ssh_config_file = str(Path(\"/etc/ssh/ssh_config\")) if resolved_ssh_config_file: self.logger.debug( f\"using '{resolved_ssh_config_file}' as resolved 'ssh_config_file' file'\" ) else: self.logger.debug(\"unable to resolve 'ssh_config_file' file\") return resolved_ssh_config_file def _resolve_ssh_known_hosts(self, ssh_known_hosts: str) -> str: \"\"\" Resolve ssh known hosts file from provided string If provided string is empty (`\"\"`) try to resolve system known hosts files located at `~/.ssh/known_hosts` or `/etc/ssh/ssh_known_hosts`. Args: ssh_known_hosts: string representation of ssh config file to try to use Returns: str: string path to ssh known hosts file or an empty string Raises: N/A \"\"\" self.logger.debug(\"attempting to resolve 'ssh_known_hosts file'\") resolved_ssh_known_hosts = \"\" if Path(ssh_known_hosts).is_file(): resolved_ssh_known_hosts = str(Path(ssh_known_hosts)) elif Path(\"~/.ssh/known_hosts\").expanduser().is_file(): resolved_ssh_known_hosts = str(Path(\"~/.ssh/known_hosts\").expanduser()) elif Path(\"/etc/ssh/ssh_known_hosts\").is_file(): resolved_ssh_known_hosts = str(Path(\"/etc/ssh/ssh_known_hosts\")) if resolved_ssh_known_hosts: self.logger.debug( f\"using '{resolved_ssh_known_hosts}' as resolved 'ssh_known_hosts' file'\" ) else: self.logger.debug(\"unable to resolve 'ssh_known_hosts' file\") return resolved_ssh_known_hosts @property def comms_prompt_pattern(self) -> str: \"\"\" Getter for `comms_prompt_pattern` attribute Args: N/A Returns: str: comms_prompt_pattern string Raises: N/A \"\"\" return self._base_channel_args.comms_prompt_pattern @comms_prompt_pattern.setter def comms_prompt_pattern(self, value: str) -> None: \"\"\" Setter for `comms_prompt_pattern` attribute Args: value: str value for comms_prompt_pattern Returns: None Raises: ScrapliTypeError: if value is not of type str \"\"\" self.logger.debug(f\"setting 'comms_prompt_pattern' value to '{value}'\") if not isinstance(value, str): raise ScrapliTypeError self._base_channel_args.comms_prompt_pattern = value @property def comms_return_char(self) -> str: \"\"\" Getter for `comms_return_char` attribute Args: N/A Returns: str: comms_return_char string Raises: N/A \"\"\" return self._base_channel_args.comms_return_char @comms_return_char.setter def comms_return_char(self, value: str) -> None: \"\"\" Setter for `comms_return_char` attribute Args: value: str value for comms_return_char Returns: None Raises: ScrapliTypeError: if value is not of type str \"\"\" self.logger.debug(f\"setting 'comms_return_char' value to {repr(value)}\") if not isinstance(value, str): raise ScrapliTypeError self._base_channel_args.comms_return_char = value @property def timeout_socket(self) -> float: \"\"\" Getter for `timeout_socket` attribute Args: N/A Returns: float: timeout_socket value Raises: N/A \"\"\" return self._base_transport_args.timeout_socket @timeout_socket.setter def timeout_socket(self, value: float) -> None: \"\"\" Setter for `timeout_socket` attribute Args: value: float value for timeout_socket Returns: None Raises: ScrapliTypeError: if value is not of type int/float \"\"\" self.logger.debug(f\"setting 'timeout_socket' value to '{value}'\") if not isinstance(value, (int, float)): raise ScrapliTypeError self._base_transport_args.timeout_socket = value @property def timeout_transport(self) -> float: \"\"\" Getter for `timeout_transport` attribute Args: N/A Returns: float: timeout_transport value Raises: N/A \"\"\" return self._base_transport_args.timeout_transport @timeout_transport.setter def timeout_transport(self, value: float) -> None: \"\"\" Setter for `timeout_transport` attribute Args: value: float value for timeout_transport Returns: None Raises: ScrapliTypeError: if value is not of type int/float \"\"\" self.logger.debug(f\"setting 'timeout_transport' value to '{value}'\") if not isinstance(value, (int, float)): raise ScrapliTypeError if value == 0: self.logger.debug(\"'timeout_transport' value is 0, this will disable timeout decorator\") self._base_transport_args.timeout_transport = value if hasattr(self.transport, \"_set_timeout\"): # transports such as paramiko/ssh2 we have to set the transport in the session # object, just updating the _base_transport_args value wont update the session! self.transport._set_timeout(value) # pylint: disable=W0212 @property def timeout_ops(self) -> float: \"\"\" Getter for `timeout_ops` attribute Args: N/A Returns: float: timeout_ops value Raises: N/A \"\"\" return self._base_channel_args.timeout_ops @timeout_ops.setter def timeout_ops(self, value: float) -> None: \"\"\" Setter for `timeout_ops` attribute Args: value: float value for timeout_ops Returns: None Raises: ScrapliTypeError: if value is not of type int/float \"\"\" self.logger.debug(f\"setting 'timeout_ops' value to '{value}'\") if not isinstance(value, (int, float)): raise ScrapliTypeError if value == 0: self.logger.debug(\"'timeout_ops' value is 0, this will disable timeout decorator\") self._base_channel_args.timeout_ops = value def isalive(self) -> bool: \"\"\" Check if underlying transport is \"alive\" Args: N/A Returns: bool: True/False if transport is alive Raises: N/A \"\"\" alive: bool = self.transport.isalive() return alive def _pre_open_closing_log(self, closing: bool = False) -> None: \"\"\" Emit \"pre open\" log message for consistency between sync/async drivers Args: closing: bool indicating if message is for closing not opening Returns: None Raises: N/A \"\"\" operation = \"closing\" if closing else \"opening\" self.logger.info(f\"{operation} connection to '{self.host}' on port '{self.port}'\") def _post_open_closing_log(self, closing: bool = False) -> None: \"\"\" Emit \"post open\" log message for consistency between sync/async drivers Args: closing: bool indicating if message is for closing not opening Returns: None Raises: N/A \"\"\" operation = \"closed\" if closing else \"opened\" self.logger.info( f\"connection to '{self.host}' on port '{self.port}' {operation} successfully\" )","title":"Module scrapli.driver.base.base_driver"},{"location":"api_docs/driver/base/base_driver/#classes","text":"","title":"Classes"},{"location":"api_docs/driver/base/base_driver/#basedriver","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 BaseDriver Object BaseDriver is the root for all Scrapli driver classes. The synchronous and asyncio driver base driver classes can be used to provide a semi-pexpect like experience over top of whatever transport a user prefers. Generally, however, the base driver classes should not be used directly. It is best to use the GenericDriver (or AsyncGenericDriver) or NetworkDriver (or AsyncNetworkDriver) sub-classes of the base drivers. Args: host: host ip/name to connect to port: port to connect to auth_username: username for authentication auth_private_key: path to private key for authentication auth_private_key_passphrase: passphrase for decrypting ssh key if necessary auth_password: password for authentication auth_strict_key: strict host checking or not auth_bypass: bypass \"in channel\" authentication -- only supported with telnet, asynctelnet, and system transport plugins timeout_socket: timeout for establishing socket/initial connection in seconds timeout_transport: timeout for ssh|telnet transport in seconds timeout_ops: timeout for ssh channel operations comms_prompt_pattern: raw string regex pattern -- preferably use `^` and `$` anchors! this is the single most important attribute here! if this does not match a prompt, scrapli will not work! IMPORTANT: regex search uses multi-line + case insensitive flags. multi-line allows for highly reliably matching for prompts however we do NOT strip trailing whitespace for each line, so be sure to add '\\\\s?' or similar if your device needs that. This should be mostly sorted for you if using network drivers (i.e. `IOSXEDriver`). Lastly, the case insensitive is just a convenience factor so i can be lazy. comms_return_char: character to use to send returns to host ssh_config_file: string to path for ssh config file, True to use default ssh config file or False to ignore default ssh config file ssh_known_hosts_file: string to path for ssh known hosts file, True to use default known file locations. Only applicable/needed if `auth_strict_key` is set to True on_init: callable that accepts the class instance as its only argument. this callable, if provided, is executed as the last step of object instantiation -- its purpose is primarily to provide a mechanism for scrapli community platforms to have an easy way to modify initialization arguments/object attributes without needing to create a class that extends the driver, instead allowing the community platforms to simply build from the GenericDriver or NetworkDriver classes, and pass this callable to do things such as appending to a username (looking at you RouterOS!!). Note that this is *always* a synchronous function (even for asyncio drivers)! on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar transport: name of the transport plugin to use for the actual telnet/ssh/netconf connection. Available \"core\" transports are: - system - telnet - asynctelnet - ssh2 - paramiko - asyncssh Please see relevant transport plugin section for details. Additionally third party transport plugins may be available. transport_options: dictionary of options to pass to selected transport class; see docs for given transport class for details of what to pass here channel_lock: True/False to lock the channel (threading.Lock/asyncio.Lock) during any channel operations, defaults to False channel_log: True/False or a string path to a file of where to write out channel logs -- these are not \"logs\" in the normal logging module sense, but only the output that is read from the channel. In other words, the output of the channel log should look similar to what you would see as a human connecting to a device channel_log_mode: \"write\"|\"append\", all other values will raise ValueError, does what it sounds like it should by setting the channel log to the provided mode logging_uid: unique identifier (string) to associate to log messages; useful if you have multiple connections to the same device (i.e. one console, one ssh, or one to each supervisor module, etc.) Returns: None Raises: N/A Expand source code class BaseDriver: def __init__( self, host: str, port: Optional[int] = None, auth_username: str = \"\", auth_password: str = \"\", auth_private_key: str = \"\", auth_private_key_passphrase: str = \"\", auth_strict_key: bool = True, auth_bypass: bool = False, timeout_socket: float = 15.0, timeout_transport: float = 30.0, timeout_ops: float = 30.0, comms_prompt_pattern: str = r\"^[a-z0-9.\\-@()/:]{1,48}[#>$]\\s*$\", comms_return_char: str = \"\\n\", ssh_config_file: Union[str, bool] = False, ssh_known_hosts_file: Union[str, bool] = False, on_init: Optional[Callable[..., Any]] = None, on_open: Optional[Callable[..., Any]] = None, on_close: Optional[Callable[..., Any]] = None, transport: str = \"system\", transport_options: Optional[Dict[str, Any]] = None, channel_log: Union[str, bool, BytesIO] = False, channel_log_mode: str = \"write\", channel_lock: bool = False, logging_uid: str = \"\", ) -> None: r\"\"\" BaseDriver Object BaseDriver is the root for all Scrapli driver classes. The synchronous and asyncio driver base driver classes can be used to provide a semi-pexpect like experience over top of whatever transport a user prefers. Generally, however, the base driver classes should not be used directly. It is best to use the GenericDriver (or AsyncGenericDriver) or NetworkDriver (or AsyncNetworkDriver) sub-classes of the base drivers. Args: host: host ip/name to connect to port: port to connect to auth_username: username for authentication auth_private_key: path to private key for authentication auth_private_key_passphrase: passphrase for decrypting ssh key if necessary auth_password: password for authentication auth_strict_key: strict host checking or not auth_bypass: bypass \"in channel\" authentication -- only supported with telnet, asynctelnet, and system transport plugins timeout_socket: timeout for establishing socket/initial connection in seconds timeout_transport: timeout for ssh|telnet transport in seconds timeout_ops: timeout for ssh channel operations comms_prompt_pattern: raw string regex pattern -- preferably use `^` and `$` anchors! this is the single most important attribute here! if this does not match a prompt, scrapli will not work! IMPORTANT: regex search uses multi-line + case insensitive flags. multi-line allows for highly reliably matching for prompts however we do NOT strip trailing whitespace for each line, so be sure to add '\\\\s?' or similar if your device needs that. This should be mostly sorted for you if using network drivers (i.e. `IOSXEDriver`). Lastly, the case insensitive is just a convenience factor so i can be lazy. comms_return_char: character to use to send returns to host ssh_config_file: string to path for ssh config file, True to use default ssh config file or False to ignore default ssh config file ssh_known_hosts_file: string to path for ssh known hosts file, True to use default known file locations. Only applicable/needed if `auth_strict_key` is set to True on_init: callable that accepts the class instance as its only argument. this callable, if provided, is executed as the last step of object instantiation -- its purpose is primarily to provide a mechanism for scrapli community platforms to have an easy way to modify initialization arguments/object attributes without needing to create a class that extends the driver, instead allowing the community platforms to simply build from the GenericDriver or NetworkDriver classes, and pass this callable to do things such as appending to a username (looking at you RouterOS!!). Note that this is *always* a synchronous function (even for asyncio drivers)! on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar transport: name of the transport plugin to use for the actual telnet/ssh/netconf connection. Available \"core\" transports are: - system - telnet - asynctelnet - ssh2 - paramiko - asyncssh Please see relevant transport plugin section for details. Additionally third party transport plugins may be available. transport_options: dictionary of options to pass to selected transport class; see docs for given transport class for details of what to pass here channel_lock: True/False to lock the channel (threading.Lock/asyncio.Lock) during any channel operations, defaults to False channel_log: True/False or a string path to a file of where to write out channel logs -- these are not \"logs\" in the normal logging module sense, but only the output that is read from the channel. In other words, the output of the channel log should look similar to what you would see as a human connecting to a device channel_log_mode: \"write\"|\"append\", all other values will raise ValueError, does what it sounds like it should by setting the channel log to the provided mode logging_uid: unique identifier (string) to associate to log messages; useful if you have multiple connections to the same device (i.e. one console, one ssh, or one to each supervisor module, etc.) Returns: None Raises: N/A \"\"\" if port is None: port = 22 if \"telnet\" in transport: port = 23 self.logger = get_instance_logger( instance_name=\"scrapli.driver\", host=host, port=port, uid=logging_uid ) self._base_channel_args = BaseChannelArgs( comms_prompt_pattern=comms_prompt_pattern, comms_return_char=comms_return_char, timeout_ops=timeout_ops, channel_log=channel_log, channel_log_mode=channel_log_mode, channel_lock=channel_lock, ) # transport options is unused in most transport plugins, but when used will be a dict of # user provided arguments, defaults to None to not be mutable argument, so if its still # None at this point turn it into an empty dict to pass into the transports transport_options = transport_options or {} self._base_transport_args = BaseTransportArgs( transport_options=transport_options, host=host, port=port, timeout_socket=timeout_socket, timeout_transport=timeout_transport, logging_uid=logging_uid, ) self.host, self.port = self._setup_host(host=host, port=port) self.auth_username = auth_username self.auth_password = auth_password self.auth_private_key_passphrase = auth_private_key_passphrase self.auth_private_key, self.auth_strict_key, self.auth_bypass = self._setup_auth( auth_private_key=auth_private_key, auth_strict_key=auth_strict_key, auth_bypass=auth_bypass, ) self.ssh_config_file, self.ssh_known_hosts_file = self._setup_ssh_file_args( transport=transport, ssh_config_file=ssh_config_file, ssh_known_hosts_file=ssh_known_hosts_file, ) self._setup_callables(on_init=on_init, on_open=on_open, on_close=on_close) self.transport_name = transport if self.transport_name in (\"asyncssh\", \"ssh2\", \"paramiko\"): # for mostly(?) historical reasons these transports use the `ssh_config` module to get # port/username/key file. asyncssh may not need this at all anymore as asyncssh core # has added ssh config file support since scrapli's inception self._update_ssh_args_from_ssh_config() transport_class, self._plugin_transport_args = self._transport_factory() self.transport = transport_class( base_transport_args=self._base_transport_args, plugin_transport_args=self._plugin_transport_args, ) if self.on_init: self.on_init(self) def __str__(self) -> str: \"\"\" Magic str method for Scrape Args: N/A Returns: str: str representation of object Raises: N/A \"\"\" return f\"Scrapli Driver {self.host}:{self.port}\" def __repr__(self) -> str: \"\"\" Magic repr method for Scrape Args: N/A Returns: str: repr for class object Raises: N/A \"\"\" password = \"REDACTED\" if self.auth_password else \"\" passphrase = \"REDACTED\" if self.auth_private_key_passphrase else \"\" return ( f\"{self.__class__.__name__}(\" f\"host={self.host!r}, \" f\"port={self.port!r}, \" f\"auth_username={self.auth_username!r}, \" f\"auth_password={password!r}, \" f\"auth_private_key={self.auth_private_key!r}, \" f\"auth_private_key_passphrase={passphrase!r}, \" f\"auth_strict_key={self.auth_strict_key!r}, \" f\"auth_bypass={self.auth_bypass!r}, \" f\"timeout_socket={self._base_transport_args.timeout_socket!r}, \" f\"timeout_transport={self._base_transport_args.timeout_transport!r}, \" f\"timeout_ops={self._base_channel_args.timeout_ops!r}, \" f\"comms_prompt_pattern={self._base_channel_args.comms_prompt_pattern!r}, \" f\"comms_return_char={self._base_channel_args.comms_return_char!r}, \" f\"ssh_config_file={self.ssh_config_file!r}, \" f\"ssh_known_hosts_file={self.ssh_known_hosts_file!r}, \" f\"on_init={self.on_init!r}, \" f\"on_open={self.on_open!r}, \" f\"on_close={self.on_close!r}, \" f\"transport={self.transport_name!r}, \" f\"transport_options={self._base_transport_args.transport_options!r})\" f\"channel_log={self._base_channel_args.channel_log!r}, \" f\"channel_lock={self._base_channel_args.channel_lock!r})\" ) @staticmethod def _setup_host(host: str, port: int) -> Tuple[str, int]: \"\"\" Parse and setup host attributes Args: host: host to parse/set port: port to parse/set Returns: tuple: host, port -- host is stripped to ensure no weird whitespace floating around Raises: ScrapliValueError: if host is not provided ScrapliTypeError: if port is not an integer \"\"\" if not host: raise ScrapliValueError(\"`host` should be a hostname/ip address, got nothing!\") if not isinstance(port, int): raise ScrapliTypeError(f\"`port` should be int, got {type(port)}\") return host.strip(), port @staticmethod def _setup_auth( auth_private_key: str, auth_strict_key: bool, auth_bypass: bool, ) -> Tuple[str, bool, bool]: \"\"\" Parse and setup auth attributes Args: auth_private_key: ssh key to parse/set auth_strict_key: strict key to parse/set auth_bypass: bypass to parse/set Returns: Tuple[str, bool, bool]: string of private key path, bool for auth_strict_key, and bool for auth_bypass values Raises: ScrapliTypeError: if auth_strict_key is not a bool ScrapliTypeError: if auth_bypass is not a bool \"\"\" if not isinstance(auth_strict_key, bool): raise ScrapliTypeError(f\"`auth_strict_key` should be bool, got {type(auth_strict_key)}\") if not isinstance(auth_bypass, bool): raise ScrapliTypeError(f\"`auth_bypass` should be bool, got {type(auth_bypass)}\") if auth_private_key: auth_private_key_path = resolve_file(file=auth_private_key) else: auth_private_key_path = \"\" return auth_private_key_path, auth_strict_key, auth_bypass def _setup_ssh_file_args( self, transport: str, ssh_config_file: Union[str, bool], ssh_known_hosts_file: Union[str, bool], ) -> Tuple[str, str]: \"\"\" Parse and setup ssh related arguments Args: transport: string name of selected transport (so we can ignore this if transport contains \"telnet\" in the name) ssh_config_file: string to path for ssh config file, True to use default ssh config file or False to ignore default ssh config file ssh_known_hosts_file: string to path for ssh known hosts file, True to use default known file locations. Only applicable/needed if `auth_strict_key` is set to True Returns: Tuple[str, str]: string path to config file, string path to known hosts file Raises: ScrapliTypeError: if invalid config file or known hosts file value provided \"\"\" if \"telnet\" in transport: self.logger.debug(\"telnet-based transport selected, ignoring ssh file arguments\") # the word \"telnet\" should occur in all telnet drivers, always. so this should be safe! return \"\", \"\" if not isinstance(ssh_config_file, (str, bool)): raise ScrapliTypeError( f\"`ssh_config_file` must be str or bool, got {type(ssh_config_file)}\" ) if not isinstance(ssh_known_hosts_file, (str, bool)): raise ScrapliTypeError( \"`ssh_known_hosts_file` must be str or bool, got \" f\"{type(ssh_known_hosts_file)}\" ) if ssh_config_file is not False: if isinstance(ssh_config_file, bool): cfg = \"\" else: cfg = ssh_config_file resolved_ssh_config_file = self._resolve_ssh_config(cfg) else: resolved_ssh_config_file = \"\" if ssh_known_hosts_file is not False: if isinstance(ssh_known_hosts_file, bool): known_hosts = \"\" else: known_hosts = ssh_known_hosts_file resolved_ssh_known_hosts_file = self._resolve_ssh_known_hosts(known_hosts) else: resolved_ssh_known_hosts_file = \"\" return resolved_ssh_config_file, resolved_ssh_known_hosts_file def _update_ssh_args_from_ssh_config(self) -> None: \"\"\" Update ssh args based on ssh config file data Args: N/A Returns: None Raises: N/A \"\"\" ssh = ssh_config_factory(ssh_config_file=self.ssh_config_file) host_config = ssh.lookup(host=self.host) if host_config.port: self.logger.info( f\"found port for host in ssh configuration file, using this value \" f\"'{host_config.port}' for port!\" ) # perhaps this should not override already set port because we dont know if the user # provided the port or we just are accepting the default port value... in any case for # port, if it is in the ssh config file we will override whatever we currently have self.port = host_config.port if host_config.user and not self.auth_username: self.logger.info( f\"found username for host in ssh configuration file, using this value \" f\"'{host_config.user}' for auth_username!\" ) # only override auth_username if it is not truthy self.auth_username = host_config.user if host_config.identity_file and not self.auth_private_key: self.logger.info( f\"found identity file for host in ssh configuration file, using this value \" f\"'{host_config.identity_file}' for auth_private_key!\" ) # only override auth_private_key if it is not truthy self.auth_private_key = host_config.identity_file def _setup_callables( self, on_init: Optional[Callable[..., Any]], on_open: Optional[Callable[..., Any]], on_close: Optional[Callable[..., Any]], ) -> None: \"\"\" Parse and setup callables (on_init/on_open/on_close) Args: on_init: on_init to parse/set on_open: on_open to parse/set on_close: on_close to parse/set Returns: None Raises: ScrapliTypeError: if any of the on_* methods are not callables (or None) \"\"\" if on_init is not None and not callable(on_init): raise ScrapliTypeError(f\"`on_init` must be a callable, got {type(on_init)}\") if on_open is not None and not callable(on_open): raise ScrapliTypeError(f\"`on_open` must be a callable, got {type(on_open)}\") if on_close is not None and not callable(on_close): raise ScrapliTypeError(f\"`on_close` must be a callable, got {type(on_close)}\") self.on_init = on_init self.on_open = on_open self.on_close = on_close def _transport_factory(self) -> Tuple[Callable[..., Any], object]: \"\"\" Determine proper transport class and necessary arguments to initialize that class Args: N/A Returns: Tuple[Callable[..., Any], object]: tuple of transport class and dataclass of transport class specific arguments Raises: N/A \"\"\" if self.transport_name in CORE_TRANSPORTS: transport_class, _plugin_transport_args_class = self._load_core_transport_plugin() else: transport_class, _plugin_transport_args_class = self._load_non_core_transport_plugin() _plugin_transport_args = { field.name: getattr(self, field.name) for field in fields(_plugin_transport_args_class) } # ignore type as we are typing it as the base class to make life simple, because of this # mypy thinks we are passing too many args plugin_transport_args = _plugin_transport_args_class(**_plugin_transport_args) return transport_class, plugin_transport_args def _load_transport_plugin_common( self, transport_plugin_module: ModuleType ) -> Tuple[Any, Type[BasePluginTransportArgs]]: \"\"\" Given transport plugin module, load transport class and transport args Args: transport_plugin_module: loaded importlib module for the given transport Returns: Tuple[Any, Type[BasePluginTransportArgs]]: transport class class and TransportArgs dataclass Raises: N/A \"\"\" transport_class = getattr( transport_plugin_module, f\"{self.transport_name.capitalize()}Transport\" ) plugin_transport_args = getattr(transport_plugin_module, \"PluginTransportArgs\") return transport_class, plugin_transport_args def _load_core_transport_plugin( self, ) -> Tuple[Any, Type[BasePluginTransportArgs]]: \"\"\" Find non-core transport plugins and required plugin arguments Args: N/A Returns: Tuple[Any, Type[BasePluginTransportArgs]]: transport class class and TransportArgs \\ dataclass Raises: ScrapliTransportPluginError: if the transport plugin is unable to be loaded \"\"\" self.logger.debug(\"load core transport requested\") try: transport_plugin_module = importlib.import_module( f\"scrapli.transport.plugins.{self.transport_name}.transport\" ) except ModuleNotFoundError as exc: title = \"Transport Plugin Extra Not Installed!\" message = ( f\"Optional transport plugin '{self.transport_name}' is not installed!\\n\" f\"To resolve this issue, install the transport plugin. You can do this in one of \" \"the following ways:\\n\" f\"1: 'pip install -r requirements-{self.transport_name}.txt'\\n\" f\"2: 'pip install scrapli[{self.transport_name}]'\" ) exception_message = format_user_warning(title=title, message=message) raise ScrapliTransportPluginError(exception_message) from exc transport_class, plugin_transport_args = self._load_transport_plugin_common( transport_plugin_module=transport_plugin_module ) self.logger.debug(f\"core transport '{self.transport_name}' loaded successfully\") return transport_class, plugin_transport_args def _load_non_core_transport_plugin(self) -> Tuple[Any, Type[BasePluginTransportArgs]]: \"\"\" Find non-core transport plugins and required plugin arguments Args: N/A Returns: Tuple[Any, Type[BasePluginTransportArgs]]: transport class class and TransportArgs dataclass Raises: ScrapliTransportPluginError: if non-core transport library is not importable \"\"\" try: transport_plugin_module = importlib.import_module( f\"scrapli_{self.transport_name}.transport\" ) except ModuleNotFoundError as exc: title = \"Transport Plugin Extra Not Installed!\" message = ( f\"Optional third party transport plugin '{self.transport_name}' is not installed!\\n\" f\"To resolve this issue, install the transport plugin. You can do this in one of \" \"the following ways:\\n\" f\"1: 'pip install -r requirements-{self.transport_name}.txt'\\n\" f\"2: 'pip install scrapli[{self.transport_name}]'\" ) exception_message = format_user_warning(title=title, message=message) raise ScrapliTransportPluginError(exception_message) from exc transport_class, plugin_transport_args = self._load_transport_plugin_common( transport_plugin_module=transport_plugin_module ) self.logger.debug(f\"non-core transport '{self.transport_name}' loaded successfully\") return transport_class, plugin_transport_args def _resolve_ssh_config(self, ssh_config_file: str) -> str: \"\"\" Resolve ssh configuration file from provided string If provided string is empty (`\"\"`) try to resolve system ssh config files located at `~/.ssh/config` or `/etc/ssh/ssh_config`. Args: ssh_config_file: string representation of ssh config file to try to use Returns: str: string path to ssh config file or an empty string Raises: N/A \"\"\" self.logger.debug(\"attempting to resolve 'ssh_config_file' file\") resolved_ssh_config_file = \"\" if Path(ssh_config_file).is_file(): resolved_ssh_config_file = str(Path(ssh_config_file)) elif Path(\"~/.ssh/config\").expanduser().is_file(): resolved_ssh_config_file = str(Path(\"~/.ssh/config\").expanduser()) elif Path(\"/etc/ssh/ssh_config\").is_file(): resolved_ssh_config_file = str(Path(\"/etc/ssh/ssh_config\")) if resolved_ssh_config_file: self.logger.debug( f\"using '{resolved_ssh_config_file}' as resolved 'ssh_config_file' file'\" ) else: self.logger.debug(\"unable to resolve 'ssh_config_file' file\") return resolved_ssh_config_file def _resolve_ssh_known_hosts(self, ssh_known_hosts: str) -> str: \"\"\" Resolve ssh known hosts file from provided string If provided string is empty (`\"\"`) try to resolve system known hosts files located at `~/.ssh/known_hosts` or `/etc/ssh/ssh_known_hosts`. Args: ssh_known_hosts: string representation of ssh config file to try to use Returns: str: string path to ssh known hosts file or an empty string Raises: N/A \"\"\" self.logger.debug(\"attempting to resolve 'ssh_known_hosts file'\") resolved_ssh_known_hosts = \"\" if Path(ssh_known_hosts).is_file(): resolved_ssh_known_hosts = str(Path(ssh_known_hosts)) elif Path(\"~/.ssh/known_hosts\").expanduser().is_file(): resolved_ssh_known_hosts = str(Path(\"~/.ssh/known_hosts\").expanduser()) elif Path(\"/etc/ssh/ssh_known_hosts\").is_file(): resolved_ssh_known_hosts = str(Path(\"/etc/ssh/ssh_known_hosts\")) if resolved_ssh_known_hosts: self.logger.debug( f\"using '{resolved_ssh_known_hosts}' as resolved 'ssh_known_hosts' file'\" ) else: self.logger.debug(\"unable to resolve 'ssh_known_hosts' file\") return resolved_ssh_known_hosts @property def comms_prompt_pattern(self) -> str: \"\"\" Getter for `comms_prompt_pattern` attribute Args: N/A Returns: str: comms_prompt_pattern string Raises: N/A \"\"\" return self._base_channel_args.comms_prompt_pattern @comms_prompt_pattern.setter def comms_prompt_pattern(self, value: str) -> None: \"\"\" Setter for `comms_prompt_pattern` attribute Args: value: str value for comms_prompt_pattern Returns: None Raises: ScrapliTypeError: if value is not of type str \"\"\" self.logger.debug(f\"setting 'comms_prompt_pattern' value to '{value}'\") if not isinstance(value, str): raise ScrapliTypeError self._base_channel_args.comms_prompt_pattern = value @property def comms_return_char(self) -> str: \"\"\" Getter for `comms_return_char` attribute Args: N/A Returns: str: comms_return_char string Raises: N/A \"\"\" return self._base_channel_args.comms_return_char @comms_return_char.setter def comms_return_char(self, value: str) -> None: \"\"\" Setter for `comms_return_char` attribute Args: value: str value for comms_return_char Returns: None Raises: ScrapliTypeError: if value is not of type str \"\"\" self.logger.debug(f\"setting 'comms_return_char' value to {repr(value)}\") if not isinstance(value, str): raise ScrapliTypeError self._base_channel_args.comms_return_char = value @property def timeout_socket(self) -> float: \"\"\" Getter for `timeout_socket` attribute Args: N/A Returns: float: timeout_socket value Raises: N/A \"\"\" return self._base_transport_args.timeout_socket @timeout_socket.setter def timeout_socket(self, value: float) -> None: \"\"\" Setter for `timeout_socket` attribute Args: value: float value for timeout_socket Returns: None Raises: ScrapliTypeError: if value is not of type int/float \"\"\" self.logger.debug(f\"setting 'timeout_socket' value to '{value}'\") if not isinstance(value, (int, float)): raise ScrapliTypeError self._base_transport_args.timeout_socket = value @property def timeout_transport(self) -> float: \"\"\" Getter for `timeout_transport` attribute Args: N/A Returns: float: timeout_transport value Raises: N/A \"\"\" return self._base_transport_args.timeout_transport @timeout_transport.setter def timeout_transport(self, value: float) -> None: \"\"\" Setter for `timeout_transport` attribute Args: value: float value for timeout_transport Returns: None Raises: ScrapliTypeError: if value is not of type int/float \"\"\" self.logger.debug(f\"setting 'timeout_transport' value to '{value}'\") if not isinstance(value, (int, float)): raise ScrapliTypeError if value == 0: self.logger.debug(\"'timeout_transport' value is 0, this will disable timeout decorator\") self._base_transport_args.timeout_transport = value if hasattr(self.transport, \"_set_timeout\"): # transports such as paramiko/ssh2 we have to set the transport in the session # object, just updating the _base_transport_args value wont update the session! self.transport._set_timeout(value) # pylint: disable=W0212 @property def timeout_ops(self) -> float: \"\"\" Getter for `timeout_ops` attribute Args: N/A Returns: float: timeout_ops value Raises: N/A \"\"\" return self._base_channel_args.timeout_ops @timeout_ops.setter def timeout_ops(self, value: float) -> None: \"\"\" Setter for `timeout_ops` attribute Args: value: float value for timeout_ops Returns: None Raises: ScrapliTypeError: if value is not of type int/float \"\"\" self.logger.debug(f\"setting 'timeout_ops' value to '{value}'\") if not isinstance(value, (int, float)): raise ScrapliTypeError if value == 0: self.logger.debug(\"'timeout_ops' value is 0, this will disable timeout decorator\") self._base_channel_args.timeout_ops = value def isalive(self) -> bool: \"\"\" Check if underlying transport is \"alive\" Args: N/A Returns: bool: True/False if transport is alive Raises: N/A \"\"\" alive: bool = self.transport.isalive() return alive def _pre_open_closing_log(self, closing: bool = False) -> None: \"\"\" Emit \"pre open\" log message for consistency between sync/async drivers Args: closing: bool indicating if message is for closing not opening Returns: None Raises: N/A \"\"\" operation = \"closing\" if closing else \"opening\" self.logger.info(f\"{operation} connection to '{self.host}' on port '{self.port}'\") def _post_open_closing_log(self, closing: bool = False) -> None: \"\"\" Emit \"post open\" log message for consistency between sync/async drivers Args: closing: bool indicating if message is for closing not opening Returns: None Raises: N/A \"\"\" operation = \"closed\" if closing else \"opened\" self.logger.info( f\"connection to '{self.host}' on port '{self.port}' {operation} successfully\" )","title":"BaseDriver"},{"location":"api_docs/driver/base/base_driver/#descendants","text":"scrapli.driver.base.async_driver.AsyncDriver scrapli.driver.base.sync_driver.Driver","title":"Descendants"},{"location":"api_docs/driver/base/base_driver/#instance-variables","text":"comms_prompt_pattern: str 1 2 3 4 5 6 7 8 9 10 Getter for `comms_prompt_pattern` attribute Args: N/A Returns: str: comms_prompt_pattern string Raises: N/A comms_return_char: str 1 2 3 4 5 6 7 8 9 10 Getter for `comms_return_char` attribute Args: N/A Returns: str: comms_return_char string Raises: N/A timeout_ops: float 1 2 3 4 5 6 7 8 9 10 Getter for `timeout_ops` attribute Args: N/A Returns: float: timeout_ops value Raises: N/A timeout_socket: float 1 2 3 4 5 6 7 8 9 10 Getter for `timeout_socket` attribute Args: N/A Returns: float: timeout_socket value Raises: N/A timeout_transport: float 1 2 3 4 5 6 7 8 9 10 Getter for `timeout_transport` attribute Args: N/A Returns: float: timeout_transport value Raises: N/A","title":"Instance variables"},{"location":"api_docs/driver/base/base_driver/#methods","text":"","title":"Methods"},{"location":"api_docs/driver/base/base_driver/#isalive","text":"isalive(self) \u2011> bool 1 2 3 4 5 6 7 8 9 10 Check if underlying transport is \"alive\" Args: N/A Returns: bool: True/False if transport is alive Raises: N/A","title":"isalive"},{"location":"api_docs/driver/base/sync_driver/","text":"window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting()) Module scrapli.driver.base.sync_driver \u00b6 scrapli.driver.base.sync_driver Expand source code \"\"\"scrapli.driver.base.sync_driver\"\"\" from types import TracebackType from typing import Any, Optional, Type, TypeVar from scrapli.channel import Channel from scrapli.driver.base.base_driver import BaseDriver from scrapli.exceptions import ScrapliValueError from scrapli.transport import ASYNCIO_TRANSPORTS _T = TypeVar(\"_T\", bound=\"Driver\") class Driver(BaseDriver): def __init__(self, **kwargs: Any): super().__init__(**kwargs) if self.transport_name in ASYNCIO_TRANSPORTS: raise ScrapliValueError( \"provided transport is *not* an sync transport, must use an sync transport with\" \" the (sync)Driver(s)\" ) self.channel = Channel( transport=self.transport, base_channel_args=self._base_channel_args, ) def __enter__(self: _T) -> _T: \"\"\" Enter method for context manager Args: N/A Returns: _T: a concrete implementation of the opened Driver object Raises: N/A \"\"\" self.open() return self def __exit__( self, exception_type: Optional[Type[BaseException]], exception_value: Optional[BaseException], traceback: Optional[TracebackType], ) -> None: \"\"\" Exit method to cleanup for context manager Args: exception_type: exception type being raised exception_value: message from exception being raised traceback: traceback from exception being raised Returns: None Raises: N/A \"\"\" self.close() def open(self) -> None: \"\"\" Open the scrapli connection Args: N/A Returns: None Raises: N/A \"\"\" self._pre_open_closing_log(closing=False) self.transport.open() self.channel.open() if self.transport_name in (\"system\",) and not self.auth_bypass: self.channel.channel_authenticate_ssh( auth_password=self.auth_password, auth_private_key_passphrase=self.auth_private_key_passphrase, ) if ( self.transport_name in ( \"telnet\", \"asynctelnet\", ) and not self.auth_bypass ): self.channel.channel_authenticate_telnet( auth_username=self.auth_username, auth_password=self.auth_password ) if self.on_open: self.on_open(self) self._post_open_closing_log(closing=False) def close(self) -> None: \"\"\" Close the scrapli connection Args: N/A Returns: None Raises: N/A \"\"\" self._pre_open_closing_log(closing=True) if self.on_close: self.on_close(self) self.transport.close() self.channel.close() self._post_open_closing_log(closing=True) def commandeer(self, conn: \"Driver\", execute_on_open: bool = True) -> None: \"\"\" Commandeer an existing connection Used to \"take over\" or \"commandeer\" a connection. This method accepts a second scrapli conn object and \"steals\" the transport from this connection and uses it for the current instance. The primary reason you would want this is to use a `GenericDriver` to connect to a console server and then to \"commandeer\" that connection and convert it to a \"normal\" network driver connection type (i.e. Junos, EOS, etc.) once connected to the network device (via the console server). Right now closing the connection that \"commandeers\" the initial connection will *also close the original connection* -- this is because we are re-using the transport in this new conn. In the future perhaps this will change to *not* close the original connection so users can handle any type of cleanup operations that need to happen on the original connection. Alternatively, you can simply continue using the \"original\" connection to close things for yourself or do any type of clean up work (just dont close the commandeering connection!). Args: conn: connection to commandeer execute_on_open: execute the `on_open` function of the current object once the existing connection has been commandeered Returns: None Raises: N/A \"\"\" original_logger = conn.logger original_transport = conn.transport original_transport_logger = conn.transport.logger original_channel_logger = conn.channel.logger original_channel_channel_log = conn.channel.channel_log self.logger = original_logger self.channel.logger = original_channel_logger self.channel.transport = original_transport self.transport = original_transport self.transport.logger = original_transport_logger if original_channel_channel_log is not None: # if the original connection had a channel log we also commandeer that; note that when # the new connection is closed this will also close the channel log; see docstring. self.channel.channel_log = original_channel_channel_log if execute_on_open and self.on_open is not None: self.on_open(self) Classes \u00b6 Driver \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 BaseDriver Object BaseDriver is the root for all Scrapli driver classes. The synchronous and asyncio driver base driver classes can be used to provide a semi-pexpect like experience over top of whatever transport a user prefers. Generally, however, the base driver classes should not be used directly. It is best to use the GenericDriver (or AsyncGenericDriver) or NetworkDriver (or AsyncNetworkDriver) sub-classes of the base drivers. Args: host: host ip/name to connect to port: port to connect to auth_username: username for authentication auth_private_key: path to private key for authentication auth_private_key_passphrase: passphrase for decrypting ssh key if necessary auth_password: password for authentication auth_strict_key: strict host checking or not auth_bypass: bypass \"in channel\" authentication -- only supported with telnet, asynctelnet, and system transport plugins timeout_socket: timeout for establishing socket/initial connection in seconds timeout_transport: timeout for ssh|telnet transport in seconds timeout_ops: timeout for ssh channel operations comms_prompt_pattern: raw string regex pattern -- preferably use `^` and `$` anchors! this is the single most important attribute here! if this does not match a prompt, scrapli will not work! IMPORTANT: regex search uses multi-line + case insensitive flags. multi-line allows for highly reliably matching for prompts however we do NOT strip trailing whitespace for each line, so be sure to add '\\\\s?' or similar if your device needs that. This should be mostly sorted for you if using network drivers (i.e. `IOSXEDriver`). Lastly, the case insensitive is just a convenience factor so i can be lazy. comms_return_char: character to use to send returns to host ssh_config_file: string to path for ssh config file, True to use default ssh config file or False to ignore default ssh config file ssh_known_hosts_file: string to path for ssh known hosts file, True to use default known file locations. Only applicable/needed if `auth_strict_key` is set to True on_init: callable that accepts the class instance as its only argument. this callable, if provided, is executed as the last step of object instantiation -- its purpose is primarily to provide a mechanism for scrapli community platforms to have an easy way to modify initialization arguments/object attributes without needing to create a class that extends the driver, instead allowing the community platforms to simply build from the GenericDriver or NetworkDriver classes, and pass this callable to do things such as appending to a username (looking at you RouterOS!!). Note that this is *always* a synchronous function (even for asyncio drivers)! on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar transport: name of the transport plugin to use for the actual telnet/ssh/netconf connection. Available \"core\" transports are: - system - telnet - asynctelnet - ssh2 - paramiko - asyncssh Please see relevant transport plugin section for details. Additionally third party transport plugins may be available. transport_options: dictionary of options to pass to selected transport class; see docs for given transport class for details of what to pass here channel_lock: True/False to lock the channel (threading.Lock/asyncio.Lock) during any channel operations, defaults to False channel_log: True/False or a string path to a file of where to write out channel logs -- these are not \"logs\" in the normal logging module sense, but only the output that is read from the channel. In other words, the output of the channel log should look similar to what you would see as a human connecting to a device channel_log_mode: \"write\"|\"append\", all other values will raise ValueError, does what it sounds like it should by setting the channel log to the provided mode logging_uid: unique identifier (string) to associate to log messages; useful if you have multiple connections to the same device (i.e. one console, one ssh, or one to each supervisor module, etc.) Returns: None Raises: N/A Expand source code class Driver(BaseDriver): def __init__(self, **kwargs: Any): super().__init__(**kwargs) if self.transport_name in ASYNCIO_TRANSPORTS: raise ScrapliValueError( \"provided transport is *not* an sync transport, must use an sync transport with\" \" the (sync)Driver(s)\" ) self.channel = Channel( transport=self.transport, base_channel_args=self._base_channel_args, ) def __enter__(self: _T) -> _T: \"\"\" Enter method for context manager Args: N/A Returns: _T: a concrete implementation of the opened Driver object Raises: N/A \"\"\" self.open() return self def __exit__( self, exception_type: Optional[Type[BaseException]], exception_value: Optional[BaseException], traceback: Optional[TracebackType], ) -> None: \"\"\" Exit method to cleanup for context manager Args: exception_type: exception type being raised exception_value: message from exception being raised traceback: traceback from exception being raised Returns: None Raises: N/A \"\"\" self.close() def open(self) -> None: \"\"\" Open the scrapli connection Args: N/A Returns: None Raises: N/A \"\"\" self._pre_open_closing_log(closing=False) self.transport.open() self.channel.open() if self.transport_name in (\"system\",) and not self.auth_bypass: self.channel.channel_authenticate_ssh( auth_password=self.auth_password, auth_private_key_passphrase=self.auth_private_key_passphrase, ) if ( self.transport_name in ( \"telnet\", \"asynctelnet\", ) and not self.auth_bypass ): self.channel.channel_authenticate_telnet( auth_username=self.auth_username, auth_password=self.auth_password ) if self.on_open: self.on_open(self) self._post_open_closing_log(closing=False) def close(self) -> None: \"\"\" Close the scrapli connection Args: N/A Returns: None Raises: N/A \"\"\" self._pre_open_closing_log(closing=True) if self.on_close: self.on_close(self) self.transport.close() self.channel.close() self._post_open_closing_log(closing=True) def commandeer(self, conn: \"Driver\", execute_on_open: bool = True) -> None: \"\"\" Commandeer an existing connection Used to \"take over\" or \"commandeer\" a connection. This method accepts a second scrapli conn object and \"steals\" the transport from this connection and uses it for the current instance. The primary reason you would want this is to use a `GenericDriver` to connect to a console server and then to \"commandeer\" that connection and convert it to a \"normal\" network driver connection type (i.e. Junos, EOS, etc.) once connected to the network device (via the console server). Right now closing the connection that \"commandeers\" the initial connection will *also close the original connection* -- this is because we are re-using the transport in this new conn. In the future perhaps this will change to *not* close the original connection so users can handle any type of cleanup operations that need to happen on the original connection. Alternatively, you can simply continue using the \"original\" connection to close things for yourself or do any type of clean up work (just dont close the commandeering connection!). Args: conn: connection to commandeer execute_on_open: execute the `on_open` function of the current object once the existing connection has been commandeered Returns: None Raises: N/A \"\"\" original_logger = conn.logger original_transport = conn.transport original_transport_logger = conn.transport.logger original_channel_logger = conn.channel.logger original_channel_channel_log = conn.channel.channel_log self.logger = original_logger self.channel.logger = original_channel_logger self.channel.transport = original_transport self.transport = original_transport self.transport.logger = original_transport_logger if original_channel_channel_log is not None: # if the original connection had a channel log we also commandeer that; note that when # the new connection is closed this will also close the channel log; see docstring. self.channel.channel_log = original_channel_channel_log if execute_on_open and self.on_open is not None: self.on_open(self) Ancestors (in MRO) \u00b6 scrapli.driver.base.base_driver.BaseDriver Descendants \u00b6 scrapli.driver.generic.sync_driver.GenericDriver Methods \u00b6 close \u00b6 close(self) \u2011> None 1 2 3 4 5 6 7 8 9 10 Close the scrapli connection Args: N/A Returns: None Raises: N/A commandeer \u00b6 commandeer(self, conn: Driver, execute_on_open: bool = True) \u2011> None 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 Commandeer an existing connection Used to \"take over\" or \"commandeer\" a connection. This method accepts a second scrapli conn object and \"steals\" the transport from this connection and uses it for the current instance. The primary reason you would want this is to use a `GenericDriver` to connect to a console server and then to \"commandeer\" that connection and convert it to a \"normal\" network driver connection type (i.e. Junos, EOS, etc.) once connected to the network device (via the console server). Right now closing the connection that \"commandeers\" the initial connection will *also close the original connection* -- this is because we are re-using the transport in this new conn. In the future perhaps this will change to *not* close the original connection so users can handle any type of cleanup operations that need to happen on the original connection. Alternatively, you can simply continue using the \"original\" connection to close things for yourself or do any type of clean up work (just dont close the commandeering connection!). Args: conn: connection to commandeer execute_on_open: execute the `on_open` function of the current object once the existing connection has been commandeered Returns: None Raises: N/A open \u00b6 open(self) \u2011> None 1 2 3 4 5 6 7 8 9 10 Open the scrapli connection Args: N/A Returns: None Raises: N/A","title":"Sync Driver"},{"location":"api_docs/driver/base/sync_driver/#module-scraplidriverbasesync_driver","text":"scrapli.driver.base.sync_driver Expand source code \"\"\"scrapli.driver.base.sync_driver\"\"\" from types import TracebackType from typing import Any, Optional, Type, TypeVar from scrapli.channel import Channel from scrapli.driver.base.base_driver import BaseDriver from scrapli.exceptions import ScrapliValueError from scrapli.transport import ASYNCIO_TRANSPORTS _T = TypeVar(\"_T\", bound=\"Driver\") class Driver(BaseDriver): def __init__(self, **kwargs: Any): super().__init__(**kwargs) if self.transport_name in ASYNCIO_TRANSPORTS: raise ScrapliValueError( \"provided transport is *not* an sync transport, must use an sync transport with\" \" the (sync)Driver(s)\" ) self.channel = Channel( transport=self.transport, base_channel_args=self._base_channel_args, ) def __enter__(self: _T) -> _T: \"\"\" Enter method for context manager Args: N/A Returns: _T: a concrete implementation of the opened Driver object Raises: N/A \"\"\" self.open() return self def __exit__( self, exception_type: Optional[Type[BaseException]], exception_value: Optional[BaseException], traceback: Optional[TracebackType], ) -> None: \"\"\" Exit method to cleanup for context manager Args: exception_type: exception type being raised exception_value: message from exception being raised traceback: traceback from exception being raised Returns: None Raises: N/A \"\"\" self.close() def open(self) -> None: \"\"\" Open the scrapli connection Args: N/A Returns: None Raises: N/A \"\"\" self._pre_open_closing_log(closing=False) self.transport.open() self.channel.open() if self.transport_name in (\"system\",) and not self.auth_bypass: self.channel.channel_authenticate_ssh( auth_password=self.auth_password, auth_private_key_passphrase=self.auth_private_key_passphrase, ) if ( self.transport_name in ( \"telnet\", \"asynctelnet\", ) and not self.auth_bypass ): self.channel.channel_authenticate_telnet( auth_username=self.auth_username, auth_password=self.auth_password ) if self.on_open: self.on_open(self) self._post_open_closing_log(closing=False) def close(self) -> None: \"\"\" Close the scrapli connection Args: N/A Returns: None Raises: N/A \"\"\" self._pre_open_closing_log(closing=True) if self.on_close: self.on_close(self) self.transport.close() self.channel.close() self._post_open_closing_log(closing=True) def commandeer(self, conn: \"Driver\", execute_on_open: bool = True) -> None: \"\"\" Commandeer an existing connection Used to \"take over\" or \"commandeer\" a connection. This method accepts a second scrapli conn object and \"steals\" the transport from this connection and uses it for the current instance. The primary reason you would want this is to use a `GenericDriver` to connect to a console server and then to \"commandeer\" that connection and convert it to a \"normal\" network driver connection type (i.e. Junos, EOS, etc.) once connected to the network device (via the console server). Right now closing the connection that \"commandeers\" the initial connection will *also close the original connection* -- this is because we are re-using the transport in this new conn. In the future perhaps this will change to *not* close the original connection so users can handle any type of cleanup operations that need to happen on the original connection. Alternatively, you can simply continue using the \"original\" connection to close things for yourself or do any type of clean up work (just dont close the commandeering connection!). Args: conn: connection to commandeer execute_on_open: execute the `on_open` function of the current object once the existing connection has been commandeered Returns: None Raises: N/A \"\"\" original_logger = conn.logger original_transport = conn.transport original_transport_logger = conn.transport.logger original_channel_logger = conn.channel.logger original_channel_channel_log = conn.channel.channel_log self.logger = original_logger self.channel.logger = original_channel_logger self.channel.transport = original_transport self.transport = original_transport self.transport.logger = original_transport_logger if original_channel_channel_log is not None: # if the original connection had a channel log we also commandeer that; note that when # the new connection is closed this will also close the channel log; see docstring. self.channel.channel_log = original_channel_channel_log if execute_on_open and self.on_open is not None: self.on_open(self)","title":"Module scrapli.driver.base.sync_driver"},{"location":"api_docs/driver/base/sync_driver/#classes","text":"","title":"Classes"},{"location":"api_docs/driver/base/sync_driver/#driver","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 BaseDriver Object BaseDriver is the root for all Scrapli driver classes. The synchronous and asyncio driver base driver classes can be used to provide a semi-pexpect like experience over top of whatever transport a user prefers. Generally, however, the base driver classes should not be used directly. It is best to use the GenericDriver (or AsyncGenericDriver) or NetworkDriver (or AsyncNetworkDriver) sub-classes of the base drivers. Args: host: host ip/name to connect to port: port to connect to auth_username: username for authentication auth_private_key: path to private key for authentication auth_private_key_passphrase: passphrase for decrypting ssh key if necessary auth_password: password for authentication auth_strict_key: strict host checking or not auth_bypass: bypass \"in channel\" authentication -- only supported with telnet, asynctelnet, and system transport plugins timeout_socket: timeout for establishing socket/initial connection in seconds timeout_transport: timeout for ssh|telnet transport in seconds timeout_ops: timeout for ssh channel operations comms_prompt_pattern: raw string regex pattern -- preferably use `^` and `$` anchors! this is the single most important attribute here! if this does not match a prompt, scrapli will not work! IMPORTANT: regex search uses multi-line + case insensitive flags. multi-line allows for highly reliably matching for prompts however we do NOT strip trailing whitespace for each line, so be sure to add '\\\\s?' or similar if your device needs that. This should be mostly sorted for you if using network drivers (i.e. `IOSXEDriver`). Lastly, the case insensitive is just a convenience factor so i can be lazy. comms_return_char: character to use to send returns to host ssh_config_file: string to path for ssh config file, True to use default ssh config file or False to ignore default ssh config file ssh_known_hosts_file: string to path for ssh known hosts file, True to use default known file locations. Only applicable/needed if `auth_strict_key` is set to True on_init: callable that accepts the class instance as its only argument. this callable, if provided, is executed as the last step of object instantiation -- its purpose is primarily to provide a mechanism for scrapli community platforms to have an easy way to modify initialization arguments/object attributes without needing to create a class that extends the driver, instead allowing the community platforms to simply build from the GenericDriver or NetworkDriver classes, and pass this callable to do things such as appending to a username (looking at you RouterOS!!). Note that this is *always* a synchronous function (even for asyncio drivers)! on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar transport: name of the transport plugin to use for the actual telnet/ssh/netconf connection. Available \"core\" transports are: - system - telnet - asynctelnet - ssh2 - paramiko - asyncssh Please see relevant transport plugin section for details. Additionally third party transport plugins may be available. transport_options: dictionary of options to pass to selected transport class; see docs for given transport class for details of what to pass here channel_lock: True/False to lock the channel (threading.Lock/asyncio.Lock) during any channel operations, defaults to False channel_log: True/False or a string path to a file of where to write out channel logs -- these are not \"logs\" in the normal logging module sense, but only the output that is read from the channel. In other words, the output of the channel log should look similar to what you would see as a human connecting to a device channel_log_mode: \"write\"|\"append\", all other values will raise ValueError, does what it sounds like it should by setting the channel log to the provided mode logging_uid: unique identifier (string) to associate to log messages; useful if you have multiple connections to the same device (i.e. one console, one ssh, or one to each supervisor module, etc.) Returns: None Raises: N/A Expand source code class Driver(BaseDriver): def __init__(self, **kwargs: Any): super().__init__(**kwargs) if self.transport_name in ASYNCIO_TRANSPORTS: raise ScrapliValueError( \"provided transport is *not* an sync transport, must use an sync transport with\" \" the (sync)Driver(s)\" ) self.channel = Channel( transport=self.transport, base_channel_args=self._base_channel_args, ) def __enter__(self: _T) -> _T: \"\"\" Enter method for context manager Args: N/A Returns: _T: a concrete implementation of the opened Driver object Raises: N/A \"\"\" self.open() return self def __exit__( self, exception_type: Optional[Type[BaseException]], exception_value: Optional[BaseException], traceback: Optional[TracebackType], ) -> None: \"\"\" Exit method to cleanup for context manager Args: exception_type: exception type being raised exception_value: message from exception being raised traceback: traceback from exception being raised Returns: None Raises: N/A \"\"\" self.close() def open(self) -> None: \"\"\" Open the scrapli connection Args: N/A Returns: None Raises: N/A \"\"\" self._pre_open_closing_log(closing=False) self.transport.open() self.channel.open() if self.transport_name in (\"system\",) and not self.auth_bypass: self.channel.channel_authenticate_ssh( auth_password=self.auth_password, auth_private_key_passphrase=self.auth_private_key_passphrase, ) if ( self.transport_name in ( \"telnet\", \"asynctelnet\", ) and not self.auth_bypass ): self.channel.channel_authenticate_telnet( auth_username=self.auth_username, auth_password=self.auth_password ) if self.on_open: self.on_open(self) self._post_open_closing_log(closing=False) def close(self) -> None: \"\"\" Close the scrapli connection Args: N/A Returns: None Raises: N/A \"\"\" self._pre_open_closing_log(closing=True) if self.on_close: self.on_close(self) self.transport.close() self.channel.close() self._post_open_closing_log(closing=True) def commandeer(self, conn: \"Driver\", execute_on_open: bool = True) -> None: \"\"\" Commandeer an existing connection Used to \"take over\" or \"commandeer\" a connection. This method accepts a second scrapli conn object and \"steals\" the transport from this connection and uses it for the current instance. The primary reason you would want this is to use a `GenericDriver` to connect to a console server and then to \"commandeer\" that connection and convert it to a \"normal\" network driver connection type (i.e. Junos, EOS, etc.) once connected to the network device (via the console server). Right now closing the connection that \"commandeers\" the initial connection will *also close the original connection* -- this is because we are re-using the transport in this new conn. In the future perhaps this will change to *not* close the original connection so users can handle any type of cleanup operations that need to happen on the original connection. Alternatively, you can simply continue using the \"original\" connection to close things for yourself or do any type of clean up work (just dont close the commandeering connection!). Args: conn: connection to commandeer execute_on_open: execute the `on_open` function of the current object once the existing connection has been commandeered Returns: None Raises: N/A \"\"\" original_logger = conn.logger original_transport = conn.transport original_transport_logger = conn.transport.logger original_channel_logger = conn.channel.logger original_channel_channel_log = conn.channel.channel_log self.logger = original_logger self.channel.logger = original_channel_logger self.channel.transport = original_transport self.transport = original_transport self.transport.logger = original_transport_logger if original_channel_channel_log is not None: # if the original connection had a channel log we also commandeer that; note that when # the new connection is closed this will also close the channel log; see docstring. self.channel.channel_log = original_channel_channel_log if execute_on_open and self.on_open is not None: self.on_open(self)","title":"Driver"},{"location":"api_docs/driver/base/sync_driver/#ancestors-in-mro","text":"scrapli.driver.base.base_driver.BaseDriver","title":"Ancestors (in MRO)"},{"location":"api_docs/driver/base/sync_driver/#descendants","text":"scrapli.driver.generic.sync_driver.GenericDriver","title":"Descendants"},{"location":"api_docs/driver/base/sync_driver/#methods","text":"","title":"Methods"},{"location":"api_docs/driver/base/sync_driver/#close","text":"close(self) \u2011> None 1 2 3 4 5 6 7 8 9 10 Close the scrapli connection Args: N/A Returns: None Raises: N/A","title":"close"},{"location":"api_docs/driver/base/sync_driver/#commandeer","text":"commandeer(self, conn: Driver, execute_on_open: bool = True) \u2011> None 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 Commandeer an existing connection Used to \"take over\" or \"commandeer\" a connection. This method accepts a second scrapli conn object and \"steals\" the transport from this connection and uses it for the current instance. The primary reason you would want this is to use a `GenericDriver` to connect to a console server and then to \"commandeer\" that connection and convert it to a \"normal\" network driver connection type (i.e. Junos, EOS, etc.) once connected to the network device (via the console server). Right now closing the connection that \"commandeers\" the initial connection will *also close the original connection* -- this is because we are re-using the transport in this new conn. In the future perhaps this will change to *not* close the original connection so users can handle any type of cleanup operations that need to happen on the original connection. Alternatively, you can simply continue using the \"original\" connection to close things for yourself or do any type of clean up work (just dont close the commandeering connection!). Args: conn: connection to commandeer execute_on_open: execute the `on_open` function of the current object once the existing connection has been commandeered Returns: None Raises: N/A","title":"commandeer"},{"location":"api_docs/driver/base/sync_driver/#open","text":"open(self) \u2011> None 1 2 3 4 5 6 7 8 9 10 Open the scrapli connection Args: N/A Returns: None Raises: N/A","title":"open"},{"location":"api_docs/driver/core/arista_eos/async_driver/","text":"window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting()) Module scrapli.driver.core.arista_eos.async_driver \u00b6 scrapli.driver.core.arista_eos.async_driver Expand source code \"\"\"scrapli.driver.core.arista_eos.async_driver\"\"\" from copy import deepcopy from io import BytesIO from typing import Any, Callable, Dict, List, Optional, Union from scrapli.driver import AsyncNetworkDriver from scrapli.driver.core.arista_eos.base_driver import FAILED_WHEN_CONTAINS, PRIVS, EOSDriverBase from scrapli.driver.network.base_driver import PrivilegeLevel async def eos_on_open(conn: AsyncNetworkDriver) -> None: \"\"\" AsyncEOSDriver default on_open callable Args: conn: NetworkDriver object Returns: None Raises: N/A \"\"\" await conn.acquire_priv(desired_priv=conn.default_desired_privilege_level) await conn.send_command(command=\"terminal length 0\") await conn.send_command(command=\"terminal width 32767\") async def eos_on_close(conn: AsyncNetworkDriver) -> None: \"\"\" AsyncEOSDriver default on_close callable Args: conn: NetworkDriver object Returns: None Raises: N/A \"\"\" await conn.acquire_priv(desired_priv=conn.default_desired_privilege_level) conn.channel.write(channel_input=\"exit\") conn.channel.send_return() class AsyncEOSDriver(AsyncNetworkDriver, EOSDriverBase): def __init__( self, host: str, privilege_levels: Optional[Dict[str, PrivilegeLevel]] = None, default_desired_privilege_level: str = \"privilege_exec\", port: Optional[int] = None, auth_username: str = \"\", auth_password: str = \"\", auth_private_key: str = \"\", auth_private_key_passphrase: str = \"\", auth_strict_key: bool = True, auth_bypass: bool = False, timeout_socket: float = 15.0, timeout_transport: float = 30.0, timeout_ops: float = 30.0, comms_return_char: str = \"\\n\", ssh_config_file: Union[str, bool] = False, ssh_known_hosts_file: Union[str, bool] = False, on_init: Optional[Callable[..., Any]] = None, on_open: Optional[Callable[..., Any]] = None, on_close: Optional[Callable[..., Any]] = None, transport: str = \"system\", transport_options: Optional[Dict[str, Any]] = None, channel_log: Union[str, bool, BytesIO] = False, channel_log_mode: str = \"write\", channel_lock: bool = False, logging_uid: str = \"\", auth_secondary: str = \"\", failed_when_contains: Optional[List[str]] = None, textfsm_platform: str = \"arista_eos\", genie_platform: str = \"\", ): \"\"\" AsyncEOSDriver Object Please see `scrapli.driver.base.base_driver.Driver` for all \"base driver\" arguments! # noqa: DAR101 Args: privilege_levels: optional user provided privilege levels, if left None will default to scrapli standard privilege levels default_desired_privilege_level: string of name of default desired priv, this is the priv level that is generally used to disable paging/set terminal width and things like that upon first login, and is also the priv level scrapli will try to acquire for normal \"command\" operations (`send_command`, `send_commands`) auth_secondary: password to use for secondary authentication (enable) on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar. textfsm_platform: string name of textfsm parser platform genie_platform: string name of cisco genie parser platform failed_when_contains: List of strings that indicate a command/config has failed Returns: None Raises: N/A \"\"\" # somewhere/somehow the mixin is causing mypy to be upset about comms_prompt_pattern... self.comms_prompt_pattern: str if privilege_levels is None: privilege_levels = deepcopy(PRIVS) if on_open is None: on_open = eos_on_open if on_close is None: on_close = eos_on_close if failed_when_contains is None: failed_when_contains = FAILED_WHEN_CONTAINS.copy() super().__init__( host=host, port=port, auth_username=auth_username, auth_password=auth_password, auth_private_key=auth_private_key, auth_private_key_passphrase=auth_private_key_passphrase, auth_strict_key=auth_strict_key, auth_bypass=auth_bypass, timeout_socket=timeout_socket, timeout_transport=timeout_transport, timeout_ops=timeout_ops, comms_return_char=comms_return_char, ssh_config_file=ssh_config_file, ssh_known_hosts_file=ssh_known_hosts_file, on_init=on_init, on_open=on_open, on_close=on_close, transport=transport, transport_options=transport_options, channel_log=channel_log, channel_log_mode=channel_log_mode, channel_lock=channel_lock, logging_uid=logging_uid, privilege_levels=privilege_levels, default_desired_privilege_level=default_desired_privilege_level, auth_secondary=auth_secondary, failed_when_contains=failed_when_contains, textfsm_platform=textfsm_platform, genie_platform=genie_platform, ) async def _abort_config(self) -> None: \"\"\" Abort EOS configuration session (if using a config session!) Args: N/A Returns: None Raises: N/A \"\"\" # eos pattern for config sessions should *always* have `config-s` if \"config\\\\-s\" in self._current_priv_level.pattern: await self.channel.send_input(channel_input=\"abort\") self._current_priv_level = self.privilege_levels[\"privilege_exec\"] def register_configuration_session(self, session_name: str) -> None: \"\"\" Register EOS configuration session Args: session_name: name of config session to register Returns: None Raises: N/A \"\"\" self._create_configuration_session(session_name=session_name) self.update_privilege_levels() Functions \u00b6 eos_on_close \u00b6 eos_on_close(conn: scrapli.driver.network.async_driver.AsyncNetworkDriver) \u2011> None 1 2 3 4 5 6 7 8 9 10 AsyncEOSDriver default on_close callable Args: conn: NetworkDriver object Returns: None Raises: N/A eos_on_open \u00b6 eos_on_open(conn: scrapli.driver.network.async_driver.AsyncNetworkDriver) \u2011> None 1 2 3 4 5 6 7 8 9 10 AsyncEOSDriver default on_open callable Args: conn: NetworkDriver object Returns: None Raises: N/A Classes \u00b6 AsyncEOSDriver \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 AsyncEOSDriver Object Please see `scrapli.driver.base.base_driver.Driver` for all \"base driver\" arguments! # noqa: DAR101 Args: privilege_levels: optional user provided privilege levels, if left None will default to scrapli standard privilege levels default_desired_privilege_level: string of name of default desired priv, this is the priv level that is generally used to disable paging/set terminal width and things like that upon first login, and is also the priv level scrapli will try to acquire for normal \"command\" operations (`send_command`, `send_commands`) auth_secondary: password to use for secondary authentication (enable) on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar. textfsm_platform: string name of textfsm parser platform genie_platform: string name of cisco genie parser platform failed_when_contains: List of strings that indicate a command/config has failed Returns: None Raises: N/A Expand source code class AsyncEOSDriver(AsyncNetworkDriver, EOSDriverBase): def __init__( self, host: str, privilege_levels: Optional[Dict[str, PrivilegeLevel]] = None, default_desired_privilege_level: str = \"privilege_exec\", port: Optional[int] = None, auth_username: str = \"\", auth_password: str = \"\", auth_private_key: str = \"\", auth_private_key_passphrase: str = \"\", auth_strict_key: bool = True, auth_bypass: bool = False, timeout_socket: float = 15.0, timeout_transport: float = 30.0, timeout_ops: float = 30.0, comms_return_char: str = \"\\n\", ssh_config_file: Union[str, bool] = False, ssh_known_hosts_file: Union[str, bool] = False, on_init: Optional[Callable[..., Any]] = None, on_open: Optional[Callable[..., Any]] = None, on_close: Optional[Callable[..., Any]] = None, transport: str = \"system\", transport_options: Optional[Dict[str, Any]] = None, channel_log: Union[str, bool, BytesIO] = False, channel_log_mode: str = \"write\", channel_lock: bool = False, logging_uid: str = \"\", auth_secondary: str = \"\", failed_when_contains: Optional[List[str]] = None, textfsm_platform: str = \"arista_eos\", genie_platform: str = \"\", ): \"\"\" AsyncEOSDriver Object Please see `scrapli.driver.base.base_driver.Driver` for all \"base driver\" arguments! # noqa: DAR101 Args: privilege_levels: optional user provided privilege levels, if left None will default to scrapli standard privilege levels default_desired_privilege_level: string of name of default desired priv, this is the priv level that is generally used to disable paging/set terminal width and things like that upon first login, and is also the priv level scrapli will try to acquire for normal \"command\" operations (`send_command`, `send_commands`) auth_secondary: password to use for secondary authentication (enable) on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar. textfsm_platform: string name of textfsm parser platform genie_platform: string name of cisco genie parser platform failed_when_contains: List of strings that indicate a command/config has failed Returns: None Raises: N/A \"\"\" # somewhere/somehow the mixin is causing mypy to be upset about comms_prompt_pattern... self.comms_prompt_pattern: str if privilege_levels is None: privilege_levels = deepcopy(PRIVS) if on_open is None: on_open = eos_on_open if on_close is None: on_close = eos_on_close if failed_when_contains is None: failed_when_contains = FAILED_WHEN_CONTAINS.copy() super().__init__( host=host, port=port, auth_username=auth_username, auth_password=auth_password, auth_private_key=auth_private_key, auth_private_key_passphrase=auth_private_key_passphrase, auth_strict_key=auth_strict_key, auth_bypass=auth_bypass, timeout_socket=timeout_socket, timeout_transport=timeout_transport, timeout_ops=timeout_ops, comms_return_char=comms_return_char, ssh_config_file=ssh_config_file, ssh_known_hosts_file=ssh_known_hosts_file, on_init=on_init, on_open=on_open, on_close=on_close, transport=transport, transport_options=transport_options, channel_log=channel_log, channel_log_mode=channel_log_mode, channel_lock=channel_lock, logging_uid=logging_uid, privilege_levels=privilege_levels, default_desired_privilege_level=default_desired_privilege_level, auth_secondary=auth_secondary, failed_when_contains=failed_when_contains, textfsm_platform=textfsm_platform, genie_platform=genie_platform, ) async def _abort_config(self) -> None: \"\"\" Abort EOS configuration session (if using a config session!) Args: N/A Returns: None Raises: N/A \"\"\" # eos pattern for config sessions should *always* have `config-s` if \"config\\\\-s\" in self._current_priv_level.pattern: await self.channel.send_input(channel_input=\"abort\") self._current_priv_level = self.privilege_levels[\"privilege_exec\"] def register_configuration_session(self, session_name: str) -> None: \"\"\" Register EOS configuration session Args: session_name: name of config session to register Returns: None Raises: N/A \"\"\" self._create_configuration_session(session_name=session_name) self.update_privilege_levels() Ancestors (in MRO) \u00b6 scrapli.driver.network.async_driver.AsyncNetworkDriver scrapli.driver.generic.async_driver.AsyncGenericDriver scrapli.driver.base.async_driver.AsyncDriver scrapli.driver.base.base_driver.BaseDriver scrapli.driver.generic.base_driver.BaseGenericDriver scrapli.driver.network.base_driver.BaseNetworkDriver scrapli.driver.core.arista_eos.base_driver.EOSDriverBase Methods \u00b6 register_configuration_session \u00b6 register_configuration_session(self, session_name: str) \u2011> None 1 2 3 4 5 6 7 8 9 10 Register EOS configuration session Args: session_name: name of config session to register Returns: None Raises: N/A","title":"Async Driver"},{"location":"api_docs/driver/core/arista_eos/async_driver/#module-scraplidrivercorearista_eosasync_driver","text":"scrapli.driver.core.arista_eos.async_driver Expand source code \"\"\"scrapli.driver.core.arista_eos.async_driver\"\"\" from copy import deepcopy from io import BytesIO from typing import Any, Callable, Dict, List, Optional, Union from scrapli.driver import AsyncNetworkDriver from scrapli.driver.core.arista_eos.base_driver import FAILED_WHEN_CONTAINS, PRIVS, EOSDriverBase from scrapli.driver.network.base_driver import PrivilegeLevel async def eos_on_open(conn: AsyncNetworkDriver) -> None: \"\"\" AsyncEOSDriver default on_open callable Args: conn: NetworkDriver object Returns: None Raises: N/A \"\"\" await conn.acquire_priv(desired_priv=conn.default_desired_privilege_level) await conn.send_command(command=\"terminal length 0\") await conn.send_command(command=\"terminal width 32767\") async def eos_on_close(conn: AsyncNetworkDriver) -> None: \"\"\" AsyncEOSDriver default on_close callable Args: conn: NetworkDriver object Returns: None Raises: N/A \"\"\" await conn.acquire_priv(desired_priv=conn.default_desired_privilege_level) conn.channel.write(channel_input=\"exit\") conn.channel.send_return() class AsyncEOSDriver(AsyncNetworkDriver, EOSDriverBase): def __init__( self, host: str, privilege_levels: Optional[Dict[str, PrivilegeLevel]] = None, default_desired_privilege_level: str = \"privilege_exec\", port: Optional[int] = None, auth_username: str = \"\", auth_password: str = \"\", auth_private_key: str = \"\", auth_private_key_passphrase: str = \"\", auth_strict_key: bool = True, auth_bypass: bool = False, timeout_socket: float = 15.0, timeout_transport: float = 30.0, timeout_ops: float = 30.0, comms_return_char: str = \"\\n\", ssh_config_file: Union[str, bool] = False, ssh_known_hosts_file: Union[str, bool] = False, on_init: Optional[Callable[..., Any]] = None, on_open: Optional[Callable[..., Any]] = None, on_close: Optional[Callable[..., Any]] = None, transport: str = \"system\", transport_options: Optional[Dict[str, Any]] = None, channel_log: Union[str, bool, BytesIO] = False, channel_log_mode: str = \"write\", channel_lock: bool = False, logging_uid: str = \"\", auth_secondary: str = \"\", failed_when_contains: Optional[List[str]] = None, textfsm_platform: str = \"arista_eos\", genie_platform: str = \"\", ): \"\"\" AsyncEOSDriver Object Please see `scrapli.driver.base.base_driver.Driver` for all \"base driver\" arguments! # noqa: DAR101 Args: privilege_levels: optional user provided privilege levels, if left None will default to scrapli standard privilege levels default_desired_privilege_level: string of name of default desired priv, this is the priv level that is generally used to disable paging/set terminal width and things like that upon first login, and is also the priv level scrapli will try to acquire for normal \"command\" operations (`send_command`, `send_commands`) auth_secondary: password to use for secondary authentication (enable) on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar. textfsm_platform: string name of textfsm parser platform genie_platform: string name of cisco genie parser platform failed_when_contains: List of strings that indicate a command/config has failed Returns: None Raises: N/A \"\"\" # somewhere/somehow the mixin is causing mypy to be upset about comms_prompt_pattern... self.comms_prompt_pattern: str if privilege_levels is None: privilege_levels = deepcopy(PRIVS) if on_open is None: on_open = eos_on_open if on_close is None: on_close = eos_on_close if failed_when_contains is None: failed_when_contains = FAILED_WHEN_CONTAINS.copy() super().__init__( host=host, port=port, auth_username=auth_username, auth_password=auth_password, auth_private_key=auth_private_key, auth_private_key_passphrase=auth_private_key_passphrase, auth_strict_key=auth_strict_key, auth_bypass=auth_bypass, timeout_socket=timeout_socket, timeout_transport=timeout_transport, timeout_ops=timeout_ops, comms_return_char=comms_return_char, ssh_config_file=ssh_config_file, ssh_known_hosts_file=ssh_known_hosts_file, on_init=on_init, on_open=on_open, on_close=on_close, transport=transport, transport_options=transport_options, channel_log=channel_log, channel_log_mode=channel_log_mode, channel_lock=channel_lock, logging_uid=logging_uid, privilege_levels=privilege_levels, default_desired_privilege_level=default_desired_privilege_level, auth_secondary=auth_secondary, failed_when_contains=failed_when_contains, textfsm_platform=textfsm_platform, genie_platform=genie_platform, ) async def _abort_config(self) -> None: \"\"\" Abort EOS configuration session (if using a config session!) Args: N/A Returns: None Raises: N/A \"\"\" # eos pattern for config sessions should *always* have `config-s` if \"config\\\\-s\" in self._current_priv_level.pattern: await self.channel.send_input(channel_input=\"abort\") self._current_priv_level = self.privilege_levels[\"privilege_exec\"] def register_configuration_session(self, session_name: str) -> None: \"\"\" Register EOS configuration session Args: session_name: name of config session to register Returns: None Raises: N/A \"\"\" self._create_configuration_session(session_name=session_name) self.update_privilege_levels()","title":"Module scrapli.driver.core.arista_eos.async_driver"},{"location":"api_docs/driver/core/arista_eos/async_driver/#functions","text":"","title":"Functions"},{"location":"api_docs/driver/core/arista_eos/async_driver/#eos_on_close","text":"eos_on_close(conn: scrapli.driver.network.async_driver.AsyncNetworkDriver) \u2011> None 1 2 3 4 5 6 7 8 9 10 AsyncEOSDriver default on_close callable Args: conn: NetworkDriver object Returns: None Raises: N/A","title":"eos_on_close"},{"location":"api_docs/driver/core/arista_eos/async_driver/#eos_on_open","text":"eos_on_open(conn: scrapli.driver.network.async_driver.AsyncNetworkDriver) \u2011> None 1 2 3 4 5 6 7 8 9 10 AsyncEOSDriver default on_open callable Args: conn: NetworkDriver object Returns: None Raises: N/A","title":"eos_on_open"},{"location":"api_docs/driver/core/arista_eos/async_driver/#classes","text":"","title":"Classes"},{"location":"api_docs/driver/core/arista_eos/async_driver/#asynceosdriver","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 AsyncEOSDriver Object Please see `scrapli.driver.base.base_driver.Driver` for all \"base driver\" arguments! # noqa: DAR101 Args: privilege_levels: optional user provided privilege levels, if left None will default to scrapli standard privilege levels default_desired_privilege_level: string of name of default desired priv, this is the priv level that is generally used to disable paging/set terminal width and things like that upon first login, and is also the priv level scrapli will try to acquire for normal \"command\" operations (`send_command`, `send_commands`) auth_secondary: password to use for secondary authentication (enable) on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar. textfsm_platform: string name of textfsm parser platform genie_platform: string name of cisco genie parser platform failed_when_contains: List of strings that indicate a command/config has failed Returns: None Raises: N/A Expand source code class AsyncEOSDriver(AsyncNetworkDriver, EOSDriverBase): def __init__( self, host: str, privilege_levels: Optional[Dict[str, PrivilegeLevel]] = None, default_desired_privilege_level: str = \"privilege_exec\", port: Optional[int] = None, auth_username: str = \"\", auth_password: str = \"\", auth_private_key: str = \"\", auth_private_key_passphrase: str = \"\", auth_strict_key: bool = True, auth_bypass: bool = False, timeout_socket: float = 15.0, timeout_transport: float = 30.0, timeout_ops: float = 30.0, comms_return_char: str = \"\\n\", ssh_config_file: Union[str, bool] = False, ssh_known_hosts_file: Union[str, bool] = False, on_init: Optional[Callable[..., Any]] = None, on_open: Optional[Callable[..., Any]] = None, on_close: Optional[Callable[..., Any]] = None, transport: str = \"system\", transport_options: Optional[Dict[str, Any]] = None, channel_log: Union[str, bool, BytesIO] = False, channel_log_mode: str = \"write\", channel_lock: bool = False, logging_uid: str = \"\", auth_secondary: str = \"\", failed_when_contains: Optional[List[str]] = None, textfsm_platform: str = \"arista_eos\", genie_platform: str = \"\", ): \"\"\" AsyncEOSDriver Object Please see `scrapli.driver.base.base_driver.Driver` for all \"base driver\" arguments! # noqa: DAR101 Args: privilege_levels: optional user provided privilege levels, if left None will default to scrapli standard privilege levels default_desired_privilege_level: string of name of default desired priv, this is the priv level that is generally used to disable paging/set terminal width and things like that upon first login, and is also the priv level scrapli will try to acquire for normal \"command\" operations (`send_command`, `send_commands`) auth_secondary: password to use for secondary authentication (enable) on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar. textfsm_platform: string name of textfsm parser platform genie_platform: string name of cisco genie parser platform failed_when_contains: List of strings that indicate a command/config has failed Returns: None Raises: N/A \"\"\" # somewhere/somehow the mixin is causing mypy to be upset about comms_prompt_pattern... self.comms_prompt_pattern: str if privilege_levels is None: privilege_levels = deepcopy(PRIVS) if on_open is None: on_open = eos_on_open if on_close is None: on_close = eos_on_close if failed_when_contains is None: failed_when_contains = FAILED_WHEN_CONTAINS.copy() super().__init__( host=host, port=port, auth_username=auth_username, auth_password=auth_password, auth_private_key=auth_private_key, auth_private_key_passphrase=auth_private_key_passphrase, auth_strict_key=auth_strict_key, auth_bypass=auth_bypass, timeout_socket=timeout_socket, timeout_transport=timeout_transport, timeout_ops=timeout_ops, comms_return_char=comms_return_char, ssh_config_file=ssh_config_file, ssh_known_hosts_file=ssh_known_hosts_file, on_init=on_init, on_open=on_open, on_close=on_close, transport=transport, transport_options=transport_options, channel_log=channel_log, channel_log_mode=channel_log_mode, channel_lock=channel_lock, logging_uid=logging_uid, privilege_levels=privilege_levels, default_desired_privilege_level=default_desired_privilege_level, auth_secondary=auth_secondary, failed_when_contains=failed_when_contains, textfsm_platform=textfsm_platform, genie_platform=genie_platform, ) async def _abort_config(self) -> None: \"\"\" Abort EOS configuration session (if using a config session!) Args: N/A Returns: None Raises: N/A \"\"\" # eos pattern for config sessions should *always* have `config-s` if \"config\\\\-s\" in self._current_priv_level.pattern: await self.channel.send_input(channel_input=\"abort\") self._current_priv_level = self.privilege_levels[\"privilege_exec\"] def register_configuration_session(self, session_name: str) -> None: \"\"\" Register EOS configuration session Args: session_name: name of config session to register Returns: None Raises: N/A \"\"\" self._create_configuration_session(session_name=session_name) self.update_privilege_levels()","title":"AsyncEOSDriver"},{"location":"api_docs/driver/core/arista_eos/async_driver/#ancestors-in-mro","text":"scrapli.driver.network.async_driver.AsyncNetworkDriver scrapli.driver.generic.async_driver.AsyncGenericDriver scrapli.driver.base.async_driver.AsyncDriver scrapli.driver.base.base_driver.BaseDriver scrapli.driver.generic.base_driver.BaseGenericDriver scrapli.driver.network.base_driver.BaseNetworkDriver scrapli.driver.core.arista_eos.base_driver.EOSDriverBase","title":"Ancestors (in MRO)"},{"location":"api_docs/driver/core/arista_eos/async_driver/#methods","text":"","title":"Methods"},{"location":"api_docs/driver/core/arista_eos/async_driver/#register_configuration_session","text":"register_configuration_session(self, session_name: str) \u2011> None 1 2 3 4 5 6 7 8 9 10 Register EOS configuration session Args: session_name: name of config session to register Returns: None Raises: N/A","title":"register_configuration_session"},{"location":"api_docs/driver/core/arista_eos/base_driver/","text":"window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting()) Module scrapli.driver.core.arista_eos.base_driver \u00b6 scrapli.driver.core.arista_eos.base_driver Expand source code \"\"\"scrapli.driver.core.arista_eos.base_driver\"\"\" import re from typing import Dict from scrapli.driver.network.base_driver import PrivilegeLevel from scrapli.exceptions import ScrapliValueError PRIVS = { \"exec\": ( PrivilegeLevel( pattern=r\"^[\\w.\\-@()/: ]{1,63}>\\s?$\", name=\"exec\", previous_priv=\"\", deescalate=\"\", escalate=\"\", escalate_auth=False, escalate_prompt=\"\", ) ), \"privilege_exec\": ( PrivilegeLevel( pattern=r\"^[\\w.\\-@()/: ]{1,63}#\\s?$\", name=\"privilege_exec\", previous_priv=\"exec\", deescalate=\"disable\", escalate=\"enable\", escalate_auth=True, escalate_prompt=r\"^[pP]assword:\\s?$\", not_contains=[\"(config\"], ) ), \"configuration\": ( PrivilegeLevel( pattern=r\"^[\\w.\\-@()/: ]{1,63}\\(config[\\w.\\-@/:]{0,32}\\)#\\s?$\", name=\"configuration\", previous_priv=\"privilege_exec\", deescalate=\"end\", escalate=\"configure terminal\", escalate_auth=False, escalate_prompt=\"\", not_contains=[\"(config-s-\"], ) ), } FAILED_WHEN_CONTAINS = [ \"% Ambiguous command\", \"% Error\", \"% Incomplete command\", \"% Invalid input\", \"% Cannot commit\", \"% Unavailable command\", ] class EOSDriverBase: # EOSDriverBase Mixin values set in init of sync/async NetworkDriver classes privilege_levels: Dict[str, PrivilegeLevel] def _create_configuration_session(self, session_name: str) -> None: \"\"\" Handle configuration session creation tasks for consistency between sync/async versions Args: session_name: name of session to register Returns: None Raises: ScrapliValueError: if a session of given name already exists \"\"\" if session_name in self.privilege_levels.keys(): msg = ( f\"session name `{session_name}` already registered as a privilege level, chose a \" \"unique session name\" ) raise ScrapliValueError(msg) sess_prompt = re.escape(session_name[:6]) pattern = ( rf\"^[a-z0-9.\\-@()/: ]{{1,63}}\\(config\\-s\\-{sess_prompt}[a-z0-9_.\\-@/:]{{0,32}}\\)#\\s?$\" ) name = session_name config_session = PrivilegeLevel( pattern=pattern, name=name, previous_priv=\"privilege_exec\", deescalate=\"end\", escalate=f\"configure session {session_name}\", escalate_auth=False, escalate_prompt=\"\", ) self.privilege_levels[name] = config_session Classes \u00b6 EOSDriverBase \u00b6 Expand source code class EOSDriverBase: # EOSDriverBase Mixin values set in init of sync/async NetworkDriver classes privilege_levels: Dict[str, PrivilegeLevel] def _create_configuration_session(self, session_name: str) -> None: \"\"\" Handle configuration session creation tasks for consistency between sync/async versions Args: session_name: name of session to register Returns: None Raises: ScrapliValueError: if a session of given name already exists \"\"\" if session_name in self.privilege_levels.keys(): msg = ( f\"session name `{session_name}` already registered as a privilege level, chose a \" \"unique session name\" ) raise ScrapliValueError(msg) sess_prompt = re.escape(session_name[:6]) pattern = ( rf\"^[a-z0-9.\\-@()/: ]{{1,63}}\\(config\\-s\\-{sess_prompt}[a-z0-9_.\\-@/:]{{0,32}}\\)#\\s?$\" ) name = session_name config_session = PrivilegeLevel( pattern=pattern, name=name, previous_priv=\"privilege_exec\", deescalate=\"end\", escalate=f\"configure session {session_name}\", escalate_auth=False, escalate_prompt=\"\", ) self.privilege_levels[name] = config_session Descendants \u00b6 scrapli.driver.core.arista_eos.async_driver.AsyncEOSDriver scrapli.driver.core.arista_eos.sync_driver.EOSDriver Class variables \u00b6 privilege_levels: Dict[str, scrapli.driver.network.base_driver.PrivilegeLevel]","title":"Base Driver"},{"location":"api_docs/driver/core/arista_eos/base_driver/#module-scraplidrivercorearista_eosbase_driver","text":"scrapli.driver.core.arista_eos.base_driver Expand source code \"\"\"scrapli.driver.core.arista_eos.base_driver\"\"\" import re from typing import Dict from scrapli.driver.network.base_driver import PrivilegeLevel from scrapli.exceptions import ScrapliValueError PRIVS = { \"exec\": ( PrivilegeLevel( pattern=r\"^[\\w.\\-@()/: ]{1,63}>\\s?$\", name=\"exec\", previous_priv=\"\", deescalate=\"\", escalate=\"\", escalate_auth=False, escalate_prompt=\"\", ) ), \"privilege_exec\": ( PrivilegeLevel( pattern=r\"^[\\w.\\-@()/: ]{1,63}#\\s?$\", name=\"privilege_exec\", previous_priv=\"exec\", deescalate=\"disable\", escalate=\"enable\", escalate_auth=True, escalate_prompt=r\"^[pP]assword:\\s?$\", not_contains=[\"(config\"], ) ), \"configuration\": ( PrivilegeLevel( pattern=r\"^[\\w.\\-@()/: ]{1,63}\\(config[\\w.\\-@/:]{0,32}\\)#\\s?$\", name=\"configuration\", previous_priv=\"privilege_exec\", deescalate=\"end\", escalate=\"configure terminal\", escalate_auth=False, escalate_prompt=\"\", not_contains=[\"(config-s-\"], ) ), } FAILED_WHEN_CONTAINS = [ \"% Ambiguous command\", \"% Error\", \"% Incomplete command\", \"% Invalid input\", \"% Cannot commit\", \"% Unavailable command\", ] class EOSDriverBase: # EOSDriverBase Mixin values set in init of sync/async NetworkDriver classes privilege_levels: Dict[str, PrivilegeLevel] def _create_configuration_session(self, session_name: str) -> None: \"\"\" Handle configuration session creation tasks for consistency between sync/async versions Args: session_name: name of session to register Returns: None Raises: ScrapliValueError: if a session of given name already exists \"\"\" if session_name in self.privilege_levels.keys(): msg = ( f\"session name `{session_name}` already registered as a privilege level, chose a \" \"unique session name\" ) raise ScrapliValueError(msg) sess_prompt = re.escape(session_name[:6]) pattern = ( rf\"^[a-z0-9.\\-@()/: ]{{1,63}}\\(config\\-s\\-{sess_prompt}[a-z0-9_.\\-@/:]{{0,32}}\\)#\\s?$\" ) name = session_name config_session = PrivilegeLevel( pattern=pattern, name=name, previous_priv=\"privilege_exec\", deescalate=\"end\", escalate=f\"configure session {session_name}\", escalate_auth=False, escalate_prompt=\"\", ) self.privilege_levels[name] = config_session","title":"Module scrapli.driver.core.arista_eos.base_driver"},{"location":"api_docs/driver/core/arista_eos/base_driver/#classes","text":"","title":"Classes"},{"location":"api_docs/driver/core/arista_eos/base_driver/#eosdriverbase","text":"Expand source code class EOSDriverBase: # EOSDriverBase Mixin values set in init of sync/async NetworkDriver classes privilege_levels: Dict[str, PrivilegeLevel] def _create_configuration_session(self, session_name: str) -> None: \"\"\" Handle configuration session creation tasks for consistency between sync/async versions Args: session_name: name of session to register Returns: None Raises: ScrapliValueError: if a session of given name already exists \"\"\" if session_name in self.privilege_levels.keys(): msg = ( f\"session name `{session_name}` already registered as a privilege level, chose a \" \"unique session name\" ) raise ScrapliValueError(msg) sess_prompt = re.escape(session_name[:6]) pattern = ( rf\"^[a-z0-9.\\-@()/: ]{{1,63}}\\(config\\-s\\-{sess_prompt}[a-z0-9_.\\-@/:]{{0,32}}\\)#\\s?$\" ) name = session_name config_session = PrivilegeLevel( pattern=pattern, name=name, previous_priv=\"privilege_exec\", deescalate=\"end\", escalate=f\"configure session {session_name}\", escalate_auth=False, escalate_prompt=\"\", ) self.privilege_levels[name] = config_session","title":"EOSDriverBase"},{"location":"api_docs/driver/core/arista_eos/base_driver/#descendants","text":"scrapli.driver.core.arista_eos.async_driver.AsyncEOSDriver scrapli.driver.core.arista_eos.sync_driver.EOSDriver","title":"Descendants"},{"location":"api_docs/driver/core/arista_eos/base_driver/#class-variables","text":"privilege_levels: Dict[str, scrapli.driver.network.base_driver.PrivilegeLevel]","title":"Class variables"},{"location":"api_docs/driver/core/arista_eos/sync_driver/","text":"window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting()) Module scrapli.driver.core.arista_eos.sync_driver \u00b6 scrapli.driver.core.arista_eos.sync_driver Expand source code \"\"\"scrapli.driver.core.arista_eos.sync_driver\"\"\" from copy import deepcopy from io import BytesIO from typing import Any, Callable, Dict, List, Optional, Union from scrapli.driver import NetworkDriver from scrapli.driver.core.arista_eos.base_driver import FAILED_WHEN_CONTAINS, PRIVS, EOSDriverBase from scrapli.driver.network.base_driver import PrivilegeLevel def eos_on_open(conn: NetworkDriver) -> None: \"\"\" EOSDriver default on_open callable Args: conn: NetworkDriver object Returns: None Raises: N/A \"\"\" conn.acquire_priv(desired_priv=conn.default_desired_privilege_level) conn.channel.send_input(channel_input=\"terminal length 0\") conn.channel.send_input(channel_input=\"terminal width 32767\") def eos_on_close(conn: NetworkDriver) -> None: \"\"\" EOSDriver default on_close callable Args: conn: NetworkDriver object Returns: None Raises: N/A \"\"\" conn.acquire_priv(desired_priv=conn.default_desired_privilege_level) conn.channel.write(channel_input=\"exit\") conn.channel.send_return() class EOSDriver(NetworkDriver, EOSDriverBase): def __init__( self, host: str, privilege_levels: Optional[Dict[str, PrivilegeLevel]] = None, default_desired_privilege_level: str = \"privilege_exec\", port: Optional[int] = None, auth_username: str = \"\", auth_password: str = \"\", auth_private_key: str = \"\", auth_private_key_passphrase: str = \"\", auth_strict_key: bool = True, auth_bypass: bool = False, timeout_socket: float = 15.0, timeout_transport: float = 30.0, timeout_ops: float = 30.0, comms_return_char: str = \"\\n\", ssh_config_file: Union[str, bool] = False, ssh_known_hosts_file: Union[str, bool] = False, on_init: Optional[Callable[..., Any]] = None, on_open: Optional[Callable[..., Any]] = None, on_close: Optional[Callable[..., Any]] = None, transport: str = \"system\", transport_options: Optional[Dict[str, Any]] = None, channel_log: Union[str, bool, BytesIO] = False, channel_log_mode: str = \"write\", channel_lock: bool = False, logging_uid: str = \"\", auth_secondary: str = \"\", failed_when_contains: Optional[List[str]] = None, textfsm_platform: str = \"arista_eos\", genie_platform: str = \"\", ): \"\"\" EOSDriver Object Please see `scrapli.driver.base.base_driver.Driver` for all \"base driver\" arguments! # noqa: DAR101 Args: privilege_levels: optional user provided privilege levels, if left None will default to scrapli standard privilege levels default_desired_privilege_level: string of name of default desired priv, this is the priv level that is generally used to disable paging/set terminal width and things like that upon first login, and is also the priv level scrapli will try to acquire for normal \"command\" operations (`send_command`, `send_commands`) auth_secondary: password to use for secondary authentication (enable) on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar. textfsm_platform: string name of textfsm parser platform genie_platform: string name of cisco genie parser platform failed_when_contains: List of strings that indicate a command/config has failed Returns: None Raises: N/A \"\"\" # somewhere/somehow the mixin is causing mypy to be upset about comms_prompt_pattern... self.comms_prompt_pattern: str if privilege_levels is None: privilege_levels = deepcopy(PRIVS) if on_open is None: on_open = eos_on_open if on_close is None: on_close = eos_on_close if failed_when_contains is None: failed_when_contains = FAILED_WHEN_CONTAINS.copy() super().__init__( host=host, port=port, auth_username=auth_username, auth_password=auth_password, auth_private_key=auth_private_key, auth_private_key_passphrase=auth_private_key_passphrase, auth_strict_key=auth_strict_key, auth_bypass=auth_bypass, timeout_socket=timeout_socket, timeout_transport=timeout_transport, timeout_ops=timeout_ops, comms_return_char=comms_return_char, ssh_config_file=ssh_config_file, ssh_known_hosts_file=ssh_known_hosts_file, on_init=on_init, on_open=on_open, on_close=on_close, transport=transport, transport_options=transport_options, channel_log=channel_log, channel_log_mode=channel_log_mode, channel_lock=channel_lock, logging_uid=logging_uid, privilege_levels=privilege_levels, default_desired_privilege_level=default_desired_privilege_level, auth_secondary=auth_secondary, failed_when_contains=failed_when_contains, textfsm_platform=textfsm_platform, genie_platform=genie_platform, ) def _abort_config(self) -> None: \"\"\" Abort EOS configuration session (if using a config session!) Args: N/A Returns: None Raises: N/A \"\"\" # eos pattern for config sessions should *always* have `config-s` if \"config\\\\-s\" in self._current_priv_level.pattern: self.channel.send_input(channel_input=\"abort\") self._current_priv_level = self.privilege_levels[\"privilege_exec\"] def register_configuration_session(self, session_name: str) -> None: \"\"\" EOS specific implementation of register_configuration_session Args: session_name: name of session to register Returns: None Raises: N/A \"\"\" self._create_configuration_session(session_name=session_name) self.update_privilege_levels() Functions \u00b6 eos_on_close \u00b6 eos_on_close(conn: scrapli.driver.network.sync_driver.NetworkDriver) \u2011> None 1 2 3 4 5 6 7 8 9 10 EOSDriver default on_close callable Args: conn: NetworkDriver object Returns: None Raises: N/A eos_on_open \u00b6 eos_on_open(conn: scrapli.driver.network.sync_driver.NetworkDriver) \u2011> None 1 2 3 4 5 6 7 8 9 10 EOSDriver default on_open callable Args: conn: NetworkDriver object Returns: None Raises: N/A Classes \u00b6 EOSDriver \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 EOSDriver Object Please see `scrapli.driver.base.base_driver.Driver` for all \"base driver\" arguments! # noqa: DAR101 Args: privilege_levels: optional user provided privilege levels, if left None will default to scrapli standard privilege levels default_desired_privilege_level: string of name of default desired priv, this is the priv level that is generally used to disable paging/set terminal width and things like that upon first login, and is also the priv level scrapli will try to acquire for normal \"command\" operations (`send_command`, `send_commands`) auth_secondary: password to use for secondary authentication (enable) on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar. textfsm_platform: string name of textfsm parser platform genie_platform: string name of cisco genie parser platform failed_when_contains: List of strings that indicate a command/config has failed Returns: None Raises: N/A Expand source code class EOSDriver(NetworkDriver, EOSDriverBase): def __init__( self, host: str, privilege_levels: Optional[Dict[str, PrivilegeLevel]] = None, default_desired_privilege_level: str = \"privilege_exec\", port: Optional[int] = None, auth_username: str = \"\", auth_password: str = \"\", auth_private_key: str = \"\", auth_private_key_passphrase: str = \"\", auth_strict_key: bool = True, auth_bypass: bool = False, timeout_socket: float = 15.0, timeout_transport: float = 30.0, timeout_ops: float = 30.0, comms_return_char: str = \"\\n\", ssh_config_file: Union[str, bool] = False, ssh_known_hosts_file: Union[str, bool] = False, on_init: Optional[Callable[..., Any]] = None, on_open: Optional[Callable[..., Any]] = None, on_close: Optional[Callable[..., Any]] = None, transport: str = \"system\", transport_options: Optional[Dict[str, Any]] = None, channel_log: Union[str, bool, BytesIO] = False, channel_log_mode: str = \"write\", channel_lock: bool = False, logging_uid: str = \"\", auth_secondary: str = \"\", failed_when_contains: Optional[List[str]] = None, textfsm_platform: str = \"arista_eos\", genie_platform: str = \"\", ): \"\"\" EOSDriver Object Please see `scrapli.driver.base.base_driver.Driver` for all \"base driver\" arguments! # noqa: DAR101 Args: privilege_levels: optional user provided privilege levels, if left None will default to scrapli standard privilege levels default_desired_privilege_level: string of name of default desired priv, this is the priv level that is generally used to disable paging/set terminal width and things like that upon first login, and is also the priv level scrapli will try to acquire for normal \"command\" operations (`send_command`, `send_commands`) auth_secondary: password to use for secondary authentication (enable) on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar. textfsm_platform: string name of textfsm parser platform genie_platform: string name of cisco genie parser platform failed_when_contains: List of strings that indicate a command/config has failed Returns: None Raises: N/A \"\"\" # somewhere/somehow the mixin is causing mypy to be upset about comms_prompt_pattern... self.comms_prompt_pattern: str if privilege_levels is None: privilege_levels = deepcopy(PRIVS) if on_open is None: on_open = eos_on_open if on_close is None: on_close = eos_on_close if failed_when_contains is None: failed_when_contains = FAILED_WHEN_CONTAINS.copy() super().__init__( host=host, port=port, auth_username=auth_username, auth_password=auth_password, auth_private_key=auth_private_key, auth_private_key_passphrase=auth_private_key_passphrase, auth_strict_key=auth_strict_key, auth_bypass=auth_bypass, timeout_socket=timeout_socket, timeout_transport=timeout_transport, timeout_ops=timeout_ops, comms_return_char=comms_return_char, ssh_config_file=ssh_config_file, ssh_known_hosts_file=ssh_known_hosts_file, on_init=on_init, on_open=on_open, on_close=on_close, transport=transport, transport_options=transport_options, channel_log=channel_log, channel_log_mode=channel_log_mode, channel_lock=channel_lock, logging_uid=logging_uid, privilege_levels=privilege_levels, default_desired_privilege_level=default_desired_privilege_level, auth_secondary=auth_secondary, failed_when_contains=failed_when_contains, textfsm_platform=textfsm_platform, genie_platform=genie_platform, ) def _abort_config(self) -> None: \"\"\" Abort EOS configuration session (if using a config session!) Args: N/A Returns: None Raises: N/A \"\"\" # eos pattern for config sessions should *always* have `config-s` if \"config\\\\-s\" in self._current_priv_level.pattern: self.channel.send_input(channel_input=\"abort\") self._current_priv_level = self.privilege_levels[\"privilege_exec\"] def register_configuration_session(self, session_name: str) -> None: \"\"\" EOS specific implementation of register_configuration_session Args: session_name: name of session to register Returns: None Raises: N/A \"\"\" self._create_configuration_session(session_name=session_name) self.update_privilege_levels() Ancestors (in MRO) \u00b6 scrapli.driver.network.sync_driver.NetworkDriver scrapli.driver.generic.sync_driver.GenericDriver scrapli.driver.base.sync_driver.Driver scrapli.driver.base.base_driver.BaseDriver scrapli.driver.generic.base_driver.BaseGenericDriver scrapli.driver.network.base_driver.BaseNetworkDriver scrapli.driver.core.arista_eos.base_driver.EOSDriverBase Methods \u00b6 register_configuration_session \u00b6 register_configuration_session(self, session_name: str) \u2011> None 1 2 3 4 5 6 7 8 9 10 EOS specific implementation of register_configuration_session Args: session_name: name of session to register Returns: None Raises: N/A","title":"Sync Driver"},{"location":"api_docs/driver/core/arista_eos/sync_driver/#module-scraplidrivercorearista_eossync_driver","text":"scrapli.driver.core.arista_eos.sync_driver Expand source code \"\"\"scrapli.driver.core.arista_eos.sync_driver\"\"\" from copy import deepcopy from io import BytesIO from typing import Any, Callable, Dict, List, Optional, Union from scrapli.driver import NetworkDriver from scrapli.driver.core.arista_eos.base_driver import FAILED_WHEN_CONTAINS, PRIVS, EOSDriverBase from scrapli.driver.network.base_driver import PrivilegeLevel def eos_on_open(conn: NetworkDriver) -> None: \"\"\" EOSDriver default on_open callable Args: conn: NetworkDriver object Returns: None Raises: N/A \"\"\" conn.acquire_priv(desired_priv=conn.default_desired_privilege_level) conn.channel.send_input(channel_input=\"terminal length 0\") conn.channel.send_input(channel_input=\"terminal width 32767\") def eos_on_close(conn: NetworkDriver) -> None: \"\"\" EOSDriver default on_close callable Args: conn: NetworkDriver object Returns: None Raises: N/A \"\"\" conn.acquire_priv(desired_priv=conn.default_desired_privilege_level) conn.channel.write(channel_input=\"exit\") conn.channel.send_return() class EOSDriver(NetworkDriver, EOSDriverBase): def __init__( self, host: str, privilege_levels: Optional[Dict[str, PrivilegeLevel]] = None, default_desired_privilege_level: str = \"privilege_exec\", port: Optional[int] = None, auth_username: str = \"\", auth_password: str = \"\", auth_private_key: str = \"\", auth_private_key_passphrase: str = \"\", auth_strict_key: bool = True, auth_bypass: bool = False, timeout_socket: float = 15.0, timeout_transport: float = 30.0, timeout_ops: float = 30.0, comms_return_char: str = \"\\n\", ssh_config_file: Union[str, bool] = False, ssh_known_hosts_file: Union[str, bool] = False, on_init: Optional[Callable[..., Any]] = None, on_open: Optional[Callable[..., Any]] = None, on_close: Optional[Callable[..., Any]] = None, transport: str = \"system\", transport_options: Optional[Dict[str, Any]] = None, channel_log: Union[str, bool, BytesIO] = False, channel_log_mode: str = \"write\", channel_lock: bool = False, logging_uid: str = \"\", auth_secondary: str = \"\", failed_when_contains: Optional[List[str]] = None, textfsm_platform: str = \"arista_eos\", genie_platform: str = \"\", ): \"\"\" EOSDriver Object Please see `scrapli.driver.base.base_driver.Driver` for all \"base driver\" arguments! # noqa: DAR101 Args: privilege_levels: optional user provided privilege levels, if left None will default to scrapli standard privilege levels default_desired_privilege_level: string of name of default desired priv, this is the priv level that is generally used to disable paging/set terminal width and things like that upon first login, and is also the priv level scrapli will try to acquire for normal \"command\" operations (`send_command`, `send_commands`) auth_secondary: password to use for secondary authentication (enable) on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar. textfsm_platform: string name of textfsm parser platform genie_platform: string name of cisco genie parser platform failed_when_contains: List of strings that indicate a command/config has failed Returns: None Raises: N/A \"\"\" # somewhere/somehow the mixin is causing mypy to be upset about comms_prompt_pattern... self.comms_prompt_pattern: str if privilege_levels is None: privilege_levels = deepcopy(PRIVS) if on_open is None: on_open = eos_on_open if on_close is None: on_close = eos_on_close if failed_when_contains is None: failed_when_contains = FAILED_WHEN_CONTAINS.copy() super().__init__( host=host, port=port, auth_username=auth_username, auth_password=auth_password, auth_private_key=auth_private_key, auth_private_key_passphrase=auth_private_key_passphrase, auth_strict_key=auth_strict_key, auth_bypass=auth_bypass, timeout_socket=timeout_socket, timeout_transport=timeout_transport, timeout_ops=timeout_ops, comms_return_char=comms_return_char, ssh_config_file=ssh_config_file, ssh_known_hosts_file=ssh_known_hosts_file, on_init=on_init, on_open=on_open, on_close=on_close, transport=transport, transport_options=transport_options, channel_log=channel_log, channel_log_mode=channel_log_mode, channel_lock=channel_lock, logging_uid=logging_uid, privilege_levels=privilege_levels, default_desired_privilege_level=default_desired_privilege_level, auth_secondary=auth_secondary, failed_when_contains=failed_when_contains, textfsm_platform=textfsm_platform, genie_platform=genie_platform, ) def _abort_config(self) -> None: \"\"\" Abort EOS configuration session (if using a config session!) Args: N/A Returns: None Raises: N/A \"\"\" # eos pattern for config sessions should *always* have `config-s` if \"config\\\\-s\" in self._current_priv_level.pattern: self.channel.send_input(channel_input=\"abort\") self._current_priv_level = self.privilege_levels[\"privilege_exec\"] def register_configuration_session(self, session_name: str) -> None: \"\"\" EOS specific implementation of register_configuration_session Args: session_name: name of session to register Returns: None Raises: N/A \"\"\" self._create_configuration_session(session_name=session_name) self.update_privilege_levels()","title":"Module scrapli.driver.core.arista_eos.sync_driver"},{"location":"api_docs/driver/core/arista_eos/sync_driver/#functions","text":"","title":"Functions"},{"location":"api_docs/driver/core/arista_eos/sync_driver/#eos_on_close","text":"eos_on_close(conn: scrapli.driver.network.sync_driver.NetworkDriver) \u2011> None 1 2 3 4 5 6 7 8 9 10 EOSDriver default on_close callable Args: conn: NetworkDriver object Returns: None Raises: N/A","title":"eos_on_close"},{"location":"api_docs/driver/core/arista_eos/sync_driver/#eos_on_open","text":"eos_on_open(conn: scrapli.driver.network.sync_driver.NetworkDriver) \u2011> None 1 2 3 4 5 6 7 8 9 10 EOSDriver default on_open callable Args: conn: NetworkDriver object Returns: None Raises: N/A","title":"eos_on_open"},{"location":"api_docs/driver/core/arista_eos/sync_driver/#classes","text":"","title":"Classes"},{"location":"api_docs/driver/core/arista_eos/sync_driver/#eosdriver","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 EOSDriver Object Please see `scrapli.driver.base.base_driver.Driver` for all \"base driver\" arguments! # noqa: DAR101 Args: privilege_levels: optional user provided privilege levels, if left None will default to scrapli standard privilege levels default_desired_privilege_level: string of name of default desired priv, this is the priv level that is generally used to disable paging/set terminal width and things like that upon first login, and is also the priv level scrapli will try to acquire for normal \"command\" operations (`send_command`, `send_commands`) auth_secondary: password to use for secondary authentication (enable) on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar. textfsm_platform: string name of textfsm parser platform genie_platform: string name of cisco genie parser platform failed_when_contains: List of strings that indicate a command/config has failed Returns: None Raises: N/A Expand source code class EOSDriver(NetworkDriver, EOSDriverBase): def __init__( self, host: str, privilege_levels: Optional[Dict[str, PrivilegeLevel]] = None, default_desired_privilege_level: str = \"privilege_exec\", port: Optional[int] = None, auth_username: str = \"\", auth_password: str = \"\", auth_private_key: str = \"\", auth_private_key_passphrase: str = \"\", auth_strict_key: bool = True, auth_bypass: bool = False, timeout_socket: float = 15.0, timeout_transport: float = 30.0, timeout_ops: float = 30.0, comms_return_char: str = \"\\n\", ssh_config_file: Union[str, bool] = False, ssh_known_hosts_file: Union[str, bool] = False, on_init: Optional[Callable[..., Any]] = None, on_open: Optional[Callable[..., Any]] = None, on_close: Optional[Callable[..., Any]] = None, transport: str = \"system\", transport_options: Optional[Dict[str, Any]] = None, channel_log: Union[str, bool, BytesIO] = False, channel_log_mode: str = \"write\", channel_lock: bool = False, logging_uid: str = \"\", auth_secondary: str = \"\", failed_when_contains: Optional[List[str]] = None, textfsm_platform: str = \"arista_eos\", genie_platform: str = \"\", ): \"\"\" EOSDriver Object Please see `scrapli.driver.base.base_driver.Driver` for all \"base driver\" arguments! # noqa: DAR101 Args: privilege_levels: optional user provided privilege levels, if left None will default to scrapli standard privilege levels default_desired_privilege_level: string of name of default desired priv, this is the priv level that is generally used to disable paging/set terminal width and things like that upon first login, and is also the priv level scrapli will try to acquire for normal \"command\" operations (`send_command`, `send_commands`) auth_secondary: password to use for secondary authentication (enable) on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar. textfsm_platform: string name of textfsm parser platform genie_platform: string name of cisco genie parser platform failed_when_contains: List of strings that indicate a command/config has failed Returns: None Raises: N/A \"\"\" # somewhere/somehow the mixin is causing mypy to be upset about comms_prompt_pattern... self.comms_prompt_pattern: str if privilege_levels is None: privilege_levels = deepcopy(PRIVS) if on_open is None: on_open = eos_on_open if on_close is None: on_close = eos_on_close if failed_when_contains is None: failed_when_contains = FAILED_WHEN_CONTAINS.copy() super().__init__( host=host, port=port, auth_username=auth_username, auth_password=auth_password, auth_private_key=auth_private_key, auth_private_key_passphrase=auth_private_key_passphrase, auth_strict_key=auth_strict_key, auth_bypass=auth_bypass, timeout_socket=timeout_socket, timeout_transport=timeout_transport, timeout_ops=timeout_ops, comms_return_char=comms_return_char, ssh_config_file=ssh_config_file, ssh_known_hosts_file=ssh_known_hosts_file, on_init=on_init, on_open=on_open, on_close=on_close, transport=transport, transport_options=transport_options, channel_log=channel_log, channel_log_mode=channel_log_mode, channel_lock=channel_lock, logging_uid=logging_uid, privilege_levels=privilege_levels, default_desired_privilege_level=default_desired_privilege_level, auth_secondary=auth_secondary, failed_when_contains=failed_when_contains, textfsm_platform=textfsm_platform, genie_platform=genie_platform, ) def _abort_config(self) -> None: \"\"\" Abort EOS configuration session (if using a config session!) Args: N/A Returns: None Raises: N/A \"\"\" # eos pattern for config sessions should *always* have `config-s` if \"config\\\\-s\" in self._current_priv_level.pattern: self.channel.send_input(channel_input=\"abort\") self._current_priv_level = self.privilege_levels[\"privilege_exec\"] def register_configuration_session(self, session_name: str) -> None: \"\"\" EOS specific implementation of register_configuration_session Args: session_name: name of session to register Returns: None Raises: N/A \"\"\" self._create_configuration_session(session_name=session_name) self.update_privilege_levels()","title":"EOSDriver"},{"location":"api_docs/driver/core/arista_eos/sync_driver/#ancestors-in-mro","text":"scrapli.driver.network.sync_driver.NetworkDriver scrapli.driver.generic.sync_driver.GenericDriver scrapli.driver.base.sync_driver.Driver scrapli.driver.base.base_driver.BaseDriver scrapli.driver.generic.base_driver.BaseGenericDriver scrapli.driver.network.base_driver.BaseNetworkDriver scrapli.driver.core.arista_eos.base_driver.EOSDriverBase","title":"Ancestors (in MRO)"},{"location":"api_docs/driver/core/arista_eos/sync_driver/#methods","text":"","title":"Methods"},{"location":"api_docs/driver/core/arista_eos/sync_driver/#register_configuration_session","text":"register_configuration_session(self, session_name: str) \u2011> None 1 2 3 4 5 6 7 8 9 10 EOS specific implementation of register_configuration_session Args: session_name: name of session to register Returns: None Raises: N/A","title":"register_configuration_session"},{"location":"api_docs/driver/core/cisco_iosxe/async_driver/","text":"window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting()) Module scrapli.driver.core.cisco_iosxe.async_driver \u00b6 scrapli.driver.core.cisco_iosxe.async_driver Expand source code \"\"\"scrapli.driver.core.cisco_iosxe.async_driver\"\"\" from copy import deepcopy from io import BytesIO from typing import Any, Callable, Dict, List, Optional, Union from scrapli.driver import AsyncNetworkDriver from scrapli.driver.core.cisco_iosxe.base_driver import FAILED_WHEN_CONTAINS, PRIVS from scrapli.driver.network.base_driver import PrivilegeLevel async def iosxe_on_open(conn: AsyncNetworkDriver) -> None: \"\"\" AsyncIOSXEDriver default on_open callable Args: conn: NetworkDriver object Returns: None Raises: N/A \"\"\" await conn.acquire_priv(desired_priv=conn.default_desired_privilege_level) await conn.send_command(command=\"terminal length 0\") await conn.send_command(command=\"terminal width 512\") async def iosxe_on_close(conn: AsyncNetworkDriver) -> None: \"\"\" AsyncIOSXEDriver default on_close callable Args: conn: NetworkDriver object Returns: None Raises: N/A \"\"\" await conn.acquire_priv(desired_priv=conn.default_desired_privilege_level) conn.channel.write(channel_input=\"exit\") conn.channel.send_return() class AsyncIOSXEDriver(AsyncNetworkDriver): def __init__( self, host: str, privilege_levels: Optional[Dict[str, PrivilegeLevel]] = None, default_desired_privilege_level: str = \"privilege_exec\", port: Optional[int] = None, auth_username: str = \"\", auth_password: str = \"\", auth_private_key: str = \"\", auth_private_key_passphrase: str = \"\", auth_strict_key: bool = True, auth_bypass: bool = False, timeout_socket: float = 15.0, timeout_transport: float = 30.0, timeout_ops: float = 30.0, comms_return_char: str = \"\\n\", ssh_config_file: Union[str, bool] = False, ssh_known_hosts_file: Union[str, bool] = False, on_init: Optional[Callable[..., Any]] = None, on_open: Optional[Callable[..., Any]] = None, on_close: Optional[Callable[..., Any]] = None, transport: str = \"system\", transport_options: Optional[Dict[str, Any]] = None, channel_log: Union[str, bool, BytesIO] = False, channel_log_mode: str = \"write\", channel_lock: bool = False, logging_uid: str = \"\", auth_secondary: str = \"\", failed_when_contains: Optional[List[str]] = None, textfsm_platform: str = \"cisco_iosxe\", genie_platform: str = \"iosxe\", ): \"\"\" AsyncIOSXEDriver Object Please see `scrapli.driver.base.base_driver.Driver` for all \"base driver\" arguments! # noqa: DAR101 Args: privilege_levels: optional user provided privilege levels, if left None will default to scrapli standard privilege levels default_desired_privilege_level: string of name of default desired priv, this is the priv level that is generally used to disable paging/set terminal width and things like that upon first login, and is also the priv level scrapli will try to acquire for normal \"command\" operations (`send_command`, `send_commands`) auth_secondary: password to use for secondary authentication (enable) on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar. textfsm_platform: string name of textfsm parser platform genie_platform: string name of cisco genie parser platform failed_when_contains: List of strings that indicate a command/config has failed Returns: None Raises: N/A \"\"\" if privilege_levels is None: privilege_levels = deepcopy(PRIVS) if on_open is None: on_open = iosxe_on_open if on_close is None: on_close = iosxe_on_close if failed_when_contains is None: failed_when_contains = FAILED_WHEN_CONTAINS.copy() super().__init__( host=host, port=port, auth_username=auth_username, auth_password=auth_password, auth_private_key=auth_private_key, auth_private_key_passphrase=auth_private_key_passphrase, auth_strict_key=auth_strict_key, auth_bypass=auth_bypass, timeout_socket=timeout_socket, timeout_transport=timeout_transport, timeout_ops=timeout_ops, comms_return_char=comms_return_char, ssh_config_file=ssh_config_file, ssh_known_hosts_file=ssh_known_hosts_file, on_init=on_init, on_open=on_open, on_close=on_close, transport=transport, transport_options=transport_options, channel_log=channel_log, channel_log_mode=channel_log_mode, channel_lock=channel_lock, logging_uid=logging_uid, privilege_levels=privilege_levels, default_desired_privilege_level=default_desired_privilege_level, auth_secondary=auth_secondary, failed_when_contains=failed_when_contains, textfsm_platform=textfsm_platform, genie_platform=genie_platform, ) Functions \u00b6 iosxe_on_close \u00b6 iosxe_on_close(conn: scrapli.driver.network.async_driver.AsyncNetworkDriver) \u2011> None 1 2 3 4 5 6 7 8 9 10 AsyncIOSXEDriver default on_close callable Args: conn: NetworkDriver object Returns: None Raises: N/A iosxe_on_open \u00b6 iosxe_on_open(conn: scrapli.driver.network.async_driver.AsyncNetworkDriver) \u2011> None 1 2 3 4 5 6 7 8 9 10 AsyncIOSXEDriver default on_open callable Args: conn: NetworkDriver object Returns: None Raises: N/A Classes \u00b6 AsyncIOSXEDriver \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 AsyncIOSXEDriver Object Please see `scrapli.driver.base.base_driver.Driver` for all \"base driver\" arguments! # noqa: DAR101 Args: privilege_levels: optional user provided privilege levels, if left None will default to scrapli standard privilege levels default_desired_privilege_level: string of name of default desired priv, this is the priv level that is generally used to disable paging/set terminal width and things like that upon first login, and is also the priv level scrapli will try to acquire for normal \"command\" operations (`send_command`, `send_commands`) auth_secondary: password to use for secondary authentication (enable) on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar. textfsm_platform: string name of textfsm parser platform genie_platform: string name of cisco genie parser platform failed_when_contains: List of strings that indicate a command/config has failed Returns: None Raises: N/A Expand source code class AsyncIOSXEDriver(AsyncNetworkDriver): def __init__( self, host: str, privilege_levels: Optional[Dict[str, PrivilegeLevel]] = None, default_desired_privilege_level: str = \"privilege_exec\", port: Optional[int] = None, auth_username: str = \"\", auth_password: str = \"\", auth_private_key: str = \"\", auth_private_key_passphrase: str = \"\", auth_strict_key: bool = True, auth_bypass: bool = False, timeout_socket: float = 15.0, timeout_transport: float = 30.0, timeout_ops: float = 30.0, comms_return_char: str = \"\\n\", ssh_config_file: Union[str, bool] = False, ssh_known_hosts_file: Union[str, bool] = False, on_init: Optional[Callable[..., Any]] = None, on_open: Optional[Callable[..., Any]] = None, on_close: Optional[Callable[..., Any]] = None, transport: str = \"system\", transport_options: Optional[Dict[str, Any]] = None, channel_log: Union[str, bool, BytesIO] = False, channel_log_mode: str = \"write\", channel_lock: bool = False, logging_uid: str = \"\", auth_secondary: str = \"\", failed_when_contains: Optional[List[str]] = None, textfsm_platform: str = \"cisco_iosxe\", genie_platform: str = \"iosxe\", ): \"\"\" AsyncIOSXEDriver Object Please see `scrapli.driver.base.base_driver.Driver` for all \"base driver\" arguments! # noqa: DAR101 Args: privilege_levels: optional user provided privilege levels, if left None will default to scrapli standard privilege levels default_desired_privilege_level: string of name of default desired priv, this is the priv level that is generally used to disable paging/set terminal width and things like that upon first login, and is also the priv level scrapli will try to acquire for normal \"command\" operations (`send_command`, `send_commands`) auth_secondary: password to use for secondary authentication (enable) on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar. textfsm_platform: string name of textfsm parser platform genie_platform: string name of cisco genie parser platform failed_when_contains: List of strings that indicate a command/config has failed Returns: None Raises: N/A \"\"\" if privilege_levels is None: privilege_levels = deepcopy(PRIVS) if on_open is None: on_open = iosxe_on_open if on_close is None: on_close = iosxe_on_close if failed_when_contains is None: failed_when_contains = FAILED_WHEN_CONTAINS.copy() super().__init__( host=host, port=port, auth_username=auth_username, auth_password=auth_password, auth_private_key=auth_private_key, auth_private_key_passphrase=auth_private_key_passphrase, auth_strict_key=auth_strict_key, auth_bypass=auth_bypass, timeout_socket=timeout_socket, timeout_transport=timeout_transport, timeout_ops=timeout_ops, comms_return_char=comms_return_char, ssh_config_file=ssh_config_file, ssh_known_hosts_file=ssh_known_hosts_file, on_init=on_init, on_open=on_open, on_close=on_close, transport=transport, transport_options=transport_options, channel_log=channel_log, channel_log_mode=channel_log_mode, channel_lock=channel_lock, logging_uid=logging_uid, privilege_levels=privilege_levels, default_desired_privilege_level=default_desired_privilege_level, auth_secondary=auth_secondary, failed_when_contains=failed_when_contains, textfsm_platform=textfsm_platform, genie_platform=genie_platform, ) Ancestors (in MRO) \u00b6 scrapli.driver.network.async_driver.AsyncNetworkDriver scrapli.driver.generic.async_driver.AsyncGenericDriver scrapli.driver.base.async_driver.AsyncDriver scrapli.driver.base.base_driver.BaseDriver scrapli.driver.generic.base_driver.BaseGenericDriver scrapli.driver.network.base_driver.BaseNetworkDriver","title":"Async Driver"},{"location":"api_docs/driver/core/cisco_iosxe/async_driver/#module-scraplidrivercorecisco_iosxeasync_driver","text":"scrapli.driver.core.cisco_iosxe.async_driver Expand source code \"\"\"scrapli.driver.core.cisco_iosxe.async_driver\"\"\" from copy import deepcopy from io import BytesIO from typing import Any, Callable, Dict, List, Optional, Union from scrapli.driver import AsyncNetworkDriver from scrapli.driver.core.cisco_iosxe.base_driver import FAILED_WHEN_CONTAINS, PRIVS from scrapli.driver.network.base_driver import PrivilegeLevel async def iosxe_on_open(conn: AsyncNetworkDriver) -> None: \"\"\" AsyncIOSXEDriver default on_open callable Args: conn: NetworkDriver object Returns: None Raises: N/A \"\"\" await conn.acquire_priv(desired_priv=conn.default_desired_privilege_level) await conn.send_command(command=\"terminal length 0\") await conn.send_command(command=\"terminal width 512\") async def iosxe_on_close(conn: AsyncNetworkDriver) -> None: \"\"\" AsyncIOSXEDriver default on_close callable Args: conn: NetworkDriver object Returns: None Raises: N/A \"\"\" await conn.acquire_priv(desired_priv=conn.default_desired_privilege_level) conn.channel.write(channel_input=\"exit\") conn.channel.send_return() class AsyncIOSXEDriver(AsyncNetworkDriver): def __init__( self, host: str, privilege_levels: Optional[Dict[str, PrivilegeLevel]] = None, default_desired_privilege_level: str = \"privilege_exec\", port: Optional[int] = None, auth_username: str = \"\", auth_password: str = \"\", auth_private_key: str = \"\", auth_private_key_passphrase: str = \"\", auth_strict_key: bool = True, auth_bypass: bool = False, timeout_socket: float = 15.0, timeout_transport: float = 30.0, timeout_ops: float = 30.0, comms_return_char: str = \"\\n\", ssh_config_file: Union[str, bool] = False, ssh_known_hosts_file: Union[str, bool] = False, on_init: Optional[Callable[..., Any]] = None, on_open: Optional[Callable[..., Any]] = None, on_close: Optional[Callable[..., Any]] = None, transport: str = \"system\", transport_options: Optional[Dict[str, Any]] = None, channel_log: Union[str, bool, BytesIO] = False, channel_log_mode: str = \"write\", channel_lock: bool = False, logging_uid: str = \"\", auth_secondary: str = \"\", failed_when_contains: Optional[List[str]] = None, textfsm_platform: str = \"cisco_iosxe\", genie_platform: str = \"iosxe\", ): \"\"\" AsyncIOSXEDriver Object Please see `scrapli.driver.base.base_driver.Driver` for all \"base driver\" arguments! # noqa: DAR101 Args: privilege_levels: optional user provided privilege levels, if left None will default to scrapli standard privilege levels default_desired_privilege_level: string of name of default desired priv, this is the priv level that is generally used to disable paging/set terminal width and things like that upon first login, and is also the priv level scrapli will try to acquire for normal \"command\" operations (`send_command`, `send_commands`) auth_secondary: password to use for secondary authentication (enable) on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar. textfsm_platform: string name of textfsm parser platform genie_platform: string name of cisco genie parser platform failed_when_contains: List of strings that indicate a command/config has failed Returns: None Raises: N/A \"\"\" if privilege_levels is None: privilege_levels = deepcopy(PRIVS) if on_open is None: on_open = iosxe_on_open if on_close is None: on_close = iosxe_on_close if failed_when_contains is None: failed_when_contains = FAILED_WHEN_CONTAINS.copy() super().__init__( host=host, port=port, auth_username=auth_username, auth_password=auth_password, auth_private_key=auth_private_key, auth_private_key_passphrase=auth_private_key_passphrase, auth_strict_key=auth_strict_key, auth_bypass=auth_bypass, timeout_socket=timeout_socket, timeout_transport=timeout_transport, timeout_ops=timeout_ops, comms_return_char=comms_return_char, ssh_config_file=ssh_config_file, ssh_known_hosts_file=ssh_known_hosts_file, on_init=on_init, on_open=on_open, on_close=on_close, transport=transport, transport_options=transport_options, channel_log=channel_log, channel_log_mode=channel_log_mode, channel_lock=channel_lock, logging_uid=logging_uid, privilege_levels=privilege_levels, default_desired_privilege_level=default_desired_privilege_level, auth_secondary=auth_secondary, failed_when_contains=failed_when_contains, textfsm_platform=textfsm_platform, genie_platform=genie_platform, )","title":"Module scrapli.driver.core.cisco_iosxe.async_driver"},{"location":"api_docs/driver/core/cisco_iosxe/async_driver/#functions","text":"","title":"Functions"},{"location":"api_docs/driver/core/cisco_iosxe/async_driver/#iosxe_on_close","text":"iosxe_on_close(conn: scrapli.driver.network.async_driver.AsyncNetworkDriver) \u2011> None 1 2 3 4 5 6 7 8 9 10 AsyncIOSXEDriver default on_close callable Args: conn: NetworkDriver object Returns: None Raises: N/A","title":"iosxe_on_close"},{"location":"api_docs/driver/core/cisco_iosxe/async_driver/#iosxe_on_open","text":"iosxe_on_open(conn: scrapli.driver.network.async_driver.AsyncNetworkDriver) \u2011> None 1 2 3 4 5 6 7 8 9 10 AsyncIOSXEDriver default on_open callable Args: conn: NetworkDriver object Returns: None Raises: N/A","title":"iosxe_on_open"},{"location":"api_docs/driver/core/cisco_iosxe/async_driver/#classes","text":"","title":"Classes"},{"location":"api_docs/driver/core/cisco_iosxe/async_driver/#asynciosxedriver","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 AsyncIOSXEDriver Object Please see `scrapli.driver.base.base_driver.Driver` for all \"base driver\" arguments! # noqa: DAR101 Args: privilege_levels: optional user provided privilege levels, if left None will default to scrapli standard privilege levels default_desired_privilege_level: string of name of default desired priv, this is the priv level that is generally used to disable paging/set terminal width and things like that upon first login, and is also the priv level scrapli will try to acquire for normal \"command\" operations (`send_command`, `send_commands`) auth_secondary: password to use for secondary authentication (enable) on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar. textfsm_platform: string name of textfsm parser platform genie_platform: string name of cisco genie parser platform failed_when_contains: List of strings that indicate a command/config has failed Returns: None Raises: N/A Expand source code class AsyncIOSXEDriver(AsyncNetworkDriver): def __init__( self, host: str, privilege_levels: Optional[Dict[str, PrivilegeLevel]] = None, default_desired_privilege_level: str = \"privilege_exec\", port: Optional[int] = None, auth_username: str = \"\", auth_password: str = \"\", auth_private_key: str = \"\", auth_private_key_passphrase: str = \"\", auth_strict_key: bool = True, auth_bypass: bool = False, timeout_socket: float = 15.0, timeout_transport: float = 30.0, timeout_ops: float = 30.0, comms_return_char: str = \"\\n\", ssh_config_file: Union[str, bool] = False, ssh_known_hosts_file: Union[str, bool] = False, on_init: Optional[Callable[..., Any]] = None, on_open: Optional[Callable[..., Any]] = None, on_close: Optional[Callable[..., Any]] = None, transport: str = \"system\", transport_options: Optional[Dict[str, Any]] = None, channel_log: Union[str, bool, BytesIO] = False, channel_log_mode: str = \"write\", channel_lock: bool = False, logging_uid: str = \"\", auth_secondary: str = \"\", failed_when_contains: Optional[List[str]] = None, textfsm_platform: str = \"cisco_iosxe\", genie_platform: str = \"iosxe\", ): \"\"\" AsyncIOSXEDriver Object Please see `scrapli.driver.base.base_driver.Driver` for all \"base driver\" arguments! # noqa: DAR101 Args: privilege_levels: optional user provided privilege levels, if left None will default to scrapli standard privilege levels default_desired_privilege_level: string of name of default desired priv, this is the priv level that is generally used to disable paging/set terminal width and things like that upon first login, and is also the priv level scrapli will try to acquire for normal \"command\" operations (`send_command`, `send_commands`) auth_secondary: password to use for secondary authentication (enable) on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar. textfsm_platform: string name of textfsm parser platform genie_platform: string name of cisco genie parser platform failed_when_contains: List of strings that indicate a command/config has failed Returns: None Raises: N/A \"\"\" if privilege_levels is None: privilege_levels = deepcopy(PRIVS) if on_open is None: on_open = iosxe_on_open if on_close is None: on_close = iosxe_on_close if failed_when_contains is None: failed_when_contains = FAILED_WHEN_CONTAINS.copy() super().__init__( host=host, port=port, auth_username=auth_username, auth_password=auth_password, auth_private_key=auth_private_key, auth_private_key_passphrase=auth_private_key_passphrase, auth_strict_key=auth_strict_key, auth_bypass=auth_bypass, timeout_socket=timeout_socket, timeout_transport=timeout_transport, timeout_ops=timeout_ops, comms_return_char=comms_return_char, ssh_config_file=ssh_config_file, ssh_known_hosts_file=ssh_known_hosts_file, on_init=on_init, on_open=on_open, on_close=on_close, transport=transport, transport_options=transport_options, channel_log=channel_log, channel_log_mode=channel_log_mode, channel_lock=channel_lock, logging_uid=logging_uid, privilege_levels=privilege_levels, default_desired_privilege_level=default_desired_privilege_level, auth_secondary=auth_secondary, failed_when_contains=failed_when_contains, textfsm_platform=textfsm_platform, genie_platform=genie_platform, )","title":"AsyncIOSXEDriver"},{"location":"api_docs/driver/core/cisco_iosxe/async_driver/#ancestors-in-mro","text":"scrapli.driver.network.async_driver.AsyncNetworkDriver scrapli.driver.generic.async_driver.AsyncGenericDriver scrapli.driver.base.async_driver.AsyncDriver scrapli.driver.base.base_driver.BaseDriver scrapli.driver.generic.base_driver.BaseGenericDriver scrapli.driver.network.base_driver.BaseNetworkDriver","title":"Ancestors (in MRO)"},{"location":"api_docs/driver/core/cisco_iosxe/base_driver/","text":"window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting()) Module scrapli.driver.core.cisco_iosxe.base_driver \u00b6 scrapli.driver.core.cisco_iosxe.base_driver Expand source code \"\"\"scrapli.driver.core.cisco_iosxe.base_driver\"\"\" from scrapli.driver.network.base_driver import PrivilegeLevel PRIVS = { \"exec\": ( PrivilegeLevel( pattern=r\"^[\\w.\\-@/:]{1,63}>$\", name=\"exec\", previous_priv=\"\", deescalate=\"\", escalate=\"\", escalate_auth=False, escalate_prompt=\"\", ) ), \"privilege_exec\": ( PrivilegeLevel( pattern=r\"^[\\w.\\-@/:]{1,63}#$\", name=\"privilege_exec\", previous_priv=\"exec\", deescalate=\"disable\", escalate=\"enable\", escalate_auth=True, escalate_prompt=r\"^(?:enable\\s){0,1}password:\\s?$\", ) ), \"configuration\": ( PrivilegeLevel( pattern=r\"^[\\w.\\-@/:]{1,63}\\([\\w.\\-@/:+]{0,32}\\)#$\", name=\"configuration\", previous_priv=\"privilege_exec\", deescalate=\"end\", escalate=\"configure terminal\", escalate_auth=False, escalate_prompt=\"\", not_contains=[\"tcl)\"], ) ), \"tclsh\": ( PrivilegeLevel( pattern=r\"^([\\w.\\-@/+>:]+\\(tcl\\)[>#]|\\+>)$\", name=\"tclsh\", previous_priv=\"privilege_exec\", deescalate=\"tclquit\", escalate=\"tclsh\", escalate_auth=False, escalate_prompt=\"\", ) ), } FAILED_WHEN_CONTAINS = [ \"% Ambiguous command\", \"% Incomplete command\", \"% Invalid input detected\", \"% Unknown command\", ]","title":"Base Driver"},{"location":"api_docs/driver/core/cisco_iosxe/base_driver/#module-scraplidrivercorecisco_iosxebase_driver","text":"scrapli.driver.core.cisco_iosxe.base_driver Expand source code \"\"\"scrapli.driver.core.cisco_iosxe.base_driver\"\"\" from scrapli.driver.network.base_driver import PrivilegeLevel PRIVS = { \"exec\": ( PrivilegeLevel( pattern=r\"^[\\w.\\-@/:]{1,63}>$\", name=\"exec\", previous_priv=\"\", deescalate=\"\", escalate=\"\", escalate_auth=False, escalate_prompt=\"\", ) ), \"privilege_exec\": ( PrivilegeLevel( pattern=r\"^[\\w.\\-@/:]{1,63}#$\", name=\"privilege_exec\", previous_priv=\"exec\", deescalate=\"disable\", escalate=\"enable\", escalate_auth=True, escalate_prompt=r\"^(?:enable\\s){0,1}password:\\s?$\", ) ), \"configuration\": ( PrivilegeLevel( pattern=r\"^[\\w.\\-@/:]{1,63}\\([\\w.\\-@/:+]{0,32}\\)#$\", name=\"configuration\", previous_priv=\"privilege_exec\", deescalate=\"end\", escalate=\"configure terminal\", escalate_auth=False, escalate_prompt=\"\", not_contains=[\"tcl)\"], ) ), \"tclsh\": ( PrivilegeLevel( pattern=r\"^([\\w.\\-@/+>:]+\\(tcl\\)[>#]|\\+>)$\", name=\"tclsh\", previous_priv=\"privilege_exec\", deescalate=\"tclquit\", escalate=\"tclsh\", escalate_auth=False, escalate_prompt=\"\", ) ), } FAILED_WHEN_CONTAINS = [ \"% Ambiguous command\", \"% Incomplete command\", \"% Invalid input detected\", \"% Unknown command\", ]","title":"Module scrapli.driver.core.cisco_iosxe.base_driver"},{"location":"api_docs/driver/core/cisco_iosxe/sync_driver/","text":"window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting()) Module scrapli.driver.core.cisco_iosxe.sync_driver \u00b6 scrapli.driver.core.cisco_iosxe.sync_driver Expand source code \"\"\"scrapli.driver.core.cisco_iosxe.sync_driver\"\"\" from copy import deepcopy from io import BytesIO from typing import Any, Callable, Dict, List, Optional, Union from scrapli.driver import NetworkDriver from scrapli.driver.core.cisco_iosxe.base_driver import FAILED_WHEN_CONTAINS, PRIVS from scrapli.driver.network.base_driver import PrivilegeLevel def iosxe_on_open(conn: NetworkDriver) -> None: \"\"\" IOSXEDriver default on_open callable Args: conn: NetworkDriver object Returns: None Raises: N/A \"\"\" conn.acquire_priv(desired_priv=conn.default_desired_privilege_level) conn.send_command(command=\"terminal length 0\") conn.send_command(command=\"terminal width 512\") def iosxe_on_close(conn: NetworkDriver) -> None: \"\"\" IOSXEDriver default on_close callable Args: conn: NetworkDriver object Returns: None Raises: N/A \"\"\" conn.acquire_priv(desired_priv=conn.default_desired_privilege_level) conn.channel.write(channel_input=\"exit\") conn.channel.send_return() class IOSXEDriver(NetworkDriver): def __init__( self, host: str, privilege_levels: Optional[Dict[str, PrivilegeLevel]] = None, default_desired_privilege_level: str = \"privilege_exec\", port: Optional[int] = None, auth_username: str = \"\", auth_password: str = \"\", auth_private_key: str = \"\", auth_private_key_passphrase: str = \"\", auth_strict_key: bool = True, auth_bypass: bool = False, timeout_socket: float = 15.0, timeout_transport: float = 30.0, timeout_ops: float = 30.0, comms_return_char: str = \"\\n\", ssh_config_file: Union[str, bool] = False, ssh_known_hosts_file: Union[str, bool] = False, on_init: Optional[Callable[..., Any]] = None, on_open: Optional[Callable[..., Any]] = None, on_close: Optional[Callable[..., Any]] = None, transport: str = \"system\", transport_options: Optional[Dict[str, Any]] = None, channel_log: Union[str, bool, BytesIO] = False, channel_log_mode: str = \"write\", channel_lock: bool = False, logging_uid: str = \"\", auth_secondary: str = \"\", failed_when_contains: Optional[List[str]] = None, textfsm_platform: str = \"cisco_iosxe\", genie_platform: str = \"iosxe\", ): \"\"\" IOSXEDriver Object Please see `scrapli.driver.base.base_driver.Driver` for all \"base driver\" arguments! # noqa: DAR101 Args: privilege_levels: optional user provided privilege levels, if left None will default to scrapli standard privilege levels default_desired_privilege_level: string of name of default desired priv, this is the priv level that is generally used to disable paging/set terminal width and things like that upon first login, and is also the priv level scrapli will try to acquire for normal \"command\" operations (`send_command`, `send_commands`) auth_secondary: password to use for secondary authentication (enable) on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar. textfsm_platform: string name of textfsm parser platform genie_platform: string name of cisco genie parser platform failed_when_contains: List of strings that indicate a command/config has failed Returns: None Raises: N/A \"\"\" if privilege_levels is None: privilege_levels = deepcopy(PRIVS) if on_open is None: on_open = iosxe_on_open if on_close is None: on_close = iosxe_on_close if failed_when_contains is None: failed_when_contains = FAILED_WHEN_CONTAINS.copy() super().__init__( host=host, port=port, auth_username=auth_username, auth_password=auth_password, auth_private_key=auth_private_key, auth_private_key_passphrase=auth_private_key_passphrase, auth_strict_key=auth_strict_key, auth_bypass=auth_bypass, timeout_socket=timeout_socket, timeout_transport=timeout_transport, timeout_ops=timeout_ops, comms_return_char=comms_return_char, ssh_config_file=ssh_config_file, ssh_known_hosts_file=ssh_known_hosts_file, on_init=on_init, on_open=on_open, on_close=on_close, transport=transport, transport_options=transport_options, channel_log=channel_log, channel_log_mode=channel_log_mode, channel_lock=channel_lock, logging_uid=logging_uid, privilege_levels=privilege_levels, default_desired_privilege_level=default_desired_privilege_level, auth_secondary=auth_secondary, failed_when_contains=failed_when_contains, textfsm_platform=textfsm_platform, genie_platform=genie_platform, ) Functions \u00b6 iosxe_on_close \u00b6 iosxe_on_close(conn: scrapli.driver.network.sync_driver.NetworkDriver) \u2011> None 1 2 3 4 5 6 7 8 9 10 IOSXEDriver default on_close callable Args: conn: NetworkDriver object Returns: None Raises: N/A iosxe_on_open \u00b6 iosxe_on_open(conn: scrapli.driver.network.sync_driver.NetworkDriver) \u2011> None 1 2 3 4 5 6 7 8 9 10 IOSXEDriver default on_open callable Args: conn: NetworkDriver object Returns: None Raises: N/A Classes \u00b6 IOSXEDriver \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 IOSXEDriver Object Please see `scrapli.driver.base.base_driver.Driver` for all \"base driver\" arguments! # noqa: DAR101 Args: privilege_levels: optional user provided privilege levels, if left None will default to scrapli standard privilege levels default_desired_privilege_level: string of name of default desired priv, this is the priv level that is generally used to disable paging/set terminal width and things like that upon first login, and is also the priv level scrapli will try to acquire for normal \"command\" operations (`send_command`, `send_commands`) auth_secondary: password to use for secondary authentication (enable) on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar. textfsm_platform: string name of textfsm parser platform genie_platform: string name of cisco genie parser platform failed_when_contains: List of strings that indicate a command/config has failed Returns: None Raises: N/A Expand source code class IOSXEDriver(NetworkDriver): def __init__( self, host: str, privilege_levels: Optional[Dict[str, PrivilegeLevel]] = None, default_desired_privilege_level: str = \"privilege_exec\", port: Optional[int] = None, auth_username: str = \"\", auth_password: str = \"\", auth_private_key: str = \"\", auth_private_key_passphrase: str = \"\", auth_strict_key: bool = True, auth_bypass: bool = False, timeout_socket: float = 15.0, timeout_transport: float = 30.0, timeout_ops: float = 30.0, comms_return_char: str = \"\\n\", ssh_config_file: Union[str, bool] = False, ssh_known_hosts_file: Union[str, bool] = False, on_init: Optional[Callable[..., Any]] = None, on_open: Optional[Callable[..., Any]] = None, on_close: Optional[Callable[..., Any]] = None, transport: str = \"system\", transport_options: Optional[Dict[str, Any]] = None, channel_log: Union[str, bool, BytesIO] = False, channel_log_mode: str = \"write\", channel_lock: bool = False, logging_uid: str = \"\", auth_secondary: str = \"\", failed_when_contains: Optional[List[str]] = None, textfsm_platform: str = \"cisco_iosxe\", genie_platform: str = \"iosxe\", ): \"\"\" IOSXEDriver Object Please see `scrapli.driver.base.base_driver.Driver` for all \"base driver\" arguments! # noqa: DAR101 Args: privilege_levels: optional user provided privilege levels, if left None will default to scrapli standard privilege levels default_desired_privilege_level: string of name of default desired priv, this is the priv level that is generally used to disable paging/set terminal width and things like that upon first login, and is also the priv level scrapli will try to acquire for normal \"command\" operations (`send_command`, `send_commands`) auth_secondary: password to use for secondary authentication (enable) on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar. textfsm_platform: string name of textfsm parser platform genie_platform: string name of cisco genie parser platform failed_when_contains: List of strings that indicate a command/config has failed Returns: None Raises: N/A \"\"\" if privilege_levels is None: privilege_levels = deepcopy(PRIVS) if on_open is None: on_open = iosxe_on_open if on_close is None: on_close = iosxe_on_close if failed_when_contains is None: failed_when_contains = FAILED_WHEN_CONTAINS.copy() super().__init__( host=host, port=port, auth_username=auth_username, auth_password=auth_password, auth_private_key=auth_private_key, auth_private_key_passphrase=auth_private_key_passphrase, auth_strict_key=auth_strict_key, auth_bypass=auth_bypass, timeout_socket=timeout_socket, timeout_transport=timeout_transport, timeout_ops=timeout_ops, comms_return_char=comms_return_char, ssh_config_file=ssh_config_file, ssh_known_hosts_file=ssh_known_hosts_file, on_init=on_init, on_open=on_open, on_close=on_close, transport=transport, transport_options=transport_options, channel_log=channel_log, channel_log_mode=channel_log_mode, channel_lock=channel_lock, logging_uid=logging_uid, privilege_levels=privilege_levels, default_desired_privilege_level=default_desired_privilege_level, auth_secondary=auth_secondary, failed_when_contains=failed_when_contains, textfsm_platform=textfsm_platform, genie_platform=genie_platform, ) Ancestors (in MRO) \u00b6 scrapli.driver.network.sync_driver.NetworkDriver scrapli.driver.generic.sync_driver.GenericDriver scrapli.driver.base.sync_driver.Driver scrapli.driver.base.base_driver.BaseDriver scrapli.driver.generic.base_driver.BaseGenericDriver scrapli.driver.network.base_driver.BaseNetworkDriver","title":"Sync Driver"},{"location":"api_docs/driver/core/cisco_iosxe/sync_driver/#module-scraplidrivercorecisco_iosxesync_driver","text":"scrapli.driver.core.cisco_iosxe.sync_driver Expand source code \"\"\"scrapli.driver.core.cisco_iosxe.sync_driver\"\"\" from copy import deepcopy from io import BytesIO from typing import Any, Callable, Dict, List, Optional, Union from scrapli.driver import NetworkDriver from scrapli.driver.core.cisco_iosxe.base_driver import FAILED_WHEN_CONTAINS, PRIVS from scrapli.driver.network.base_driver import PrivilegeLevel def iosxe_on_open(conn: NetworkDriver) -> None: \"\"\" IOSXEDriver default on_open callable Args: conn: NetworkDriver object Returns: None Raises: N/A \"\"\" conn.acquire_priv(desired_priv=conn.default_desired_privilege_level) conn.send_command(command=\"terminal length 0\") conn.send_command(command=\"terminal width 512\") def iosxe_on_close(conn: NetworkDriver) -> None: \"\"\" IOSXEDriver default on_close callable Args: conn: NetworkDriver object Returns: None Raises: N/A \"\"\" conn.acquire_priv(desired_priv=conn.default_desired_privilege_level) conn.channel.write(channel_input=\"exit\") conn.channel.send_return() class IOSXEDriver(NetworkDriver): def __init__( self, host: str, privilege_levels: Optional[Dict[str, PrivilegeLevel]] = None, default_desired_privilege_level: str = \"privilege_exec\", port: Optional[int] = None, auth_username: str = \"\", auth_password: str = \"\", auth_private_key: str = \"\", auth_private_key_passphrase: str = \"\", auth_strict_key: bool = True, auth_bypass: bool = False, timeout_socket: float = 15.0, timeout_transport: float = 30.0, timeout_ops: float = 30.0, comms_return_char: str = \"\\n\", ssh_config_file: Union[str, bool] = False, ssh_known_hosts_file: Union[str, bool] = False, on_init: Optional[Callable[..., Any]] = None, on_open: Optional[Callable[..., Any]] = None, on_close: Optional[Callable[..., Any]] = None, transport: str = \"system\", transport_options: Optional[Dict[str, Any]] = None, channel_log: Union[str, bool, BytesIO] = False, channel_log_mode: str = \"write\", channel_lock: bool = False, logging_uid: str = \"\", auth_secondary: str = \"\", failed_when_contains: Optional[List[str]] = None, textfsm_platform: str = \"cisco_iosxe\", genie_platform: str = \"iosxe\", ): \"\"\" IOSXEDriver Object Please see `scrapli.driver.base.base_driver.Driver` for all \"base driver\" arguments! # noqa: DAR101 Args: privilege_levels: optional user provided privilege levels, if left None will default to scrapli standard privilege levels default_desired_privilege_level: string of name of default desired priv, this is the priv level that is generally used to disable paging/set terminal width and things like that upon first login, and is also the priv level scrapli will try to acquire for normal \"command\" operations (`send_command`, `send_commands`) auth_secondary: password to use for secondary authentication (enable) on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar. textfsm_platform: string name of textfsm parser platform genie_platform: string name of cisco genie parser platform failed_when_contains: List of strings that indicate a command/config has failed Returns: None Raises: N/A \"\"\" if privilege_levels is None: privilege_levels = deepcopy(PRIVS) if on_open is None: on_open = iosxe_on_open if on_close is None: on_close = iosxe_on_close if failed_when_contains is None: failed_when_contains = FAILED_WHEN_CONTAINS.copy() super().__init__( host=host, port=port, auth_username=auth_username, auth_password=auth_password, auth_private_key=auth_private_key, auth_private_key_passphrase=auth_private_key_passphrase, auth_strict_key=auth_strict_key, auth_bypass=auth_bypass, timeout_socket=timeout_socket, timeout_transport=timeout_transport, timeout_ops=timeout_ops, comms_return_char=comms_return_char, ssh_config_file=ssh_config_file, ssh_known_hosts_file=ssh_known_hosts_file, on_init=on_init, on_open=on_open, on_close=on_close, transport=transport, transport_options=transport_options, channel_log=channel_log, channel_log_mode=channel_log_mode, channel_lock=channel_lock, logging_uid=logging_uid, privilege_levels=privilege_levels, default_desired_privilege_level=default_desired_privilege_level, auth_secondary=auth_secondary, failed_when_contains=failed_when_contains, textfsm_platform=textfsm_platform, genie_platform=genie_platform, )","title":"Module scrapli.driver.core.cisco_iosxe.sync_driver"},{"location":"api_docs/driver/core/cisco_iosxe/sync_driver/#functions","text":"","title":"Functions"},{"location":"api_docs/driver/core/cisco_iosxe/sync_driver/#iosxe_on_close","text":"iosxe_on_close(conn: scrapli.driver.network.sync_driver.NetworkDriver) \u2011> None 1 2 3 4 5 6 7 8 9 10 IOSXEDriver default on_close callable Args: conn: NetworkDriver object Returns: None Raises: N/A","title":"iosxe_on_close"},{"location":"api_docs/driver/core/cisco_iosxe/sync_driver/#iosxe_on_open","text":"iosxe_on_open(conn: scrapli.driver.network.sync_driver.NetworkDriver) \u2011> None 1 2 3 4 5 6 7 8 9 10 IOSXEDriver default on_open callable Args: conn: NetworkDriver object Returns: None Raises: N/A","title":"iosxe_on_open"},{"location":"api_docs/driver/core/cisco_iosxe/sync_driver/#classes","text":"","title":"Classes"},{"location":"api_docs/driver/core/cisco_iosxe/sync_driver/#iosxedriver","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 IOSXEDriver Object Please see `scrapli.driver.base.base_driver.Driver` for all \"base driver\" arguments! # noqa: DAR101 Args: privilege_levels: optional user provided privilege levels, if left None will default to scrapli standard privilege levels default_desired_privilege_level: string of name of default desired priv, this is the priv level that is generally used to disable paging/set terminal width and things like that upon first login, and is also the priv level scrapli will try to acquire for normal \"command\" operations (`send_command`, `send_commands`) auth_secondary: password to use for secondary authentication (enable) on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar. textfsm_platform: string name of textfsm parser platform genie_platform: string name of cisco genie parser platform failed_when_contains: List of strings that indicate a command/config has failed Returns: None Raises: N/A Expand source code class IOSXEDriver(NetworkDriver): def __init__( self, host: str, privilege_levels: Optional[Dict[str, PrivilegeLevel]] = None, default_desired_privilege_level: str = \"privilege_exec\", port: Optional[int] = None, auth_username: str = \"\", auth_password: str = \"\", auth_private_key: str = \"\", auth_private_key_passphrase: str = \"\", auth_strict_key: bool = True, auth_bypass: bool = False, timeout_socket: float = 15.0, timeout_transport: float = 30.0, timeout_ops: float = 30.0, comms_return_char: str = \"\\n\", ssh_config_file: Union[str, bool] = False, ssh_known_hosts_file: Union[str, bool] = False, on_init: Optional[Callable[..., Any]] = None, on_open: Optional[Callable[..., Any]] = None, on_close: Optional[Callable[..., Any]] = None, transport: str = \"system\", transport_options: Optional[Dict[str, Any]] = None, channel_log: Union[str, bool, BytesIO] = False, channel_log_mode: str = \"write\", channel_lock: bool = False, logging_uid: str = \"\", auth_secondary: str = \"\", failed_when_contains: Optional[List[str]] = None, textfsm_platform: str = \"cisco_iosxe\", genie_platform: str = \"iosxe\", ): \"\"\" IOSXEDriver Object Please see `scrapli.driver.base.base_driver.Driver` for all \"base driver\" arguments! # noqa: DAR101 Args: privilege_levels: optional user provided privilege levels, if left None will default to scrapli standard privilege levels default_desired_privilege_level: string of name of default desired priv, this is the priv level that is generally used to disable paging/set terminal width and things like that upon first login, and is also the priv level scrapli will try to acquire for normal \"command\" operations (`send_command`, `send_commands`) auth_secondary: password to use for secondary authentication (enable) on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar. textfsm_platform: string name of textfsm parser platform genie_platform: string name of cisco genie parser platform failed_when_contains: List of strings that indicate a command/config has failed Returns: None Raises: N/A \"\"\" if privilege_levels is None: privilege_levels = deepcopy(PRIVS) if on_open is None: on_open = iosxe_on_open if on_close is None: on_close = iosxe_on_close if failed_when_contains is None: failed_when_contains = FAILED_WHEN_CONTAINS.copy() super().__init__( host=host, port=port, auth_username=auth_username, auth_password=auth_password, auth_private_key=auth_private_key, auth_private_key_passphrase=auth_private_key_passphrase, auth_strict_key=auth_strict_key, auth_bypass=auth_bypass, timeout_socket=timeout_socket, timeout_transport=timeout_transport, timeout_ops=timeout_ops, comms_return_char=comms_return_char, ssh_config_file=ssh_config_file, ssh_known_hosts_file=ssh_known_hosts_file, on_init=on_init, on_open=on_open, on_close=on_close, transport=transport, transport_options=transport_options, channel_log=channel_log, channel_log_mode=channel_log_mode, channel_lock=channel_lock, logging_uid=logging_uid, privilege_levels=privilege_levels, default_desired_privilege_level=default_desired_privilege_level, auth_secondary=auth_secondary, failed_when_contains=failed_when_contains, textfsm_platform=textfsm_platform, genie_platform=genie_platform, )","title":"IOSXEDriver"},{"location":"api_docs/driver/core/cisco_iosxe/sync_driver/#ancestors-in-mro","text":"scrapli.driver.network.sync_driver.NetworkDriver scrapli.driver.generic.sync_driver.GenericDriver scrapli.driver.base.sync_driver.Driver scrapli.driver.base.base_driver.BaseDriver scrapli.driver.generic.base_driver.BaseGenericDriver scrapli.driver.network.base_driver.BaseNetworkDriver","title":"Ancestors (in MRO)"},{"location":"api_docs/driver/core/cisco_iosxr/async_driver/","text":"window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting()) Module scrapli.driver.core.cisco_iosxr.async_driver \u00b6 scrapli.driver.core.cisco_iosxr.async_driver Expand source code \"\"\"scrapli.driver.core.cisco_iosxr.async_driver\"\"\" from copy import deepcopy from io import BytesIO from typing import Any, Callable, Dict, List, Optional, Union from scrapli.driver import AsyncNetworkDriver from scrapli.driver.core.cisco_iosxr.base_driver import FAILED_WHEN_CONTAINS, PRIVS from scrapli.driver.network.base_driver import PrivilegeLevel async def iosxr_on_open(conn: AsyncNetworkDriver) -> None: \"\"\" IOSXRDriver default on_open callable Args: conn: NetworkDriver object Returns: None Raises: N/A \"\"\" await conn.acquire_priv(desired_priv=conn.default_desired_privilege_level) await conn.send_command(command=\"terminal length 0\") await conn.send_command(command=\"terminal width 512\") async def iosxr_on_close(conn: AsyncNetworkDriver) -> None: \"\"\" IOSXRDriver default on_close callable Args: conn: NetworkDriver object Returns: None Raises: N/A \"\"\" await conn.acquire_priv(desired_priv=conn.default_desired_privilege_level) conn.channel.write(channel_input=\"exit\") conn.channel.send_return() class AsyncIOSXRDriver(AsyncNetworkDriver): def __init__( self, host: str, privilege_levels: Optional[Dict[str, PrivilegeLevel]] = None, default_desired_privilege_level: str = \"privilege_exec\", port: Optional[int] = None, auth_username: str = \"\", auth_password: str = \"\", auth_private_key: str = \"\", auth_private_key_passphrase: str = \"\", auth_strict_key: bool = True, auth_bypass: bool = False, timeout_socket: float = 15.0, timeout_transport: float = 30.0, timeout_ops: float = 30.0, comms_return_char: str = \"\\n\", ssh_config_file: Union[str, bool] = False, ssh_known_hosts_file: Union[str, bool] = False, on_init: Optional[Callable[..., Any]] = None, on_open: Optional[Callable[..., Any]] = None, on_close: Optional[Callable[..., Any]] = None, transport: str = \"system\", transport_options: Optional[Dict[str, Any]] = None, channel_log: Union[str, bool, BytesIO] = False, channel_log_mode: str = \"write\", channel_lock: bool = False, logging_uid: str = \"\", auth_secondary: str = \"\", failed_when_contains: Optional[List[str]] = None, textfsm_platform: str = \"cisco_xr\", genie_platform: str = \"iosxr\", ): \"\"\" IOSXRDriver Object Please see `scrapli.driver.base.base_driver.Driver` for all \"base driver\" arguments! # noqa: DAR101 Args: privilege_levels: optional user provided privilege levels, if left None will default to scrapli standard privilege levels default_desired_privilege_level: string of name of default desired priv, this is the priv level that is generally used to disable paging/set terminal width and things like that upon first login, and is also the priv level scrapli will try to acquire for normal \"command\" operations (`send_command`, `send_commands`) auth_secondary: password to use for secondary authentication (enable) on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar. textfsm_platform: string name of textfsm parser platform genie_platform: string name of cisco genie parser platform failed_when_contains: List of strings that indicate a command/config has failed Returns: N/A # noqa: DAR202 Raises: N/A \"\"\" if privilege_levels is None: privilege_levels = deepcopy(PRIVS) if on_open is None: on_open = iosxr_on_open if on_close is None: on_close = iosxr_on_close if failed_when_contains is None: failed_when_contains = FAILED_WHEN_CONTAINS.copy() super().__init__( host=host, port=port, auth_username=auth_username, auth_password=auth_password, auth_private_key=auth_private_key, auth_private_key_passphrase=auth_private_key_passphrase, auth_strict_key=auth_strict_key, auth_bypass=auth_bypass, timeout_socket=timeout_socket, timeout_transport=timeout_transport, timeout_ops=timeout_ops, comms_return_char=comms_return_char, ssh_config_file=ssh_config_file, ssh_known_hosts_file=ssh_known_hosts_file, on_init=on_init, on_open=on_open, on_close=on_close, transport=transport, transport_options=transport_options, channel_log=channel_log, channel_log_mode=channel_log_mode, channel_lock=channel_lock, logging_uid=logging_uid, privilege_levels=privilege_levels, default_desired_privilege_level=default_desired_privilege_level, auth_secondary=auth_secondary, failed_when_contains=failed_when_contains, textfsm_platform=textfsm_platform, genie_platform=genie_platform, ) async def _abort_config(self) -> None: \"\"\" Abort IOSXR configuration session Args: N/A Returns: None Raises: N/A \"\"\" await self.channel.send_input(channel_input=\"abort\") self._current_priv_level = self.privilege_levels[\"privilege_exec\"] Functions \u00b6 iosxr_on_close \u00b6 iosxr_on_close(conn: scrapli.driver.network.async_driver.AsyncNetworkDriver) \u2011> None 1 2 3 4 5 6 7 8 9 10 IOSXRDriver default on_close callable Args: conn: NetworkDriver object Returns: None Raises: N/A iosxr_on_open \u00b6 iosxr_on_open(conn: scrapli.driver.network.async_driver.AsyncNetworkDriver) \u2011> None 1 2 3 4 5 6 7 8 9 10 IOSXRDriver default on_open callable Args: conn: NetworkDriver object Returns: None Raises: N/A Classes \u00b6 AsyncIOSXRDriver \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 IOSXRDriver Object Please see `scrapli.driver.base.base_driver.Driver` for all \"base driver\" arguments! # noqa: DAR101 Args: privilege_levels: optional user provided privilege levels, if left None will default to scrapli standard privilege levels default_desired_privilege_level: string of name of default desired priv, this is the priv level that is generally used to disable paging/set terminal width and things like that upon first login, and is also the priv level scrapli will try to acquire for normal \"command\" operations (`send_command`, `send_commands`) auth_secondary: password to use for secondary authentication (enable) on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar. textfsm_platform: string name of textfsm parser platform genie_platform: string name of cisco genie parser platform failed_when_contains: List of strings that indicate a command/config has failed Returns: N/A # noqa: DAR202 Raises: N/A Expand source code class AsyncIOSXRDriver(AsyncNetworkDriver): def __init__( self, host: str, privilege_levels: Optional[Dict[str, PrivilegeLevel]] = None, default_desired_privilege_level: str = \"privilege_exec\", port: Optional[int] = None, auth_username: str = \"\", auth_password: str = \"\", auth_private_key: str = \"\", auth_private_key_passphrase: str = \"\", auth_strict_key: bool = True, auth_bypass: bool = False, timeout_socket: float = 15.0, timeout_transport: float = 30.0, timeout_ops: float = 30.0, comms_return_char: str = \"\\n\", ssh_config_file: Union[str, bool] = False, ssh_known_hosts_file: Union[str, bool] = False, on_init: Optional[Callable[..., Any]] = None, on_open: Optional[Callable[..., Any]] = None, on_close: Optional[Callable[..., Any]] = None, transport: str = \"system\", transport_options: Optional[Dict[str, Any]] = None, channel_log: Union[str, bool, BytesIO] = False, channel_log_mode: str = \"write\", channel_lock: bool = False, logging_uid: str = \"\", auth_secondary: str = \"\", failed_when_contains: Optional[List[str]] = None, textfsm_platform: str = \"cisco_xr\", genie_platform: str = \"iosxr\", ): \"\"\" IOSXRDriver Object Please see `scrapli.driver.base.base_driver.Driver` for all \"base driver\" arguments! # noqa: DAR101 Args: privilege_levels: optional user provided privilege levels, if left None will default to scrapli standard privilege levels default_desired_privilege_level: string of name of default desired priv, this is the priv level that is generally used to disable paging/set terminal width and things like that upon first login, and is also the priv level scrapli will try to acquire for normal \"command\" operations (`send_command`, `send_commands`) auth_secondary: password to use for secondary authentication (enable) on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar. textfsm_platform: string name of textfsm parser platform genie_platform: string name of cisco genie parser platform failed_when_contains: List of strings that indicate a command/config has failed Returns: N/A # noqa: DAR202 Raises: N/A \"\"\" if privilege_levels is None: privilege_levels = deepcopy(PRIVS) if on_open is None: on_open = iosxr_on_open if on_close is None: on_close = iosxr_on_close if failed_when_contains is None: failed_when_contains = FAILED_WHEN_CONTAINS.copy() super().__init__( host=host, port=port, auth_username=auth_username, auth_password=auth_password, auth_private_key=auth_private_key, auth_private_key_passphrase=auth_private_key_passphrase, auth_strict_key=auth_strict_key, auth_bypass=auth_bypass, timeout_socket=timeout_socket, timeout_transport=timeout_transport, timeout_ops=timeout_ops, comms_return_char=comms_return_char, ssh_config_file=ssh_config_file, ssh_known_hosts_file=ssh_known_hosts_file, on_init=on_init, on_open=on_open, on_close=on_close, transport=transport, transport_options=transport_options, channel_log=channel_log, channel_log_mode=channel_log_mode, channel_lock=channel_lock, logging_uid=logging_uid, privilege_levels=privilege_levels, default_desired_privilege_level=default_desired_privilege_level, auth_secondary=auth_secondary, failed_when_contains=failed_when_contains, textfsm_platform=textfsm_platform, genie_platform=genie_platform, ) async def _abort_config(self) -> None: \"\"\" Abort IOSXR configuration session Args: N/A Returns: None Raises: N/A \"\"\" await self.channel.send_input(channel_input=\"abort\") self._current_priv_level = self.privilege_levels[\"privilege_exec\"] Ancestors (in MRO) \u00b6 scrapli.driver.network.async_driver.AsyncNetworkDriver scrapli.driver.generic.async_driver.AsyncGenericDriver scrapli.driver.base.async_driver.AsyncDriver scrapli.driver.base.base_driver.BaseDriver scrapli.driver.generic.base_driver.BaseGenericDriver scrapli.driver.network.base_driver.BaseNetworkDriver","title":"Async Driver"},{"location":"api_docs/driver/core/cisco_iosxr/async_driver/#module-scraplidrivercorecisco_iosxrasync_driver","text":"scrapli.driver.core.cisco_iosxr.async_driver Expand source code \"\"\"scrapli.driver.core.cisco_iosxr.async_driver\"\"\" from copy import deepcopy from io import BytesIO from typing import Any, Callable, Dict, List, Optional, Union from scrapli.driver import AsyncNetworkDriver from scrapli.driver.core.cisco_iosxr.base_driver import FAILED_WHEN_CONTAINS, PRIVS from scrapli.driver.network.base_driver import PrivilegeLevel async def iosxr_on_open(conn: AsyncNetworkDriver) -> None: \"\"\" IOSXRDriver default on_open callable Args: conn: NetworkDriver object Returns: None Raises: N/A \"\"\" await conn.acquire_priv(desired_priv=conn.default_desired_privilege_level) await conn.send_command(command=\"terminal length 0\") await conn.send_command(command=\"terminal width 512\") async def iosxr_on_close(conn: AsyncNetworkDriver) -> None: \"\"\" IOSXRDriver default on_close callable Args: conn: NetworkDriver object Returns: None Raises: N/A \"\"\" await conn.acquire_priv(desired_priv=conn.default_desired_privilege_level) conn.channel.write(channel_input=\"exit\") conn.channel.send_return() class AsyncIOSXRDriver(AsyncNetworkDriver): def __init__( self, host: str, privilege_levels: Optional[Dict[str, PrivilegeLevel]] = None, default_desired_privilege_level: str = \"privilege_exec\", port: Optional[int] = None, auth_username: str = \"\", auth_password: str = \"\", auth_private_key: str = \"\", auth_private_key_passphrase: str = \"\", auth_strict_key: bool = True, auth_bypass: bool = False, timeout_socket: float = 15.0, timeout_transport: float = 30.0, timeout_ops: float = 30.0, comms_return_char: str = \"\\n\", ssh_config_file: Union[str, bool] = False, ssh_known_hosts_file: Union[str, bool] = False, on_init: Optional[Callable[..., Any]] = None, on_open: Optional[Callable[..., Any]] = None, on_close: Optional[Callable[..., Any]] = None, transport: str = \"system\", transport_options: Optional[Dict[str, Any]] = None, channel_log: Union[str, bool, BytesIO] = False, channel_log_mode: str = \"write\", channel_lock: bool = False, logging_uid: str = \"\", auth_secondary: str = \"\", failed_when_contains: Optional[List[str]] = None, textfsm_platform: str = \"cisco_xr\", genie_platform: str = \"iosxr\", ): \"\"\" IOSXRDriver Object Please see `scrapli.driver.base.base_driver.Driver` for all \"base driver\" arguments! # noqa: DAR101 Args: privilege_levels: optional user provided privilege levels, if left None will default to scrapli standard privilege levels default_desired_privilege_level: string of name of default desired priv, this is the priv level that is generally used to disable paging/set terminal width and things like that upon first login, and is also the priv level scrapli will try to acquire for normal \"command\" operations (`send_command`, `send_commands`) auth_secondary: password to use for secondary authentication (enable) on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar. textfsm_platform: string name of textfsm parser platform genie_platform: string name of cisco genie parser platform failed_when_contains: List of strings that indicate a command/config has failed Returns: N/A # noqa: DAR202 Raises: N/A \"\"\" if privilege_levels is None: privilege_levels = deepcopy(PRIVS) if on_open is None: on_open = iosxr_on_open if on_close is None: on_close = iosxr_on_close if failed_when_contains is None: failed_when_contains = FAILED_WHEN_CONTAINS.copy() super().__init__( host=host, port=port, auth_username=auth_username, auth_password=auth_password, auth_private_key=auth_private_key, auth_private_key_passphrase=auth_private_key_passphrase, auth_strict_key=auth_strict_key, auth_bypass=auth_bypass, timeout_socket=timeout_socket, timeout_transport=timeout_transport, timeout_ops=timeout_ops, comms_return_char=comms_return_char, ssh_config_file=ssh_config_file, ssh_known_hosts_file=ssh_known_hosts_file, on_init=on_init, on_open=on_open, on_close=on_close, transport=transport, transport_options=transport_options, channel_log=channel_log, channel_log_mode=channel_log_mode, channel_lock=channel_lock, logging_uid=logging_uid, privilege_levels=privilege_levels, default_desired_privilege_level=default_desired_privilege_level, auth_secondary=auth_secondary, failed_when_contains=failed_when_contains, textfsm_platform=textfsm_platform, genie_platform=genie_platform, ) async def _abort_config(self) -> None: \"\"\" Abort IOSXR configuration session Args: N/A Returns: None Raises: N/A \"\"\" await self.channel.send_input(channel_input=\"abort\") self._current_priv_level = self.privilege_levels[\"privilege_exec\"]","title":"Module scrapli.driver.core.cisco_iosxr.async_driver"},{"location":"api_docs/driver/core/cisco_iosxr/async_driver/#functions","text":"","title":"Functions"},{"location":"api_docs/driver/core/cisco_iosxr/async_driver/#iosxr_on_close","text":"iosxr_on_close(conn: scrapli.driver.network.async_driver.AsyncNetworkDriver) \u2011> None 1 2 3 4 5 6 7 8 9 10 IOSXRDriver default on_close callable Args: conn: NetworkDriver object Returns: None Raises: N/A","title":"iosxr_on_close"},{"location":"api_docs/driver/core/cisco_iosxr/async_driver/#iosxr_on_open","text":"iosxr_on_open(conn: scrapli.driver.network.async_driver.AsyncNetworkDriver) \u2011> None 1 2 3 4 5 6 7 8 9 10 IOSXRDriver default on_open callable Args: conn: NetworkDriver object Returns: None Raises: N/A","title":"iosxr_on_open"},{"location":"api_docs/driver/core/cisco_iosxr/async_driver/#classes","text":"","title":"Classes"},{"location":"api_docs/driver/core/cisco_iosxr/async_driver/#asynciosxrdriver","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 IOSXRDriver Object Please see `scrapli.driver.base.base_driver.Driver` for all \"base driver\" arguments! # noqa: DAR101 Args: privilege_levels: optional user provided privilege levels, if left None will default to scrapli standard privilege levels default_desired_privilege_level: string of name of default desired priv, this is the priv level that is generally used to disable paging/set terminal width and things like that upon first login, and is also the priv level scrapli will try to acquire for normal \"command\" operations (`send_command`, `send_commands`) auth_secondary: password to use for secondary authentication (enable) on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar. textfsm_platform: string name of textfsm parser platform genie_platform: string name of cisco genie parser platform failed_when_contains: List of strings that indicate a command/config has failed Returns: N/A # noqa: DAR202 Raises: N/A Expand source code class AsyncIOSXRDriver(AsyncNetworkDriver): def __init__( self, host: str, privilege_levels: Optional[Dict[str, PrivilegeLevel]] = None, default_desired_privilege_level: str = \"privilege_exec\", port: Optional[int] = None, auth_username: str = \"\", auth_password: str = \"\", auth_private_key: str = \"\", auth_private_key_passphrase: str = \"\", auth_strict_key: bool = True, auth_bypass: bool = False, timeout_socket: float = 15.0, timeout_transport: float = 30.0, timeout_ops: float = 30.0, comms_return_char: str = \"\\n\", ssh_config_file: Union[str, bool] = False, ssh_known_hosts_file: Union[str, bool] = False, on_init: Optional[Callable[..., Any]] = None, on_open: Optional[Callable[..., Any]] = None, on_close: Optional[Callable[..., Any]] = None, transport: str = \"system\", transport_options: Optional[Dict[str, Any]] = None, channel_log: Union[str, bool, BytesIO] = False, channel_log_mode: str = \"write\", channel_lock: bool = False, logging_uid: str = \"\", auth_secondary: str = \"\", failed_when_contains: Optional[List[str]] = None, textfsm_platform: str = \"cisco_xr\", genie_platform: str = \"iosxr\", ): \"\"\" IOSXRDriver Object Please see `scrapli.driver.base.base_driver.Driver` for all \"base driver\" arguments! # noqa: DAR101 Args: privilege_levels: optional user provided privilege levels, if left None will default to scrapli standard privilege levels default_desired_privilege_level: string of name of default desired priv, this is the priv level that is generally used to disable paging/set terminal width and things like that upon first login, and is also the priv level scrapli will try to acquire for normal \"command\" operations (`send_command`, `send_commands`) auth_secondary: password to use for secondary authentication (enable) on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar. textfsm_platform: string name of textfsm parser platform genie_platform: string name of cisco genie parser platform failed_when_contains: List of strings that indicate a command/config has failed Returns: N/A # noqa: DAR202 Raises: N/A \"\"\" if privilege_levels is None: privilege_levels = deepcopy(PRIVS) if on_open is None: on_open = iosxr_on_open if on_close is None: on_close = iosxr_on_close if failed_when_contains is None: failed_when_contains = FAILED_WHEN_CONTAINS.copy() super().__init__( host=host, port=port, auth_username=auth_username, auth_password=auth_password, auth_private_key=auth_private_key, auth_private_key_passphrase=auth_private_key_passphrase, auth_strict_key=auth_strict_key, auth_bypass=auth_bypass, timeout_socket=timeout_socket, timeout_transport=timeout_transport, timeout_ops=timeout_ops, comms_return_char=comms_return_char, ssh_config_file=ssh_config_file, ssh_known_hosts_file=ssh_known_hosts_file, on_init=on_init, on_open=on_open, on_close=on_close, transport=transport, transport_options=transport_options, channel_log=channel_log, channel_log_mode=channel_log_mode, channel_lock=channel_lock, logging_uid=logging_uid, privilege_levels=privilege_levels, default_desired_privilege_level=default_desired_privilege_level, auth_secondary=auth_secondary, failed_when_contains=failed_when_contains, textfsm_platform=textfsm_platform, genie_platform=genie_platform, ) async def _abort_config(self) -> None: \"\"\" Abort IOSXR configuration session Args: N/A Returns: None Raises: N/A \"\"\" await self.channel.send_input(channel_input=\"abort\") self._current_priv_level = self.privilege_levels[\"privilege_exec\"]","title":"AsyncIOSXRDriver"},{"location":"api_docs/driver/core/cisco_iosxr/async_driver/#ancestors-in-mro","text":"scrapli.driver.network.async_driver.AsyncNetworkDriver scrapli.driver.generic.async_driver.AsyncGenericDriver scrapli.driver.base.async_driver.AsyncDriver scrapli.driver.base.base_driver.BaseDriver scrapli.driver.generic.base_driver.BaseGenericDriver scrapli.driver.network.base_driver.BaseNetworkDriver","title":"Ancestors (in MRO)"},{"location":"api_docs/driver/core/cisco_iosxr/base_driver/","text":"window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting()) Module scrapli.driver.core.cisco_iosxr.base_driver \u00b6 scrapli.driver.core.cisco_iosxr.base_driver Expand source code \"\"\"scrapli.driver.core.cisco_iosxr.base_driver\"\"\" from scrapli.driver.network.base_driver import PrivilegeLevel PRIVS = { \"privilege_exec\": ( PrivilegeLevel( pattern=r\"^[\\w.\\-@/:]{1,63}#\\s?$\", name=\"privilege_exec\", previous_priv=\"\", deescalate=\"\", escalate=\"\", escalate_auth=False, escalate_prompt=\"\", ) ), \"configuration\": ( PrivilegeLevel( pattern=r\"^[\\w.\\-@/:]{1,63}\\(config[\\w.\\-@/:]{0,32}\\)#\\s?$\", name=\"configuration\", previous_priv=\"privilege_exec\", deescalate=\"end\", escalate=\"configure terminal\", escalate_auth=False, escalate_prompt=\"\", ) ), \"configuration_exclusive\": ( PrivilegeLevel( pattern=r\"^[\\w.\\-@/:]{1,63}\\(config[\\w.\\-@/:]{0,32}\\)#\\s?$\", name=\"configuration_exclusive\", previous_priv=\"privilege_exec\", deescalate=\"end\", escalate=\"configure exclusive\", escalate_auth=False, escalate_prompt=\"\", ) ), } FAILED_WHEN_CONTAINS = [ \"% Ambiguous command\", \"% Incomplete command\", \"% Invalid input detected\", ]","title":"Base Driver"},{"location":"api_docs/driver/core/cisco_iosxr/base_driver/#module-scraplidrivercorecisco_iosxrbase_driver","text":"scrapli.driver.core.cisco_iosxr.base_driver Expand source code \"\"\"scrapli.driver.core.cisco_iosxr.base_driver\"\"\" from scrapli.driver.network.base_driver import PrivilegeLevel PRIVS = { \"privilege_exec\": ( PrivilegeLevel( pattern=r\"^[\\w.\\-@/:]{1,63}#\\s?$\", name=\"privilege_exec\", previous_priv=\"\", deescalate=\"\", escalate=\"\", escalate_auth=False, escalate_prompt=\"\", ) ), \"configuration\": ( PrivilegeLevel( pattern=r\"^[\\w.\\-@/:]{1,63}\\(config[\\w.\\-@/:]{0,32}\\)#\\s?$\", name=\"configuration\", previous_priv=\"privilege_exec\", deescalate=\"end\", escalate=\"configure terminal\", escalate_auth=False, escalate_prompt=\"\", ) ), \"configuration_exclusive\": ( PrivilegeLevel( pattern=r\"^[\\w.\\-@/:]{1,63}\\(config[\\w.\\-@/:]{0,32}\\)#\\s?$\", name=\"configuration_exclusive\", previous_priv=\"privilege_exec\", deescalate=\"end\", escalate=\"configure exclusive\", escalate_auth=False, escalate_prompt=\"\", ) ), } FAILED_WHEN_CONTAINS = [ \"% Ambiguous command\", \"% Incomplete command\", \"% Invalid input detected\", ]","title":"Module scrapli.driver.core.cisco_iosxr.base_driver"},{"location":"api_docs/driver/core/cisco_iosxr/sync_driver/","text":"window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting()) Module scrapli.driver.core.cisco_iosxr.sync_driver \u00b6 scrapli.driver.core.cisco_iosxr.sync_driver Expand source code \"\"\"scrapli.driver.core.cisco_iosxr.sync_driver\"\"\" from copy import deepcopy from io import BytesIO from typing import Any, Callable, Dict, List, Optional, Union from scrapli.driver import NetworkDriver from scrapli.driver.core.cisco_iosxr.base_driver import FAILED_WHEN_CONTAINS, PRIVS from scrapli.driver.network.base_driver import PrivilegeLevel def iosxr_on_open(conn: NetworkDriver) -> None: \"\"\" IOSXRDriver default on_open callable Args: conn: NetworkDriver object Returns: None Raises: N/A \"\"\" conn.acquire_priv(desired_priv=conn.default_desired_privilege_level) conn.send_command(command=\"terminal length 0\") conn.send_command(command=\"terminal width 512\") def iosxr_on_close(conn: NetworkDriver) -> None: \"\"\" IOSXRDriver default on_close callable Args: conn: NetworkDriver object Returns: None Raises: N/A \"\"\" # write exit directly to the transport as channel would fail to find the prompt after sending # the exit command! conn.acquire_priv(desired_priv=conn.default_desired_privilege_level) conn.channel.write(channel_input=\"exit\") conn.channel.send_return() class IOSXRDriver(NetworkDriver): def __init__( self, host: str, privilege_levels: Optional[Dict[str, PrivilegeLevel]] = None, default_desired_privilege_level: str = \"privilege_exec\", port: Optional[int] = None, auth_username: str = \"\", auth_password: str = \"\", auth_private_key: str = \"\", auth_private_key_passphrase: str = \"\", auth_strict_key: bool = True, auth_bypass: bool = False, timeout_socket: float = 15.0, timeout_transport: float = 30.0, timeout_ops: float = 30.0, comms_return_char: str = \"\\n\", ssh_config_file: Union[str, bool] = False, ssh_known_hosts_file: Union[str, bool] = False, on_init: Optional[Callable[..., Any]] = None, on_open: Optional[Callable[..., Any]] = None, on_close: Optional[Callable[..., Any]] = None, transport: str = \"system\", transport_options: Optional[Dict[str, Any]] = None, channel_log: Union[str, bool, BytesIO] = False, channel_log_mode: str = \"write\", channel_lock: bool = False, logging_uid: str = \"\", auth_secondary: str = \"\", failed_when_contains: Optional[List[str]] = None, textfsm_platform: str = \"cisco_xr\", genie_platform: str = \"iosxr\", ): \"\"\" IOSXRDriver Object Please see `scrapli.driver.base.base_driver.Driver` for all \"base driver\" arguments! # noqa: DAR101 Args: privilege_levels: optional user provided privilege levels, if left None will default to scrapli standard privilege levels default_desired_privilege_level: string of name of default desired priv, this is the priv level that is generally used to disable paging/set terminal width and things like that upon first login, and is also the priv level scrapli will try to acquire for normal \"command\" operations (`send_command`, `send_commands`) auth_secondary: password to use for secondary authentication (enable) on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar. textfsm_platform: string name of textfsm parser platform genie_platform: string name of cisco genie parser platform failed_when_contains: List of strings that indicate a command/config has failed Returns: None Raises: N/A \"\"\" if privilege_levels is None: privilege_levels = deepcopy(PRIVS) if on_open is None: on_open = iosxr_on_open if on_close is None: on_close = iosxr_on_close if failed_when_contains is None: failed_when_contains = FAILED_WHEN_CONTAINS.copy() super().__init__( host=host, port=port, auth_username=auth_username, auth_password=auth_password, auth_private_key=auth_private_key, auth_private_key_passphrase=auth_private_key_passphrase, auth_strict_key=auth_strict_key, auth_bypass=auth_bypass, timeout_socket=timeout_socket, timeout_transport=timeout_transport, timeout_ops=timeout_ops, comms_return_char=comms_return_char, ssh_config_file=ssh_config_file, ssh_known_hosts_file=ssh_known_hosts_file, on_init=on_init, on_open=on_open, on_close=on_close, transport=transport, transport_options=transport_options, channel_log=channel_log, channel_log_mode=channel_log_mode, channel_lock=channel_lock, logging_uid=logging_uid, privilege_levels=privilege_levels, default_desired_privilege_level=default_desired_privilege_level, auth_secondary=auth_secondary, failed_when_contains=failed_when_contains, textfsm_platform=textfsm_platform, genie_platform=genie_platform, ) def _abort_config(self) -> None: \"\"\" Abort IOSXR configuration session Args: N/A Returns: None Raises: N/A \"\"\" self.channel.send_input(channel_input=\"abort\") self._current_priv_level = self.privilege_levels[\"privilege_exec\"] Functions \u00b6 iosxr_on_close \u00b6 iosxr_on_close(conn: scrapli.driver.network.sync_driver.NetworkDriver) \u2011> None 1 2 3 4 5 6 7 8 9 10 IOSXRDriver default on_close callable Args: conn: NetworkDriver object Returns: None Raises: N/A iosxr_on_open \u00b6 iosxr_on_open(conn: scrapli.driver.network.sync_driver.NetworkDriver) \u2011> None 1 2 3 4 5 6 7 8 9 10 IOSXRDriver default on_open callable Args: conn: NetworkDriver object Returns: None Raises: N/A Classes \u00b6 IOSXRDriver \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 IOSXRDriver Object Please see `scrapli.driver.base.base_driver.Driver` for all \"base driver\" arguments! # noqa: DAR101 Args: privilege_levels: optional user provided privilege levels, if left None will default to scrapli standard privilege levels default_desired_privilege_level: string of name of default desired priv, this is the priv level that is generally used to disable paging/set terminal width and things like that upon first login, and is also the priv level scrapli will try to acquire for normal \"command\" operations (`send_command`, `send_commands`) auth_secondary: password to use for secondary authentication (enable) on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar. textfsm_platform: string name of textfsm parser platform genie_platform: string name of cisco genie parser platform failed_when_contains: List of strings that indicate a command/config has failed Returns: None Raises: N/A Expand source code class IOSXRDriver(NetworkDriver): def __init__( self, host: str, privilege_levels: Optional[Dict[str, PrivilegeLevel]] = None, default_desired_privilege_level: str = \"privilege_exec\", port: Optional[int] = None, auth_username: str = \"\", auth_password: str = \"\", auth_private_key: str = \"\", auth_private_key_passphrase: str = \"\", auth_strict_key: bool = True, auth_bypass: bool = False, timeout_socket: float = 15.0, timeout_transport: float = 30.0, timeout_ops: float = 30.0, comms_return_char: str = \"\\n\", ssh_config_file: Union[str, bool] = False, ssh_known_hosts_file: Union[str, bool] = False, on_init: Optional[Callable[..., Any]] = None, on_open: Optional[Callable[..., Any]] = None, on_close: Optional[Callable[..., Any]] = None, transport: str = \"system\", transport_options: Optional[Dict[str, Any]] = None, channel_log: Union[str, bool, BytesIO] = False, channel_log_mode: str = \"write\", channel_lock: bool = False, logging_uid: str = \"\", auth_secondary: str = \"\", failed_when_contains: Optional[List[str]] = None, textfsm_platform: str = \"cisco_xr\", genie_platform: str = \"iosxr\", ): \"\"\" IOSXRDriver Object Please see `scrapli.driver.base.base_driver.Driver` for all \"base driver\" arguments! # noqa: DAR101 Args: privilege_levels: optional user provided privilege levels, if left None will default to scrapli standard privilege levels default_desired_privilege_level: string of name of default desired priv, this is the priv level that is generally used to disable paging/set terminal width and things like that upon first login, and is also the priv level scrapli will try to acquire for normal \"command\" operations (`send_command`, `send_commands`) auth_secondary: password to use for secondary authentication (enable) on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar. textfsm_platform: string name of textfsm parser platform genie_platform: string name of cisco genie parser platform failed_when_contains: List of strings that indicate a command/config has failed Returns: None Raises: N/A \"\"\" if privilege_levels is None: privilege_levels = deepcopy(PRIVS) if on_open is None: on_open = iosxr_on_open if on_close is None: on_close = iosxr_on_close if failed_when_contains is None: failed_when_contains = FAILED_WHEN_CONTAINS.copy() super().__init__( host=host, port=port, auth_username=auth_username, auth_password=auth_password, auth_private_key=auth_private_key, auth_private_key_passphrase=auth_private_key_passphrase, auth_strict_key=auth_strict_key, auth_bypass=auth_bypass, timeout_socket=timeout_socket, timeout_transport=timeout_transport, timeout_ops=timeout_ops, comms_return_char=comms_return_char, ssh_config_file=ssh_config_file, ssh_known_hosts_file=ssh_known_hosts_file, on_init=on_init, on_open=on_open, on_close=on_close, transport=transport, transport_options=transport_options, channel_log=channel_log, channel_log_mode=channel_log_mode, channel_lock=channel_lock, logging_uid=logging_uid, privilege_levels=privilege_levels, default_desired_privilege_level=default_desired_privilege_level, auth_secondary=auth_secondary, failed_when_contains=failed_when_contains, textfsm_platform=textfsm_platform, genie_platform=genie_platform, ) def _abort_config(self) -> None: \"\"\" Abort IOSXR configuration session Args: N/A Returns: None Raises: N/A \"\"\" self.channel.send_input(channel_input=\"abort\") self._current_priv_level = self.privilege_levels[\"privilege_exec\"] Ancestors (in MRO) \u00b6 scrapli.driver.network.sync_driver.NetworkDriver scrapli.driver.generic.sync_driver.GenericDriver scrapli.driver.base.sync_driver.Driver scrapli.driver.base.base_driver.BaseDriver scrapli.driver.generic.base_driver.BaseGenericDriver scrapli.driver.network.base_driver.BaseNetworkDriver","title":"Sync Driver"},{"location":"api_docs/driver/core/cisco_iosxr/sync_driver/#module-scraplidrivercorecisco_iosxrsync_driver","text":"scrapli.driver.core.cisco_iosxr.sync_driver Expand source code \"\"\"scrapli.driver.core.cisco_iosxr.sync_driver\"\"\" from copy import deepcopy from io import BytesIO from typing import Any, Callable, Dict, List, Optional, Union from scrapli.driver import NetworkDriver from scrapli.driver.core.cisco_iosxr.base_driver import FAILED_WHEN_CONTAINS, PRIVS from scrapli.driver.network.base_driver import PrivilegeLevel def iosxr_on_open(conn: NetworkDriver) -> None: \"\"\" IOSXRDriver default on_open callable Args: conn: NetworkDriver object Returns: None Raises: N/A \"\"\" conn.acquire_priv(desired_priv=conn.default_desired_privilege_level) conn.send_command(command=\"terminal length 0\") conn.send_command(command=\"terminal width 512\") def iosxr_on_close(conn: NetworkDriver) -> None: \"\"\" IOSXRDriver default on_close callable Args: conn: NetworkDriver object Returns: None Raises: N/A \"\"\" # write exit directly to the transport as channel would fail to find the prompt after sending # the exit command! conn.acquire_priv(desired_priv=conn.default_desired_privilege_level) conn.channel.write(channel_input=\"exit\") conn.channel.send_return() class IOSXRDriver(NetworkDriver): def __init__( self, host: str, privilege_levels: Optional[Dict[str, PrivilegeLevel]] = None, default_desired_privilege_level: str = \"privilege_exec\", port: Optional[int] = None, auth_username: str = \"\", auth_password: str = \"\", auth_private_key: str = \"\", auth_private_key_passphrase: str = \"\", auth_strict_key: bool = True, auth_bypass: bool = False, timeout_socket: float = 15.0, timeout_transport: float = 30.0, timeout_ops: float = 30.0, comms_return_char: str = \"\\n\", ssh_config_file: Union[str, bool] = False, ssh_known_hosts_file: Union[str, bool] = False, on_init: Optional[Callable[..., Any]] = None, on_open: Optional[Callable[..., Any]] = None, on_close: Optional[Callable[..., Any]] = None, transport: str = \"system\", transport_options: Optional[Dict[str, Any]] = None, channel_log: Union[str, bool, BytesIO] = False, channel_log_mode: str = \"write\", channel_lock: bool = False, logging_uid: str = \"\", auth_secondary: str = \"\", failed_when_contains: Optional[List[str]] = None, textfsm_platform: str = \"cisco_xr\", genie_platform: str = \"iosxr\", ): \"\"\" IOSXRDriver Object Please see `scrapli.driver.base.base_driver.Driver` for all \"base driver\" arguments! # noqa: DAR101 Args: privilege_levels: optional user provided privilege levels, if left None will default to scrapli standard privilege levels default_desired_privilege_level: string of name of default desired priv, this is the priv level that is generally used to disable paging/set terminal width and things like that upon first login, and is also the priv level scrapli will try to acquire for normal \"command\" operations (`send_command`, `send_commands`) auth_secondary: password to use for secondary authentication (enable) on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar. textfsm_platform: string name of textfsm parser platform genie_platform: string name of cisco genie parser platform failed_when_contains: List of strings that indicate a command/config has failed Returns: None Raises: N/A \"\"\" if privilege_levels is None: privilege_levels = deepcopy(PRIVS) if on_open is None: on_open = iosxr_on_open if on_close is None: on_close = iosxr_on_close if failed_when_contains is None: failed_when_contains = FAILED_WHEN_CONTAINS.copy() super().__init__( host=host, port=port, auth_username=auth_username, auth_password=auth_password, auth_private_key=auth_private_key, auth_private_key_passphrase=auth_private_key_passphrase, auth_strict_key=auth_strict_key, auth_bypass=auth_bypass, timeout_socket=timeout_socket, timeout_transport=timeout_transport, timeout_ops=timeout_ops, comms_return_char=comms_return_char, ssh_config_file=ssh_config_file, ssh_known_hosts_file=ssh_known_hosts_file, on_init=on_init, on_open=on_open, on_close=on_close, transport=transport, transport_options=transport_options, channel_log=channel_log, channel_log_mode=channel_log_mode, channel_lock=channel_lock, logging_uid=logging_uid, privilege_levels=privilege_levels, default_desired_privilege_level=default_desired_privilege_level, auth_secondary=auth_secondary, failed_when_contains=failed_when_contains, textfsm_platform=textfsm_platform, genie_platform=genie_platform, ) def _abort_config(self) -> None: \"\"\" Abort IOSXR configuration session Args: N/A Returns: None Raises: N/A \"\"\" self.channel.send_input(channel_input=\"abort\") self._current_priv_level = self.privilege_levels[\"privilege_exec\"]","title":"Module scrapli.driver.core.cisco_iosxr.sync_driver"},{"location":"api_docs/driver/core/cisco_iosxr/sync_driver/#functions","text":"","title":"Functions"},{"location":"api_docs/driver/core/cisco_iosxr/sync_driver/#iosxr_on_close","text":"iosxr_on_close(conn: scrapli.driver.network.sync_driver.NetworkDriver) \u2011> None 1 2 3 4 5 6 7 8 9 10 IOSXRDriver default on_close callable Args: conn: NetworkDriver object Returns: None Raises: N/A","title":"iosxr_on_close"},{"location":"api_docs/driver/core/cisco_iosxr/sync_driver/#iosxr_on_open","text":"iosxr_on_open(conn: scrapli.driver.network.sync_driver.NetworkDriver) \u2011> None 1 2 3 4 5 6 7 8 9 10 IOSXRDriver default on_open callable Args: conn: NetworkDriver object Returns: None Raises: N/A","title":"iosxr_on_open"},{"location":"api_docs/driver/core/cisco_iosxr/sync_driver/#classes","text":"","title":"Classes"},{"location":"api_docs/driver/core/cisco_iosxr/sync_driver/#iosxrdriver","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 IOSXRDriver Object Please see `scrapli.driver.base.base_driver.Driver` for all \"base driver\" arguments! # noqa: DAR101 Args: privilege_levels: optional user provided privilege levels, if left None will default to scrapli standard privilege levels default_desired_privilege_level: string of name of default desired priv, this is the priv level that is generally used to disable paging/set terminal width and things like that upon first login, and is also the priv level scrapli will try to acquire for normal \"command\" operations (`send_command`, `send_commands`) auth_secondary: password to use for secondary authentication (enable) on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar. textfsm_platform: string name of textfsm parser platform genie_platform: string name of cisco genie parser platform failed_when_contains: List of strings that indicate a command/config has failed Returns: None Raises: N/A Expand source code class IOSXRDriver(NetworkDriver): def __init__( self, host: str, privilege_levels: Optional[Dict[str, PrivilegeLevel]] = None, default_desired_privilege_level: str = \"privilege_exec\", port: Optional[int] = None, auth_username: str = \"\", auth_password: str = \"\", auth_private_key: str = \"\", auth_private_key_passphrase: str = \"\", auth_strict_key: bool = True, auth_bypass: bool = False, timeout_socket: float = 15.0, timeout_transport: float = 30.0, timeout_ops: float = 30.0, comms_return_char: str = \"\\n\", ssh_config_file: Union[str, bool] = False, ssh_known_hosts_file: Union[str, bool] = False, on_init: Optional[Callable[..., Any]] = None, on_open: Optional[Callable[..., Any]] = None, on_close: Optional[Callable[..., Any]] = None, transport: str = \"system\", transport_options: Optional[Dict[str, Any]] = None, channel_log: Union[str, bool, BytesIO] = False, channel_log_mode: str = \"write\", channel_lock: bool = False, logging_uid: str = \"\", auth_secondary: str = \"\", failed_when_contains: Optional[List[str]] = None, textfsm_platform: str = \"cisco_xr\", genie_platform: str = \"iosxr\", ): \"\"\" IOSXRDriver Object Please see `scrapli.driver.base.base_driver.Driver` for all \"base driver\" arguments! # noqa: DAR101 Args: privilege_levels: optional user provided privilege levels, if left None will default to scrapli standard privilege levels default_desired_privilege_level: string of name of default desired priv, this is the priv level that is generally used to disable paging/set terminal width and things like that upon first login, and is also the priv level scrapli will try to acquire for normal \"command\" operations (`send_command`, `send_commands`) auth_secondary: password to use for secondary authentication (enable) on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar. textfsm_platform: string name of textfsm parser platform genie_platform: string name of cisco genie parser platform failed_when_contains: List of strings that indicate a command/config has failed Returns: None Raises: N/A \"\"\" if privilege_levels is None: privilege_levels = deepcopy(PRIVS) if on_open is None: on_open = iosxr_on_open if on_close is None: on_close = iosxr_on_close if failed_when_contains is None: failed_when_contains = FAILED_WHEN_CONTAINS.copy() super().__init__( host=host, port=port, auth_username=auth_username, auth_password=auth_password, auth_private_key=auth_private_key, auth_private_key_passphrase=auth_private_key_passphrase, auth_strict_key=auth_strict_key, auth_bypass=auth_bypass, timeout_socket=timeout_socket, timeout_transport=timeout_transport, timeout_ops=timeout_ops, comms_return_char=comms_return_char, ssh_config_file=ssh_config_file, ssh_known_hosts_file=ssh_known_hosts_file, on_init=on_init, on_open=on_open, on_close=on_close, transport=transport, transport_options=transport_options, channel_log=channel_log, channel_log_mode=channel_log_mode, channel_lock=channel_lock, logging_uid=logging_uid, privilege_levels=privilege_levels, default_desired_privilege_level=default_desired_privilege_level, auth_secondary=auth_secondary, failed_when_contains=failed_when_contains, textfsm_platform=textfsm_platform, genie_platform=genie_platform, ) def _abort_config(self) -> None: \"\"\" Abort IOSXR configuration session Args: N/A Returns: None Raises: N/A \"\"\" self.channel.send_input(channel_input=\"abort\") self._current_priv_level = self.privilege_levels[\"privilege_exec\"]","title":"IOSXRDriver"},{"location":"api_docs/driver/core/cisco_iosxr/sync_driver/#ancestors-in-mro","text":"scrapli.driver.network.sync_driver.NetworkDriver scrapli.driver.generic.sync_driver.GenericDriver scrapli.driver.base.sync_driver.Driver scrapli.driver.base.base_driver.BaseDriver scrapli.driver.generic.base_driver.BaseGenericDriver scrapli.driver.network.base_driver.BaseNetworkDriver","title":"Ancestors (in MRO)"},{"location":"api_docs/driver/core/cisco_nxos/async_driver/","text":"window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting()) Module scrapli.driver.core.cisco_nxos.async_driver \u00b6 scrapli.driver.core.cisco_nxos.async_driver Expand source code \"\"\"scrapli.driver.core.cisco_nxos.async_driver\"\"\" from copy import deepcopy from io import BytesIO from typing import Any, Callable, Dict, List, Optional, Union from scrapli.driver import AsyncNetworkDriver from scrapli.driver.core.cisco_nxos.base_driver import FAILED_WHEN_CONTAINS, PRIVS, NXOSDriverBase from scrapli.driver.network.base_driver import PrivilegeLevel async def nxos_on_open(conn: AsyncNetworkDriver) -> None: \"\"\" AsyncNXOSDriver default on_open callable Args: conn: NetworkDriver object Returns: None Raises: N/A \"\"\" await conn.acquire_priv(desired_priv=conn.default_desired_privilege_level) await conn.send_command(command=\"terminal length 0\") await conn.send_command(command=\"terminal width 511\") async def nxos_on_close(conn: AsyncNetworkDriver) -> None: \"\"\" AsyncNXOSDriver default on_close callable Args: conn: NetworkDriver object Returns: None Raises: N/A \"\"\" await conn.acquire_priv(desired_priv=conn.default_desired_privilege_level) conn.channel.write(channel_input=\"exit\") conn.channel.send_return() class AsyncNXOSDriver(AsyncNetworkDriver, NXOSDriverBase): def __init__( self, host: str, privilege_levels: Optional[Dict[str, PrivilegeLevel]] = None, default_desired_privilege_level: str = \"privilege_exec\", port: Optional[int] = None, auth_username: str = \"\", auth_password: str = \"\", auth_private_key: str = \"\", auth_private_key_passphrase: str = \"\", auth_strict_key: bool = True, auth_bypass: bool = False, timeout_socket: float = 15.0, timeout_transport: float = 30.0, timeout_ops: float = 30.0, comms_return_char: str = \"\\n\", ssh_config_file: Union[str, bool] = False, ssh_known_hosts_file: Union[str, bool] = False, on_init: Optional[Callable[..., Any]] = None, on_open: Optional[Callable[..., Any]] = None, on_close: Optional[Callable[..., Any]] = None, transport: str = \"system\", transport_options: Optional[Dict[str, Any]] = None, channel_log: Union[str, bool, BytesIO] = False, channel_log_mode: str = \"write\", channel_lock: bool = False, logging_uid: str = \"\", auth_secondary: str = \"\", failed_when_contains: Optional[List[str]] = None, textfsm_platform: str = \"cisco_nxos\", genie_platform: str = \"nxos\", ): \"\"\" NXOSDriver Object Please see `scrapli.driver.base.base_driver.Driver` for all \"base driver\" arguments! # noqa: DAR101 Args: privilege_levels: optional user provided privilege levels, if left None will default to scrapli standard privilege levels default_desired_privilege_level: string of name of default desired priv, this is the priv level that is generally used to disable paging/set terminal width and things like that upon first login, and is also the priv level scrapli will try to acquire for normal \"command\" operations (`send_command`, `send_commands`) auth_secondary: password to use for secondary authentication (enable) on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar. textfsm_platform: string name of textfsm parser platform genie_platform: string name of cisco genie parser platform failed_when_contains: List of strings that indicate a command/config has failed Returns: None Raises: N/A \"\"\" # somewhere/somehow the mixin is causing mypy to be upset about comms_prompt_pattern... self.comms_prompt_pattern: str if privilege_levels is None: privilege_levels = deepcopy(PRIVS) if on_open is None: on_open = nxos_on_open if on_close is None: on_close = nxos_on_close if failed_when_contains is None: failed_when_contains = FAILED_WHEN_CONTAINS.copy() super().__init__( host=host, port=port, auth_username=auth_username, auth_password=auth_password, auth_private_key=auth_private_key, auth_private_key_passphrase=auth_private_key_passphrase, auth_strict_key=auth_strict_key, auth_bypass=auth_bypass, timeout_socket=timeout_socket, timeout_transport=timeout_transport, timeout_ops=timeout_ops, comms_return_char=comms_return_char, ssh_config_file=ssh_config_file, ssh_known_hosts_file=ssh_known_hosts_file, on_init=on_init, on_open=on_open, on_close=on_close, transport=transport, transport_options=transport_options, channel_log=channel_log, channel_log_mode=channel_log_mode, channel_lock=channel_lock, logging_uid=logging_uid, privilege_levels=privilege_levels, default_desired_privilege_level=default_desired_privilege_level, auth_secondary=auth_secondary, failed_when_contains=failed_when_contains, textfsm_platform=textfsm_platform, genie_platform=genie_platform, ) async def _abort_config(self) -> None: \"\"\" Abort NXOS configuration session (if using a config session!) Args: N/A Returns: None Raises: N/A \"\"\" # nxos pattern for config sessions should *always* have `config-s` if \"config\\\\-s\" in self._current_priv_level.pattern: await self.channel.send_input(channel_input=\"abort\") self._current_priv_level = self.privilege_levels[\"privilege_exec\"] def register_configuration_session(self, session_name: str) -> None: \"\"\" NXOS specific implementation of register_configuration_session Args: session_name: name of session to register Returns: None Raises: N/A \"\"\" self._create_configuration_session(session_name=session_name) self.update_privilege_levels() Functions \u00b6 nxos_on_close \u00b6 nxos_on_close(conn: scrapli.driver.network.async_driver.AsyncNetworkDriver) \u2011> None 1 2 3 4 5 6 7 8 9 10 AsyncNXOSDriver default on_close callable Args: conn: NetworkDriver object Returns: None Raises: N/A nxos_on_open \u00b6 nxos_on_open(conn: scrapli.driver.network.async_driver.AsyncNetworkDriver) \u2011> None 1 2 3 4 5 6 7 8 9 10 AsyncNXOSDriver default on_open callable Args: conn: NetworkDriver object Returns: None Raises: N/A Classes \u00b6 AsyncNXOSDriver \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 NXOSDriver Object Please see `scrapli.driver.base.base_driver.Driver` for all \"base driver\" arguments! # noqa: DAR101 Args: privilege_levels: optional user provided privilege levels, if left None will default to scrapli standard privilege levels default_desired_privilege_level: string of name of default desired priv, this is the priv level that is generally used to disable paging/set terminal width and things like that upon first login, and is also the priv level scrapli will try to acquire for normal \"command\" operations (`send_command`, `send_commands`) auth_secondary: password to use for secondary authentication (enable) on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar. textfsm_platform: string name of textfsm parser platform genie_platform: string name of cisco genie parser platform failed_when_contains: List of strings that indicate a command/config has failed Returns: None Raises: N/A Expand source code class AsyncNXOSDriver(AsyncNetworkDriver, NXOSDriverBase): def __init__( self, host: str, privilege_levels: Optional[Dict[str, PrivilegeLevel]] = None, default_desired_privilege_level: str = \"privilege_exec\", port: Optional[int] = None, auth_username: str = \"\", auth_password: str = \"\", auth_private_key: str = \"\", auth_private_key_passphrase: str = \"\", auth_strict_key: bool = True, auth_bypass: bool = False, timeout_socket: float = 15.0, timeout_transport: float = 30.0, timeout_ops: float = 30.0, comms_return_char: str = \"\\n\", ssh_config_file: Union[str, bool] = False, ssh_known_hosts_file: Union[str, bool] = False, on_init: Optional[Callable[..., Any]] = None, on_open: Optional[Callable[..., Any]] = None, on_close: Optional[Callable[..., Any]] = None, transport: str = \"system\", transport_options: Optional[Dict[str, Any]] = None, channel_log: Union[str, bool, BytesIO] = False, channel_log_mode: str = \"write\", channel_lock: bool = False, logging_uid: str = \"\", auth_secondary: str = \"\", failed_when_contains: Optional[List[str]] = None, textfsm_platform: str = \"cisco_nxos\", genie_platform: str = \"nxos\", ): \"\"\" NXOSDriver Object Please see `scrapli.driver.base.base_driver.Driver` for all \"base driver\" arguments! # noqa: DAR101 Args: privilege_levels: optional user provided privilege levels, if left None will default to scrapli standard privilege levels default_desired_privilege_level: string of name of default desired priv, this is the priv level that is generally used to disable paging/set terminal width and things like that upon first login, and is also the priv level scrapli will try to acquire for normal \"command\" operations (`send_command`, `send_commands`) auth_secondary: password to use for secondary authentication (enable) on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar. textfsm_platform: string name of textfsm parser platform genie_platform: string name of cisco genie parser platform failed_when_contains: List of strings that indicate a command/config has failed Returns: None Raises: N/A \"\"\" # somewhere/somehow the mixin is causing mypy to be upset about comms_prompt_pattern... self.comms_prompt_pattern: str if privilege_levels is None: privilege_levels = deepcopy(PRIVS) if on_open is None: on_open = nxos_on_open if on_close is None: on_close = nxos_on_close if failed_when_contains is None: failed_when_contains = FAILED_WHEN_CONTAINS.copy() super().__init__( host=host, port=port, auth_username=auth_username, auth_password=auth_password, auth_private_key=auth_private_key, auth_private_key_passphrase=auth_private_key_passphrase, auth_strict_key=auth_strict_key, auth_bypass=auth_bypass, timeout_socket=timeout_socket, timeout_transport=timeout_transport, timeout_ops=timeout_ops, comms_return_char=comms_return_char, ssh_config_file=ssh_config_file, ssh_known_hosts_file=ssh_known_hosts_file, on_init=on_init, on_open=on_open, on_close=on_close, transport=transport, transport_options=transport_options, channel_log=channel_log, channel_log_mode=channel_log_mode, channel_lock=channel_lock, logging_uid=logging_uid, privilege_levels=privilege_levels, default_desired_privilege_level=default_desired_privilege_level, auth_secondary=auth_secondary, failed_when_contains=failed_when_contains, textfsm_platform=textfsm_platform, genie_platform=genie_platform, ) async def _abort_config(self) -> None: \"\"\" Abort NXOS configuration session (if using a config session!) Args: N/A Returns: None Raises: N/A \"\"\" # nxos pattern for config sessions should *always* have `config-s` if \"config\\\\-s\" in self._current_priv_level.pattern: await self.channel.send_input(channel_input=\"abort\") self._current_priv_level = self.privilege_levels[\"privilege_exec\"] def register_configuration_session(self, session_name: str) -> None: \"\"\" NXOS specific implementation of register_configuration_session Args: session_name: name of session to register Returns: None Raises: N/A \"\"\" self._create_configuration_session(session_name=session_name) self.update_privilege_levels() Ancestors (in MRO) \u00b6 scrapli.driver.network.async_driver.AsyncNetworkDriver scrapli.driver.generic.async_driver.AsyncGenericDriver scrapli.driver.base.async_driver.AsyncDriver scrapli.driver.base.base_driver.BaseDriver scrapli.driver.generic.base_driver.BaseGenericDriver scrapli.driver.network.base_driver.BaseNetworkDriver scrapli.driver.core.cisco_nxos.base_driver.NXOSDriverBase Methods \u00b6 register_configuration_session \u00b6 register_configuration_session(self, session_name: str) \u2011> None 1 2 3 4 5 6 7 8 9 10 NXOS specific implementation of register_configuration_session Args: session_name: name of session to register Returns: None Raises: N/A","title":"Async Driver"},{"location":"api_docs/driver/core/cisco_nxos/async_driver/#module-scraplidrivercorecisco_nxosasync_driver","text":"scrapli.driver.core.cisco_nxos.async_driver Expand source code \"\"\"scrapli.driver.core.cisco_nxos.async_driver\"\"\" from copy import deepcopy from io import BytesIO from typing import Any, Callable, Dict, List, Optional, Union from scrapli.driver import AsyncNetworkDriver from scrapli.driver.core.cisco_nxos.base_driver import FAILED_WHEN_CONTAINS, PRIVS, NXOSDriverBase from scrapli.driver.network.base_driver import PrivilegeLevel async def nxos_on_open(conn: AsyncNetworkDriver) -> None: \"\"\" AsyncNXOSDriver default on_open callable Args: conn: NetworkDriver object Returns: None Raises: N/A \"\"\" await conn.acquire_priv(desired_priv=conn.default_desired_privilege_level) await conn.send_command(command=\"terminal length 0\") await conn.send_command(command=\"terminal width 511\") async def nxos_on_close(conn: AsyncNetworkDriver) -> None: \"\"\" AsyncNXOSDriver default on_close callable Args: conn: NetworkDriver object Returns: None Raises: N/A \"\"\" await conn.acquire_priv(desired_priv=conn.default_desired_privilege_level) conn.channel.write(channel_input=\"exit\") conn.channel.send_return() class AsyncNXOSDriver(AsyncNetworkDriver, NXOSDriverBase): def __init__( self, host: str, privilege_levels: Optional[Dict[str, PrivilegeLevel]] = None, default_desired_privilege_level: str = \"privilege_exec\", port: Optional[int] = None, auth_username: str = \"\", auth_password: str = \"\", auth_private_key: str = \"\", auth_private_key_passphrase: str = \"\", auth_strict_key: bool = True, auth_bypass: bool = False, timeout_socket: float = 15.0, timeout_transport: float = 30.0, timeout_ops: float = 30.0, comms_return_char: str = \"\\n\", ssh_config_file: Union[str, bool] = False, ssh_known_hosts_file: Union[str, bool] = False, on_init: Optional[Callable[..., Any]] = None, on_open: Optional[Callable[..., Any]] = None, on_close: Optional[Callable[..., Any]] = None, transport: str = \"system\", transport_options: Optional[Dict[str, Any]] = None, channel_log: Union[str, bool, BytesIO] = False, channel_log_mode: str = \"write\", channel_lock: bool = False, logging_uid: str = \"\", auth_secondary: str = \"\", failed_when_contains: Optional[List[str]] = None, textfsm_platform: str = \"cisco_nxos\", genie_platform: str = \"nxos\", ): \"\"\" NXOSDriver Object Please see `scrapli.driver.base.base_driver.Driver` for all \"base driver\" arguments! # noqa: DAR101 Args: privilege_levels: optional user provided privilege levels, if left None will default to scrapli standard privilege levels default_desired_privilege_level: string of name of default desired priv, this is the priv level that is generally used to disable paging/set terminal width and things like that upon first login, and is also the priv level scrapli will try to acquire for normal \"command\" operations (`send_command`, `send_commands`) auth_secondary: password to use for secondary authentication (enable) on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar. textfsm_platform: string name of textfsm parser platform genie_platform: string name of cisco genie parser platform failed_when_contains: List of strings that indicate a command/config has failed Returns: None Raises: N/A \"\"\" # somewhere/somehow the mixin is causing mypy to be upset about comms_prompt_pattern... self.comms_prompt_pattern: str if privilege_levels is None: privilege_levels = deepcopy(PRIVS) if on_open is None: on_open = nxos_on_open if on_close is None: on_close = nxos_on_close if failed_when_contains is None: failed_when_contains = FAILED_WHEN_CONTAINS.copy() super().__init__( host=host, port=port, auth_username=auth_username, auth_password=auth_password, auth_private_key=auth_private_key, auth_private_key_passphrase=auth_private_key_passphrase, auth_strict_key=auth_strict_key, auth_bypass=auth_bypass, timeout_socket=timeout_socket, timeout_transport=timeout_transport, timeout_ops=timeout_ops, comms_return_char=comms_return_char, ssh_config_file=ssh_config_file, ssh_known_hosts_file=ssh_known_hosts_file, on_init=on_init, on_open=on_open, on_close=on_close, transport=transport, transport_options=transport_options, channel_log=channel_log, channel_log_mode=channel_log_mode, channel_lock=channel_lock, logging_uid=logging_uid, privilege_levels=privilege_levels, default_desired_privilege_level=default_desired_privilege_level, auth_secondary=auth_secondary, failed_when_contains=failed_when_contains, textfsm_platform=textfsm_platform, genie_platform=genie_platform, ) async def _abort_config(self) -> None: \"\"\" Abort NXOS configuration session (if using a config session!) Args: N/A Returns: None Raises: N/A \"\"\" # nxos pattern for config sessions should *always* have `config-s` if \"config\\\\-s\" in self._current_priv_level.pattern: await self.channel.send_input(channel_input=\"abort\") self._current_priv_level = self.privilege_levels[\"privilege_exec\"] def register_configuration_session(self, session_name: str) -> None: \"\"\" NXOS specific implementation of register_configuration_session Args: session_name: name of session to register Returns: None Raises: N/A \"\"\" self._create_configuration_session(session_name=session_name) self.update_privilege_levels()","title":"Module scrapli.driver.core.cisco_nxos.async_driver"},{"location":"api_docs/driver/core/cisco_nxos/async_driver/#functions","text":"","title":"Functions"},{"location":"api_docs/driver/core/cisco_nxos/async_driver/#nxos_on_close","text":"nxos_on_close(conn: scrapli.driver.network.async_driver.AsyncNetworkDriver) \u2011> None 1 2 3 4 5 6 7 8 9 10 AsyncNXOSDriver default on_close callable Args: conn: NetworkDriver object Returns: None Raises: N/A","title":"nxos_on_close"},{"location":"api_docs/driver/core/cisco_nxos/async_driver/#nxos_on_open","text":"nxos_on_open(conn: scrapli.driver.network.async_driver.AsyncNetworkDriver) \u2011> None 1 2 3 4 5 6 7 8 9 10 AsyncNXOSDriver default on_open callable Args: conn: NetworkDriver object Returns: None Raises: N/A","title":"nxos_on_open"},{"location":"api_docs/driver/core/cisco_nxos/async_driver/#classes","text":"","title":"Classes"},{"location":"api_docs/driver/core/cisco_nxos/async_driver/#asyncnxosdriver","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 NXOSDriver Object Please see `scrapli.driver.base.base_driver.Driver` for all \"base driver\" arguments! # noqa: DAR101 Args: privilege_levels: optional user provided privilege levels, if left None will default to scrapli standard privilege levels default_desired_privilege_level: string of name of default desired priv, this is the priv level that is generally used to disable paging/set terminal width and things like that upon first login, and is also the priv level scrapli will try to acquire for normal \"command\" operations (`send_command`, `send_commands`) auth_secondary: password to use for secondary authentication (enable) on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar. textfsm_platform: string name of textfsm parser platform genie_platform: string name of cisco genie parser platform failed_when_contains: List of strings that indicate a command/config has failed Returns: None Raises: N/A Expand source code class AsyncNXOSDriver(AsyncNetworkDriver, NXOSDriverBase): def __init__( self, host: str, privilege_levels: Optional[Dict[str, PrivilegeLevel]] = None, default_desired_privilege_level: str = \"privilege_exec\", port: Optional[int] = None, auth_username: str = \"\", auth_password: str = \"\", auth_private_key: str = \"\", auth_private_key_passphrase: str = \"\", auth_strict_key: bool = True, auth_bypass: bool = False, timeout_socket: float = 15.0, timeout_transport: float = 30.0, timeout_ops: float = 30.0, comms_return_char: str = \"\\n\", ssh_config_file: Union[str, bool] = False, ssh_known_hosts_file: Union[str, bool] = False, on_init: Optional[Callable[..., Any]] = None, on_open: Optional[Callable[..., Any]] = None, on_close: Optional[Callable[..., Any]] = None, transport: str = \"system\", transport_options: Optional[Dict[str, Any]] = None, channel_log: Union[str, bool, BytesIO] = False, channel_log_mode: str = \"write\", channel_lock: bool = False, logging_uid: str = \"\", auth_secondary: str = \"\", failed_when_contains: Optional[List[str]] = None, textfsm_platform: str = \"cisco_nxos\", genie_platform: str = \"nxos\", ): \"\"\" NXOSDriver Object Please see `scrapli.driver.base.base_driver.Driver` for all \"base driver\" arguments! # noqa: DAR101 Args: privilege_levels: optional user provided privilege levels, if left None will default to scrapli standard privilege levels default_desired_privilege_level: string of name of default desired priv, this is the priv level that is generally used to disable paging/set terminal width and things like that upon first login, and is also the priv level scrapli will try to acquire for normal \"command\" operations (`send_command`, `send_commands`) auth_secondary: password to use for secondary authentication (enable) on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar. textfsm_platform: string name of textfsm parser platform genie_platform: string name of cisco genie parser platform failed_when_contains: List of strings that indicate a command/config has failed Returns: None Raises: N/A \"\"\" # somewhere/somehow the mixin is causing mypy to be upset about comms_prompt_pattern... self.comms_prompt_pattern: str if privilege_levels is None: privilege_levels = deepcopy(PRIVS) if on_open is None: on_open = nxos_on_open if on_close is None: on_close = nxos_on_close if failed_when_contains is None: failed_when_contains = FAILED_WHEN_CONTAINS.copy() super().__init__( host=host, port=port, auth_username=auth_username, auth_password=auth_password, auth_private_key=auth_private_key, auth_private_key_passphrase=auth_private_key_passphrase, auth_strict_key=auth_strict_key, auth_bypass=auth_bypass, timeout_socket=timeout_socket, timeout_transport=timeout_transport, timeout_ops=timeout_ops, comms_return_char=comms_return_char, ssh_config_file=ssh_config_file, ssh_known_hosts_file=ssh_known_hosts_file, on_init=on_init, on_open=on_open, on_close=on_close, transport=transport, transport_options=transport_options, channel_log=channel_log, channel_log_mode=channel_log_mode, channel_lock=channel_lock, logging_uid=logging_uid, privilege_levels=privilege_levels, default_desired_privilege_level=default_desired_privilege_level, auth_secondary=auth_secondary, failed_when_contains=failed_when_contains, textfsm_platform=textfsm_platform, genie_platform=genie_platform, ) async def _abort_config(self) -> None: \"\"\" Abort NXOS configuration session (if using a config session!) Args: N/A Returns: None Raises: N/A \"\"\" # nxos pattern for config sessions should *always* have `config-s` if \"config\\\\-s\" in self._current_priv_level.pattern: await self.channel.send_input(channel_input=\"abort\") self._current_priv_level = self.privilege_levels[\"privilege_exec\"] def register_configuration_session(self, session_name: str) -> None: \"\"\" NXOS specific implementation of register_configuration_session Args: session_name: name of session to register Returns: None Raises: N/A \"\"\" self._create_configuration_session(session_name=session_name) self.update_privilege_levels()","title":"AsyncNXOSDriver"},{"location":"api_docs/driver/core/cisco_nxos/async_driver/#ancestors-in-mro","text":"scrapli.driver.network.async_driver.AsyncNetworkDriver scrapli.driver.generic.async_driver.AsyncGenericDriver scrapli.driver.base.async_driver.AsyncDriver scrapli.driver.base.base_driver.BaseDriver scrapli.driver.generic.base_driver.BaseGenericDriver scrapli.driver.network.base_driver.BaseNetworkDriver scrapli.driver.core.cisco_nxos.base_driver.NXOSDriverBase","title":"Ancestors (in MRO)"},{"location":"api_docs/driver/core/cisco_nxos/async_driver/#methods","text":"","title":"Methods"},{"location":"api_docs/driver/core/cisco_nxos/async_driver/#register_configuration_session","text":"register_configuration_session(self, session_name: str) \u2011> None 1 2 3 4 5 6 7 8 9 10 NXOS specific implementation of register_configuration_session Args: session_name: name of session to register Returns: None Raises: N/A","title":"register_configuration_session"},{"location":"api_docs/driver/core/cisco_nxos/base_driver/","text":"window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting()) Module scrapli.driver.core.cisco_nxos.base_driver \u00b6 scrapli.driver.core.cisco_nxos.base_driver Expand source code \"\"\"scrapli.driver.core.cisco_nxos.base_driver\"\"\" from typing import Dict from scrapli.driver.network.base_driver import PrivilegeLevel from scrapli.exceptions import ScrapliValueError PRIVS = { \"exec\": ( PrivilegeLevel( pattern=r\"^[\\w.\\-]{1,63}>\\s?$\", name=\"exec\", previous_priv=\"\", deescalate=\"\", escalate=\"\", escalate_auth=False, escalate_prompt=\"\", ) ), \"privilege_exec\": ( PrivilegeLevel( pattern=r\"^[\\w.\\-]{1,63}#\\s?$\", name=\"privilege_exec\", previous_priv=\"exec\", deescalate=\"disable\", escalate=\"enable\", escalate_auth=True, escalate_prompt=r\"^[pP]assword:\\s?$\", not_contains=[\"-tcl\"], ) ), \"configuration\": ( PrivilegeLevel( pattern=r\"^[\\w.\\-]{1,63}\\(config[\\w.\\-@/:\\+]{0,32}\\)#\\s?$\", name=\"configuration\", previous_priv=\"privilege_exec\", deescalate=\"end\", escalate=\"configure terminal\", escalate_auth=False, escalate_prompt=\"\", not_contains=[\"config-tcl\", \"config-s)\", \"config-s-\"], ) ), \"tclsh\": ( PrivilegeLevel( # annoyingly tclsh has many variations... exec/priv exec/config and just \">\" # for now doesnt seem to be a reason to differentiate between them, so just have one # giant pattern pattern=( r\"(^[\\w.\\-]{1,63}\\-tcl#\\s?$)|\" r\"(^[\\w.\\-]{1,63}\\(config\\-tcl\\)#\\s?$)|\" r\"(^>\\s?$)\" ), name=\"tclsh\", previous_priv=\"privilege_exec\", deescalate=\"tclquit\", escalate=\"tclsh\", escalate_auth=False, escalate_prompt=\"\", ) ), } FAILED_WHEN_CONTAINS = [ \"% Ambiguous command\", \"% Incomplete command\", \"% Invalid input detected\", \"% Invalid command at\", \"% Invalid parameter\", ] class NXOSDriverBase: # NXOSDriverBase Mixin values set in init of sync/async NetworkDriver classes privilege_levels: Dict[str, PrivilegeLevel] def _create_configuration_session(self, session_name: str) -> None: \"\"\" Handle configuration session creation tasks for consistency between sync/async versions Args: session_name: name of session to register Returns: None Raises: ScrapliValueError: if a session of given name already exists \"\"\" if session_name in self.privilege_levels.keys(): msg = ( f\"session name `{session_name}` already registered as a privilege level, chose a \" \"unique session name\" ) raise ScrapliValueError(msg) pattern = r\"^[a-z0-9.\\-_@/:]{1,32}\\(config\\-s[a-z0-9.\\-@/:]{0,32}\\)#\\s?$\" name = session_name config_session = PrivilegeLevel( pattern=pattern, name=name, previous_priv=\"privilege_exec\", deescalate=\"end\", escalate=f\"configure session {session_name}\", escalate_auth=False, escalate_prompt=\"\", ) self.privilege_levels[name] = config_session Classes \u00b6 NXOSDriverBase \u00b6 Expand source code class NXOSDriverBase: # NXOSDriverBase Mixin values set in init of sync/async NetworkDriver classes privilege_levels: Dict[str, PrivilegeLevel] def _create_configuration_session(self, session_name: str) -> None: \"\"\" Handle configuration session creation tasks for consistency between sync/async versions Args: session_name: name of session to register Returns: None Raises: ScrapliValueError: if a session of given name already exists \"\"\" if session_name in self.privilege_levels.keys(): msg = ( f\"session name `{session_name}` already registered as a privilege level, chose a \" \"unique session name\" ) raise ScrapliValueError(msg) pattern = r\"^[a-z0-9.\\-_@/:]{1,32}\\(config\\-s[a-z0-9.\\-@/:]{0,32}\\)#\\s?$\" name = session_name config_session = PrivilegeLevel( pattern=pattern, name=name, previous_priv=\"privilege_exec\", deescalate=\"end\", escalate=f\"configure session {session_name}\", escalate_auth=False, escalate_prompt=\"\", ) self.privilege_levels[name] = config_session Descendants \u00b6 scrapli.driver.core.cisco_nxos.async_driver.AsyncNXOSDriver scrapli.driver.core.cisco_nxos.sync_driver.NXOSDriver Class variables \u00b6 privilege_levels: Dict[str, scrapli.driver.network.base_driver.PrivilegeLevel]","title":"Base Driver"},{"location":"api_docs/driver/core/cisco_nxos/base_driver/#module-scraplidrivercorecisco_nxosbase_driver","text":"scrapli.driver.core.cisco_nxos.base_driver Expand source code \"\"\"scrapli.driver.core.cisco_nxos.base_driver\"\"\" from typing import Dict from scrapli.driver.network.base_driver import PrivilegeLevel from scrapli.exceptions import ScrapliValueError PRIVS = { \"exec\": ( PrivilegeLevel( pattern=r\"^[\\w.\\-]{1,63}>\\s?$\", name=\"exec\", previous_priv=\"\", deescalate=\"\", escalate=\"\", escalate_auth=False, escalate_prompt=\"\", ) ), \"privilege_exec\": ( PrivilegeLevel( pattern=r\"^[\\w.\\-]{1,63}#\\s?$\", name=\"privilege_exec\", previous_priv=\"exec\", deescalate=\"disable\", escalate=\"enable\", escalate_auth=True, escalate_prompt=r\"^[pP]assword:\\s?$\", not_contains=[\"-tcl\"], ) ), \"configuration\": ( PrivilegeLevel( pattern=r\"^[\\w.\\-]{1,63}\\(config[\\w.\\-@/:\\+]{0,32}\\)#\\s?$\", name=\"configuration\", previous_priv=\"privilege_exec\", deescalate=\"end\", escalate=\"configure terminal\", escalate_auth=False, escalate_prompt=\"\", not_contains=[\"config-tcl\", \"config-s)\", \"config-s-\"], ) ), \"tclsh\": ( PrivilegeLevel( # annoyingly tclsh has many variations... exec/priv exec/config and just \">\" # for now doesnt seem to be a reason to differentiate between them, so just have one # giant pattern pattern=( r\"(^[\\w.\\-]{1,63}\\-tcl#\\s?$)|\" r\"(^[\\w.\\-]{1,63}\\(config\\-tcl\\)#\\s?$)|\" r\"(^>\\s?$)\" ), name=\"tclsh\", previous_priv=\"privilege_exec\", deescalate=\"tclquit\", escalate=\"tclsh\", escalate_auth=False, escalate_prompt=\"\", ) ), } FAILED_WHEN_CONTAINS = [ \"% Ambiguous command\", \"% Incomplete command\", \"% Invalid input detected\", \"% Invalid command at\", \"% Invalid parameter\", ] class NXOSDriverBase: # NXOSDriverBase Mixin values set in init of sync/async NetworkDriver classes privilege_levels: Dict[str, PrivilegeLevel] def _create_configuration_session(self, session_name: str) -> None: \"\"\" Handle configuration session creation tasks for consistency between sync/async versions Args: session_name: name of session to register Returns: None Raises: ScrapliValueError: if a session of given name already exists \"\"\" if session_name in self.privilege_levels.keys(): msg = ( f\"session name `{session_name}` already registered as a privilege level, chose a \" \"unique session name\" ) raise ScrapliValueError(msg) pattern = r\"^[a-z0-9.\\-_@/:]{1,32}\\(config\\-s[a-z0-9.\\-@/:]{0,32}\\)#\\s?$\" name = session_name config_session = PrivilegeLevel( pattern=pattern, name=name, previous_priv=\"privilege_exec\", deescalate=\"end\", escalate=f\"configure session {session_name}\", escalate_auth=False, escalate_prompt=\"\", ) self.privilege_levels[name] = config_session","title":"Module scrapli.driver.core.cisco_nxos.base_driver"},{"location":"api_docs/driver/core/cisco_nxos/base_driver/#classes","text":"","title":"Classes"},{"location":"api_docs/driver/core/cisco_nxos/base_driver/#nxosdriverbase","text":"Expand source code class NXOSDriverBase: # NXOSDriverBase Mixin values set in init of sync/async NetworkDriver classes privilege_levels: Dict[str, PrivilegeLevel] def _create_configuration_session(self, session_name: str) -> None: \"\"\" Handle configuration session creation tasks for consistency between sync/async versions Args: session_name: name of session to register Returns: None Raises: ScrapliValueError: if a session of given name already exists \"\"\" if session_name in self.privilege_levels.keys(): msg = ( f\"session name `{session_name}` already registered as a privilege level, chose a \" \"unique session name\" ) raise ScrapliValueError(msg) pattern = r\"^[a-z0-9.\\-_@/:]{1,32}\\(config\\-s[a-z0-9.\\-@/:]{0,32}\\)#\\s?$\" name = session_name config_session = PrivilegeLevel( pattern=pattern, name=name, previous_priv=\"privilege_exec\", deescalate=\"end\", escalate=f\"configure session {session_name}\", escalate_auth=False, escalate_prompt=\"\", ) self.privilege_levels[name] = config_session","title":"NXOSDriverBase"},{"location":"api_docs/driver/core/cisco_nxos/base_driver/#descendants","text":"scrapli.driver.core.cisco_nxos.async_driver.AsyncNXOSDriver scrapli.driver.core.cisco_nxos.sync_driver.NXOSDriver","title":"Descendants"},{"location":"api_docs/driver/core/cisco_nxos/base_driver/#class-variables","text":"privilege_levels: Dict[str, scrapli.driver.network.base_driver.PrivilegeLevel]","title":"Class variables"},{"location":"api_docs/driver/core/cisco_nxos/sync_driver/","text":"window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting()) Module scrapli.driver.core.cisco_nxos.sync_driver \u00b6 scrapli.driver.core.cisco_nxos.sync_driver Expand source code \"\"\"scrapli.driver.core.cisco_nxos.sync_driver\"\"\" from copy import deepcopy from io import BytesIO from typing import Any, Callable, Dict, List, Optional, Union from scrapli.driver import NetworkDriver from scrapli.driver.core.cisco_nxos.base_driver import FAILED_WHEN_CONTAINS, PRIVS, NXOSDriverBase from scrapli.driver.network.base_driver import PrivilegeLevel def nxos_on_open(conn: NetworkDriver) -> None: \"\"\" NXOSDriver default on_open callable Args: conn: NetworkDriver object Returns: None Raises: N/A \"\"\" conn.acquire_priv(desired_priv=conn.default_desired_privilege_level) conn.send_command(command=\"terminal length 0\") conn.send_command(command=\"terminal width 511\") def nxos_on_close(conn: NetworkDriver) -> None: \"\"\" NXOSDriver default on_close callable Args: conn: NetworkDriver object Returns: None Raises: N/A \"\"\" conn.acquire_priv(desired_priv=conn.default_desired_privilege_level) conn.channel.write(channel_input=\"exit\") conn.channel.send_return() class NXOSDriver(NetworkDriver, NXOSDriverBase): def __init__( self, host: str, privilege_levels: Optional[Dict[str, PrivilegeLevel]] = None, default_desired_privilege_level: str = \"privilege_exec\", port: Optional[int] = None, auth_username: str = \"\", auth_password: str = \"\", auth_private_key: str = \"\", auth_private_key_passphrase: str = \"\", auth_strict_key: bool = True, auth_bypass: bool = False, timeout_socket: float = 15.0, timeout_transport: float = 30.0, timeout_ops: float = 30.0, comms_return_char: str = \"\\n\", ssh_config_file: Union[str, bool] = False, ssh_known_hosts_file: Union[str, bool] = False, on_init: Optional[Callable[..., Any]] = None, on_open: Optional[Callable[..., Any]] = None, on_close: Optional[Callable[..., Any]] = None, transport: str = \"system\", transport_options: Optional[Dict[str, Any]] = None, channel_log: Union[str, bool, BytesIO] = False, channel_log_mode: str = \"write\", channel_lock: bool = False, logging_uid: str = \"\", auth_secondary: str = \"\", failed_when_contains: Optional[List[str]] = None, textfsm_platform: str = \"cisco_nxos\", genie_platform: str = \"nxos\", ): \"\"\" NXOSDriver Object Please see `scrapli.driver.base.base_driver.Driver` for all \"base driver\" arguments! # noqa: DAR101 Args: privilege_levels: optional user provided privilege levels, if left None will default to scrapli standard privilege levels default_desired_privilege_level: string of name of default desired priv, this is the priv level that is generally used to disable paging/set terminal width and things like that upon first login, and is also the priv level scrapli will try to acquire for normal \"command\" operations (`send_command`, `send_commands`) auth_secondary: password to use for secondary authentication (enable) on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar. textfsm_platform: string name of textfsm parser platform genie_platform: string name of cisco genie parser platform failed_when_contains: List of strings that indicate a command/config has failed Returns: None Raises: N/A \"\"\" # somewhere/somehow the mixin is causing mypy to be upset about comms_prompt_pattern... self.comms_prompt_pattern: str if privilege_levels is None: privilege_levels = deepcopy(PRIVS) if on_open is None: on_open = nxos_on_open if on_close is None: on_close = nxos_on_close if failed_when_contains is None: failed_when_contains = FAILED_WHEN_CONTAINS.copy() super().__init__( host=host, port=port, auth_username=auth_username, auth_password=auth_password, auth_private_key=auth_private_key, auth_private_key_passphrase=auth_private_key_passphrase, auth_strict_key=auth_strict_key, auth_bypass=auth_bypass, timeout_socket=timeout_socket, timeout_transport=timeout_transport, timeout_ops=timeout_ops, comms_return_char=comms_return_char, ssh_config_file=ssh_config_file, ssh_known_hosts_file=ssh_known_hosts_file, on_init=on_init, on_open=on_open, on_close=on_close, transport=transport, transport_options=transport_options, channel_log=channel_log, channel_log_mode=channel_log_mode, channel_lock=channel_lock, logging_uid=logging_uid, privilege_levels=privilege_levels, default_desired_privilege_level=default_desired_privilege_level, auth_secondary=auth_secondary, failed_when_contains=failed_when_contains, textfsm_platform=textfsm_platform, genie_platform=genie_platform, ) def _abort_config(self) -> None: \"\"\" Abort NXOS configuration session (if using a config session!) Args: N/A Returns: None Raises: N/A \"\"\" # nxos pattern for config sessions should *always* have `config-s` if \"config\\\\-s\" in self._current_priv_level.pattern: self.channel.send_input(channel_input=\"abort\") self._current_priv_level = self.privilege_levels[\"privilege_exec\"] def register_configuration_session(self, session_name: str) -> None: \"\"\" NXOS specific implementation of register_configuration_session Args: session_name: name of session to register Returns: None Raises: N/A \"\"\" self._create_configuration_session(session_name=session_name) self.update_privilege_levels() Functions \u00b6 nxos_on_close \u00b6 nxos_on_close(conn: scrapli.driver.network.sync_driver.NetworkDriver) \u2011> None 1 2 3 4 5 6 7 8 9 10 NXOSDriver default on_close callable Args: conn: NetworkDriver object Returns: None Raises: N/A nxos_on_open \u00b6 nxos_on_open(conn: scrapli.driver.network.sync_driver.NetworkDriver) \u2011> None 1 2 3 4 5 6 7 8 9 10 NXOSDriver default on_open callable Args: conn: NetworkDriver object Returns: None Raises: N/A Classes \u00b6 NXOSDriver \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 NXOSDriver Object Please see `scrapli.driver.base.base_driver.Driver` for all \"base driver\" arguments! # noqa: DAR101 Args: privilege_levels: optional user provided privilege levels, if left None will default to scrapli standard privilege levels default_desired_privilege_level: string of name of default desired priv, this is the priv level that is generally used to disable paging/set terminal width and things like that upon first login, and is also the priv level scrapli will try to acquire for normal \"command\" operations (`send_command`, `send_commands`) auth_secondary: password to use for secondary authentication (enable) on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar. textfsm_platform: string name of textfsm parser platform genie_platform: string name of cisco genie parser platform failed_when_contains: List of strings that indicate a command/config has failed Returns: None Raises: N/A Expand source code class NXOSDriver(NetworkDriver, NXOSDriverBase): def __init__( self, host: str, privilege_levels: Optional[Dict[str, PrivilegeLevel]] = None, default_desired_privilege_level: str = \"privilege_exec\", port: Optional[int] = None, auth_username: str = \"\", auth_password: str = \"\", auth_private_key: str = \"\", auth_private_key_passphrase: str = \"\", auth_strict_key: bool = True, auth_bypass: bool = False, timeout_socket: float = 15.0, timeout_transport: float = 30.0, timeout_ops: float = 30.0, comms_return_char: str = \"\\n\", ssh_config_file: Union[str, bool] = False, ssh_known_hosts_file: Union[str, bool] = False, on_init: Optional[Callable[..., Any]] = None, on_open: Optional[Callable[..., Any]] = None, on_close: Optional[Callable[..., Any]] = None, transport: str = \"system\", transport_options: Optional[Dict[str, Any]] = None, channel_log: Union[str, bool, BytesIO] = False, channel_log_mode: str = \"write\", channel_lock: bool = False, logging_uid: str = \"\", auth_secondary: str = \"\", failed_when_contains: Optional[List[str]] = None, textfsm_platform: str = \"cisco_nxos\", genie_platform: str = \"nxos\", ): \"\"\" NXOSDriver Object Please see `scrapli.driver.base.base_driver.Driver` for all \"base driver\" arguments! # noqa: DAR101 Args: privilege_levels: optional user provided privilege levels, if left None will default to scrapli standard privilege levels default_desired_privilege_level: string of name of default desired priv, this is the priv level that is generally used to disable paging/set terminal width and things like that upon first login, and is also the priv level scrapli will try to acquire for normal \"command\" operations (`send_command`, `send_commands`) auth_secondary: password to use for secondary authentication (enable) on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar. textfsm_platform: string name of textfsm parser platform genie_platform: string name of cisco genie parser platform failed_when_contains: List of strings that indicate a command/config has failed Returns: None Raises: N/A \"\"\" # somewhere/somehow the mixin is causing mypy to be upset about comms_prompt_pattern... self.comms_prompt_pattern: str if privilege_levels is None: privilege_levels = deepcopy(PRIVS) if on_open is None: on_open = nxos_on_open if on_close is None: on_close = nxos_on_close if failed_when_contains is None: failed_when_contains = FAILED_WHEN_CONTAINS.copy() super().__init__( host=host, port=port, auth_username=auth_username, auth_password=auth_password, auth_private_key=auth_private_key, auth_private_key_passphrase=auth_private_key_passphrase, auth_strict_key=auth_strict_key, auth_bypass=auth_bypass, timeout_socket=timeout_socket, timeout_transport=timeout_transport, timeout_ops=timeout_ops, comms_return_char=comms_return_char, ssh_config_file=ssh_config_file, ssh_known_hosts_file=ssh_known_hosts_file, on_init=on_init, on_open=on_open, on_close=on_close, transport=transport, transport_options=transport_options, channel_log=channel_log, channel_log_mode=channel_log_mode, channel_lock=channel_lock, logging_uid=logging_uid, privilege_levels=privilege_levels, default_desired_privilege_level=default_desired_privilege_level, auth_secondary=auth_secondary, failed_when_contains=failed_when_contains, textfsm_platform=textfsm_platform, genie_platform=genie_platform, ) def _abort_config(self) -> None: \"\"\" Abort NXOS configuration session (if using a config session!) Args: N/A Returns: None Raises: N/A \"\"\" # nxos pattern for config sessions should *always* have `config-s` if \"config\\\\-s\" in self._current_priv_level.pattern: self.channel.send_input(channel_input=\"abort\") self._current_priv_level = self.privilege_levels[\"privilege_exec\"] def register_configuration_session(self, session_name: str) -> None: \"\"\" NXOS specific implementation of register_configuration_session Args: session_name: name of session to register Returns: None Raises: N/A \"\"\" self._create_configuration_session(session_name=session_name) self.update_privilege_levels() Ancestors (in MRO) \u00b6 scrapli.driver.network.sync_driver.NetworkDriver scrapli.driver.generic.sync_driver.GenericDriver scrapli.driver.base.sync_driver.Driver scrapli.driver.base.base_driver.BaseDriver scrapli.driver.generic.base_driver.BaseGenericDriver scrapli.driver.network.base_driver.BaseNetworkDriver scrapli.driver.core.cisco_nxos.base_driver.NXOSDriverBase Methods \u00b6 register_configuration_session \u00b6 register_configuration_session(self, session_name: str) \u2011> None 1 2 3 4 5 6 7 8 9 10 NXOS specific implementation of register_configuration_session Args: session_name: name of session to register Returns: None Raises: N/A","title":"Sync Driver"},{"location":"api_docs/driver/core/cisco_nxos/sync_driver/#module-scraplidrivercorecisco_nxossync_driver","text":"scrapli.driver.core.cisco_nxos.sync_driver Expand source code \"\"\"scrapli.driver.core.cisco_nxos.sync_driver\"\"\" from copy import deepcopy from io import BytesIO from typing import Any, Callable, Dict, List, Optional, Union from scrapli.driver import NetworkDriver from scrapli.driver.core.cisco_nxos.base_driver import FAILED_WHEN_CONTAINS, PRIVS, NXOSDriverBase from scrapli.driver.network.base_driver import PrivilegeLevel def nxos_on_open(conn: NetworkDriver) -> None: \"\"\" NXOSDriver default on_open callable Args: conn: NetworkDriver object Returns: None Raises: N/A \"\"\" conn.acquire_priv(desired_priv=conn.default_desired_privilege_level) conn.send_command(command=\"terminal length 0\") conn.send_command(command=\"terminal width 511\") def nxos_on_close(conn: NetworkDriver) -> None: \"\"\" NXOSDriver default on_close callable Args: conn: NetworkDriver object Returns: None Raises: N/A \"\"\" conn.acquire_priv(desired_priv=conn.default_desired_privilege_level) conn.channel.write(channel_input=\"exit\") conn.channel.send_return() class NXOSDriver(NetworkDriver, NXOSDriverBase): def __init__( self, host: str, privilege_levels: Optional[Dict[str, PrivilegeLevel]] = None, default_desired_privilege_level: str = \"privilege_exec\", port: Optional[int] = None, auth_username: str = \"\", auth_password: str = \"\", auth_private_key: str = \"\", auth_private_key_passphrase: str = \"\", auth_strict_key: bool = True, auth_bypass: bool = False, timeout_socket: float = 15.0, timeout_transport: float = 30.0, timeout_ops: float = 30.0, comms_return_char: str = \"\\n\", ssh_config_file: Union[str, bool] = False, ssh_known_hosts_file: Union[str, bool] = False, on_init: Optional[Callable[..., Any]] = None, on_open: Optional[Callable[..., Any]] = None, on_close: Optional[Callable[..., Any]] = None, transport: str = \"system\", transport_options: Optional[Dict[str, Any]] = None, channel_log: Union[str, bool, BytesIO] = False, channel_log_mode: str = \"write\", channel_lock: bool = False, logging_uid: str = \"\", auth_secondary: str = \"\", failed_when_contains: Optional[List[str]] = None, textfsm_platform: str = \"cisco_nxos\", genie_platform: str = \"nxos\", ): \"\"\" NXOSDriver Object Please see `scrapli.driver.base.base_driver.Driver` for all \"base driver\" arguments! # noqa: DAR101 Args: privilege_levels: optional user provided privilege levels, if left None will default to scrapli standard privilege levels default_desired_privilege_level: string of name of default desired priv, this is the priv level that is generally used to disable paging/set terminal width and things like that upon first login, and is also the priv level scrapli will try to acquire for normal \"command\" operations (`send_command`, `send_commands`) auth_secondary: password to use for secondary authentication (enable) on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar. textfsm_platform: string name of textfsm parser platform genie_platform: string name of cisco genie parser platform failed_when_contains: List of strings that indicate a command/config has failed Returns: None Raises: N/A \"\"\" # somewhere/somehow the mixin is causing mypy to be upset about comms_prompt_pattern... self.comms_prompt_pattern: str if privilege_levels is None: privilege_levels = deepcopy(PRIVS) if on_open is None: on_open = nxos_on_open if on_close is None: on_close = nxos_on_close if failed_when_contains is None: failed_when_contains = FAILED_WHEN_CONTAINS.copy() super().__init__( host=host, port=port, auth_username=auth_username, auth_password=auth_password, auth_private_key=auth_private_key, auth_private_key_passphrase=auth_private_key_passphrase, auth_strict_key=auth_strict_key, auth_bypass=auth_bypass, timeout_socket=timeout_socket, timeout_transport=timeout_transport, timeout_ops=timeout_ops, comms_return_char=comms_return_char, ssh_config_file=ssh_config_file, ssh_known_hosts_file=ssh_known_hosts_file, on_init=on_init, on_open=on_open, on_close=on_close, transport=transport, transport_options=transport_options, channel_log=channel_log, channel_log_mode=channel_log_mode, channel_lock=channel_lock, logging_uid=logging_uid, privilege_levels=privilege_levels, default_desired_privilege_level=default_desired_privilege_level, auth_secondary=auth_secondary, failed_when_contains=failed_when_contains, textfsm_platform=textfsm_platform, genie_platform=genie_platform, ) def _abort_config(self) -> None: \"\"\" Abort NXOS configuration session (if using a config session!) Args: N/A Returns: None Raises: N/A \"\"\" # nxos pattern for config sessions should *always* have `config-s` if \"config\\\\-s\" in self._current_priv_level.pattern: self.channel.send_input(channel_input=\"abort\") self._current_priv_level = self.privilege_levels[\"privilege_exec\"] def register_configuration_session(self, session_name: str) -> None: \"\"\" NXOS specific implementation of register_configuration_session Args: session_name: name of session to register Returns: None Raises: N/A \"\"\" self._create_configuration_session(session_name=session_name) self.update_privilege_levels()","title":"Module scrapli.driver.core.cisco_nxos.sync_driver"},{"location":"api_docs/driver/core/cisco_nxos/sync_driver/#functions","text":"","title":"Functions"},{"location":"api_docs/driver/core/cisco_nxos/sync_driver/#nxos_on_close","text":"nxos_on_close(conn: scrapli.driver.network.sync_driver.NetworkDriver) \u2011> None 1 2 3 4 5 6 7 8 9 10 NXOSDriver default on_close callable Args: conn: NetworkDriver object Returns: None Raises: N/A","title":"nxos_on_close"},{"location":"api_docs/driver/core/cisco_nxos/sync_driver/#nxos_on_open","text":"nxos_on_open(conn: scrapli.driver.network.sync_driver.NetworkDriver) \u2011> None 1 2 3 4 5 6 7 8 9 10 NXOSDriver default on_open callable Args: conn: NetworkDriver object Returns: None Raises: N/A","title":"nxos_on_open"},{"location":"api_docs/driver/core/cisco_nxos/sync_driver/#classes","text":"","title":"Classes"},{"location":"api_docs/driver/core/cisco_nxos/sync_driver/#nxosdriver","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 NXOSDriver Object Please see `scrapli.driver.base.base_driver.Driver` for all \"base driver\" arguments! # noqa: DAR101 Args: privilege_levels: optional user provided privilege levels, if left None will default to scrapli standard privilege levels default_desired_privilege_level: string of name of default desired priv, this is the priv level that is generally used to disable paging/set terminal width and things like that upon first login, and is also the priv level scrapli will try to acquire for normal \"command\" operations (`send_command`, `send_commands`) auth_secondary: password to use for secondary authentication (enable) on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar. textfsm_platform: string name of textfsm parser platform genie_platform: string name of cisco genie parser platform failed_when_contains: List of strings that indicate a command/config has failed Returns: None Raises: N/A Expand source code class NXOSDriver(NetworkDriver, NXOSDriverBase): def __init__( self, host: str, privilege_levels: Optional[Dict[str, PrivilegeLevel]] = None, default_desired_privilege_level: str = \"privilege_exec\", port: Optional[int] = None, auth_username: str = \"\", auth_password: str = \"\", auth_private_key: str = \"\", auth_private_key_passphrase: str = \"\", auth_strict_key: bool = True, auth_bypass: bool = False, timeout_socket: float = 15.0, timeout_transport: float = 30.0, timeout_ops: float = 30.0, comms_return_char: str = \"\\n\", ssh_config_file: Union[str, bool] = False, ssh_known_hosts_file: Union[str, bool] = False, on_init: Optional[Callable[..., Any]] = None, on_open: Optional[Callable[..., Any]] = None, on_close: Optional[Callable[..., Any]] = None, transport: str = \"system\", transport_options: Optional[Dict[str, Any]] = None, channel_log: Union[str, bool, BytesIO] = False, channel_log_mode: str = \"write\", channel_lock: bool = False, logging_uid: str = \"\", auth_secondary: str = \"\", failed_when_contains: Optional[List[str]] = None, textfsm_platform: str = \"cisco_nxos\", genie_platform: str = \"nxos\", ): \"\"\" NXOSDriver Object Please see `scrapli.driver.base.base_driver.Driver` for all \"base driver\" arguments! # noqa: DAR101 Args: privilege_levels: optional user provided privilege levels, if left None will default to scrapli standard privilege levels default_desired_privilege_level: string of name of default desired priv, this is the priv level that is generally used to disable paging/set terminal width and things like that upon first login, and is also the priv level scrapli will try to acquire for normal \"command\" operations (`send_command`, `send_commands`) auth_secondary: password to use for secondary authentication (enable) on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar. textfsm_platform: string name of textfsm parser platform genie_platform: string name of cisco genie parser platform failed_when_contains: List of strings that indicate a command/config has failed Returns: None Raises: N/A \"\"\" # somewhere/somehow the mixin is causing mypy to be upset about comms_prompt_pattern... self.comms_prompt_pattern: str if privilege_levels is None: privilege_levels = deepcopy(PRIVS) if on_open is None: on_open = nxos_on_open if on_close is None: on_close = nxos_on_close if failed_when_contains is None: failed_when_contains = FAILED_WHEN_CONTAINS.copy() super().__init__( host=host, port=port, auth_username=auth_username, auth_password=auth_password, auth_private_key=auth_private_key, auth_private_key_passphrase=auth_private_key_passphrase, auth_strict_key=auth_strict_key, auth_bypass=auth_bypass, timeout_socket=timeout_socket, timeout_transport=timeout_transport, timeout_ops=timeout_ops, comms_return_char=comms_return_char, ssh_config_file=ssh_config_file, ssh_known_hosts_file=ssh_known_hosts_file, on_init=on_init, on_open=on_open, on_close=on_close, transport=transport, transport_options=transport_options, channel_log=channel_log, channel_log_mode=channel_log_mode, channel_lock=channel_lock, logging_uid=logging_uid, privilege_levels=privilege_levels, default_desired_privilege_level=default_desired_privilege_level, auth_secondary=auth_secondary, failed_when_contains=failed_when_contains, textfsm_platform=textfsm_platform, genie_platform=genie_platform, ) def _abort_config(self) -> None: \"\"\" Abort NXOS configuration session (if using a config session!) Args: N/A Returns: None Raises: N/A \"\"\" # nxos pattern for config sessions should *always* have `config-s` if \"config\\\\-s\" in self._current_priv_level.pattern: self.channel.send_input(channel_input=\"abort\") self._current_priv_level = self.privilege_levels[\"privilege_exec\"] def register_configuration_session(self, session_name: str) -> None: \"\"\" NXOS specific implementation of register_configuration_session Args: session_name: name of session to register Returns: None Raises: N/A \"\"\" self._create_configuration_session(session_name=session_name) self.update_privilege_levels()","title":"NXOSDriver"},{"location":"api_docs/driver/core/cisco_nxos/sync_driver/#ancestors-in-mro","text":"scrapli.driver.network.sync_driver.NetworkDriver scrapli.driver.generic.sync_driver.GenericDriver scrapli.driver.base.sync_driver.Driver scrapli.driver.base.base_driver.BaseDriver scrapli.driver.generic.base_driver.BaseGenericDriver scrapli.driver.network.base_driver.BaseNetworkDriver scrapli.driver.core.cisco_nxos.base_driver.NXOSDriverBase","title":"Ancestors (in MRO)"},{"location":"api_docs/driver/core/cisco_nxos/sync_driver/#methods","text":"","title":"Methods"},{"location":"api_docs/driver/core/cisco_nxos/sync_driver/#register_configuration_session","text":"register_configuration_session(self, session_name: str) \u2011> None 1 2 3 4 5 6 7 8 9 10 NXOS specific implementation of register_configuration_session Args: session_name: name of session to register Returns: None Raises: N/A","title":"register_configuration_session"},{"location":"api_docs/driver/core/juniper_junos/async_driver/","text":"window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting()) Module scrapli.driver.core.juniper_junos.async_driver \u00b6 scrapli.driver.core.juniper_junos.async_driver Expand source code \"\"\"scrapli.driver.core.juniper_junos.async_driver\"\"\" from copy import deepcopy from io import BytesIO from typing import Any, Callable, Dict, List, Optional, Union from scrapli.driver import AsyncNetworkDriver from scrapli.driver.core.juniper_junos.base_driver import FAILED_WHEN_CONTAINS, PRIVS from scrapli.driver.network.base_driver import PrivilegeLevel async def junos_on_open(conn: AsyncNetworkDriver) -> None: \"\"\" JunosDriver default on_open callable Args: conn: NetworkDriver object Returns: None Raises: N/A \"\"\" await conn.acquire_priv(desired_priv=conn.default_desired_privilege_level) await conn.send_command(command=\"set cli screen-length 0\") await conn.send_command(command=\"set cli screen-width 511\") await conn.send_command(command=\"set cli complete-on-space off\") async def junos_on_close(conn: AsyncNetworkDriver) -> None: \"\"\" JunosDriver default on_close callable Args: conn: NetworkDriver object Returns: None Raises: N/A \"\"\" await conn.acquire_priv(desired_priv=conn.default_desired_privilege_level) conn.channel.write(channel_input=\"exit\") conn.channel.send_return() class AsyncJunosDriver(AsyncNetworkDriver): def __init__( self, host: str, privilege_levels: Optional[Dict[str, PrivilegeLevel]] = None, default_desired_privilege_level: str = \"exec\", port: Optional[int] = None, auth_username: str = \"\", auth_password: str = \"\", auth_private_key: str = \"\", auth_private_key_passphrase: str = \"\", auth_strict_key: bool = True, auth_bypass: bool = False, timeout_socket: float = 15.0, timeout_transport: float = 30.0, timeout_ops: float = 30.0, comms_return_char: str = \"\\n\", ssh_config_file: Union[str, bool] = False, ssh_known_hosts_file: Union[str, bool] = False, on_init: Optional[Callable[..., Any]] = None, on_open: Optional[Callable[..., Any]] = None, on_close: Optional[Callable[..., Any]] = None, transport: str = \"system\", transport_options: Optional[Dict[str, Any]] = None, channel_log: Union[str, bool, BytesIO] = False, channel_log_mode: str = \"write\", channel_lock: bool = False, logging_uid: str = \"\", auth_secondary: str = \"\", failed_when_contains: Optional[List[str]] = None, textfsm_platform: str = \"juniper_junos\", genie_platform: str = \"\", ): \"\"\" JunosDriver Object Please see `scrapli.driver.base.base_driver.Driver` for all \"base driver\" arguments! # noqa: DAR101 Args: privilege_levels: optional user provided privilege levels, if left None will default to scrapli standard privilege levels default_desired_privilege_level: string of name of default desired priv, this is the priv level that is generally used to disable paging/set terminal width and things like that upon first login, and is also the priv level scrapli will try to acquire for normal \"command\" operations (`send_command`, `send_commands`) auth_secondary: password to use for secondary authentication (enable) on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar. textfsm_platform: string name of textfsm parser platform genie_platform: string name of cisco genie parser platform failed_when_contains: List of strings that indicate a command/config has failed Returns: None Raises: N/A \"\"\" if privilege_levels is None: privilege_levels = deepcopy(PRIVS) if on_open is None: on_open = junos_on_open if on_close is None: on_close = junos_on_close if failed_when_contains is None: failed_when_contains = FAILED_WHEN_CONTAINS.copy() super().__init__( host=host, port=port, auth_username=auth_username, auth_password=auth_password, auth_private_key=auth_private_key, auth_private_key_passphrase=auth_private_key_passphrase, auth_strict_key=auth_strict_key, auth_bypass=auth_bypass, timeout_socket=timeout_socket, timeout_transport=timeout_transport, timeout_ops=timeout_ops, comms_return_char=comms_return_char, ssh_config_file=ssh_config_file, ssh_known_hosts_file=ssh_known_hosts_file, on_init=on_init, on_open=on_open, on_close=on_close, transport=transport, transport_options=transport_options, channel_log=channel_log, channel_log_mode=channel_log_mode, channel_lock=channel_lock, logging_uid=logging_uid, privilege_levels=privilege_levels, default_desired_privilege_level=default_desired_privilege_level, auth_secondary=auth_secondary, failed_when_contains=failed_when_contains, textfsm_platform=textfsm_platform, genie_platform=genie_platform, ) async def _abort_config(self) -> None: \"\"\" Abort Junos configuration session Args: N/A Returns: None Raises: N/A \"\"\" await self.send_configs([\"rollback 0\", \"exit\"]) self._current_priv_level = self.privilege_levels[\"exec\"] Functions \u00b6 junos_on_close \u00b6 junos_on_close(conn: scrapli.driver.network.async_driver.AsyncNetworkDriver) \u2011> None 1 2 3 4 5 6 7 8 9 10 JunosDriver default on_close callable Args: conn: NetworkDriver object Returns: None Raises: N/A junos_on_open \u00b6 junos_on_open(conn: scrapli.driver.network.async_driver.AsyncNetworkDriver) \u2011> None 1 2 3 4 5 6 7 8 9 10 JunosDriver default on_open callable Args: conn: NetworkDriver object Returns: None Raises: N/A Classes \u00b6 AsyncJunosDriver \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 JunosDriver Object Please see `scrapli.driver.base.base_driver.Driver` for all \"base driver\" arguments! # noqa: DAR101 Args: privilege_levels: optional user provided privilege levels, if left None will default to scrapli standard privilege levels default_desired_privilege_level: string of name of default desired priv, this is the priv level that is generally used to disable paging/set terminal width and things like that upon first login, and is also the priv level scrapli will try to acquire for normal \"command\" operations (`send_command`, `send_commands`) auth_secondary: password to use for secondary authentication (enable) on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar. textfsm_platform: string name of textfsm parser platform genie_platform: string name of cisco genie parser platform failed_when_contains: List of strings that indicate a command/config has failed Returns: None Raises: N/A Expand source code class AsyncJunosDriver(AsyncNetworkDriver): def __init__( self, host: str, privilege_levels: Optional[Dict[str, PrivilegeLevel]] = None, default_desired_privilege_level: str = \"exec\", port: Optional[int] = None, auth_username: str = \"\", auth_password: str = \"\", auth_private_key: str = \"\", auth_private_key_passphrase: str = \"\", auth_strict_key: bool = True, auth_bypass: bool = False, timeout_socket: float = 15.0, timeout_transport: float = 30.0, timeout_ops: float = 30.0, comms_return_char: str = \"\\n\", ssh_config_file: Union[str, bool] = False, ssh_known_hosts_file: Union[str, bool] = False, on_init: Optional[Callable[..., Any]] = None, on_open: Optional[Callable[..., Any]] = None, on_close: Optional[Callable[..., Any]] = None, transport: str = \"system\", transport_options: Optional[Dict[str, Any]] = None, channel_log: Union[str, bool, BytesIO] = False, channel_log_mode: str = \"write\", channel_lock: bool = False, logging_uid: str = \"\", auth_secondary: str = \"\", failed_when_contains: Optional[List[str]] = None, textfsm_platform: str = \"juniper_junos\", genie_platform: str = \"\", ): \"\"\" JunosDriver Object Please see `scrapli.driver.base.base_driver.Driver` for all \"base driver\" arguments! # noqa: DAR101 Args: privilege_levels: optional user provided privilege levels, if left None will default to scrapli standard privilege levels default_desired_privilege_level: string of name of default desired priv, this is the priv level that is generally used to disable paging/set terminal width and things like that upon first login, and is also the priv level scrapli will try to acquire for normal \"command\" operations (`send_command`, `send_commands`) auth_secondary: password to use for secondary authentication (enable) on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar. textfsm_platform: string name of textfsm parser platform genie_platform: string name of cisco genie parser platform failed_when_contains: List of strings that indicate a command/config has failed Returns: None Raises: N/A \"\"\" if privilege_levels is None: privilege_levels = deepcopy(PRIVS) if on_open is None: on_open = junos_on_open if on_close is None: on_close = junos_on_close if failed_when_contains is None: failed_when_contains = FAILED_WHEN_CONTAINS.copy() super().__init__( host=host, port=port, auth_username=auth_username, auth_password=auth_password, auth_private_key=auth_private_key, auth_private_key_passphrase=auth_private_key_passphrase, auth_strict_key=auth_strict_key, auth_bypass=auth_bypass, timeout_socket=timeout_socket, timeout_transport=timeout_transport, timeout_ops=timeout_ops, comms_return_char=comms_return_char, ssh_config_file=ssh_config_file, ssh_known_hosts_file=ssh_known_hosts_file, on_init=on_init, on_open=on_open, on_close=on_close, transport=transport, transport_options=transport_options, channel_log=channel_log, channel_log_mode=channel_log_mode, channel_lock=channel_lock, logging_uid=logging_uid, privilege_levels=privilege_levels, default_desired_privilege_level=default_desired_privilege_level, auth_secondary=auth_secondary, failed_when_contains=failed_when_contains, textfsm_platform=textfsm_platform, genie_platform=genie_platform, ) async def _abort_config(self) -> None: \"\"\" Abort Junos configuration session Args: N/A Returns: None Raises: N/A \"\"\" await self.send_configs([\"rollback 0\", \"exit\"]) self._current_priv_level = self.privilege_levels[\"exec\"] Ancestors (in MRO) \u00b6 scrapli.driver.network.async_driver.AsyncNetworkDriver scrapli.driver.generic.async_driver.AsyncGenericDriver scrapli.driver.base.async_driver.AsyncDriver scrapli.driver.base.base_driver.BaseDriver scrapli.driver.generic.base_driver.BaseGenericDriver scrapli.driver.network.base_driver.BaseNetworkDriver","title":"Async Driver"},{"location":"api_docs/driver/core/juniper_junos/async_driver/#module-scraplidrivercorejuniper_junosasync_driver","text":"scrapli.driver.core.juniper_junos.async_driver Expand source code \"\"\"scrapli.driver.core.juniper_junos.async_driver\"\"\" from copy import deepcopy from io import BytesIO from typing import Any, Callable, Dict, List, Optional, Union from scrapli.driver import AsyncNetworkDriver from scrapli.driver.core.juniper_junos.base_driver import FAILED_WHEN_CONTAINS, PRIVS from scrapli.driver.network.base_driver import PrivilegeLevel async def junos_on_open(conn: AsyncNetworkDriver) -> None: \"\"\" JunosDriver default on_open callable Args: conn: NetworkDriver object Returns: None Raises: N/A \"\"\" await conn.acquire_priv(desired_priv=conn.default_desired_privilege_level) await conn.send_command(command=\"set cli screen-length 0\") await conn.send_command(command=\"set cli screen-width 511\") await conn.send_command(command=\"set cli complete-on-space off\") async def junos_on_close(conn: AsyncNetworkDriver) -> None: \"\"\" JunosDriver default on_close callable Args: conn: NetworkDriver object Returns: None Raises: N/A \"\"\" await conn.acquire_priv(desired_priv=conn.default_desired_privilege_level) conn.channel.write(channel_input=\"exit\") conn.channel.send_return() class AsyncJunosDriver(AsyncNetworkDriver): def __init__( self, host: str, privilege_levels: Optional[Dict[str, PrivilegeLevel]] = None, default_desired_privilege_level: str = \"exec\", port: Optional[int] = None, auth_username: str = \"\", auth_password: str = \"\", auth_private_key: str = \"\", auth_private_key_passphrase: str = \"\", auth_strict_key: bool = True, auth_bypass: bool = False, timeout_socket: float = 15.0, timeout_transport: float = 30.0, timeout_ops: float = 30.0, comms_return_char: str = \"\\n\", ssh_config_file: Union[str, bool] = False, ssh_known_hosts_file: Union[str, bool] = False, on_init: Optional[Callable[..., Any]] = None, on_open: Optional[Callable[..., Any]] = None, on_close: Optional[Callable[..., Any]] = None, transport: str = \"system\", transport_options: Optional[Dict[str, Any]] = None, channel_log: Union[str, bool, BytesIO] = False, channel_log_mode: str = \"write\", channel_lock: bool = False, logging_uid: str = \"\", auth_secondary: str = \"\", failed_when_contains: Optional[List[str]] = None, textfsm_platform: str = \"juniper_junos\", genie_platform: str = \"\", ): \"\"\" JunosDriver Object Please see `scrapli.driver.base.base_driver.Driver` for all \"base driver\" arguments! # noqa: DAR101 Args: privilege_levels: optional user provided privilege levels, if left None will default to scrapli standard privilege levels default_desired_privilege_level: string of name of default desired priv, this is the priv level that is generally used to disable paging/set terminal width and things like that upon first login, and is also the priv level scrapli will try to acquire for normal \"command\" operations (`send_command`, `send_commands`) auth_secondary: password to use for secondary authentication (enable) on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar. textfsm_platform: string name of textfsm parser platform genie_platform: string name of cisco genie parser platform failed_when_contains: List of strings that indicate a command/config has failed Returns: None Raises: N/A \"\"\" if privilege_levels is None: privilege_levels = deepcopy(PRIVS) if on_open is None: on_open = junos_on_open if on_close is None: on_close = junos_on_close if failed_when_contains is None: failed_when_contains = FAILED_WHEN_CONTAINS.copy() super().__init__( host=host, port=port, auth_username=auth_username, auth_password=auth_password, auth_private_key=auth_private_key, auth_private_key_passphrase=auth_private_key_passphrase, auth_strict_key=auth_strict_key, auth_bypass=auth_bypass, timeout_socket=timeout_socket, timeout_transport=timeout_transport, timeout_ops=timeout_ops, comms_return_char=comms_return_char, ssh_config_file=ssh_config_file, ssh_known_hosts_file=ssh_known_hosts_file, on_init=on_init, on_open=on_open, on_close=on_close, transport=transport, transport_options=transport_options, channel_log=channel_log, channel_log_mode=channel_log_mode, channel_lock=channel_lock, logging_uid=logging_uid, privilege_levels=privilege_levels, default_desired_privilege_level=default_desired_privilege_level, auth_secondary=auth_secondary, failed_when_contains=failed_when_contains, textfsm_platform=textfsm_platform, genie_platform=genie_platform, ) async def _abort_config(self) -> None: \"\"\" Abort Junos configuration session Args: N/A Returns: None Raises: N/A \"\"\" await self.send_configs([\"rollback 0\", \"exit\"]) self._current_priv_level = self.privilege_levels[\"exec\"]","title":"Module scrapli.driver.core.juniper_junos.async_driver"},{"location":"api_docs/driver/core/juniper_junos/async_driver/#functions","text":"","title":"Functions"},{"location":"api_docs/driver/core/juniper_junos/async_driver/#junos_on_close","text":"junos_on_close(conn: scrapli.driver.network.async_driver.AsyncNetworkDriver) \u2011> None 1 2 3 4 5 6 7 8 9 10 JunosDriver default on_close callable Args: conn: NetworkDriver object Returns: None Raises: N/A","title":"junos_on_close"},{"location":"api_docs/driver/core/juniper_junos/async_driver/#junos_on_open","text":"junos_on_open(conn: scrapli.driver.network.async_driver.AsyncNetworkDriver) \u2011> None 1 2 3 4 5 6 7 8 9 10 JunosDriver default on_open callable Args: conn: NetworkDriver object Returns: None Raises: N/A","title":"junos_on_open"},{"location":"api_docs/driver/core/juniper_junos/async_driver/#classes","text":"","title":"Classes"},{"location":"api_docs/driver/core/juniper_junos/async_driver/#asyncjunosdriver","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 JunosDriver Object Please see `scrapli.driver.base.base_driver.Driver` for all \"base driver\" arguments! # noqa: DAR101 Args: privilege_levels: optional user provided privilege levels, if left None will default to scrapli standard privilege levels default_desired_privilege_level: string of name of default desired priv, this is the priv level that is generally used to disable paging/set terminal width and things like that upon first login, and is also the priv level scrapli will try to acquire for normal \"command\" operations (`send_command`, `send_commands`) auth_secondary: password to use for secondary authentication (enable) on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar. textfsm_platform: string name of textfsm parser platform genie_platform: string name of cisco genie parser platform failed_when_contains: List of strings that indicate a command/config has failed Returns: None Raises: N/A Expand source code class AsyncJunosDriver(AsyncNetworkDriver): def __init__( self, host: str, privilege_levels: Optional[Dict[str, PrivilegeLevel]] = None, default_desired_privilege_level: str = \"exec\", port: Optional[int] = None, auth_username: str = \"\", auth_password: str = \"\", auth_private_key: str = \"\", auth_private_key_passphrase: str = \"\", auth_strict_key: bool = True, auth_bypass: bool = False, timeout_socket: float = 15.0, timeout_transport: float = 30.0, timeout_ops: float = 30.0, comms_return_char: str = \"\\n\", ssh_config_file: Union[str, bool] = False, ssh_known_hosts_file: Union[str, bool] = False, on_init: Optional[Callable[..., Any]] = None, on_open: Optional[Callable[..., Any]] = None, on_close: Optional[Callable[..., Any]] = None, transport: str = \"system\", transport_options: Optional[Dict[str, Any]] = None, channel_log: Union[str, bool, BytesIO] = False, channel_log_mode: str = \"write\", channel_lock: bool = False, logging_uid: str = \"\", auth_secondary: str = \"\", failed_when_contains: Optional[List[str]] = None, textfsm_platform: str = \"juniper_junos\", genie_platform: str = \"\", ): \"\"\" JunosDriver Object Please see `scrapli.driver.base.base_driver.Driver` for all \"base driver\" arguments! # noqa: DAR101 Args: privilege_levels: optional user provided privilege levels, if left None will default to scrapli standard privilege levels default_desired_privilege_level: string of name of default desired priv, this is the priv level that is generally used to disable paging/set terminal width and things like that upon first login, and is also the priv level scrapli will try to acquire for normal \"command\" operations (`send_command`, `send_commands`) auth_secondary: password to use for secondary authentication (enable) on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar. textfsm_platform: string name of textfsm parser platform genie_platform: string name of cisco genie parser platform failed_when_contains: List of strings that indicate a command/config has failed Returns: None Raises: N/A \"\"\" if privilege_levels is None: privilege_levels = deepcopy(PRIVS) if on_open is None: on_open = junos_on_open if on_close is None: on_close = junos_on_close if failed_when_contains is None: failed_when_contains = FAILED_WHEN_CONTAINS.copy() super().__init__( host=host, port=port, auth_username=auth_username, auth_password=auth_password, auth_private_key=auth_private_key, auth_private_key_passphrase=auth_private_key_passphrase, auth_strict_key=auth_strict_key, auth_bypass=auth_bypass, timeout_socket=timeout_socket, timeout_transport=timeout_transport, timeout_ops=timeout_ops, comms_return_char=comms_return_char, ssh_config_file=ssh_config_file, ssh_known_hosts_file=ssh_known_hosts_file, on_init=on_init, on_open=on_open, on_close=on_close, transport=transport, transport_options=transport_options, channel_log=channel_log, channel_log_mode=channel_log_mode, channel_lock=channel_lock, logging_uid=logging_uid, privilege_levels=privilege_levels, default_desired_privilege_level=default_desired_privilege_level, auth_secondary=auth_secondary, failed_when_contains=failed_when_contains, textfsm_platform=textfsm_platform, genie_platform=genie_platform, ) async def _abort_config(self) -> None: \"\"\" Abort Junos configuration session Args: N/A Returns: None Raises: N/A \"\"\" await self.send_configs([\"rollback 0\", \"exit\"]) self._current_priv_level = self.privilege_levels[\"exec\"]","title":"AsyncJunosDriver"},{"location":"api_docs/driver/core/juniper_junos/async_driver/#ancestors-in-mro","text":"scrapli.driver.network.async_driver.AsyncNetworkDriver scrapli.driver.generic.async_driver.AsyncGenericDriver scrapli.driver.base.async_driver.AsyncDriver scrapli.driver.base.base_driver.BaseDriver scrapli.driver.generic.base_driver.BaseGenericDriver scrapli.driver.network.base_driver.BaseNetworkDriver","title":"Ancestors (in MRO)"},{"location":"api_docs/driver/core/juniper_junos/base_driver/","text":"window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting()) Module scrapli.driver.core.juniper_junos.base_driver \u00b6 scrapli.driver.core.juniper_junos.base_driver Expand source code \"\"\"scrapli.driver.core.juniper_junos.base_driver\"\"\" from scrapli.driver.network.base_driver import PrivilegeLevel PRIVS = { \"exec\": ( PrivilegeLevel( pattern=r\"^({\\w+:\\d}\\n){0,1}[\\w\\-@()/:\\.]{1,63}>\\s?$\", name=\"exec\", previous_priv=\"\", deescalate=\"\", escalate=\"\", escalate_auth=False, escalate_prompt=\"\", ) ), \"configuration\": ( PrivilegeLevel( pattern=r\"^({\\w+:\\d}\\[edit\\]\\n){0,1}[\\w\\-@()/:\\.]{1,63}#\\s?$\", name=\"configuration\", previous_priv=\"exec\", deescalate=\"exit configuration-mode\", escalate=\"configure\", escalate_auth=False, escalate_prompt=\"\", ) ), \"configuration_exclusive\": ( PrivilegeLevel( pattern=r\"^({\\w+:\\d}\\[edit\\]\\n){0,1}[\\w\\-@()/:\\.]{1,63}#\\s?$\", name=\"configuration_exclusive\", previous_priv=\"exec\", deescalate=\"exit configuration-mode\", escalate=\"configure exclusive\", escalate_auth=False, escalate_prompt=\"\", ) ), \"configuration_private\": ( PrivilegeLevel( pattern=r\"^({\\w+:\\d}\\[edit\\]\\n){0,1}[\\w\\-@()/:\\.]{1,63}#\\s?$\", name=\"configuration_private\", previous_priv=\"exec\", deescalate=\"exit configuration-mode\", escalate=\"configure private\", escalate_auth=False, escalate_prompt=\"\", ) ), \"shell\": ( PrivilegeLevel( pattern=r\"^.*[%\\$]\\s?$\", not_contains=[\"root\"], name=\"shell\", previous_priv=\"exec\", deescalate=\"exit\", escalate=\"start shell\", escalate_auth=False, escalate_prompt=\"\", ) ), \"root_shell\": ( PrivilegeLevel( pattern=r\"^.*root@(?:\\S*:?\\S*\\s?)?[%\\#]\\s?$\", name=\"root_shell\", previous_priv=\"exec\", deescalate=\"exit\", escalate=\"start shell user root\", escalate_auth=True, escalate_prompt=r\"^[pP]assword:\\s?$\", ) ), } FAILED_WHEN_CONTAINS = [ \"is ambiguous\", \"No valid completions\", \"unknown command\", \"syntax error\", ]","title":"Base Driver"},{"location":"api_docs/driver/core/juniper_junos/base_driver/#module-scraplidrivercorejuniper_junosbase_driver","text":"scrapli.driver.core.juniper_junos.base_driver Expand source code \"\"\"scrapli.driver.core.juniper_junos.base_driver\"\"\" from scrapli.driver.network.base_driver import PrivilegeLevel PRIVS = { \"exec\": ( PrivilegeLevel( pattern=r\"^({\\w+:\\d}\\n){0,1}[\\w\\-@()/:\\.]{1,63}>\\s?$\", name=\"exec\", previous_priv=\"\", deescalate=\"\", escalate=\"\", escalate_auth=False, escalate_prompt=\"\", ) ), \"configuration\": ( PrivilegeLevel( pattern=r\"^({\\w+:\\d}\\[edit\\]\\n){0,1}[\\w\\-@()/:\\.]{1,63}#\\s?$\", name=\"configuration\", previous_priv=\"exec\", deescalate=\"exit configuration-mode\", escalate=\"configure\", escalate_auth=False, escalate_prompt=\"\", ) ), \"configuration_exclusive\": ( PrivilegeLevel( pattern=r\"^({\\w+:\\d}\\[edit\\]\\n){0,1}[\\w\\-@()/:\\.]{1,63}#\\s?$\", name=\"configuration_exclusive\", previous_priv=\"exec\", deescalate=\"exit configuration-mode\", escalate=\"configure exclusive\", escalate_auth=False, escalate_prompt=\"\", ) ), \"configuration_private\": ( PrivilegeLevel( pattern=r\"^({\\w+:\\d}\\[edit\\]\\n){0,1}[\\w\\-@()/:\\.]{1,63}#\\s?$\", name=\"configuration_private\", previous_priv=\"exec\", deescalate=\"exit configuration-mode\", escalate=\"configure private\", escalate_auth=False, escalate_prompt=\"\", ) ), \"shell\": ( PrivilegeLevel( pattern=r\"^.*[%\\$]\\s?$\", not_contains=[\"root\"], name=\"shell\", previous_priv=\"exec\", deescalate=\"exit\", escalate=\"start shell\", escalate_auth=False, escalate_prompt=\"\", ) ), \"root_shell\": ( PrivilegeLevel( pattern=r\"^.*root@(?:\\S*:?\\S*\\s?)?[%\\#]\\s?$\", name=\"root_shell\", previous_priv=\"exec\", deescalate=\"exit\", escalate=\"start shell user root\", escalate_auth=True, escalate_prompt=r\"^[pP]assword:\\s?$\", ) ), } FAILED_WHEN_CONTAINS = [ \"is ambiguous\", \"No valid completions\", \"unknown command\", \"syntax error\", ]","title":"Module scrapli.driver.core.juniper_junos.base_driver"},{"location":"api_docs/driver/core/juniper_junos/sync_driver/","text":"window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting()) Module scrapli.driver.core.juniper_junos.sync_driver \u00b6 scrapli.driver.core.juniper_junos.driver Expand source code \"\"\"scrapli.driver.core.juniper_junos.driver\"\"\" from copy import deepcopy from io import BytesIO from typing import Any, Callable, Dict, List, Optional, Union from scrapli.driver import NetworkDriver from scrapli.driver.core.juniper_junos.base_driver import FAILED_WHEN_CONTAINS, PRIVS from scrapli.driver.network.base_driver import PrivilegeLevel def junos_on_open(conn: NetworkDriver) -> None: \"\"\" JunosDriver default on_open callable Args: conn: NetworkDriver object Returns: None Raises: N/A \"\"\" conn.acquire_priv(desired_priv=conn.default_desired_privilege_level) conn.send_command(command=\"set cli screen-length 0\") conn.send_command(command=\"set cli screen-width 511\") conn.send_command(command=\"set cli complete-on-space off\") def junos_on_close(conn: NetworkDriver) -> None: \"\"\" JunosDriver default on_close callable Args: conn: NetworkDriver object Returns: None Raises: N/A \"\"\" conn.acquire_priv(desired_priv=conn.default_desired_privilege_level) conn.channel.write(channel_input=\"exit\") conn.channel.send_return() class JunosDriver(NetworkDriver): def __init__( self, host: str, privilege_levels: Optional[Dict[str, PrivilegeLevel]] = None, default_desired_privilege_level: str = \"exec\", port: Optional[int] = None, auth_username: str = \"\", auth_password: str = \"\", auth_private_key: str = \"\", auth_private_key_passphrase: str = \"\", auth_strict_key: bool = True, auth_bypass: bool = False, timeout_socket: float = 15.0, timeout_transport: float = 30.0, timeout_ops: float = 30.0, comms_return_char: str = \"\\n\", ssh_config_file: Union[str, bool] = False, ssh_known_hosts_file: Union[str, bool] = False, on_init: Optional[Callable[..., Any]] = None, on_open: Optional[Callable[..., Any]] = None, on_close: Optional[Callable[..., Any]] = None, transport: str = \"system\", transport_options: Optional[Dict[str, Any]] = None, channel_log: Union[str, bool, BytesIO] = False, channel_log_mode: str = \"write\", channel_lock: bool = False, logging_uid: str = \"\", auth_secondary: str = \"\", failed_when_contains: Optional[List[str]] = None, textfsm_platform: str = \"juniper_junos\", genie_platform: str = \"junos\", ): \"\"\" JunosDriver Object Please see `scrapli.driver.base.base_driver.Driver` for all \"base driver\" arguments! # noqa: DAR101 Args: privilege_levels: optional user provided privilege levels, if left None will default to scrapli standard privilege levels default_desired_privilege_level: string of name of default desired priv, this is the priv level that is generally used to disable paging/set terminal width and things like that upon first login, and is also the priv level scrapli will try to acquire for normal \"command\" operations (`send_command`, `send_commands`) auth_secondary: password to use for secondary authentication (enable) on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar. textfsm_platform: string name of textfsm parser platform genie_platform: string name of cisco genie parser platform. Default: junos failed_when_contains: List of strings that indicate a command/config has failed Returns: None Raises: N/A \"\"\" if privilege_levels is None: privilege_levels = deepcopy(PRIVS) if on_open is None: on_open = junos_on_open if on_close is None: on_close = junos_on_close if failed_when_contains is None: failed_when_contains = FAILED_WHEN_CONTAINS.copy() super().__init__( host=host, port=port, auth_username=auth_username, auth_password=auth_password, auth_private_key=auth_private_key, auth_private_key_passphrase=auth_private_key_passphrase, auth_strict_key=auth_strict_key, auth_bypass=auth_bypass, timeout_socket=timeout_socket, timeout_transport=timeout_transport, timeout_ops=timeout_ops, comms_return_char=comms_return_char, ssh_config_file=ssh_config_file, ssh_known_hosts_file=ssh_known_hosts_file, on_init=on_init, on_open=on_open, on_close=on_close, transport=transport, transport_options=transport_options, channel_log=channel_log, channel_log_mode=channel_log_mode, channel_lock=channel_lock, logging_uid=logging_uid, privilege_levels=privilege_levels, default_desired_privilege_level=default_desired_privilege_level, auth_secondary=auth_secondary, failed_when_contains=failed_when_contains, textfsm_platform=textfsm_platform, genie_platform=genie_platform, ) def _abort_config(self) -> None: \"\"\" Abort Junos configuration session Args: N/A Returns: None Raises: N/A \"\"\" self.send_configs([\"rollback 0\", \"exit\"]) self._current_priv_level = self.privilege_levels[\"exec\"] Functions \u00b6 junos_on_close \u00b6 junos_on_close(conn: scrapli.driver.network.sync_driver.NetworkDriver) \u2011> None 1 2 3 4 5 6 7 8 9 10 JunosDriver default on_close callable Args: conn: NetworkDriver object Returns: None Raises: N/A junos_on_open \u00b6 junos_on_open(conn: scrapli.driver.network.sync_driver.NetworkDriver) \u2011> None 1 2 3 4 5 6 7 8 9 10 JunosDriver default on_open callable Args: conn: NetworkDriver object Returns: None Raises: N/A Classes \u00b6 JunosDriver \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 JunosDriver Object Please see `scrapli.driver.base.base_driver.Driver` for all \"base driver\" arguments! # noqa: DAR101 Args: privilege_levels: optional user provided privilege levels, if left None will default to scrapli standard privilege levels default_desired_privilege_level: string of name of default desired priv, this is the priv level that is generally used to disable paging/set terminal width and things like that upon first login, and is also the priv level scrapli will try to acquire for normal \"command\" operations (`send_command`, `send_commands`) auth_secondary: password to use for secondary authentication (enable) on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar. textfsm_platform: string name of textfsm parser platform genie_platform: string name of cisco genie parser platform. Default: junos failed_when_contains: List of strings that indicate a command/config has failed Returns: None Raises: N/A Expand source code class JunosDriver(NetworkDriver): def __init__( self, host: str, privilege_levels: Optional[Dict[str, PrivilegeLevel]] = None, default_desired_privilege_level: str = \"exec\", port: Optional[int] = None, auth_username: str = \"\", auth_password: str = \"\", auth_private_key: str = \"\", auth_private_key_passphrase: str = \"\", auth_strict_key: bool = True, auth_bypass: bool = False, timeout_socket: float = 15.0, timeout_transport: float = 30.0, timeout_ops: float = 30.0, comms_return_char: str = \"\\n\", ssh_config_file: Union[str, bool] = False, ssh_known_hosts_file: Union[str, bool] = False, on_init: Optional[Callable[..., Any]] = None, on_open: Optional[Callable[..., Any]] = None, on_close: Optional[Callable[..., Any]] = None, transport: str = \"system\", transport_options: Optional[Dict[str, Any]] = None, channel_log: Union[str, bool, BytesIO] = False, channel_log_mode: str = \"write\", channel_lock: bool = False, logging_uid: str = \"\", auth_secondary: str = \"\", failed_when_contains: Optional[List[str]] = None, textfsm_platform: str = \"juniper_junos\", genie_platform: str = \"junos\", ): \"\"\" JunosDriver Object Please see `scrapli.driver.base.base_driver.Driver` for all \"base driver\" arguments! # noqa: DAR101 Args: privilege_levels: optional user provided privilege levels, if left None will default to scrapli standard privilege levels default_desired_privilege_level: string of name of default desired priv, this is the priv level that is generally used to disable paging/set terminal width and things like that upon first login, and is also the priv level scrapli will try to acquire for normal \"command\" operations (`send_command`, `send_commands`) auth_secondary: password to use for secondary authentication (enable) on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar. textfsm_platform: string name of textfsm parser platform genie_platform: string name of cisco genie parser platform. Default: junos failed_when_contains: List of strings that indicate a command/config has failed Returns: None Raises: N/A \"\"\" if privilege_levels is None: privilege_levels = deepcopy(PRIVS) if on_open is None: on_open = junos_on_open if on_close is None: on_close = junos_on_close if failed_when_contains is None: failed_when_contains = FAILED_WHEN_CONTAINS.copy() super().__init__( host=host, port=port, auth_username=auth_username, auth_password=auth_password, auth_private_key=auth_private_key, auth_private_key_passphrase=auth_private_key_passphrase, auth_strict_key=auth_strict_key, auth_bypass=auth_bypass, timeout_socket=timeout_socket, timeout_transport=timeout_transport, timeout_ops=timeout_ops, comms_return_char=comms_return_char, ssh_config_file=ssh_config_file, ssh_known_hosts_file=ssh_known_hosts_file, on_init=on_init, on_open=on_open, on_close=on_close, transport=transport, transport_options=transport_options, channel_log=channel_log, channel_log_mode=channel_log_mode, channel_lock=channel_lock, logging_uid=logging_uid, privilege_levels=privilege_levels, default_desired_privilege_level=default_desired_privilege_level, auth_secondary=auth_secondary, failed_when_contains=failed_when_contains, textfsm_platform=textfsm_platform, genie_platform=genie_platform, ) def _abort_config(self) -> None: \"\"\" Abort Junos configuration session Args: N/A Returns: None Raises: N/A \"\"\" self.send_configs([\"rollback 0\", \"exit\"]) self._current_priv_level = self.privilege_levels[\"exec\"] Ancestors (in MRO) \u00b6 scrapli.driver.network.sync_driver.NetworkDriver scrapli.driver.generic.sync_driver.GenericDriver scrapli.driver.base.sync_driver.Driver scrapli.driver.base.base_driver.BaseDriver scrapli.driver.generic.base_driver.BaseGenericDriver scrapli.driver.network.base_driver.BaseNetworkDriver","title":"Sync Driver"},{"location":"api_docs/driver/core/juniper_junos/sync_driver/#module-scraplidrivercorejuniper_junossync_driver","text":"scrapli.driver.core.juniper_junos.driver Expand source code \"\"\"scrapli.driver.core.juniper_junos.driver\"\"\" from copy import deepcopy from io import BytesIO from typing import Any, Callable, Dict, List, Optional, Union from scrapli.driver import NetworkDriver from scrapli.driver.core.juniper_junos.base_driver import FAILED_WHEN_CONTAINS, PRIVS from scrapli.driver.network.base_driver import PrivilegeLevel def junos_on_open(conn: NetworkDriver) -> None: \"\"\" JunosDriver default on_open callable Args: conn: NetworkDriver object Returns: None Raises: N/A \"\"\" conn.acquire_priv(desired_priv=conn.default_desired_privilege_level) conn.send_command(command=\"set cli screen-length 0\") conn.send_command(command=\"set cli screen-width 511\") conn.send_command(command=\"set cli complete-on-space off\") def junos_on_close(conn: NetworkDriver) -> None: \"\"\" JunosDriver default on_close callable Args: conn: NetworkDriver object Returns: None Raises: N/A \"\"\" conn.acquire_priv(desired_priv=conn.default_desired_privilege_level) conn.channel.write(channel_input=\"exit\") conn.channel.send_return() class JunosDriver(NetworkDriver): def __init__( self, host: str, privilege_levels: Optional[Dict[str, PrivilegeLevel]] = None, default_desired_privilege_level: str = \"exec\", port: Optional[int] = None, auth_username: str = \"\", auth_password: str = \"\", auth_private_key: str = \"\", auth_private_key_passphrase: str = \"\", auth_strict_key: bool = True, auth_bypass: bool = False, timeout_socket: float = 15.0, timeout_transport: float = 30.0, timeout_ops: float = 30.0, comms_return_char: str = \"\\n\", ssh_config_file: Union[str, bool] = False, ssh_known_hosts_file: Union[str, bool] = False, on_init: Optional[Callable[..., Any]] = None, on_open: Optional[Callable[..., Any]] = None, on_close: Optional[Callable[..., Any]] = None, transport: str = \"system\", transport_options: Optional[Dict[str, Any]] = None, channel_log: Union[str, bool, BytesIO] = False, channel_log_mode: str = \"write\", channel_lock: bool = False, logging_uid: str = \"\", auth_secondary: str = \"\", failed_when_contains: Optional[List[str]] = None, textfsm_platform: str = \"juniper_junos\", genie_platform: str = \"junos\", ): \"\"\" JunosDriver Object Please see `scrapli.driver.base.base_driver.Driver` for all \"base driver\" arguments! # noqa: DAR101 Args: privilege_levels: optional user provided privilege levels, if left None will default to scrapli standard privilege levels default_desired_privilege_level: string of name of default desired priv, this is the priv level that is generally used to disable paging/set terminal width and things like that upon first login, and is also the priv level scrapli will try to acquire for normal \"command\" operations (`send_command`, `send_commands`) auth_secondary: password to use for secondary authentication (enable) on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar. textfsm_platform: string name of textfsm parser platform genie_platform: string name of cisco genie parser platform. Default: junos failed_when_contains: List of strings that indicate a command/config has failed Returns: None Raises: N/A \"\"\" if privilege_levels is None: privilege_levels = deepcopy(PRIVS) if on_open is None: on_open = junos_on_open if on_close is None: on_close = junos_on_close if failed_when_contains is None: failed_when_contains = FAILED_WHEN_CONTAINS.copy() super().__init__( host=host, port=port, auth_username=auth_username, auth_password=auth_password, auth_private_key=auth_private_key, auth_private_key_passphrase=auth_private_key_passphrase, auth_strict_key=auth_strict_key, auth_bypass=auth_bypass, timeout_socket=timeout_socket, timeout_transport=timeout_transport, timeout_ops=timeout_ops, comms_return_char=comms_return_char, ssh_config_file=ssh_config_file, ssh_known_hosts_file=ssh_known_hosts_file, on_init=on_init, on_open=on_open, on_close=on_close, transport=transport, transport_options=transport_options, channel_log=channel_log, channel_log_mode=channel_log_mode, channel_lock=channel_lock, logging_uid=logging_uid, privilege_levels=privilege_levels, default_desired_privilege_level=default_desired_privilege_level, auth_secondary=auth_secondary, failed_when_contains=failed_when_contains, textfsm_platform=textfsm_platform, genie_platform=genie_platform, ) def _abort_config(self) -> None: \"\"\" Abort Junos configuration session Args: N/A Returns: None Raises: N/A \"\"\" self.send_configs([\"rollback 0\", \"exit\"]) self._current_priv_level = self.privilege_levels[\"exec\"]","title":"Module scrapli.driver.core.juniper_junos.sync_driver"},{"location":"api_docs/driver/core/juniper_junos/sync_driver/#functions","text":"","title":"Functions"},{"location":"api_docs/driver/core/juniper_junos/sync_driver/#junos_on_close","text":"junos_on_close(conn: scrapli.driver.network.sync_driver.NetworkDriver) \u2011> None 1 2 3 4 5 6 7 8 9 10 JunosDriver default on_close callable Args: conn: NetworkDriver object Returns: None Raises: N/A","title":"junos_on_close"},{"location":"api_docs/driver/core/juniper_junos/sync_driver/#junos_on_open","text":"junos_on_open(conn: scrapli.driver.network.sync_driver.NetworkDriver) \u2011> None 1 2 3 4 5 6 7 8 9 10 JunosDriver default on_open callable Args: conn: NetworkDriver object Returns: None Raises: N/A","title":"junos_on_open"},{"location":"api_docs/driver/core/juniper_junos/sync_driver/#classes","text":"","title":"Classes"},{"location":"api_docs/driver/core/juniper_junos/sync_driver/#junosdriver","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 JunosDriver Object Please see `scrapli.driver.base.base_driver.Driver` for all \"base driver\" arguments! # noqa: DAR101 Args: privilege_levels: optional user provided privilege levels, if left None will default to scrapli standard privilege levels default_desired_privilege_level: string of name of default desired priv, this is the priv level that is generally used to disable paging/set terminal width and things like that upon first login, and is also the priv level scrapli will try to acquire for normal \"command\" operations (`send_command`, `send_commands`) auth_secondary: password to use for secondary authentication (enable) on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar. textfsm_platform: string name of textfsm parser platform genie_platform: string name of cisco genie parser platform. Default: junos failed_when_contains: List of strings that indicate a command/config has failed Returns: None Raises: N/A Expand source code class JunosDriver(NetworkDriver): def __init__( self, host: str, privilege_levels: Optional[Dict[str, PrivilegeLevel]] = None, default_desired_privilege_level: str = \"exec\", port: Optional[int] = None, auth_username: str = \"\", auth_password: str = \"\", auth_private_key: str = \"\", auth_private_key_passphrase: str = \"\", auth_strict_key: bool = True, auth_bypass: bool = False, timeout_socket: float = 15.0, timeout_transport: float = 30.0, timeout_ops: float = 30.0, comms_return_char: str = \"\\n\", ssh_config_file: Union[str, bool] = False, ssh_known_hosts_file: Union[str, bool] = False, on_init: Optional[Callable[..., Any]] = None, on_open: Optional[Callable[..., Any]] = None, on_close: Optional[Callable[..., Any]] = None, transport: str = \"system\", transport_options: Optional[Dict[str, Any]] = None, channel_log: Union[str, bool, BytesIO] = False, channel_log_mode: str = \"write\", channel_lock: bool = False, logging_uid: str = \"\", auth_secondary: str = \"\", failed_when_contains: Optional[List[str]] = None, textfsm_platform: str = \"juniper_junos\", genie_platform: str = \"junos\", ): \"\"\" JunosDriver Object Please see `scrapli.driver.base.base_driver.Driver` for all \"base driver\" arguments! # noqa: DAR101 Args: privilege_levels: optional user provided privilege levels, if left None will default to scrapli standard privilege levels default_desired_privilege_level: string of name of default desired priv, this is the priv level that is generally used to disable paging/set terminal width and things like that upon first login, and is also the priv level scrapli will try to acquire for normal \"command\" operations (`send_command`, `send_commands`) auth_secondary: password to use for secondary authentication (enable) on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar. textfsm_platform: string name of textfsm parser platform genie_platform: string name of cisco genie parser platform. Default: junos failed_when_contains: List of strings that indicate a command/config has failed Returns: None Raises: N/A \"\"\" if privilege_levels is None: privilege_levels = deepcopy(PRIVS) if on_open is None: on_open = junos_on_open if on_close is None: on_close = junos_on_close if failed_when_contains is None: failed_when_contains = FAILED_WHEN_CONTAINS.copy() super().__init__( host=host, port=port, auth_username=auth_username, auth_password=auth_password, auth_private_key=auth_private_key, auth_private_key_passphrase=auth_private_key_passphrase, auth_strict_key=auth_strict_key, auth_bypass=auth_bypass, timeout_socket=timeout_socket, timeout_transport=timeout_transport, timeout_ops=timeout_ops, comms_return_char=comms_return_char, ssh_config_file=ssh_config_file, ssh_known_hosts_file=ssh_known_hosts_file, on_init=on_init, on_open=on_open, on_close=on_close, transport=transport, transport_options=transport_options, channel_log=channel_log, channel_log_mode=channel_log_mode, channel_lock=channel_lock, logging_uid=logging_uid, privilege_levels=privilege_levels, default_desired_privilege_level=default_desired_privilege_level, auth_secondary=auth_secondary, failed_when_contains=failed_when_contains, textfsm_platform=textfsm_platform, genie_platform=genie_platform, ) def _abort_config(self) -> None: \"\"\" Abort Junos configuration session Args: N/A Returns: None Raises: N/A \"\"\" self.send_configs([\"rollback 0\", \"exit\"]) self._current_priv_level = self.privilege_levels[\"exec\"]","title":"JunosDriver"},{"location":"api_docs/driver/core/juniper_junos/sync_driver/#ancestors-in-mro","text":"scrapli.driver.network.sync_driver.NetworkDriver scrapli.driver.generic.sync_driver.GenericDriver scrapli.driver.base.sync_driver.Driver scrapli.driver.base.base_driver.BaseDriver scrapli.driver.generic.base_driver.BaseGenericDriver scrapli.driver.network.base_driver.BaseNetworkDriver","title":"Ancestors (in MRO)"},{"location":"api_docs/driver/generic/async_driver/","text":"window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting()) Module scrapli.driver.generic.async_driver \u00b6 scrapli.driver.generic.async_driver Expand source code \"\"\"scrapli.driver.generic.async_driver\"\"\" import asyncio from io import BytesIO from typing import TYPE_CHECKING, Any, Callable, Dict, List, Optional, Tuple, Union from scrapli.decorators import timeout_modifier from scrapli.driver import AsyncDriver from scrapli.driver.generic.base_driver import BaseGenericDriver from scrapli.exceptions import ScrapliTimeout, ScrapliValueError from scrapli.response import MultiResponse, Response if TYPE_CHECKING: from scrapli.driver.generic.base_driver import ( # pragma: no cover ReadCallback, ReadCallbackReturnable, ) class AsyncGenericDriver(AsyncDriver, BaseGenericDriver): def __init__( self, host: str, port: Optional[int] = None, auth_username: str = \"\", auth_password: str = \"\", auth_private_key: str = \"\", auth_private_key_passphrase: str = \"\", auth_strict_key: bool = True, auth_bypass: bool = False, timeout_socket: float = 15.0, timeout_transport: float = 30.0, timeout_ops: float = 30.0, comms_prompt_pattern: str = r\"^\\S{0,48}[#>$~@:\\]]\\s*$\", comms_return_char: str = \"\\n\", ssh_config_file: Union[str, bool] = False, ssh_known_hosts_file: Union[str, bool] = False, on_init: Optional[Callable[..., Any]] = None, on_open: Optional[Callable[..., Any]] = None, on_close: Optional[Callable[..., Any]] = None, transport: str = \"system\", transport_options: Optional[Dict[str, Any]] = None, channel_log: Union[str, bool, BytesIO] = False, channel_log_mode: str = \"write\", channel_lock: bool = False, logging_uid: str = \"\", ) -> None: super().__init__( host=host, port=port, auth_username=auth_username, auth_password=auth_password, auth_private_key=auth_private_key, auth_private_key_passphrase=auth_private_key_passphrase, auth_strict_key=auth_strict_key, auth_bypass=auth_bypass, timeout_socket=timeout_socket, timeout_transport=timeout_transport, timeout_ops=timeout_ops, comms_prompt_pattern=comms_prompt_pattern, comms_return_char=comms_return_char, ssh_config_file=ssh_config_file, ssh_known_hosts_file=ssh_known_hosts_file, on_init=on_init, on_open=on_open, on_close=on_close, transport=transport, transport_options=transport_options, channel_log=channel_log, channel_log_mode=channel_log_mode, channel_lock=channel_lock, logging_uid=logging_uid, ) async def get_prompt(self) -> str: \"\"\" Convenience method to fetch prompt from the underlying Channel object Args: N/A Returns: str: string of the current prompt Raises: N/A \"\"\" prompt: str = await self.channel.get_prompt() return prompt @timeout_modifier async def _send_command( self, command: str, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, eager: bool = False, timeout_ops: Optional[float] = None, ) -> Response: \"\"\" Send a command Private method so that we can handle `eager` w/out having to have that argument showing up in all the methods that super to the \"normal\" send_command method as we only ever want eager to be used for the plural options -- i.e. send_commands not send_command! Args: command: string to send to device in privilege exec mode strip_prompt: strip prompt or not, defaults to True (yes, strip the prompt) failed_when_contains: string or list of strings indicating failure if found in response eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed Returns: Response: Scrapli Response object Raises: ScrapliValueError: if _base_transport_args is None for some reason \"\"\" # decorator cares about timeout_ops, but nothing else does, assign to _ to appease linters _ = timeout_ops if not self._base_transport_args: # should not happen! :) raise ScrapliValueError(\"driver _base_transport_args not set for some reason\") response = self._pre_send_command( host=self._base_transport_args.host, command=command, failed_when_contains=failed_when_contains, ) raw_response, processed_response = await self.channel.send_input( channel_input=command, strip_prompt=strip_prompt, eager=eager ) return self._post_send_command( raw_response=raw_response, processed_response=processed_response, response=response ) async def send_command( self, command: str, *, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, timeout_ops: Optional[float] = None, ) -> Response: \"\"\" Send a command Args: command: string to send to device in privilege exec mode strip_prompt: strip prompt or not, defaults to True (yes, strip the prompt) failed_when_contains: string or list of strings indicating failure if found in response timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed Returns: Response: Scrapli Response object Raises: N/A \"\"\" response: Response = await self._send_command( command=command, strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, timeout_ops=timeout_ops, ) return response async def send_commands( self, commands: List[str], *, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, stop_on_failed: bool = False, eager: bool = False, timeout_ops: Optional[float] = None, ) -> MultiResponse: \"\"\" Send multiple commands Args: commands: list of strings to send to device in privilege exec mode strip_prompt: strip prompt or not, defaults to True (yes, strip the prompt) failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER COMMAND sent, not for the total of the commands being sent! Returns: MultiResponse: Scrapli MultiResponse object Raises: N/A \"\"\" responses = self._pre_send_commands(commands=commands) for command in commands[:-1]: response = await self._send_command( command=command, strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, timeout_ops=timeout_ops, eager=eager, ) responses.append(response) if stop_on_failed and response.failed is True: # should we find the prompt here w/ get_prompt?? or just let subsequent operations # deal w/ finding that? future us problem? :) break else: # if we did *not* break (i.e. no failure and/or no stop_on_failed) send the last command # with eager = False -- this way we *always* find the prompt at the end of the commands response = await self._send_command( command=commands[-1], strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, timeout_ops=timeout_ops, eager=False, ) responses.append(response) return responses async def send_commands_from_file( self, file: str, *, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, stop_on_failed: bool = False, eager: bool = False, timeout_ops: Optional[float] = None, ) -> MultiResponse: \"\"\" Send command(s) from file Args: file: string path to file strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER COMMAND sent, not for the total of the commands being sent! Returns: MultiResponse: Scrapli MultiResponse object Raises: N/A \"\"\" commands = self._pre_send_from_file(file=file, caller=\"send_commands_from_file\") return await self.send_commands( commands=commands, strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, stop_on_failed=stop_on_failed, eager=eager, timeout_ops=timeout_ops, ) @timeout_modifier async def send_and_read( self, channel_input: str, *, expected_outputs: Optional[List[str]] = None, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, timeout_ops: Optional[float] = None, read_duration: float = 2.5, ) -> Response: \"\"\" Send an input and read outputs. Unlike \"normal\" scrapli behavior this method reads until the prompt(normal) OR until any of a list of expected outputs is seen, OR until the read duration is exceeded. This method does not care about/understand privilege levels. This *can* cause you some potential issues if not used carefully! Args: channel_input: input to send to the channel; intentionally named \"channel_input\" instead of \"command\" or \"config\" due to this method not caring about privilege levels expected_outputs: List of outputs to look for in device response; returns as soon as any of the outputs are seen strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed read_duration: float duration to read for Returns: Response: Scrapli Response object Raises: ScrapliValueError: if _base_transport_args is None for some reason \"\"\" # decorator cares about timeout_ops, but nothing else does, assign to _ to appease linters _ = timeout_ops if not self._base_transport_args: # should not happen! :) raise ScrapliValueError(\"driver _base_transport_args not set for some reason\") response = self._pre_send_command( host=self._base_transport_args.host, command=channel_input, failed_when_contains=failed_when_contains, ) raw_response, processed_response = await self.channel.send_input_and_read( channel_input=channel_input, strip_prompt=strip_prompt, expected_outputs=expected_outputs, read_duration=read_duration, ) return self._post_send_command( raw_response=raw_response, processed_response=processed_response, response=response ) @timeout_modifier async def send_interactive( self, interact_events: Union[List[Tuple[str, str]], List[Tuple[str, str, bool]]], *, failed_when_contains: Optional[Union[str, List[str]]] = None, privilege_level: str = \"\", timeout_ops: Optional[float] = None, interaction_complete_patterns: Optional[List[str]] = None, ) -> Response: \"\"\" Interact with a device with changing prompts per input. Used to interact with devices where prompts change per input, and where inputs may be hidden such as in the case of a password input. This can be used to respond to challenges from devices such as the confirmation for the command \"clear logging\" on IOSXE devices for example. You may have as many elements in the \"interact_events\" list as needed, and each element of that list should be a tuple of two or three elements. The first element is always the input to send as a string, the second should be the expected response as a string, and the optional third a bool for whether or not the input is \"hidden\" (i.e. password input) An example where we need this sort of capability: 1 2 3 4 5 6 7 8 9 10 11 12 3560CX#copy flash: scp: Source filename []? test1.txt Address or name of remote host []? 172.31.254.100 Destination username [carl]? Writing test1.txt Password: Password: Sink: C0644 639 test1.txt ! 639 bytes copied in 12.066 secs (53 bytes/sec) 3560CX# To accomplish this we can use the following: 1 2 3 4 5 6 7 8 9 interact = conn.channel.send_inputs_interact( [ (\"copy flash: scp:\", \"Source filename []?\", False), (\"test1.txt\", \"Address or name of remote host []?\", False), (\"172.31.254.100\", \"Destination username [carl]?\", False), (\"carl\", \"Password:\", False), (\"super_secure_password\", prompt, True), ] ) If we needed to deal with more prompts we could simply continue adding tuples to the list of interact \"events\". Args: interact_events: list of tuples containing the \"interactions\" with the device each list element must have an input and an expected response, and may have an optional bool for the third and final element -- the optional bool specifies if the input that is sent to the device is \"hidden\" (ex: password), if the hidden param is not provided it is assumed the input is \"normal\" (not hidden) failed_when_contains: list of strings that, if present in final output, represent a failed command/interaction privilege_level: ignored in this base class; for LSP reasons for subclasses timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER COMMAND sent, not for the total of the commands being sent! interaction_complete_patterns: list of patterns, that if seen, indicate the interactive \"session\" has ended and we should exit the interactive session. Returns: Response: scrapli Response object Raises: ScrapliValueError: if _base_transport_args is None for some reason \"\"\" # decorator cares about timeout_ops, but nothing else does, assign to _ to appease linters _ = timeout_ops # privilege level only matters \"up\" in the network driver layer _ = privilege_level if not self._base_transport_args: # should not happen! :) raise ScrapliValueError(\"driver _base_transport_args not set for some reason\") response = self._pre_send_interactive( host=self._base_transport_args.host, interact_events=interact_events, failed_when_contains=failed_when_contains, ) raw_response, processed_response = await self.channel.send_inputs_interact( interact_events=interact_events, interaction_complete_patterns=interaction_complete_patterns, ) return self._post_send_command( raw_response=raw_response, processed_response=processed_response, response=response ) async def read_callback( # noqa: C901 self, callbacks: List[\"ReadCallback\"], initial_input: Optional[str] = None, read_output: bytes = b\"\", read_delay: float = 0.1, read_timeout: float = -1.0, ) -> \"ReadCallbackReturnable\": r\"\"\" Read from a channel and react to the output with some callback. This method is kind of like an \"advanced\" send_interactive -- the idea is simple: send some \"stuff\" to the channel (optionally), and then read from the channel. Based on the output do something. The callbacks is a list of `ReadCallback` which is an object containing the actual callback to execute, some info about when to trigger that callback (also when *not* to trigger that callback), as well as some attributes to control the next (if desired) iteration of read_callback. You could in theory do basically everything with this method by chaining callbacks forever, but you probably don't want to do that for real! Example usage: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 from scrapli.driver.core import IOSXEDriver from scrapli.driver.generic.base_driver import ReadCallback from scrapli.driver.generic.sync_driver import GenericDriver device = { \"host\": \"rtr1\", \"auth_strict_key\": False, \"ssh_config_file\": True, } def callback_one(cls: GenericDriver, read_output: str): cls.acquire_priv(\"configuration\") cls.channel.send_return() def callback_two(cls: GenericDriver, read_output: str): print(f\"previous read output : {read_output}\") r = cls.send_command(\"show run | i hostname\") print(f\"result: {r.result}\") with IOSXEDriver(**device) as conn: callbacks = [ ReadCallback( contains=\"rtr1#\", callback=callback_one, name=\"call1\", case_insensitive=False ), ReadCallback( contains_re=r\"^rtr1\\(config\\)#\", callback=callback_two, complete=True, ) ] conn.read_callback(callbacks=callbacks, initial_input=\"show run | i hostname\") Args: callbacks: a list of ReadCallback objects initial_input: optional string to send to \"kick off\" the read_callback method read_output: optional bytes to append any new reads to read_delay: sleep interval between reads read_timeout: value to set the `transport_timeout` to for the duration of the reading portion of this method. If left default (-1.0) or set to anything below 0, the transport timeout value will be left alone (whatever the timeout_transport value is) otherwise, the provided value will be temporarily set as the timeout_transport for duration of the reading. Returns: ReadCallbackReturnable: either None or call to read_callback again Raises: ScrapliTimeout: if the read operation times out (base don the read_timeout value) during the read callback check. \"\"\" if initial_input is not None: self.channel.write(channel_input=f\"{initial_input}{self.comms_return_char}\") return await self.read_callback(callbacks=callbacks, initial_input=None) original_transport_timeout = self.timeout_transport # if the read_timeout value is -1.0 or just less than 0, that indicates we should use # the \"normal\" transport timeout and not modify anything self.timeout_transport = read_timeout if read_timeout >= 0 else self.timeout_transport _read_delay = 0.1 if read_delay < = 0 else read_delay while True: try: read_output += await self.channel.read() except ScrapliTimeout as exc: self.timeout_transport = original_transport_timeout raise ScrapliTimeout(\"timeout during read in read_callback operation\") from exc for callback in callbacks: _run_callback = callback.check(read_output=read_output) if ( callback.only_once is True and callback._triggered is True # pylint: disable=W0212 ): self.logger.warning( f\"callback {callback.name} matches but is set to 'only_once', \" \"skipping this callback\" ) continue if _run_callback is True: self.logger.info(f\"callback {callback.name} matched, executing\") self.timeout_transport = original_transport_timeout coro = callback.run(driver=self) if coro is not None: # should always be a coroutine in this case, this appeases mypy await coro if callback.complete: self.logger.debug(\"callback complete is true, done with read_callback\") return None if callback.reset_output: read_output = b\"\" return await self.read_callback( callbacks=callbacks, initial_input=None, read_output=read_output, read_delay=callback.next_delay, read_timeout=callback.next_timeout, ) await asyncio.sleep(_read_delay) Classes \u00b6 AsyncGenericDriver \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 BaseDriver Object BaseDriver is the root for all Scrapli driver classes. The synchronous and asyncio driver base driver classes can be used to provide a semi-pexpect like experience over top of whatever transport a user prefers. Generally, however, the base driver classes should not be used directly. It is best to use the GenericDriver (or AsyncGenericDriver) or NetworkDriver (or AsyncNetworkDriver) sub-classes of the base drivers. Args: host: host ip/name to connect to port: port to connect to auth_username: username for authentication auth_private_key: path to private key for authentication auth_private_key_passphrase: passphrase for decrypting ssh key if necessary auth_password: password for authentication auth_strict_key: strict host checking or not auth_bypass: bypass \"in channel\" authentication -- only supported with telnet, asynctelnet, and system transport plugins timeout_socket: timeout for establishing socket/initial connection in seconds timeout_transport: timeout for ssh|telnet transport in seconds timeout_ops: timeout for ssh channel operations comms_prompt_pattern: raw string regex pattern -- preferably use `^` and `$` anchors! this is the single most important attribute here! if this does not match a prompt, scrapli will not work! IMPORTANT: regex search uses multi-line + case insensitive flags. multi-line allows for highly reliably matching for prompts however we do NOT strip trailing whitespace for each line, so be sure to add '\\\\s?' or similar if your device needs that. This should be mostly sorted for you if using network drivers (i.e. `IOSXEDriver`). Lastly, the case insensitive is just a convenience factor so i can be lazy. comms_return_char: character to use to send returns to host ssh_config_file: string to path for ssh config file, True to use default ssh config file or False to ignore default ssh config file ssh_known_hosts_file: string to path for ssh known hosts file, True to use default known file locations. Only applicable/needed if `auth_strict_key` is set to True on_init: callable that accepts the class instance as its only argument. this callable, if provided, is executed as the last step of object instantiation -- its purpose is primarily to provide a mechanism for scrapli community platforms to have an easy way to modify initialization arguments/object attributes without needing to create a class that extends the driver, instead allowing the community platforms to simply build from the GenericDriver or NetworkDriver classes, and pass this callable to do things such as appending to a username (looking at you RouterOS!!). Note that this is *always* a synchronous function (even for asyncio drivers)! on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar transport: name of the transport plugin to use for the actual telnet/ssh/netconf connection. Available \"core\" transports are: - system - telnet - asynctelnet - ssh2 - paramiko - asyncssh Please see relevant transport plugin section for details. Additionally third party transport plugins may be available. transport_options: dictionary of options to pass to selected transport class; see docs for given transport class for details of what to pass here channel_lock: True/False to lock the channel (threading.Lock/asyncio.Lock) during any channel operations, defaults to False channel_log: True/False or a string path to a file of where to write out channel logs -- these are not \"logs\" in the normal logging module sense, but only the output that is read from the channel. In other words, the output of the channel log should look similar to what you would see as a human connecting to a device channel_log_mode: \"write\"|\"append\", all other values will raise ValueError, does what it sounds like it should by setting the channel log to the provided mode logging_uid: unique identifier (string) to associate to log messages; useful if you have multiple connections to the same device (i.e. one console, one ssh, or one to each supervisor module, etc.) Returns: None Raises: N/A Expand source code class AsyncGenericDriver(AsyncDriver, BaseGenericDriver): def __init__( self, host: str, port: Optional[int] = None, auth_username: str = \"\", auth_password: str = \"\", auth_private_key: str = \"\", auth_private_key_passphrase: str = \"\", auth_strict_key: bool = True, auth_bypass: bool = False, timeout_socket: float = 15.0, timeout_transport: float = 30.0, timeout_ops: float = 30.0, comms_prompt_pattern: str = r\"^\\S{0,48}[#>$~@:\\]]\\s*$\", comms_return_char: str = \"\\n\", ssh_config_file: Union[str, bool] = False, ssh_known_hosts_file: Union[str, bool] = False, on_init: Optional[Callable[..., Any]] = None, on_open: Optional[Callable[..., Any]] = None, on_close: Optional[Callable[..., Any]] = None, transport: str = \"system\", transport_options: Optional[Dict[str, Any]] = None, channel_log: Union[str, bool, BytesIO] = False, channel_log_mode: str = \"write\", channel_lock: bool = False, logging_uid: str = \"\", ) -> None: super().__init__( host=host, port=port, auth_username=auth_username, auth_password=auth_password, auth_private_key=auth_private_key, auth_private_key_passphrase=auth_private_key_passphrase, auth_strict_key=auth_strict_key, auth_bypass=auth_bypass, timeout_socket=timeout_socket, timeout_transport=timeout_transport, timeout_ops=timeout_ops, comms_prompt_pattern=comms_prompt_pattern, comms_return_char=comms_return_char, ssh_config_file=ssh_config_file, ssh_known_hosts_file=ssh_known_hosts_file, on_init=on_init, on_open=on_open, on_close=on_close, transport=transport, transport_options=transport_options, channel_log=channel_log, channel_log_mode=channel_log_mode, channel_lock=channel_lock, logging_uid=logging_uid, ) async def get_prompt(self) -> str: \"\"\" Convenience method to fetch prompt from the underlying Channel object Args: N/A Returns: str: string of the current prompt Raises: N/A \"\"\" prompt: str = await self.channel.get_prompt() return prompt @timeout_modifier async def _send_command( self, command: str, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, eager: bool = False, timeout_ops: Optional[float] = None, ) -> Response: \"\"\" Send a command Private method so that we can handle `eager` w/out having to have that argument showing up in all the methods that super to the \"normal\" send_command method as we only ever want eager to be used for the plural options -- i.e. send_commands not send_command! Args: command: string to send to device in privilege exec mode strip_prompt: strip prompt or not, defaults to True (yes, strip the prompt) failed_when_contains: string or list of strings indicating failure if found in response eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed Returns: Response: Scrapli Response object Raises: ScrapliValueError: if _base_transport_args is None for some reason \"\"\" # decorator cares about timeout_ops, but nothing else does, assign to _ to appease linters _ = timeout_ops if not self._base_transport_args: # should not happen! :) raise ScrapliValueError(\"driver _base_transport_args not set for some reason\") response = self._pre_send_command( host=self._base_transport_args.host, command=command, failed_when_contains=failed_when_contains, ) raw_response, processed_response = await self.channel.send_input( channel_input=command, strip_prompt=strip_prompt, eager=eager ) return self._post_send_command( raw_response=raw_response, processed_response=processed_response, response=response ) async def send_command( self, command: str, *, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, timeout_ops: Optional[float] = None, ) -> Response: \"\"\" Send a command Args: command: string to send to device in privilege exec mode strip_prompt: strip prompt or not, defaults to True (yes, strip the prompt) failed_when_contains: string or list of strings indicating failure if found in response timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed Returns: Response: Scrapli Response object Raises: N/A \"\"\" response: Response = await self._send_command( command=command, strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, timeout_ops=timeout_ops, ) return response async def send_commands( self, commands: List[str], *, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, stop_on_failed: bool = False, eager: bool = False, timeout_ops: Optional[float] = None, ) -> MultiResponse: \"\"\" Send multiple commands Args: commands: list of strings to send to device in privilege exec mode strip_prompt: strip prompt or not, defaults to True (yes, strip the prompt) failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER COMMAND sent, not for the total of the commands being sent! Returns: MultiResponse: Scrapli MultiResponse object Raises: N/A \"\"\" responses = self._pre_send_commands(commands=commands) for command in commands[:-1]: response = await self._send_command( command=command, strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, timeout_ops=timeout_ops, eager=eager, ) responses.append(response) if stop_on_failed and response.failed is True: # should we find the prompt here w/ get_prompt?? or just let subsequent operations # deal w/ finding that? future us problem? :) break else: # if we did *not* break (i.e. no failure and/or no stop_on_failed) send the last command # with eager = False -- this way we *always* find the prompt at the end of the commands response = await self._send_command( command=commands[-1], strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, timeout_ops=timeout_ops, eager=False, ) responses.append(response) return responses async def send_commands_from_file( self, file: str, *, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, stop_on_failed: bool = False, eager: bool = False, timeout_ops: Optional[float] = None, ) -> MultiResponse: \"\"\" Send command(s) from file Args: file: string path to file strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER COMMAND sent, not for the total of the commands being sent! Returns: MultiResponse: Scrapli MultiResponse object Raises: N/A \"\"\" commands = self._pre_send_from_file(file=file, caller=\"send_commands_from_file\") return await self.send_commands( commands=commands, strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, stop_on_failed=stop_on_failed, eager=eager, timeout_ops=timeout_ops, ) @timeout_modifier async def send_and_read( self, channel_input: str, *, expected_outputs: Optional[List[str]] = None, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, timeout_ops: Optional[float] = None, read_duration: float = 2.5, ) -> Response: \"\"\" Send an input and read outputs. Unlike \"normal\" scrapli behavior this method reads until the prompt(normal) OR until any of a list of expected outputs is seen, OR until the read duration is exceeded. This method does not care about/understand privilege levels. This *can* cause you some potential issues if not used carefully! Args: channel_input: input to send to the channel; intentionally named \"channel_input\" instead of \"command\" or \"config\" due to this method not caring about privilege levels expected_outputs: List of outputs to look for in device response; returns as soon as any of the outputs are seen strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed read_duration: float duration to read for Returns: Response: Scrapli Response object Raises: ScrapliValueError: if _base_transport_args is None for some reason \"\"\" # decorator cares about timeout_ops, but nothing else does, assign to _ to appease linters _ = timeout_ops if not self._base_transport_args: # should not happen! :) raise ScrapliValueError(\"driver _base_transport_args not set for some reason\") response = self._pre_send_command( host=self._base_transport_args.host, command=channel_input, failed_when_contains=failed_when_contains, ) raw_response, processed_response = await self.channel.send_input_and_read( channel_input=channel_input, strip_prompt=strip_prompt, expected_outputs=expected_outputs, read_duration=read_duration, ) return self._post_send_command( raw_response=raw_response, processed_response=processed_response, response=response ) @timeout_modifier async def send_interactive( self, interact_events: Union[List[Tuple[str, str]], List[Tuple[str, str, bool]]], *, failed_when_contains: Optional[Union[str, List[str]]] = None, privilege_level: str = \"\", timeout_ops: Optional[float] = None, interaction_complete_patterns: Optional[List[str]] = None, ) -> Response: \"\"\" Interact with a device with changing prompts per input. Used to interact with devices where prompts change per input, and where inputs may be hidden such as in the case of a password input. This can be used to respond to challenges from devices such as the confirmation for the command \"clear logging\" on IOSXE devices for example. You may have as many elements in the \"interact_events\" list as needed, and each element of that list should be a tuple of two or three elements. The first element is always the input to send as a string, the second should be the expected response as a string, and the optional third a bool for whether or not the input is \"hidden\" (i.e. password input) An example where we need this sort of capability: 1 2 3 4 5 6 7 8 9 10 11 12 3560CX#copy flash: scp: Source filename []? test1.txt Address or name of remote host []? 172.31.254.100 Destination username [carl]? Writing test1.txt Password: Password: Sink: C0644 639 test1.txt ! 639 bytes copied in 12.066 secs (53 bytes/sec) 3560CX# To accomplish this we can use the following: 1 2 3 4 5 6 7 8 9 interact = conn.channel.send_inputs_interact( [ (\"copy flash: scp:\", \"Source filename []?\", False), (\"test1.txt\", \"Address or name of remote host []?\", False), (\"172.31.254.100\", \"Destination username [carl]?\", False), (\"carl\", \"Password:\", False), (\"super_secure_password\", prompt, True), ] ) If we needed to deal with more prompts we could simply continue adding tuples to the list of interact \"events\". Args: interact_events: list of tuples containing the \"interactions\" with the device each list element must have an input and an expected response, and may have an optional bool for the third and final element -- the optional bool specifies if the input that is sent to the device is \"hidden\" (ex: password), if the hidden param is not provided it is assumed the input is \"normal\" (not hidden) failed_when_contains: list of strings that, if present in final output, represent a failed command/interaction privilege_level: ignored in this base class; for LSP reasons for subclasses timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER COMMAND sent, not for the total of the commands being sent! interaction_complete_patterns: list of patterns, that if seen, indicate the interactive \"session\" has ended and we should exit the interactive session. Returns: Response: scrapli Response object Raises: ScrapliValueError: if _base_transport_args is None for some reason \"\"\" # decorator cares about timeout_ops, but nothing else does, assign to _ to appease linters _ = timeout_ops # privilege level only matters \"up\" in the network driver layer _ = privilege_level if not self._base_transport_args: # should not happen! :) raise ScrapliValueError(\"driver _base_transport_args not set for some reason\") response = self._pre_send_interactive( host=self._base_transport_args.host, interact_events=interact_events, failed_when_contains=failed_when_contains, ) raw_response, processed_response = await self.channel.send_inputs_interact( interact_events=interact_events, interaction_complete_patterns=interaction_complete_patterns, ) return self._post_send_command( raw_response=raw_response, processed_response=processed_response, response=response ) async def read_callback( # noqa: C901 self, callbacks: List[\"ReadCallback\"], initial_input: Optional[str] = None, read_output: bytes = b\"\", read_delay: float = 0.1, read_timeout: float = -1.0, ) -> \"ReadCallbackReturnable\": r\"\"\" Read from a channel and react to the output with some callback. This method is kind of like an \"advanced\" send_interactive -- the idea is simple: send some \"stuff\" to the channel (optionally), and then read from the channel. Based on the output do something. The callbacks is a list of `ReadCallback` which is an object containing the actual callback to execute, some info about when to trigger that callback (also when *not* to trigger that callback), as well as some attributes to control the next (if desired) iteration of read_callback. You could in theory do basically everything with this method by chaining callbacks forever, but you probably don't want to do that for real! Example usage: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 from scrapli.driver.core import IOSXEDriver from scrapli.driver.generic.base_driver import ReadCallback from scrapli.driver.generic.sync_driver import GenericDriver device = { \"host\": \"rtr1\", \"auth_strict_key\": False, \"ssh_config_file\": True, } def callback_one(cls: GenericDriver, read_output: str): cls.acquire_priv(\"configuration\") cls.channel.send_return() def callback_two(cls: GenericDriver, read_output: str): print(f\"previous read output : {read_output}\") r = cls.send_command(\"show run | i hostname\") print(f\"result: {r.result}\") with IOSXEDriver(**device) as conn: callbacks = [ ReadCallback( contains=\"rtr1#\", callback=callback_one, name=\"call1\", case_insensitive=False ), ReadCallback( contains_re=r\"^rtr1\\(config\\)#\", callback=callback_two, complete=True, ) ] conn.read_callback(callbacks=callbacks, initial_input=\"show run | i hostname\") Args: callbacks: a list of ReadCallback objects initial_input: optional string to send to \"kick off\" the read_callback method read_output: optional bytes to append any new reads to read_delay: sleep interval between reads read_timeout: value to set the `transport_timeout` to for the duration of the reading portion of this method. If left default (-1.0) or set to anything below 0, the transport timeout value will be left alone (whatever the timeout_transport value is) otherwise, the provided value will be temporarily set as the timeout_transport for duration of the reading. Returns: ReadCallbackReturnable: either None or call to read_callback again Raises: ScrapliTimeout: if the read operation times out (base don the read_timeout value) during the read callback check. \"\"\" if initial_input is not None: self.channel.write(channel_input=f\"{initial_input}{self.comms_return_char}\") return await self.read_callback(callbacks=callbacks, initial_input=None) original_transport_timeout = self.timeout_transport # if the read_timeout value is -1.0 or just less than 0, that indicates we should use # the \"normal\" transport timeout and not modify anything self.timeout_transport = read_timeout if read_timeout >= 0 else self.timeout_transport _read_delay = 0.1 if read_delay < = 0 else read_delay while True: try: read_output += await self.channel.read() except ScrapliTimeout as exc: self.timeout_transport = original_transport_timeout raise ScrapliTimeout(\"timeout during read in read_callback operation\") from exc for callback in callbacks: _run_callback = callback.check(read_output=read_output) if ( callback.only_once is True and callback._triggered is True # pylint: disable=W0212 ): self.logger.warning( f\"callback {callback.name} matches but is set to 'only_once', \" \"skipping this callback\" ) continue if _run_callback is True: self.logger.info(f\"callback {callback.name} matched, executing\") self.timeout_transport = original_transport_timeout coro = callback.run(driver=self) if coro is not None: # should always be a coroutine in this case, this appeases mypy await coro if callback.complete: self.logger.debug(\"callback complete is true, done with read_callback\") return None if callback.reset_output: read_output = b\"\" return await self.read_callback( callbacks=callbacks, initial_input=None, read_output=read_output, read_delay=callback.next_delay, read_timeout=callback.next_timeout, ) await asyncio.sleep(_read_delay) Ancestors (in MRO) \u00b6 scrapli.driver.base.async_driver.AsyncDriver scrapli.driver.base.base_driver.BaseDriver scrapli.driver.generic.base_driver.BaseGenericDriver Descendants \u00b6 scrapli.driver.network.async_driver.AsyncNetworkDriver Methods \u00b6 get_prompt \u00b6 get_prompt(self) \u2011> str 1 2 3 4 5 6 7 8 9 10 Convenience method to fetch prompt from the underlying Channel object Args: N/A Returns: str: string of the current prompt Raises: N/A read_callback \u00b6 read_callback(self, callbacks: List[ForwardRef('ReadCallback')], initial_input: Optional[str] = None, read_output: bytes = b'', read_delay: float = 0.1, read_timeout: float = -1.0) \u2011> ReadCallbackReturnable 1 2 3 4 5 6 7 8 9 10 11 Read from a channel and react to the output with some callback. This method is kind of like an \"advanced\" send_interactive -- the idea is simple: send some \"stuff\" to the channel (optionally), and then read from the channel. Based on the output do something. The callbacks is a list of `ReadCallback` which is an object containing the actual callback to execute, some info about when to trigger that callback (also when *not* to trigger that callback), as well as some attributes to control the next (if desired) iteration of read_callback. You could in theory do basically everything with this method by chaining callbacks forever, but you probably don't want to do that for real! Example usage: from scrapli.driver.core import IOSXEDriver from scrapli.driver.generic.base_driver import ReadCallback from scrapli.driver.generic.sync_driver import GenericDriver device = { \"host\": \"rtr1\", \"auth_strict_key\": False, \"ssh_config_file\": True, } def callback_one(cls: GenericDriver, read_output: str): cls.acquire_priv(\"configuration\") cls.channel.send_return() def callback_two(cls: GenericDriver, read_output: str): print(f\"previous read output : {read_output}\") r = cls . send_command ( \" show run | i hostname \" ) print ( f \" result: {r.result} \" ) with IOSXEDriver(**device) as conn: callbacks = [ ReadCallback( contains=\"rtr1#\", callback=callback_one, name=\"call1\", case_insensitive=False ), ReadCallback( contains_re=r\"^rtr1(config)#\", callback=callback_two, complete=True, ) ] conn.read_callback(callbacks=callbacks, initial_input=\"show run | i hostname\") 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 Args: callbacks: a list of ReadCallback objects initial_input: optional string to send to \"kick off\" the read_callback method read_output: optional bytes to append any new reads to read_delay: sleep interval between reads read_timeout: value to set the `transport_timeout` to for the duration of the reading portion of this method. If left default (-1.0) or set to anything below 0, the transport timeout value will be left alone (whatever the timeout_transport value is) otherwise, the provided value will be temporarily set as the timeout_transport for duration of the reading. Returns: ReadCallbackReturnable: either None or call to read_callback again Raises: ScrapliTimeout: if the read operation times out (base don the read_timeout value) during the read callback check. send_and_read \u00b6 send_and_read(self, channel_input: str, *, expected_outputs: Optional[List[str]] = None, strip_prompt: bool = True, failed_when_contains: Union[str, List[str], ForwardRef(None)] = None, timeout_ops: Optional[float] = None, read_duration: float = 2.5) \u2011> scrapli.response.Response 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 Send an input and read outputs. Unlike \"normal\" scrapli behavior this method reads until the prompt(normal) OR until any of a list of expected outputs is seen, OR until the read duration is exceeded. This method does not care about/understand privilege levels. This *can* cause you some potential issues if not used carefully! Args: channel_input: input to send to the channel; intentionally named \"channel_input\" instead of \"command\" or \"config\" due to this method not caring about privilege levels expected_outputs: List of outputs to look for in device response; returns as soon as any of the outputs are seen strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed read_duration: float duration to read for Returns: Response: Scrapli Response object Raises: ScrapliValueError: if _base_transport_args is None for some reason send_command \u00b6 send_command(self, command: str, *, strip_prompt: bool = True, failed_when_contains: Union[str, List[str], ForwardRef(None)] = None, timeout_ops: Optional[float] = None) \u2011> scrapli.response.Response 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 Send a command Args: command: string to send to device in privilege exec mode strip_prompt: strip prompt or not, defaults to True (yes, strip the prompt) failed_when_contains: string or list of strings indicating failure if found in response timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed Returns: Response: Scrapli Response object Raises: N/A send_commands \u00b6 send_commands(self, commands: List[str], *, strip_prompt: bool = True, failed_when_contains: Union[str, List[str], ForwardRef(None)] = None, stop_on_failed: bool = False, eager: bool = False, timeout_ops: Optional[float] = None) \u2011> scrapli.response.MultiResponse 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 Send multiple commands Args: commands: list of strings to send to device in privilege exec mode strip_prompt: strip prompt or not, defaults to True (yes, strip the prompt) failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER COMMAND sent, not for the total of the commands being sent! Returns: MultiResponse: Scrapli MultiResponse object Raises: N/A send_commands_from_file \u00b6 send_commands_from_file(self, file: str, *, strip_prompt: bool = True, failed_when_contains: Union[str, List[str], ForwardRef(None)] = None, stop_on_failed: bool = False, eager: bool = False, timeout_ops: Optional[float] = None) \u2011> scrapli.response.MultiResponse 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 Send command(s) from file Args: file: string path to file strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER COMMAND sent, not for the total of the commands being sent! Returns: MultiResponse: Scrapli MultiResponse object Raises: N/A send_interactive \u00b6 send_interactive(self, interact_events: Union[List[Tuple[str, str]], List[Tuple[str, str, bool]]], *, failed_when_contains: Union[str, List[str], ForwardRef(None)] = None, privilege_level: str = '', timeout_ops: Optional[float] = None, interaction_complete_patterns: Optional[List[str]] = None) \u2011> scrapli.response.Response 1 2 3 4 5 6 7 8 9 10 11 Interact with a device with changing prompts per input. Used to interact with devices where prompts change per input, and where inputs may be hidden such as in the case of a password input. This can be used to respond to challenges from devices such as the confirmation for the command \"clear logging\" on IOSXE devices for example. You may have as many elements in the \"interact_events\" list as needed, and each element of that list should be a tuple of two or three elements. The first element is always the input to send as a string, the second should be the expected response as a string, and the optional third a bool for whether or not the input is \"hidden\" (i.e. password input) An example where we need this sort of capability: 3560CX#copy flash: scp: Source filename []? test1.txt Address or name of remote host []? 172.31.254.100 Destination username [carl]? Writing test1.txt Password: Password: Sink: C0644 639 test1.txt ! 639 bytes copied in 12.066 secs (53 bytes/sec) 3560CX# 1 To accomplish this we can use the following: interact = conn.channel.send_inputs_interact( [ (\"copy flash: scp:\", \"Source filename []?\", False), (\"test1.txt\", \"Address or name of remote host []?\", False), (\"172.31.254.100\", \"Destination username [carl]?\", False), (\"carl\", \"Password:\", False), (\"super_secure_password\", prompt, True), ] ) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 If we needed to deal with more prompts we could simply continue adding tuples to the list of interact \"events\". Args: interact_events: list of tuples containing the \"interactions\" with the device each list element must have an input and an expected response, and may have an optional bool for the third and final element -- the optional bool specifies if the input that is sent to the device is \"hidden\" (ex: password), if the hidden param is not provided it is assumed the input is \"normal\" (not hidden) failed_when_contains: list of strings that, if present in final output, represent a failed command/interaction privilege_level: ignored in this base class; for LSP reasons for subclasses timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER COMMAND sent, not for the total of the commands being sent! interaction_complete_patterns: list of patterns, that if seen, indicate the interactive \"session\" has ended and we should exit the interactive session. Returns: Response: scrapli Response object Raises: ScrapliValueError: if _base_transport_args is None for some reason","title":"Async Driver"},{"location":"api_docs/driver/generic/async_driver/#module-scraplidrivergenericasync_driver","text":"scrapli.driver.generic.async_driver Expand source code \"\"\"scrapli.driver.generic.async_driver\"\"\" import asyncio from io import BytesIO from typing import TYPE_CHECKING, Any, Callable, Dict, List, Optional, Tuple, Union from scrapli.decorators import timeout_modifier from scrapli.driver import AsyncDriver from scrapli.driver.generic.base_driver import BaseGenericDriver from scrapli.exceptions import ScrapliTimeout, ScrapliValueError from scrapli.response import MultiResponse, Response if TYPE_CHECKING: from scrapli.driver.generic.base_driver import ( # pragma: no cover ReadCallback, ReadCallbackReturnable, ) class AsyncGenericDriver(AsyncDriver, BaseGenericDriver): def __init__( self, host: str, port: Optional[int] = None, auth_username: str = \"\", auth_password: str = \"\", auth_private_key: str = \"\", auth_private_key_passphrase: str = \"\", auth_strict_key: bool = True, auth_bypass: bool = False, timeout_socket: float = 15.0, timeout_transport: float = 30.0, timeout_ops: float = 30.0, comms_prompt_pattern: str = r\"^\\S{0,48}[#>$~@:\\]]\\s*$\", comms_return_char: str = \"\\n\", ssh_config_file: Union[str, bool] = False, ssh_known_hosts_file: Union[str, bool] = False, on_init: Optional[Callable[..., Any]] = None, on_open: Optional[Callable[..., Any]] = None, on_close: Optional[Callable[..., Any]] = None, transport: str = \"system\", transport_options: Optional[Dict[str, Any]] = None, channel_log: Union[str, bool, BytesIO] = False, channel_log_mode: str = \"write\", channel_lock: bool = False, logging_uid: str = \"\", ) -> None: super().__init__( host=host, port=port, auth_username=auth_username, auth_password=auth_password, auth_private_key=auth_private_key, auth_private_key_passphrase=auth_private_key_passphrase, auth_strict_key=auth_strict_key, auth_bypass=auth_bypass, timeout_socket=timeout_socket, timeout_transport=timeout_transport, timeout_ops=timeout_ops, comms_prompt_pattern=comms_prompt_pattern, comms_return_char=comms_return_char, ssh_config_file=ssh_config_file, ssh_known_hosts_file=ssh_known_hosts_file, on_init=on_init, on_open=on_open, on_close=on_close, transport=transport, transport_options=transport_options, channel_log=channel_log, channel_log_mode=channel_log_mode, channel_lock=channel_lock, logging_uid=logging_uid, ) async def get_prompt(self) -> str: \"\"\" Convenience method to fetch prompt from the underlying Channel object Args: N/A Returns: str: string of the current prompt Raises: N/A \"\"\" prompt: str = await self.channel.get_prompt() return prompt @timeout_modifier async def _send_command( self, command: str, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, eager: bool = False, timeout_ops: Optional[float] = None, ) -> Response: \"\"\" Send a command Private method so that we can handle `eager` w/out having to have that argument showing up in all the methods that super to the \"normal\" send_command method as we only ever want eager to be used for the plural options -- i.e. send_commands not send_command! Args: command: string to send to device in privilege exec mode strip_prompt: strip prompt or not, defaults to True (yes, strip the prompt) failed_when_contains: string or list of strings indicating failure if found in response eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed Returns: Response: Scrapli Response object Raises: ScrapliValueError: if _base_transport_args is None for some reason \"\"\" # decorator cares about timeout_ops, but nothing else does, assign to _ to appease linters _ = timeout_ops if not self._base_transport_args: # should not happen! :) raise ScrapliValueError(\"driver _base_transport_args not set for some reason\") response = self._pre_send_command( host=self._base_transport_args.host, command=command, failed_when_contains=failed_when_contains, ) raw_response, processed_response = await self.channel.send_input( channel_input=command, strip_prompt=strip_prompt, eager=eager ) return self._post_send_command( raw_response=raw_response, processed_response=processed_response, response=response ) async def send_command( self, command: str, *, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, timeout_ops: Optional[float] = None, ) -> Response: \"\"\" Send a command Args: command: string to send to device in privilege exec mode strip_prompt: strip prompt or not, defaults to True (yes, strip the prompt) failed_when_contains: string or list of strings indicating failure if found in response timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed Returns: Response: Scrapli Response object Raises: N/A \"\"\" response: Response = await self._send_command( command=command, strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, timeout_ops=timeout_ops, ) return response async def send_commands( self, commands: List[str], *, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, stop_on_failed: bool = False, eager: bool = False, timeout_ops: Optional[float] = None, ) -> MultiResponse: \"\"\" Send multiple commands Args: commands: list of strings to send to device in privilege exec mode strip_prompt: strip prompt or not, defaults to True (yes, strip the prompt) failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER COMMAND sent, not for the total of the commands being sent! Returns: MultiResponse: Scrapli MultiResponse object Raises: N/A \"\"\" responses = self._pre_send_commands(commands=commands) for command in commands[:-1]: response = await self._send_command( command=command, strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, timeout_ops=timeout_ops, eager=eager, ) responses.append(response) if stop_on_failed and response.failed is True: # should we find the prompt here w/ get_prompt?? or just let subsequent operations # deal w/ finding that? future us problem? :) break else: # if we did *not* break (i.e. no failure and/or no stop_on_failed) send the last command # with eager = False -- this way we *always* find the prompt at the end of the commands response = await self._send_command( command=commands[-1], strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, timeout_ops=timeout_ops, eager=False, ) responses.append(response) return responses async def send_commands_from_file( self, file: str, *, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, stop_on_failed: bool = False, eager: bool = False, timeout_ops: Optional[float] = None, ) -> MultiResponse: \"\"\" Send command(s) from file Args: file: string path to file strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER COMMAND sent, not for the total of the commands being sent! Returns: MultiResponse: Scrapli MultiResponse object Raises: N/A \"\"\" commands = self._pre_send_from_file(file=file, caller=\"send_commands_from_file\") return await self.send_commands( commands=commands, strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, stop_on_failed=stop_on_failed, eager=eager, timeout_ops=timeout_ops, ) @timeout_modifier async def send_and_read( self, channel_input: str, *, expected_outputs: Optional[List[str]] = None, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, timeout_ops: Optional[float] = None, read_duration: float = 2.5, ) -> Response: \"\"\" Send an input and read outputs. Unlike \"normal\" scrapli behavior this method reads until the prompt(normal) OR until any of a list of expected outputs is seen, OR until the read duration is exceeded. This method does not care about/understand privilege levels. This *can* cause you some potential issues if not used carefully! Args: channel_input: input to send to the channel; intentionally named \"channel_input\" instead of \"command\" or \"config\" due to this method not caring about privilege levels expected_outputs: List of outputs to look for in device response; returns as soon as any of the outputs are seen strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed read_duration: float duration to read for Returns: Response: Scrapli Response object Raises: ScrapliValueError: if _base_transport_args is None for some reason \"\"\" # decorator cares about timeout_ops, but nothing else does, assign to _ to appease linters _ = timeout_ops if not self._base_transport_args: # should not happen! :) raise ScrapliValueError(\"driver _base_transport_args not set for some reason\") response = self._pre_send_command( host=self._base_transport_args.host, command=channel_input, failed_when_contains=failed_when_contains, ) raw_response, processed_response = await self.channel.send_input_and_read( channel_input=channel_input, strip_prompt=strip_prompt, expected_outputs=expected_outputs, read_duration=read_duration, ) return self._post_send_command( raw_response=raw_response, processed_response=processed_response, response=response ) @timeout_modifier async def send_interactive( self, interact_events: Union[List[Tuple[str, str]], List[Tuple[str, str, bool]]], *, failed_when_contains: Optional[Union[str, List[str]]] = None, privilege_level: str = \"\", timeout_ops: Optional[float] = None, interaction_complete_patterns: Optional[List[str]] = None, ) -> Response: \"\"\" Interact with a device with changing prompts per input. Used to interact with devices where prompts change per input, and where inputs may be hidden such as in the case of a password input. This can be used to respond to challenges from devices such as the confirmation for the command \"clear logging\" on IOSXE devices for example. You may have as many elements in the \"interact_events\" list as needed, and each element of that list should be a tuple of two or three elements. The first element is always the input to send as a string, the second should be the expected response as a string, and the optional third a bool for whether or not the input is \"hidden\" (i.e. password input) An example where we need this sort of capability: 1 2 3 4 5 6 7 8 9 10 11 12 3560CX#copy flash: scp: Source filename []? test1.txt Address or name of remote host []? 172.31.254.100 Destination username [carl]? Writing test1.txt Password: Password: Sink: C0644 639 test1.txt ! 639 bytes copied in 12.066 secs (53 bytes/sec) 3560CX# To accomplish this we can use the following: 1 2 3 4 5 6 7 8 9 interact = conn.channel.send_inputs_interact( [ (\"copy flash: scp:\", \"Source filename []?\", False), (\"test1.txt\", \"Address or name of remote host []?\", False), (\"172.31.254.100\", \"Destination username [carl]?\", False), (\"carl\", \"Password:\", False), (\"super_secure_password\", prompt, True), ] ) If we needed to deal with more prompts we could simply continue adding tuples to the list of interact \"events\". Args: interact_events: list of tuples containing the \"interactions\" with the device each list element must have an input and an expected response, and may have an optional bool for the third and final element -- the optional bool specifies if the input that is sent to the device is \"hidden\" (ex: password), if the hidden param is not provided it is assumed the input is \"normal\" (not hidden) failed_when_contains: list of strings that, if present in final output, represent a failed command/interaction privilege_level: ignored in this base class; for LSP reasons for subclasses timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER COMMAND sent, not for the total of the commands being sent! interaction_complete_patterns: list of patterns, that if seen, indicate the interactive \"session\" has ended and we should exit the interactive session. Returns: Response: scrapli Response object Raises: ScrapliValueError: if _base_transport_args is None for some reason \"\"\" # decorator cares about timeout_ops, but nothing else does, assign to _ to appease linters _ = timeout_ops # privilege level only matters \"up\" in the network driver layer _ = privilege_level if not self._base_transport_args: # should not happen! :) raise ScrapliValueError(\"driver _base_transport_args not set for some reason\") response = self._pre_send_interactive( host=self._base_transport_args.host, interact_events=interact_events, failed_when_contains=failed_when_contains, ) raw_response, processed_response = await self.channel.send_inputs_interact( interact_events=interact_events, interaction_complete_patterns=interaction_complete_patterns, ) return self._post_send_command( raw_response=raw_response, processed_response=processed_response, response=response ) async def read_callback( # noqa: C901 self, callbacks: List[\"ReadCallback\"], initial_input: Optional[str] = None, read_output: bytes = b\"\", read_delay: float = 0.1, read_timeout: float = -1.0, ) -> \"ReadCallbackReturnable\": r\"\"\" Read from a channel and react to the output with some callback. This method is kind of like an \"advanced\" send_interactive -- the idea is simple: send some \"stuff\" to the channel (optionally), and then read from the channel. Based on the output do something. The callbacks is a list of `ReadCallback` which is an object containing the actual callback to execute, some info about when to trigger that callback (also when *not* to trigger that callback), as well as some attributes to control the next (if desired) iteration of read_callback. You could in theory do basically everything with this method by chaining callbacks forever, but you probably don't want to do that for real! Example usage: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 from scrapli.driver.core import IOSXEDriver from scrapli.driver.generic.base_driver import ReadCallback from scrapli.driver.generic.sync_driver import GenericDriver device = { \"host\": \"rtr1\", \"auth_strict_key\": False, \"ssh_config_file\": True, } def callback_one(cls: GenericDriver, read_output: str): cls.acquire_priv(\"configuration\") cls.channel.send_return() def callback_two(cls: GenericDriver, read_output: str): print(f\"previous read output : {read_output}\") r = cls.send_command(\"show run | i hostname\") print(f\"result: {r.result}\") with IOSXEDriver(**device) as conn: callbacks = [ ReadCallback( contains=\"rtr1#\", callback=callback_one, name=\"call1\", case_insensitive=False ), ReadCallback( contains_re=r\"^rtr1\\(config\\)#\", callback=callback_two, complete=True, ) ] conn.read_callback(callbacks=callbacks, initial_input=\"show run | i hostname\") Args: callbacks: a list of ReadCallback objects initial_input: optional string to send to \"kick off\" the read_callback method read_output: optional bytes to append any new reads to read_delay: sleep interval between reads read_timeout: value to set the `transport_timeout` to for the duration of the reading portion of this method. If left default (-1.0) or set to anything below 0, the transport timeout value will be left alone (whatever the timeout_transport value is) otherwise, the provided value will be temporarily set as the timeout_transport for duration of the reading. Returns: ReadCallbackReturnable: either None or call to read_callback again Raises: ScrapliTimeout: if the read operation times out (base don the read_timeout value) during the read callback check. \"\"\" if initial_input is not None: self.channel.write(channel_input=f\"{initial_input}{self.comms_return_char}\") return await self.read_callback(callbacks=callbacks, initial_input=None) original_transport_timeout = self.timeout_transport # if the read_timeout value is -1.0 or just less than 0, that indicates we should use # the \"normal\" transport timeout and not modify anything self.timeout_transport = read_timeout if read_timeout >= 0 else self.timeout_transport _read_delay = 0.1 if read_delay < = 0 else read_delay while True: try: read_output += await self.channel.read() except ScrapliTimeout as exc: self.timeout_transport = original_transport_timeout raise ScrapliTimeout(\"timeout during read in read_callback operation\") from exc for callback in callbacks: _run_callback = callback.check(read_output=read_output) if ( callback.only_once is True and callback._triggered is True # pylint: disable=W0212 ): self.logger.warning( f\"callback {callback.name} matches but is set to 'only_once', \" \"skipping this callback\" ) continue if _run_callback is True: self.logger.info(f\"callback {callback.name} matched, executing\") self.timeout_transport = original_transport_timeout coro = callback.run(driver=self) if coro is not None: # should always be a coroutine in this case, this appeases mypy await coro if callback.complete: self.logger.debug(\"callback complete is true, done with read_callback\") return None if callback.reset_output: read_output = b\"\" return await self.read_callback( callbacks=callbacks, initial_input=None, read_output=read_output, read_delay=callback.next_delay, read_timeout=callback.next_timeout, ) await asyncio.sleep(_read_delay)","title":"Module scrapli.driver.generic.async_driver"},{"location":"api_docs/driver/generic/async_driver/#classes","text":"","title":"Classes"},{"location":"api_docs/driver/generic/async_driver/#asyncgenericdriver","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 BaseDriver Object BaseDriver is the root for all Scrapli driver classes. The synchronous and asyncio driver base driver classes can be used to provide a semi-pexpect like experience over top of whatever transport a user prefers. Generally, however, the base driver classes should not be used directly. It is best to use the GenericDriver (or AsyncGenericDriver) or NetworkDriver (or AsyncNetworkDriver) sub-classes of the base drivers. Args: host: host ip/name to connect to port: port to connect to auth_username: username for authentication auth_private_key: path to private key for authentication auth_private_key_passphrase: passphrase for decrypting ssh key if necessary auth_password: password for authentication auth_strict_key: strict host checking or not auth_bypass: bypass \"in channel\" authentication -- only supported with telnet, asynctelnet, and system transport plugins timeout_socket: timeout for establishing socket/initial connection in seconds timeout_transport: timeout for ssh|telnet transport in seconds timeout_ops: timeout for ssh channel operations comms_prompt_pattern: raw string regex pattern -- preferably use `^` and `$` anchors! this is the single most important attribute here! if this does not match a prompt, scrapli will not work! IMPORTANT: regex search uses multi-line + case insensitive flags. multi-line allows for highly reliably matching for prompts however we do NOT strip trailing whitespace for each line, so be sure to add '\\\\s?' or similar if your device needs that. This should be mostly sorted for you if using network drivers (i.e. `IOSXEDriver`). Lastly, the case insensitive is just a convenience factor so i can be lazy. comms_return_char: character to use to send returns to host ssh_config_file: string to path for ssh config file, True to use default ssh config file or False to ignore default ssh config file ssh_known_hosts_file: string to path for ssh known hosts file, True to use default known file locations. Only applicable/needed if `auth_strict_key` is set to True on_init: callable that accepts the class instance as its only argument. this callable, if provided, is executed as the last step of object instantiation -- its purpose is primarily to provide a mechanism for scrapli community platforms to have an easy way to modify initialization arguments/object attributes without needing to create a class that extends the driver, instead allowing the community platforms to simply build from the GenericDriver or NetworkDriver classes, and pass this callable to do things such as appending to a username (looking at you RouterOS!!). Note that this is *always* a synchronous function (even for asyncio drivers)! on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar transport: name of the transport plugin to use for the actual telnet/ssh/netconf connection. Available \"core\" transports are: - system - telnet - asynctelnet - ssh2 - paramiko - asyncssh Please see relevant transport plugin section for details. Additionally third party transport plugins may be available. transport_options: dictionary of options to pass to selected transport class; see docs for given transport class for details of what to pass here channel_lock: True/False to lock the channel (threading.Lock/asyncio.Lock) during any channel operations, defaults to False channel_log: True/False or a string path to a file of where to write out channel logs -- these are not \"logs\" in the normal logging module sense, but only the output that is read from the channel. In other words, the output of the channel log should look similar to what you would see as a human connecting to a device channel_log_mode: \"write\"|\"append\", all other values will raise ValueError, does what it sounds like it should by setting the channel log to the provided mode logging_uid: unique identifier (string) to associate to log messages; useful if you have multiple connections to the same device (i.e. one console, one ssh, or one to each supervisor module, etc.) Returns: None Raises: N/A Expand source code class AsyncGenericDriver(AsyncDriver, BaseGenericDriver): def __init__( self, host: str, port: Optional[int] = None, auth_username: str = \"\", auth_password: str = \"\", auth_private_key: str = \"\", auth_private_key_passphrase: str = \"\", auth_strict_key: bool = True, auth_bypass: bool = False, timeout_socket: float = 15.0, timeout_transport: float = 30.0, timeout_ops: float = 30.0, comms_prompt_pattern: str = r\"^\\S{0,48}[#>$~@:\\]]\\s*$\", comms_return_char: str = \"\\n\", ssh_config_file: Union[str, bool] = False, ssh_known_hosts_file: Union[str, bool] = False, on_init: Optional[Callable[..., Any]] = None, on_open: Optional[Callable[..., Any]] = None, on_close: Optional[Callable[..., Any]] = None, transport: str = \"system\", transport_options: Optional[Dict[str, Any]] = None, channel_log: Union[str, bool, BytesIO] = False, channel_log_mode: str = \"write\", channel_lock: bool = False, logging_uid: str = \"\", ) -> None: super().__init__( host=host, port=port, auth_username=auth_username, auth_password=auth_password, auth_private_key=auth_private_key, auth_private_key_passphrase=auth_private_key_passphrase, auth_strict_key=auth_strict_key, auth_bypass=auth_bypass, timeout_socket=timeout_socket, timeout_transport=timeout_transport, timeout_ops=timeout_ops, comms_prompt_pattern=comms_prompt_pattern, comms_return_char=comms_return_char, ssh_config_file=ssh_config_file, ssh_known_hosts_file=ssh_known_hosts_file, on_init=on_init, on_open=on_open, on_close=on_close, transport=transport, transport_options=transport_options, channel_log=channel_log, channel_log_mode=channel_log_mode, channel_lock=channel_lock, logging_uid=logging_uid, ) async def get_prompt(self) -> str: \"\"\" Convenience method to fetch prompt from the underlying Channel object Args: N/A Returns: str: string of the current prompt Raises: N/A \"\"\" prompt: str = await self.channel.get_prompt() return prompt @timeout_modifier async def _send_command( self, command: str, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, eager: bool = False, timeout_ops: Optional[float] = None, ) -> Response: \"\"\" Send a command Private method so that we can handle `eager` w/out having to have that argument showing up in all the methods that super to the \"normal\" send_command method as we only ever want eager to be used for the plural options -- i.e. send_commands not send_command! Args: command: string to send to device in privilege exec mode strip_prompt: strip prompt or not, defaults to True (yes, strip the prompt) failed_when_contains: string or list of strings indicating failure if found in response eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed Returns: Response: Scrapli Response object Raises: ScrapliValueError: if _base_transport_args is None for some reason \"\"\" # decorator cares about timeout_ops, but nothing else does, assign to _ to appease linters _ = timeout_ops if not self._base_transport_args: # should not happen! :) raise ScrapliValueError(\"driver _base_transport_args not set for some reason\") response = self._pre_send_command( host=self._base_transport_args.host, command=command, failed_when_contains=failed_when_contains, ) raw_response, processed_response = await self.channel.send_input( channel_input=command, strip_prompt=strip_prompt, eager=eager ) return self._post_send_command( raw_response=raw_response, processed_response=processed_response, response=response ) async def send_command( self, command: str, *, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, timeout_ops: Optional[float] = None, ) -> Response: \"\"\" Send a command Args: command: string to send to device in privilege exec mode strip_prompt: strip prompt or not, defaults to True (yes, strip the prompt) failed_when_contains: string or list of strings indicating failure if found in response timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed Returns: Response: Scrapli Response object Raises: N/A \"\"\" response: Response = await self._send_command( command=command, strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, timeout_ops=timeout_ops, ) return response async def send_commands( self, commands: List[str], *, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, stop_on_failed: bool = False, eager: bool = False, timeout_ops: Optional[float] = None, ) -> MultiResponse: \"\"\" Send multiple commands Args: commands: list of strings to send to device in privilege exec mode strip_prompt: strip prompt or not, defaults to True (yes, strip the prompt) failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER COMMAND sent, not for the total of the commands being sent! Returns: MultiResponse: Scrapli MultiResponse object Raises: N/A \"\"\" responses = self._pre_send_commands(commands=commands) for command in commands[:-1]: response = await self._send_command( command=command, strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, timeout_ops=timeout_ops, eager=eager, ) responses.append(response) if stop_on_failed and response.failed is True: # should we find the prompt here w/ get_prompt?? or just let subsequent operations # deal w/ finding that? future us problem? :) break else: # if we did *not* break (i.e. no failure and/or no stop_on_failed) send the last command # with eager = False -- this way we *always* find the prompt at the end of the commands response = await self._send_command( command=commands[-1], strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, timeout_ops=timeout_ops, eager=False, ) responses.append(response) return responses async def send_commands_from_file( self, file: str, *, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, stop_on_failed: bool = False, eager: bool = False, timeout_ops: Optional[float] = None, ) -> MultiResponse: \"\"\" Send command(s) from file Args: file: string path to file strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER COMMAND sent, not for the total of the commands being sent! Returns: MultiResponse: Scrapli MultiResponse object Raises: N/A \"\"\" commands = self._pre_send_from_file(file=file, caller=\"send_commands_from_file\") return await self.send_commands( commands=commands, strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, stop_on_failed=stop_on_failed, eager=eager, timeout_ops=timeout_ops, ) @timeout_modifier async def send_and_read( self, channel_input: str, *, expected_outputs: Optional[List[str]] = None, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, timeout_ops: Optional[float] = None, read_duration: float = 2.5, ) -> Response: \"\"\" Send an input and read outputs. Unlike \"normal\" scrapli behavior this method reads until the prompt(normal) OR until any of a list of expected outputs is seen, OR until the read duration is exceeded. This method does not care about/understand privilege levels. This *can* cause you some potential issues if not used carefully! Args: channel_input: input to send to the channel; intentionally named \"channel_input\" instead of \"command\" or \"config\" due to this method not caring about privilege levels expected_outputs: List of outputs to look for in device response; returns as soon as any of the outputs are seen strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed read_duration: float duration to read for Returns: Response: Scrapli Response object Raises: ScrapliValueError: if _base_transport_args is None for some reason \"\"\" # decorator cares about timeout_ops, but nothing else does, assign to _ to appease linters _ = timeout_ops if not self._base_transport_args: # should not happen! :) raise ScrapliValueError(\"driver _base_transport_args not set for some reason\") response = self._pre_send_command( host=self._base_transport_args.host, command=channel_input, failed_when_contains=failed_when_contains, ) raw_response, processed_response = await self.channel.send_input_and_read( channel_input=channel_input, strip_prompt=strip_prompt, expected_outputs=expected_outputs, read_duration=read_duration, ) return self._post_send_command( raw_response=raw_response, processed_response=processed_response, response=response ) @timeout_modifier async def send_interactive( self, interact_events: Union[List[Tuple[str, str]], List[Tuple[str, str, bool]]], *, failed_when_contains: Optional[Union[str, List[str]]] = None, privilege_level: str = \"\", timeout_ops: Optional[float] = None, interaction_complete_patterns: Optional[List[str]] = None, ) -> Response: \"\"\" Interact with a device with changing prompts per input. Used to interact with devices where prompts change per input, and where inputs may be hidden such as in the case of a password input. This can be used to respond to challenges from devices such as the confirmation for the command \"clear logging\" on IOSXE devices for example. You may have as many elements in the \"interact_events\" list as needed, and each element of that list should be a tuple of two or three elements. The first element is always the input to send as a string, the second should be the expected response as a string, and the optional third a bool for whether or not the input is \"hidden\" (i.e. password input) An example where we need this sort of capability: 1 2 3 4 5 6 7 8 9 10 11 12 3560CX#copy flash: scp: Source filename []? test1.txt Address or name of remote host []? 172.31.254.100 Destination username [carl]? Writing test1.txt Password: Password: Sink: C0644 639 test1.txt ! 639 bytes copied in 12.066 secs (53 bytes/sec) 3560CX# To accomplish this we can use the following: 1 2 3 4 5 6 7 8 9 interact = conn.channel.send_inputs_interact( [ (\"copy flash: scp:\", \"Source filename []?\", False), (\"test1.txt\", \"Address or name of remote host []?\", False), (\"172.31.254.100\", \"Destination username [carl]?\", False), (\"carl\", \"Password:\", False), (\"super_secure_password\", prompt, True), ] ) If we needed to deal with more prompts we could simply continue adding tuples to the list of interact \"events\". Args: interact_events: list of tuples containing the \"interactions\" with the device each list element must have an input and an expected response, and may have an optional bool for the third and final element -- the optional bool specifies if the input that is sent to the device is \"hidden\" (ex: password), if the hidden param is not provided it is assumed the input is \"normal\" (not hidden) failed_when_contains: list of strings that, if present in final output, represent a failed command/interaction privilege_level: ignored in this base class; for LSP reasons for subclasses timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER COMMAND sent, not for the total of the commands being sent! interaction_complete_patterns: list of patterns, that if seen, indicate the interactive \"session\" has ended and we should exit the interactive session. Returns: Response: scrapli Response object Raises: ScrapliValueError: if _base_transport_args is None for some reason \"\"\" # decorator cares about timeout_ops, but nothing else does, assign to _ to appease linters _ = timeout_ops # privilege level only matters \"up\" in the network driver layer _ = privilege_level if not self._base_transport_args: # should not happen! :) raise ScrapliValueError(\"driver _base_transport_args not set for some reason\") response = self._pre_send_interactive( host=self._base_transport_args.host, interact_events=interact_events, failed_when_contains=failed_when_contains, ) raw_response, processed_response = await self.channel.send_inputs_interact( interact_events=interact_events, interaction_complete_patterns=interaction_complete_patterns, ) return self._post_send_command( raw_response=raw_response, processed_response=processed_response, response=response ) async def read_callback( # noqa: C901 self, callbacks: List[\"ReadCallback\"], initial_input: Optional[str] = None, read_output: bytes = b\"\", read_delay: float = 0.1, read_timeout: float = -1.0, ) -> \"ReadCallbackReturnable\": r\"\"\" Read from a channel and react to the output with some callback. This method is kind of like an \"advanced\" send_interactive -- the idea is simple: send some \"stuff\" to the channel (optionally), and then read from the channel. Based on the output do something. The callbacks is a list of `ReadCallback` which is an object containing the actual callback to execute, some info about when to trigger that callback (also when *not* to trigger that callback), as well as some attributes to control the next (if desired) iteration of read_callback. You could in theory do basically everything with this method by chaining callbacks forever, but you probably don't want to do that for real! Example usage: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 from scrapli.driver.core import IOSXEDriver from scrapli.driver.generic.base_driver import ReadCallback from scrapli.driver.generic.sync_driver import GenericDriver device = { \"host\": \"rtr1\", \"auth_strict_key\": False, \"ssh_config_file\": True, } def callback_one(cls: GenericDriver, read_output: str): cls.acquire_priv(\"configuration\") cls.channel.send_return() def callback_two(cls: GenericDriver, read_output: str): print(f\"previous read output : {read_output}\") r = cls.send_command(\"show run | i hostname\") print(f\"result: {r.result}\") with IOSXEDriver(**device) as conn: callbacks = [ ReadCallback( contains=\"rtr1#\", callback=callback_one, name=\"call1\", case_insensitive=False ), ReadCallback( contains_re=r\"^rtr1\\(config\\)#\", callback=callback_two, complete=True, ) ] conn.read_callback(callbacks=callbacks, initial_input=\"show run | i hostname\") Args: callbacks: a list of ReadCallback objects initial_input: optional string to send to \"kick off\" the read_callback method read_output: optional bytes to append any new reads to read_delay: sleep interval between reads read_timeout: value to set the `transport_timeout` to for the duration of the reading portion of this method. If left default (-1.0) or set to anything below 0, the transport timeout value will be left alone (whatever the timeout_transport value is) otherwise, the provided value will be temporarily set as the timeout_transport for duration of the reading. Returns: ReadCallbackReturnable: either None or call to read_callback again Raises: ScrapliTimeout: if the read operation times out (base don the read_timeout value) during the read callback check. \"\"\" if initial_input is not None: self.channel.write(channel_input=f\"{initial_input}{self.comms_return_char}\") return await self.read_callback(callbacks=callbacks, initial_input=None) original_transport_timeout = self.timeout_transport # if the read_timeout value is -1.0 or just less than 0, that indicates we should use # the \"normal\" transport timeout and not modify anything self.timeout_transport = read_timeout if read_timeout >= 0 else self.timeout_transport _read_delay = 0.1 if read_delay < = 0 else read_delay while True: try: read_output += await self.channel.read() except ScrapliTimeout as exc: self.timeout_transport = original_transport_timeout raise ScrapliTimeout(\"timeout during read in read_callback operation\") from exc for callback in callbacks: _run_callback = callback.check(read_output=read_output) if ( callback.only_once is True and callback._triggered is True # pylint: disable=W0212 ): self.logger.warning( f\"callback {callback.name} matches but is set to 'only_once', \" \"skipping this callback\" ) continue if _run_callback is True: self.logger.info(f\"callback {callback.name} matched, executing\") self.timeout_transport = original_transport_timeout coro = callback.run(driver=self) if coro is not None: # should always be a coroutine in this case, this appeases mypy await coro if callback.complete: self.logger.debug(\"callback complete is true, done with read_callback\") return None if callback.reset_output: read_output = b\"\" return await self.read_callback( callbacks=callbacks, initial_input=None, read_output=read_output, read_delay=callback.next_delay, read_timeout=callback.next_timeout, ) await asyncio.sleep(_read_delay)","title":"AsyncGenericDriver"},{"location":"api_docs/driver/generic/async_driver/#ancestors-in-mro","text":"scrapli.driver.base.async_driver.AsyncDriver scrapli.driver.base.base_driver.BaseDriver scrapli.driver.generic.base_driver.BaseGenericDriver","title":"Ancestors (in MRO)"},{"location":"api_docs/driver/generic/async_driver/#descendants","text":"scrapli.driver.network.async_driver.AsyncNetworkDriver","title":"Descendants"},{"location":"api_docs/driver/generic/async_driver/#methods","text":"","title":"Methods"},{"location":"api_docs/driver/generic/async_driver/#get_prompt","text":"get_prompt(self) \u2011> str 1 2 3 4 5 6 7 8 9 10 Convenience method to fetch prompt from the underlying Channel object Args: N/A Returns: str: string of the current prompt Raises: N/A","title":"get_prompt"},{"location":"api_docs/driver/generic/async_driver/#read_callback","text":"read_callback(self, callbacks: List[ForwardRef('ReadCallback')], initial_input: Optional[str] = None, read_output: bytes = b'', read_delay: float = 0.1, read_timeout: float = -1.0) \u2011> ReadCallbackReturnable 1 2 3 4 5 6 7 8 9 10 11 Read from a channel and react to the output with some callback. This method is kind of like an \"advanced\" send_interactive -- the idea is simple: send some \"stuff\" to the channel (optionally), and then read from the channel. Based on the output do something. The callbacks is a list of `ReadCallback` which is an object containing the actual callback to execute, some info about when to trigger that callback (also when *not* to trigger that callback), as well as some attributes to control the next (if desired) iteration of read_callback. You could in theory do basically everything with this method by chaining callbacks forever, but you probably don't want to do that for real! Example usage: from scrapli.driver.core import IOSXEDriver from scrapli.driver.generic.base_driver import ReadCallback from scrapli.driver.generic.sync_driver import GenericDriver device = { \"host\": \"rtr1\", \"auth_strict_key\": False, \"ssh_config_file\": True, } def callback_one(cls: GenericDriver, read_output: str): cls.acquire_priv(\"configuration\") cls.channel.send_return() def callback_two(cls: GenericDriver, read_output: str): print(f\"previous read output : {read_output}\") r = cls . send_command ( \" show run | i hostname \" ) print ( f \" result: {r.result} \" ) with IOSXEDriver(**device) as conn: callbacks = [ ReadCallback( contains=\"rtr1#\", callback=callback_one, name=\"call1\", case_insensitive=False ), ReadCallback( contains_re=r\"^rtr1(config)#\", callback=callback_two, complete=True, ) ] conn.read_callback(callbacks=callbacks, initial_input=\"show run | i hostname\") 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 Args: callbacks: a list of ReadCallback objects initial_input: optional string to send to \"kick off\" the read_callback method read_output: optional bytes to append any new reads to read_delay: sleep interval between reads read_timeout: value to set the `transport_timeout` to for the duration of the reading portion of this method. If left default (-1.0) or set to anything below 0, the transport timeout value will be left alone (whatever the timeout_transport value is) otherwise, the provided value will be temporarily set as the timeout_transport for duration of the reading. Returns: ReadCallbackReturnable: either None or call to read_callback again Raises: ScrapliTimeout: if the read operation times out (base don the read_timeout value) during the read callback check.","title":"read_callback"},{"location":"api_docs/driver/generic/async_driver/#send_and_read","text":"send_and_read(self, channel_input: str, *, expected_outputs: Optional[List[str]] = None, strip_prompt: bool = True, failed_when_contains: Union[str, List[str], ForwardRef(None)] = None, timeout_ops: Optional[float] = None, read_duration: float = 2.5) \u2011> scrapli.response.Response 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 Send an input and read outputs. Unlike \"normal\" scrapli behavior this method reads until the prompt(normal) OR until any of a list of expected outputs is seen, OR until the read duration is exceeded. This method does not care about/understand privilege levels. This *can* cause you some potential issues if not used carefully! Args: channel_input: input to send to the channel; intentionally named \"channel_input\" instead of \"command\" or \"config\" due to this method not caring about privilege levels expected_outputs: List of outputs to look for in device response; returns as soon as any of the outputs are seen strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed read_duration: float duration to read for Returns: Response: Scrapli Response object Raises: ScrapliValueError: if _base_transport_args is None for some reason","title":"send_and_read"},{"location":"api_docs/driver/generic/async_driver/#send_command","text":"send_command(self, command: str, *, strip_prompt: bool = True, failed_when_contains: Union[str, List[str], ForwardRef(None)] = None, timeout_ops: Optional[float] = None) \u2011> scrapli.response.Response 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 Send a command Args: command: string to send to device in privilege exec mode strip_prompt: strip prompt or not, defaults to True (yes, strip the prompt) failed_when_contains: string or list of strings indicating failure if found in response timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed Returns: Response: Scrapli Response object Raises: N/A","title":"send_command"},{"location":"api_docs/driver/generic/async_driver/#send_commands","text":"send_commands(self, commands: List[str], *, strip_prompt: bool = True, failed_when_contains: Union[str, List[str], ForwardRef(None)] = None, stop_on_failed: bool = False, eager: bool = False, timeout_ops: Optional[float] = None) \u2011> scrapli.response.MultiResponse 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 Send multiple commands Args: commands: list of strings to send to device in privilege exec mode strip_prompt: strip prompt or not, defaults to True (yes, strip the prompt) failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER COMMAND sent, not for the total of the commands being sent! Returns: MultiResponse: Scrapli MultiResponse object Raises: N/A","title":"send_commands"},{"location":"api_docs/driver/generic/async_driver/#send_commands_from_file","text":"send_commands_from_file(self, file: str, *, strip_prompt: bool = True, failed_when_contains: Union[str, List[str], ForwardRef(None)] = None, stop_on_failed: bool = False, eager: bool = False, timeout_ops: Optional[float] = None) \u2011> scrapli.response.MultiResponse 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 Send command(s) from file Args: file: string path to file strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER COMMAND sent, not for the total of the commands being sent! Returns: MultiResponse: Scrapli MultiResponse object Raises: N/A","title":"send_commands_from_file"},{"location":"api_docs/driver/generic/async_driver/#send_interactive","text":"send_interactive(self, interact_events: Union[List[Tuple[str, str]], List[Tuple[str, str, bool]]], *, failed_when_contains: Union[str, List[str], ForwardRef(None)] = None, privilege_level: str = '', timeout_ops: Optional[float] = None, interaction_complete_patterns: Optional[List[str]] = None) \u2011> scrapli.response.Response 1 2 3 4 5 6 7 8 9 10 11 Interact with a device with changing prompts per input. Used to interact with devices where prompts change per input, and where inputs may be hidden such as in the case of a password input. This can be used to respond to challenges from devices such as the confirmation for the command \"clear logging\" on IOSXE devices for example. You may have as many elements in the \"interact_events\" list as needed, and each element of that list should be a tuple of two or three elements. The first element is always the input to send as a string, the second should be the expected response as a string, and the optional third a bool for whether or not the input is \"hidden\" (i.e. password input) An example where we need this sort of capability: 3560CX#copy flash: scp: Source filename []? test1.txt Address or name of remote host []? 172.31.254.100 Destination username [carl]? Writing test1.txt Password: Password: Sink: C0644 639 test1.txt ! 639 bytes copied in 12.066 secs (53 bytes/sec) 3560CX# 1 To accomplish this we can use the following: interact = conn.channel.send_inputs_interact( [ (\"copy flash: scp:\", \"Source filename []?\", False), (\"test1.txt\", \"Address or name of remote host []?\", False), (\"172.31.254.100\", \"Destination username [carl]?\", False), (\"carl\", \"Password:\", False), (\"super_secure_password\", prompt, True), ] ) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 If we needed to deal with more prompts we could simply continue adding tuples to the list of interact \"events\". Args: interact_events: list of tuples containing the \"interactions\" with the device each list element must have an input and an expected response, and may have an optional bool for the third and final element -- the optional bool specifies if the input that is sent to the device is \"hidden\" (ex: password), if the hidden param is not provided it is assumed the input is \"normal\" (not hidden) failed_when_contains: list of strings that, if present in final output, represent a failed command/interaction privilege_level: ignored in this base class; for LSP reasons for subclasses timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER COMMAND sent, not for the total of the commands being sent! interaction_complete_patterns: list of patterns, that if seen, indicate the interactive \"session\" has ended and we should exit the interactive session. Returns: Response: scrapli Response object Raises: ScrapliValueError: if _base_transport_args is None for some reason","title":"send_interactive"},{"location":"api_docs/driver/generic/base_driver/","text":"window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting()) Module scrapli.driver.generic.base_driver \u00b6 scrapli.driver.generic.base_driver Expand source code \"\"\"scrapli.driver.generic.base_driver\"\"\" import re from typing import ( TYPE_CHECKING, Any, Awaitable, Callable, Coroutine, List, Optional, Pattern, Tuple, Union, ) from scrapli.exceptions import ScrapliTypeError from scrapli.helper import resolve_file from scrapli.response import MultiResponse, Response if TYPE_CHECKING: from scrapli.driver.generic.async_driver import AsyncGenericDriver # pragma: no cover from scrapli.driver.generic.sync_driver import GenericDriver # pragma: no cover class ReadCallback: def __init__( self, callback: Callable[ [Union[\"GenericDriver\", \"AsyncGenericDriver\"], str], Union[None, Coroutine[Any, Any, None]], ], contains: str = \"\", not_contains: str = \"\", contains_re: str = \"\", case_insensitive: bool = True, multiline: bool = True, reset_output: bool = True, only_once: bool = False, next_delay: float = -1.0, next_timeout: float = -1.0, complete: bool = False, name: str = \"\", ): \"\"\" Object representing a single callback to be used with `GenericDriver` `read_callback` method Though the callable is typed with GenericDriver and AsyncGenericDriver, the callable can of course accept a NetworkDriver or AsyncNetworkDriver or any class extending those, you just may get some IDE/mypy complaints! Args: callback: callback function to execute, callback function must accept instance of the class as first argument, and the \"read_output\" as second contains: string of text that, if in the read output, indicates to execute this callback not_contains: string of text that should *not* be contained in the output contains_re: string of a regex pattern that will be compiled and used to match the callback case_insensitive: ignored unless contains_re provided, sets re.I on compiled regex multiline: ignored unless contains_re provided, sets re.M on compiled regex reset_output: bool indicating to reset (clear) the output or to pass the output along to the next iteration. Sometimes you may want to clear the output to not accidentally continue matching on one callback over and over again. You could also use `only_once` to help with that only_once: bool indicating if this callback should only ever be executed one time next_delay: optional sleep between reads for next callback check next_timeout: optionally set the transport timeout (to timeout the read operation) for the subsequent callback checks -- the default value of -1.0 will tell scrapli to use the \"normal\" transport timeout for the operation complete: bool indicating if this is the \"last\" callback to execute name: friendly name to give the callback, will be function name if not provided Returns: N/A Raises: N/A \"\"\" self.name = name if self.name == \"\": self.name = callback.__name__ self.callback = callback self.contains = contains self._contains_bytes = b\"\" self.not_contains = not_contains self._not_contains_bytes = b\"\" self.contains_re = contains_re self._contains_re_bytes: Optional[Pattern[bytes]] = None self.case_insensitive = case_insensitive self.multiline = multiline self.reset_output = reset_output self.only_once = only_once self._triggered = False self.next_delay = next_delay self.next_timeout = next_timeout self.complete = complete self._read_output = b\"\" @property def contains_bytes(self) -> bytes: \"\"\" Property to encode provided not contains if requested Args: N/A Returns: bytes: encoded not contains string Raises: N/A \"\"\" if self.contains and not self._contains_bytes: self._contains_bytes = self.contains.encode() return self._contains_bytes @property def not_contains_bytes(self) -> bytes: \"\"\" Property to encode provided contains if requested Args: N/A Returns: bytes: encoded contains string Raises: N/A \"\"\" if self.not_contains and not self._not_contains_bytes: self._not_contains_bytes = self.not_contains.encode() return self._not_contains_bytes @property def contains_re_bytes(self) -> Pattern[bytes]: \"\"\" Property to encode provided regex contains if requested Args: N/A Returns: re.Pattern: compiled bytes pattern Raises: N/A \"\"\" if not self._contains_re_bytes: flags = 0 if self.case_insensitive and self.multiline: flags = re.I | re.M elif self.case_insensitive: flags = re.I elif self.multiline: flags = re.M self._contains_re_bytes = re.compile(pattern=self.contains_re.encode(), flags=flags) return self._contains_re_bytes def check(self, read_output: bytes) -> bool: \"\"\" Determine if a callback has matched based on device output Args: read_output: bytes read from the device Returns: bool: True/False indicating if the callback \"matches\" the output Raises: N/A \"\"\" self._read_output = read_output if self.case_insensitive: _read_output = read_output.lower() else: _read_output = read_output if ( self.contains_bytes and self.contains_bytes in _read_output and not (self.not_contains and self.not_contains_bytes in _read_output) ): return True if ( self.contains_re and re.search(self.contains_re_bytes, _read_output) and not (self.not_contains and self.not_contains_bytes in _read_output) ): return True return False def run( self, driver: Union[\"GenericDriver\", \"AsyncGenericDriver\"] ) -> Union[None, Awaitable[Any]]: \"\"\" Run the callback Args: driver: driver object to pass to the callback function Returns: Union[None, Awaitable[Any]]: return the result of the callable if sync or the future Raises: N/A \"\"\" if self.only_once is True: self._triggered = True return self.callback(driver, self._read_output.decode()) ReadCallbackReturnable = Union[ None, Callable[[List[ReadCallback], Optional[str], bytes, float], Union[None, Any]], ] class BaseGenericDriver: @staticmethod def _pre_send_command( host: str, command: str, failed_when_contains: Optional[Union[str, List[str]]] = None ) -> Response: \"\"\" Handle pre \"send_command\" tasks for consistency between sync/async versions Args: host: string name of the host command: string to send to device in privilege exec mode failed_when_contains: string or list of strings indicating failure if found in response Returns: Response: Scrapli Response object Raises: ScrapliTypeError: if command is anything but a string \"\"\" if not isinstance(command, str): raise ScrapliTypeError( f\"`send_command` expects a single string, got {type(command)}, \" \"to send a list of commands use the `send_commands` method instead.\" ) return Response( host=host, channel_input=command, failed_when_contains=failed_when_contains, ) @staticmethod def _post_send_command( raw_response: bytes, processed_response: bytes, response: Response ) -> Response: \"\"\" Handle post \"send_command\" tasks for consistency between sync/async versions Args: raw_response: raw response returned from the channel processed_response: processed response returned from the channel response: response object to update with channel results Returns: Response: Scrapli Response object Raises: N/A \"\"\" response.record_response(result=processed_response) response.raw_result = raw_response return response @staticmethod def _pre_send_commands(commands: List[str]) -> MultiResponse: \"\"\" Handle pre \"send_command\" tasks for consistency between sync/async versions Args: commands: list of strings to send to device in privilege exec mode Returns: MultiResponse: Scrapli MultiResponse object Raises: ScrapliTypeError: if command is anything but a string \"\"\" if not isinstance(commands, list): raise ScrapliTypeError( f\"`send_commands` expects a list of strings, got {type(commands)}, \" \"to send a single command use the `send_command` method instead.\" ) return MultiResponse() @staticmethod def _pre_send_from_file(file: str, caller: str) -> List[str]: \"\"\" Handle pre \"send_*_from_file\" tasks for consistency between sync/async versions Args: file: string path to file caller: name of the calling method for more helpful error message Returns: list: list of commands/configs read from file Raises: ScrapliTypeError: if anything but a string is provided for `file` \"\"\" if not isinstance(file, str): raise ScrapliTypeError(f\"`{caller}` expects a string path to a file, got {type(file)}\") resolved_file = resolve_file(file) with open(resolved_file, \"r\", encoding=\"utf-8\") as f: commands = f.read().splitlines() return commands @classmethod def _pre_send_interactive( cls, host: str, interact_events: Union[List[Tuple[str, str]], List[Tuple[str, str, bool]]], failed_when_contains: Optional[Union[str, List[str]]] = None, ) -> Response: \"\"\" Handle pre \"send_interactive\" tasks for consistency between sync/async versions Args: host: string name of the host interact_events: list of tuples containing the \"interactions\" with the device each list element must have an input and an expected response, and may have an optional bool for the third and final element -- the optional bool specifies if the input that is sent to the device is \"hidden\" (ex: password), if the hidden param is not provided it is assumed the input is \"normal\" (not hidden) failed_when_contains: string or list of strings indicating failure if found in response Returns: Response: Scrapli Response object Raises: N/A \"\"\" joined_input = \", \".join(event[0] for event in interact_events) return cls._pre_send_command( host=host, command=joined_input, failed_when_contains=failed_when_contains ) Classes \u00b6 BaseGenericDriver \u00b6 Expand source code class BaseGenericDriver: @staticmethod def _pre_send_command( host: str, command: str, failed_when_contains: Optional[Union[str, List[str]]] = None ) -> Response: \"\"\" Handle pre \"send_command\" tasks for consistency between sync/async versions Args: host: string name of the host command: string to send to device in privilege exec mode failed_when_contains: string or list of strings indicating failure if found in response Returns: Response: Scrapli Response object Raises: ScrapliTypeError: if command is anything but a string \"\"\" if not isinstance(command, str): raise ScrapliTypeError( f\"`send_command` expects a single string, got {type(command)}, \" \"to send a list of commands use the `send_commands` method instead.\" ) return Response( host=host, channel_input=command, failed_when_contains=failed_when_contains, ) @staticmethod def _post_send_command( raw_response: bytes, processed_response: bytes, response: Response ) -> Response: \"\"\" Handle post \"send_command\" tasks for consistency between sync/async versions Args: raw_response: raw response returned from the channel processed_response: processed response returned from the channel response: response object to update with channel results Returns: Response: Scrapli Response object Raises: N/A \"\"\" response.record_response(result=processed_response) response.raw_result = raw_response return response @staticmethod def _pre_send_commands(commands: List[str]) -> MultiResponse: \"\"\" Handle pre \"send_command\" tasks for consistency between sync/async versions Args: commands: list of strings to send to device in privilege exec mode Returns: MultiResponse: Scrapli MultiResponse object Raises: ScrapliTypeError: if command is anything but a string \"\"\" if not isinstance(commands, list): raise ScrapliTypeError( f\"`send_commands` expects a list of strings, got {type(commands)}, \" \"to send a single command use the `send_command` method instead.\" ) return MultiResponse() @staticmethod def _pre_send_from_file(file: str, caller: str) -> List[str]: \"\"\" Handle pre \"send_*_from_file\" tasks for consistency between sync/async versions Args: file: string path to file caller: name of the calling method for more helpful error message Returns: list: list of commands/configs read from file Raises: ScrapliTypeError: if anything but a string is provided for `file` \"\"\" if not isinstance(file, str): raise ScrapliTypeError(f\"`{caller}` expects a string path to a file, got {type(file)}\") resolved_file = resolve_file(file) with open(resolved_file, \"r\", encoding=\"utf-8\") as f: commands = f.read().splitlines() return commands @classmethod def _pre_send_interactive( cls, host: str, interact_events: Union[List[Tuple[str, str]], List[Tuple[str, str, bool]]], failed_when_contains: Optional[Union[str, List[str]]] = None, ) -> Response: \"\"\" Handle pre \"send_interactive\" tasks for consistency between sync/async versions Args: host: string name of the host interact_events: list of tuples containing the \"interactions\" with the device each list element must have an input and an expected response, and may have an optional bool for the third and final element -- the optional bool specifies if the input that is sent to the device is \"hidden\" (ex: password), if the hidden param is not provided it is assumed the input is \"normal\" (not hidden) failed_when_contains: string or list of strings indicating failure if found in response Returns: Response: Scrapli Response object Raises: N/A \"\"\" joined_input = \", \".join(event[0] for event in interact_events) return cls._pre_send_command( host=host, command=joined_input, failed_when_contains=failed_when_contains ) Descendants \u00b6 scrapli.driver.generic.async_driver.AsyncGenericDriver scrapli.driver.generic.sync_driver.GenericDriver ReadCallback \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 Object representing a single callback to be used with `GenericDriver` `read_callback` method Though the callable is typed with GenericDriver and AsyncGenericDriver, the callable can of course accept a NetworkDriver or AsyncNetworkDriver or any class extending those, you just may get some IDE/mypy complaints! Args: callback: callback function to execute, callback function must accept instance of the class as first argument, and the \"read_output\" as second contains: string of text that, if in the read output, indicates to execute this callback not_contains: string of text that should *not* be contained in the output contains_re: string of a regex pattern that will be compiled and used to match the callback case_insensitive: ignored unless contains_re provided, sets re.I on compiled regex multiline: ignored unless contains_re provided, sets re.M on compiled regex reset_output: bool indicating to reset (clear) the output or to pass the output along to the next iteration. Sometimes you may want to clear the output to not accidentally continue matching on one callback over and over again. You could also use `only_once` to help with that only_once: bool indicating if this callback should only ever be executed one time next_delay: optional sleep between reads for next callback check next_timeout: optionally set the transport timeout (to timeout the read operation) for the subsequent callback checks -- the default value of -1.0 will tell scrapli to use the \"normal\" transport timeout for the operation complete: bool indicating if this is the \"last\" callback to execute name: friendly name to give the callback, will be function name if not provided Returns: N/A Raises: N/A Expand source code class ReadCallback: def __init__( self, callback: Callable[ [Union[\"GenericDriver\", \"AsyncGenericDriver\"], str], Union[None, Coroutine[Any, Any, None]], ], contains: str = \"\", not_contains: str = \"\", contains_re: str = \"\", case_insensitive: bool = True, multiline: bool = True, reset_output: bool = True, only_once: bool = False, next_delay: float = -1.0, next_timeout: float = -1.0, complete: bool = False, name: str = \"\", ): \"\"\" Object representing a single callback to be used with `GenericDriver` `read_callback` method Though the callable is typed with GenericDriver and AsyncGenericDriver, the callable can of course accept a NetworkDriver or AsyncNetworkDriver or any class extending those, you just may get some IDE/mypy complaints! Args: callback: callback function to execute, callback function must accept instance of the class as first argument, and the \"read_output\" as second contains: string of text that, if in the read output, indicates to execute this callback not_contains: string of text that should *not* be contained in the output contains_re: string of a regex pattern that will be compiled and used to match the callback case_insensitive: ignored unless contains_re provided, sets re.I on compiled regex multiline: ignored unless contains_re provided, sets re.M on compiled regex reset_output: bool indicating to reset (clear) the output or to pass the output along to the next iteration. Sometimes you may want to clear the output to not accidentally continue matching on one callback over and over again. You could also use `only_once` to help with that only_once: bool indicating if this callback should only ever be executed one time next_delay: optional sleep between reads for next callback check next_timeout: optionally set the transport timeout (to timeout the read operation) for the subsequent callback checks -- the default value of -1.0 will tell scrapli to use the \"normal\" transport timeout for the operation complete: bool indicating if this is the \"last\" callback to execute name: friendly name to give the callback, will be function name if not provided Returns: N/A Raises: N/A \"\"\" self.name = name if self.name == \"\": self.name = callback.__name__ self.callback = callback self.contains = contains self._contains_bytes = b\"\" self.not_contains = not_contains self._not_contains_bytes = b\"\" self.contains_re = contains_re self._contains_re_bytes: Optional[Pattern[bytes]] = None self.case_insensitive = case_insensitive self.multiline = multiline self.reset_output = reset_output self.only_once = only_once self._triggered = False self.next_delay = next_delay self.next_timeout = next_timeout self.complete = complete self._read_output = b\"\" @property def contains_bytes(self) -> bytes: \"\"\" Property to encode provided not contains if requested Args: N/A Returns: bytes: encoded not contains string Raises: N/A \"\"\" if self.contains and not self._contains_bytes: self._contains_bytes = self.contains.encode() return self._contains_bytes @property def not_contains_bytes(self) -> bytes: \"\"\" Property to encode provided contains if requested Args: N/A Returns: bytes: encoded contains string Raises: N/A \"\"\" if self.not_contains and not self._not_contains_bytes: self._not_contains_bytes = self.not_contains.encode() return self._not_contains_bytes @property def contains_re_bytes(self) -> Pattern[bytes]: \"\"\" Property to encode provided regex contains if requested Args: N/A Returns: re.Pattern: compiled bytes pattern Raises: N/A \"\"\" if not self._contains_re_bytes: flags = 0 if self.case_insensitive and self.multiline: flags = re.I | re.M elif self.case_insensitive: flags = re.I elif self.multiline: flags = re.M self._contains_re_bytes = re.compile(pattern=self.contains_re.encode(), flags=flags) return self._contains_re_bytes def check(self, read_output: bytes) -> bool: \"\"\" Determine if a callback has matched based on device output Args: read_output: bytes read from the device Returns: bool: True/False indicating if the callback \"matches\" the output Raises: N/A \"\"\" self._read_output = read_output if self.case_insensitive: _read_output = read_output.lower() else: _read_output = read_output if ( self.contains_bytes and self.contains_bytes in _read_output and not (self.not_contains and self.not_contains_bytes in _read_output) ): return True if ( self.contains_re and re.search(self.contains_re_bytes, _read_output) and not (self.not_contains and self.not_contains_bytes in _read_output) ): return True return False def run( self, driver: Union[\"GenericDriver\", \"AsyncGenericDriver\"] ) -> Union[None, Awaitable[Any]]: \"\"\" Run the callback Args: driver: driver object to pass to the callback function Returns: Union[None, Awaitable[Any]]: return the result of the callable if sync or the future Raises: N/A \"\"\" if self.only_once is True: self._triggered = True return self.callback(driver, self._read_output.decode()) Instance variables \u00b6 contains_bytes: bytes 1 2 3 4 5 6 7 8 9 10 Property to encode provided not contains if requested Args: N/A Returns: bytes: encoded not contains string Raises: N/A contains_re_bytes: Pattern[bytes] 1 2 3 4 5 6 7 8 9 10 Property to encode provided regex contains if requested Args: N/A Returns: re.Pattern: compiled bytes pattern Raises: N/A not_contains_bytes: bytes 1 2 3 4 5 6 7 8 9 10 Property to encode provided contains if requested Args: N/A Returns: bytes: encoded contains string Raises: N/A Methods \u00b6 check \u00b6 check(self, read_output: bytes) \u2011> bool 1 2 3 4 5 6 7 8 9 10 Determine if a callback has matched based on device output Args: read_output: bytes read from the device Returns: bool: True/False indicating if the callback \"matches\" the output Raises: N/A run \u00b6 run(self, driver: Union[ForwardRef('GenericDriver'), ForwardRef('AsyncGenericDriver')]) \u2011> Optional[None] 1 2 3 4 5 6 7 8 9 10 Run the callback Args: driver: driver object to pass to the callback function Returns: Union[None, Awaitable[Any]]: return the result of the callable if sync or the future Raises: N/A","title":"Base Driver"},{"location":"api_docs/driver/generic/base_driver/#module-scraplidrivergenericbase_driver","text":"scrapli.driver.generic.base_driver Expand source code \"\"\"scrapli.driver.generic.base_driver\"\"\" import re from typing import ( TYPE_CHECKING, Any, Awaitable, Callable, Coroutine, List, Optional, Pattern, Tuple, Union, ) from scrapli.exceptions import ScrapliTypeError from scrapli.helper import resolve_file from scrapli.response import MultiResponse, Response if TYPE_CHECKING: from scrapli.driver.generic.async_driver import AsyncGenericDriver # pragma: no cover from scrapli.driver.generic.sync_driver import GenericDriver # pragma: no cover class ReadCallback: def __init__( self, callback: Callable[ [Union[\"GenericDriver\", \"AsyncGenericDriver\"], str], Union[None, Coroutine[Any, Any, None]], ], contains: str = \"\", not_contains: str = \"\", contains_re: str = \"\", case_insensitive: bool = True, multiline: bool = True, reset_output: bool = True, only_once: bool = False, next_delay: float = -1.0, next_timeout: float = -1.0, complete: bool = False, name: str = \"\", ): \"\"\" Object representing a single callback to be used with `GenericDriver` `read_callback` method Though the callable is typed with GenericDriver and AsyncGenericDriver, the callable can of course accept a NetworkDriver or AsyncNetworkDriver or any class extending those, you just may get some IDE/mypy complaints! Args: callback: callback function to execute, callback function must accept instance of the class as first argument, and the \"read_output\" as second contains: string of text that, if in the read output, indicates to execute this callback not_contains: string of text that should *not* be contained in the output contains_re: string of a regex pattern that will be compiled and used to match the callback case_insensitive: ignored unless contains_re provided, sets re.I on compiled regex multiline: ignored unless contains_re provided, sets re.M on compiled regex reset_output: bool indicating to reset (clear) the output or to pass the output along to the next iteration. Sometimes you may want to clear the output to not accidentally continue matching on one callback over and over again. You could also use `only_once` to help with that only_once: bool indicating if this callback should only ever be executed one time next_delay: optional sleep between reads for next callback check next_timeout: optionally set the transport timeout (to timeout the read operation) for the subsequent callback checks -- the default value of -1.0 will tell scrapli to use the \"normal\" transport timeout for the operation complete: bool indicating if this is the \"last\" callback to execute name: friendly name to give the callback, will be function name if not provided Returns: N/A Raises: N/A \"\"\" self.name = name if self.name == \"\": self.name = callback.__name__ self.callback = callback self.contains = contains self._contains_bytes = b\"\" self.not_contains = not_contains self._not_contains_bytes = b\"\" self.contains_re = contains_re self._contains_re_bytes: Optional[Pattern[bytes]] = None self.case_insensitive = case_insensitive self.multiline = multiline self.reset_output = reset_output self.only_once = only_once self._triggered = False self.next_delay = next_delay self.next_timeout = next_timeout self.complete = complete self._read_output = b\"\" @property def contains_bytes(self) -> bytes: \"\"\" Property to encode provided not contains if requested Args: N/A Returns: bytes: encoded not contains string Raises: N/A \"\"\" if self.contains and not self._contains_bytes: self._contains_bytes = self.contains.encode() return self._contains_bytes @property def not_contains_bytes(self) -> bytes: \"\"\" Property to encode provided contains if requested Args: N/A Returns: bytes: encoded contains string Raises: N/A \"\"\" if self.not_contains and not self._not_contains_bytes: self._not_contains_bytes = self.not_contains.encode() return self._not_contains_bytes @property def contains_re_bytes(self) -> Pattern[bytes]: \"\"\" Property to encode provided regex contains if requested Args: N/A Returns: re.Pattern: compiled bytes pattern Raises: N/A \"\"\" if not self._contains_re_bytes: flags = 0 if self.case_insensitive and self.multiline: flags = re.I | re.M elif self.case_insensitive: flags = re.I elif self.multiline: flags = re.M self._contains_re_bytes = re.compile(pattern=self.contains_re.encode(), flags=flags) return self._contains_re_bytes def check(self, read_output: bytes) -> bool: \"\"\" Determine if a callback has matched based on device output Args: read_output: bytes read from the device Returns: bool: True/False indicating if the callback \"matches\" the output Raises: N/A \"\"\" self._read_output = read_output if self.case_insensitive: _read_output = read_output.lower() else: _read_output = read_output if ( self.contains_bytes and self.contains_bytes in _read_output and not (self.not_contains and self.not_contains_bytes in _read_output) ): return True if ( self.contains_re and re.search(self.contains_re_bytes, _read_output) and not (self.not_contains and self.not_contains_bytes in _read_output) ): return True return False def run( self, driver: Union[\"GenericDriver\", \"AsyncGenericDriver\"] ) -> Union[None, Awaitable[Any]]: \"\"\" Run the callback Args: driver: driver object to pass to the callback function Returns: Union[None, Awaitable[Any]]: return the result of the callable if sync or the future Raises: N/A \"\"\" if self.only_once is True: self._triggered = True return self.callback(driver, self._read_output.decode()) ReadCallbackReturnable = Union[ None, Callable[[List[ReadCallback], Optional[str], bytes, float], Union[None, Any]], ] class BaseGenericDriver: @staticmethod def _pre_send_command( host: str, command: str, failed_when_contains: Optional[Union[str, List[str]]] = None ) -> Response: \"\"\" Handle pre \"send_command\" tasks for consistency between sync/async versions Args: host: string name of the host command: string to send to device in privilege exec mode failed_when_contains: string or list of strings indicating failure if found in response Returns: Response: Scrapli Response object Raises: ScrapliTypeError: if command is anything but a string \"\"\" if not isinstance(command, str): raise ScrapliTypeError( f\"`send_command` expects a single string, got {type(command)}, \" \"to send a list of commands use the `send_commands` method instead.\" ) return Response( host=host, channel_input=command, failed_when_contains=failed_when_contains, ) @staticmethod def _post_send_command( raw_response: bytes, processed_response: bytes, response: Response ) -> Response: \"\"\" Handle post \"send_command\" tasks for consistency between sync/async versions Args: raw_response: raw response returned from the channel processed_response: processed response returned from the channel response: response object to update with channel results Returns: Response: Scrapli Response object Raises: N/A \"\"\" response.record_response(result=processed_response) response.raw_result = raw_response return response @staticmethod def _pre_send_commands(commands: List[str]) -> MultiResponse: \"\"\" Handle pre \"send_command\" tasks for consistency between sync/async versions Args: commands: list of strings to send to device in privilege exec mode Returns: MultiResponse: Scrapli MultiResponse object Raises: ScrapliTypeError: if command is anything but a string \"\"\" if not isinstance(commands, list): raise ScrapliTypeError( f\"`send_commands` expects a list of strings, got {type(commands)}, \" \"to send a single command use the `send_command` method instead.\" ) return MultiResponse() @staticmethod def _pre_send_from_file(file: str, caller: str) -> List[str]: \"\"\" Handle pre \"send_*_from_file\" tasks for consistency between sync/async versions Args: file: string path to file caller: name of the calling method for more helpful error message Returns: list: list of commands/configs read from file Raises: ScrapliTypeError: if anything but a string is provided for `file` \"\"\" if not isinstance(file, str): raise ScrapliTypeError(f\"`{caller}` expects a string path to a file, got {type(file)}\") resolved_file = resolve_file(file) with open(resolved_file, \"r\", encoding=\"utf-8\") as f: commands = f.read().splitlines() return commands @classmethod def _pre_send_interactive( cls, host: str, interact_events: Union[List[Tuple[str, str]], List[Tuple[str, str, bool]]], failed_when_contains: Optional[Union[str, List[str]]] = None, ) -> Response: \"\"\" Handle pre \"send_interactive\" tasks for consistency between sync/async versions Args: host: string name of the host interact_events: list of tuples containing the \"interactions\" with the device each list element must have an input and an expected response, and may have an optional bool for the third and final element -- the optional bool specifies if the input that is sent to the device is \"hidden\" (ex: password), if the hidden param is not provided it is assumed the input is \"normal\" (not hidden) failed_when_contains: string or list of strings indicating failure if found in response Returns: Response: Scrapli Response object Raises: N/A \"\"\" joined_input = \", \".join(event[0] for event in interact_events) return cls._pre_send_command( host=host, command=joined_input, failed_when_contains=failed_when_contains )","title":"Module scrapli.driver.generic.base_driver"},{"location":"api_docs/driver/generic/base_driver/#classes","text":"","title":"Classes"},{"location":"api_docs/driver/generic/base_driver/#basegenericdriver","text":"Expand source code class BaseGenericDriver: @staticmethod def _pre_send_command( host: str, command: str, failed_when_contains: Optional[Union[str, List[str]]] = None ) -> Response: \"\"\" Handle pre \"send_command\" tasks for consistency between sync/async versions Args: host: string name of the host command: string to send to device in privilege exec mode failed_when_contains: string or list of strings indicating failure if found in response Returns: Response: Scrapli Response object Raises: ScrapliTypeError: if command is anything but a string \"\"\" if not isinstance(command, str): raise ScrapliTypeError( f\"`send_command` expects a single string, got {type(command)}, \" \"to send a list of commands use the `send_commands` method instead.\" ) return Response( host=host, channel_input=command, failed_when_contains=failed_when_contains, ) @staticmethod def _post_send_command( raw_response: bytes, processed_response: bytes, response: Response ) -> Response: \"\"\" Handle post \"send_command\" tasks for consistency between sync/async versions Args: raw_response: raw response returned from the channel processed_response: processed response returned from the channel response: response object to update with channel results Returns: Response: Scrapli Response object Raises: N/A \"\"\" response.record_response(result=processed_response) response.raw_result = raw_response return response @staticmethod def _pre_send_commands(commands: List[str]) -> MultiResponse: \"\"\" Handle pre \"send_command\" tasks for consistency between sync/async versions Args: commands: list of strings to send to device in privilege exec mode Returns: MultiResponse: Scrapli MultiResponse object Raises: ScrapliTypeError: if command is anything but a string \"\"\" if not isinstance(commands, list): raise ScrapliTypeError( f\"`send_commands` expects a list of strings, got {type(commands)}, \" \"to send a single command use the `send_command` method instead.\" ) return MultiResponse() @staticmethod def _pre_send_from_file(file: str, caller: str) -> List[str]: \"\"\" Handle pre \"send_*_from_file\" tasks for consistency between sync/async versions Args: file: string path to file caller: name of the calling method for more helpful error message Returns: list: list of commands/configs read from file Raises: ScrapliTypeError: if anything but a string is provided for `file` \"\"\" if not isinstance(file, str): raise ScrapliTypeError(f\"`{caller}` expects a string path to a file, got {type(file)}\") resolved_file = resolve_file(file) with open(resolved_file, \"r\", encoding=\"utf-8\") as f: commands = f.read().splitlines() return commands @classmethod def _pre_send_interactive( cls, host: str, interact_events: Union[List[Tuple[str, str]], List[Tuple[str, str, bool]]], failed_when_contains: Optional[Union[str, List[str]]] = None, ) -> Response: \"\"\" Handle pre \"send_interactive\" tasks for consistency between sync/async versions Args: host: string name of the host interact_events: list of tuples containing the \"interactions\" with the device each list element must have an input and an expected response, and may have an optional bool for the third and final element -- the optional bool specifies if the input that is sent to the device is \"hidden\" (ex: password), if the hidden param is not provided it is assumed the input is \"normal\" (not hidden) failed_when_contains: string or list of strings indicating failure if found in response Returns: Response: Scrapli Response object Raises: N/A \"\"\" joined_input = \", \".join(event[0] for event in interact_events) return cls._pre_send_command( host=host, command=joined_input, failed_when_contains=failed_when_contains )","title":"BaseGenericDriver"},{"location":"api_docs/driver/generic/base_driver/#descendants","text":"scrapli.driver.generic.async_driver.AsyncGenericDriver scrapli.driver.generic.sync_driver.GenericDriver","title":"Descendants"},{"location":"api_docs/driver/generic/base_driver/#readcallback","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 Object representing a single callback to be used with `GenericDriver` `read_callback` method Though the callable is typed with GenericDriver and AsyncGenericDriver, the callable can of course accept a NetworkDriver or AsyncNetworkDriver or any class extending those, you just may get some IDE/mypy complaints! Args: callback: callback function to execute, callback function must accept instance of the class as first argument, and the \"read_output\" as second contains: string of text that, if in the read output, indicates to execute this callback not_contains: string of text that should *not* be contained in the output contains_re: string of a regex pattern that will be compiled and used to match the callback case_insensitive: ignored unless contains_re provided, sets re.I on compiled regex multiline: ignored unless contains_re provided, sets re.M on compiled regex reset_output: bool indicating to reset (clear) the output or to pass the output along to the next iteration. Sometimes you may want to clear the output to not accidentally continue matching on one callback over and over again. You could also use `only_once` to help with that only_once: bool indicating if this callback should only ever be executed one time next_delay: optional sleep between reads for next callback check next_timeout: optionally set the transport timeout (to timeout the read operation) for the subsequent callback checks -- the default value of -1.0 will tell scrapli to use the \"normal\" transport timeout for the operation complete: bool indicating if this is the \"last\" callback to execute name: friendly name to give the callback, will be function name if not provided Returns: N/A Raises: N/A Expand source code class ReadCallback: def __init__( self, callback: Callable[ [Union[\"GenericDriver\", \"AsyncGenericDriver\"], str], Union[None, Coroutine[Any, Any, None]], ], contains: str = \"\", not_contains: str = \"\", contains_re: str = \"\", case_insensitive: bool = True, multiline: bool = True, reset_output: bool = True, only_once: bool = False, next_delay: float = -1.0, next_timeout: float = -1.0, complete: bool = False, name: str = \"\", ): \"\"\" Object representing a single callback to be used with `GenericDriver` `read_callback` method Though the callable is typed with GenericDriver and AsyncGenericDriver, the callable can of course accept a NetworkDriver or AsyncNetworkDriver or any class extending those, you just may get some IDE/mypy complaints! Args: callback: callback function to execute, callback function must accept instance of the class as first argument, and the \"read_output\" as second contains: string of text that, if in the read output, indicates to execute this callback not_contains: string of text that should *not* be contained in the output contains_re: string of a regex pattern that will be compiled and used to match the callback case_insensitive: ignored unless contains_re provided, sets re.I on compiled regex multiline: ignored unless contains_re provided, sets re.M on compiled regex reset_output: bool indicating to reset (clear) the output or to pass the output along to the next iteration. Sometimes you may want to clear the output to not accidentally continue matching on one callback over and over again. You could also use `only_once` to help with that only_once: bool indicating if this callback should only ever be executed one time next_delay: optional sleep between reads for next callback check next_timeout: optionally set the transport timeout (to timeout the read operation) for the subsequent callback checks -- the default value of -1.0 will tell scrapli to use the \"normal\" transport timeout for the operation complete: bool indicating if this is the \"last\" callback to execute name: friendly name to give the callback, will be function name if not provided Returns: N/A Raises: N/A \"\"\" self.name = name if self.name == \"\": self.name = callback.__name__ self.callback = callback self.contains = contains self._contains_bytes = b\"\" self.not_contains = not_contains self._not_contains_bytes = b\"\" self.contains_re = contains_re self._contains_re_bytes: Optional[Pattern[bytes]] = None self.case_insensitive = case_insensitive self.multiline = multiline self.reset_output = reset_output self.only_once = only_once self._triggered = False self.next_delay = next_delay self.next_timeout = next_timeout self.complete = complete self._read_output = b\"\" @property def contains_bytes(self) -> bytes: \"\"\" Property to encode provided not contains if requested Args: N/A Returns: bytes: encoded not contains string Raises: N/A \"\"\" if self.contains and not self._contains_bytes: self._contains_bytes = self.contains.encode() return self._contains_bytes @property def not_contains_bytes(self) -> bytes: \"\"\" Property to encode provided contains if requested Args: N/A Returns: bytes: encoded contains string Raises: N/A \"\"\" if self.not_contains and not self._not_contains_bytes: self._not_contains_bytes = self.not_contains.encode() return self._not_contains_bytes @property def contains_re_bytes(self) -> Pattern[bytes]: \"\"\" Property to encode provided regex contains if requested Args: N/A Returns: re.Pattern: compiled bytes pattern Raises: N/A \"\"\" if not self._contains_re_bytes: flags = 0 if self.case_insensitive and self.multiline: flags = re.I | re.M elif self.case_insensitive: flags = re.I elif self.multiline: flags = re.M self._contains_re_bytes = re.compile(pattern=self.contains_re.encode(), flags=flags) return self._contains_re_bytes def check(self, read_output: bytes) -> bool: \"\"\" Determine if a callback has matched based on device output Args: read_output: bytes read from the device Returns: bool: True/False indicating if the callback \"matches\" the output Raises: N/A \"\"\" self._read_output = read_output if self.case_insensitive: _read_output = read_output.lower() else: _read_output = read_output if ( self.contains_bytes and self.contains_bytes in _read_output and not (self.not_contains and self.not_contains_bytes in _read_output) ): return True if ( self.contains_re and re.search(self.contains_re_bytes, _read_output) and not (self.not_contains and self.not_contains_bytes in _read_output) ): return True return False def run( self, driver: Union[\"GenericDriver\", \"AsyncGenericDriver\"] ) -> Union[None, Awaitable[Any]]: \"\"\" Run the callback Args: driver: driver object to pass to the callback function Returns: Union[None, Awaitable[Any]]: return the result of the callable if sync or the future Raises: N/A \"\"\" if self.only_once is True: self._triggered = True return self.callback(driver, self._read_output.decode())","title":"ReadCallback"},{"location":"api_docs/driver/generic/base_driver/#instance-variables","text":"contains_bytes: bytes 1 2 3 4 5 6 7 8 9 10 Property to encode provided not contains if requested Args: N/A Returns: bytes: encoded not contains string Raises: N/A contains_re_bytes: Pattern[bytes] 1 2 3 4 5 6 7 8 9 10 Property to encode provided regex contains if requested Args: N/A Returns: re.Pattern: compiled bytes pattern Raises: N/A not_contains_bytes: bytes 1 2 3 4 5 6 7 8 9 10 Property to encode provided contains if requested Args: N/A Returns: bytes: encoded contains string Raises: N/A","title":"Instance variables"},{"location":"api_docs/driver/generic/base_driver/#methods","text":"","title":"Methods"},{"location":"api_docs/driver/generic/base_driver/#check","text":"check(self, read_output: bytes) \u2011> bool 1 2 3 4 5 6 7 8 9 10 Determine if a callback has matched based on device output Args: read_output: bytes read from the device Returns: bool: True/False indicating if the callback \"matches\" the output Raises: N/A","title":"check"},{"location":"api_docs/driver/generic/base_driver/#run","text":"run(self, driver: Union[ForwardRef('GenericDriver'), ForwardRef('AsyncGenericDriver')]) \u2011> Optional[None] 1 2 3 4 5 6 7 8 9 10 Run the callback Args: driver: driver object to pass to the callback function Returns: Union[None, Awaitable[Any]]: return the result of the callable if sync or the future Raises: N/A","title":"run"},{"location":"api_docs/driver/generic/sync_driver/","text":"window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting()) Module scrapli.driver.generic.sync_driver \u00b6 scrapli.driver.generic.sync_driver Expand source code \"\"\"scrapli.driver.generic.sync_driver\"\"\" import time from io import BytesIO from typing import TYPE_CHECKING, Any, Callable, Dict, List, Optional, Tuple, Union from scrapli.decorators import timeout_modifier from scrapli.driver import Driver from scrapli.driver.generic.base_driver import BaseGenericDriver from scrapli.exceptions import ScrapliTimeout, ScrapliValueError from scrapli.response import MultiResponse, Response if TYPE_CHECKING: from scrapli.driver.generic.base_driver import ( # pragma: no cover ReadCallback, ReadCallbackReturnable, ) class GenericDriver(Driver, BaseGenericDriver): def __init__( self, host: str, port: Optional[int] = None, auth_username: str = \"\", auth_password: str = \"\", auth_private_key: str = \"\", auth_private_key_passphrase: str = \"\", auth_strict_key: bool = True, auth_bypass: bool = False, timeout_socket: float = 15.0, timeout_transport: float = 30.0, timeout_ops: float = 30.0, comms_prompt_pattern: str = r\"^\\S{0,48}[#>$~@:\\]]\\s*$\", comms_return_char: str = \"\\n\", ssh_config_file: Union[str, bool] = False, ssh_known_hosts_file: Union[str, bool] = False, on_init: Optional[Callable[..., Any]] = None, on_open: Optional[Callable[..., Any]] = None, on_close: Optional[Callable[..., Any]] = None, transport: str = \"system\", transport_options: Optional[Dict[str, Any]] = None, channel_log: Union[str, bool, BytesIO] = False, channel_log_mode: str = \"write\", channel_lock: bool = False, logging_uid: str = \"\", ) -> None: super().__init__( host=host, port=port, auth_username=auth_username, auth_password=auth_password, auth_private_key=auth_private_key, auth_private_key_passphrase=auth_private_key_passphrase, auth_strict_key=auth_strict_key, auth_bypass=auth_bypass, timeout_socket=timeout_socket, timeout_transport=timeout_transport, timeout_ops=timeout_ops, comms_prompt_pattern=comms_prompt_pattern, comms_return_char=comms_return_char, ssh_config_file=ssh_config_file, ssh_known_hosts_file=ssh_known_hosts_file, on_init=on_init, on_open=on_open, on_close=on_close, transport=transport, transport_options=transport_options, channel_log=channel_log, channel_log_mode=channel_log_mode, channel_lock=channel_lock, logging_uid=logging_uid, ) def get_prompt(self) -> str: \"\"\" Convenience method to fetch prompt from the underlying Channel object Args: N/A Returns: str: string of the current prompt Raises: N/A \"\"\" # assigned/typed here as decorator indicates return of Any prompt: str = self.channel.get_prompt() return prompt @timeout_modifier def _send_command( self, command: str, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, eager: bool = False, timeout_ops: Optional[float] = None, ) -> Response: \"\"\" Send a command Private method so that we can handle `eager` w/out having to have that argument showing up in all the methods that super to the \"normal\" send_command method as we only ever want eager to be used for the plural options -- i.e. send_commands not send_command! Args: command: string to send to device in privilege exec mode strip_prompt: strip prompt or not, defaults to True (yes, strip the prompt) failed_when_contains: string or list of strings indicating failure if found in response eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed Returns: Response: Scrapli Response object Raises: ScrapliValueError: if _base_transport_args is None for some reason \"\"\" # decorator cares about timeout_ops, but nothing else does, assign to _ to appease linters _ = timeout_ops if not self._base_transport_args: # should not happen! :) raise ScrapliValueError(\"driver _base_transport_args not set for some reason\") response = self._pre_send_command( host=self._base_transport_args.host, command=command, failed_when_contains=failed_when_contains, ) raw_response, processed_response = self.channel.send_input( channel_input=command, strip_prompt=strip_prompt, eager=eager ) return self._post_send_command( raw_response=raw_response, processed_response=processed_response, response=response ) def send_command( self, command: str, *, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, timeout_ops: Optional[float] = None, ) -> Response: \"\"\" Send a command Args: command: string to send to device in privilege exec mode strip_prompt: strip prompt or not, defaults to True (yes, strip the prompt) failed_when_contains: string or list of strings indicating failure if found in response timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed Returns: Response: Scrapli Response object Raises: N/A \"\"\" response: Response = self._send_command( command=command, strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, timeout_ops=timeout_ops, ) return response def send_commands( self, commands: List[str], *, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, stop_on_failed: bool = False, eager: bool = False, timeout_ops: Optional[float] = None, ) -> MultiResponse: \"\"\" Send multiple commands Args: commands: list of strings to send to device in privilege exec mode strip_prompt: strip prompt or not, defaults to True (yes, strip the prompt) failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER COMMAND sent, not for the total of the commands being sent! Returns: MultiResponse: Scrapli MultiResponse object Raises: N/A \"\"\" responses = self._pre_send_commands(commands=commands) for command in commands[:-1]: response = self._send_command( command=command, strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, timeout_ops=timeout_ops, eager=eager, ) responses.append(response) if stop_on_failed and response.failed is True: # should we find the prompt here w/ get_prompt?? or just let subsequent operations # deal w/ finding that? future us problem? :) break else: # if we did *not* break (i.e. no failure and/or no stop_on_failed) send the last command # with eager = False -- this way we *always* find the prompt at the end of the commands response = self._send_command( command=commands[-1], strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, timeout_ops=timeout_ops, eager=False, ) responses.append(response) return responses def send_commands_from_file( self, file: str, *, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, stop_on_failed: bool = False, eager: bool = False, timeout_ops: Optional[float] = None, ) -> MultiResponse: \"\"\" Send command(s) from file Args: file: string path to file strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER COMMAND sent, not for the total of the commands being sent! Returns: MultiResponse: Scrapli MultiResponse object Raises: N/A \"\"\" commands = self._pre_send_from_file(file=file, caller=\"send_commands_from_file\") return self.send_commands( commands=commands, strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, stop_on_failed=stop_on_failed, eager=eager, timeout_ops=timeout_ops, ) @timeout_modifier def send_and_read( self, channel_input: str, *, expected_outputs: Optional[List[str]] = None, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, timeout_ops: Optional[float] = None, read_duration: float = 2.5, ) -> Response: \"\"\" Send an input and read outputs. Unlike \"normal\" scrapli behavior this method reads until the prompt(normal) OR until any of a list of expected outputs is seen, OR until the read duration is exceeded. This method does not care about/understand privilege levels. This *can* cause you some potential issues if not used carefully! Args: channel_input: input to send to the channel; intentionally named \"channel_input\" instead of \"command\" or \"config\" due to this method not caring about privilege levels expected_outputs: List of outputs to look for in device response; returns as soon as any of the outputs are seen strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed read_duration: float duration to read for Returns: Response: Scrapli Response object Raises: ScrapliValueError: if _base_transport_args is None for some reason \"\"\" # decorator cares about timeout_ops, but nothing else does, assign to _ to appease linters _ = timeout_ops if not self._base_transport_args: # should not happen! :) raise ScrapliValueError(\"driver _base_transport_args not set for some reason\") response = self._pre_send_command( host=self._base_transport_args.host, command=channel_input, failed_when_contains=failed_when_contains, ) raw_response, processed_response = self.channel.send_input_and_read( channel_input=channel_input, strip_prompt=strip_prompt, expected_outputs=expected_outputs, read_duration=read_duration, ) return self._post_send_command( raw_response=raw_response, processed_response=processed_response, response=response ) @timeout_modifier def send_interactive( self, interact_events: Union[List[Tuple[str, str]], List[Tuple[str, str, bool]]], *, failed_when_contains: Optional[Union[str, List[str]]] = None, privilege_level: str = \"\", timeout_ops: Optional[float] = None, interaction_complete_patterns: Optional[List[str]] = None, ) -> Response: \"\"\" Interact with a device with changing prompts per input. Used to interact with devices where prompts change per input, and where inputs may be hidden such as in the case of a password input. This can be used to respond to challenges from devices such as the confirmation for the command \"clear logging\" on IOSXE devices for example. You may have as many elements in the \"interact_events\" list as needed, and each element of that list should be a tuple of two or three elements. The first element is always the input to send as a string, the second should be the expected response as a string, and the optional third a bool for whether or not the input is \"hidden\" (i.e. password input) An example where we need this sort of capability: 1 2 3 4 5 6 7 8 9 10 11 12 3560CX#copy flash: scp: Source filename []? test1.txt Address or name of remote host []? 172.31.254.100 Destination username [carl]? Writing test1.txt Password: Password: Sink: C0644 639 test1.txt ! 639 bytes copied in 12.066 secs (53 bytes/sec) 3560CX# To accomplish this we can use the following: 1 2 3 4 5 6 7 8 9 interact = conn.channel.send_inputs_interact( [ (\"copy flash: scp:\", \"Source filename []?\", False), (\"test1.txt\", \"Address or name of remote host []?\", False), (\"172.31.254.100\", \"Destination username [carl]?\", False), (\"carl\", \"Password:\", False), (\"super_secure_password\", prompt, True), ] ) If we needed to deal with more prompts we could simply continue adding tuples to the list of interact \"events\". Args: interact_events: list of tuples containing the \"interactions\" with the device each list element must have an input and an expected response, and may have an optional bool for the third and final element -- the optional bool specifies if the input that is sent to the device is \"hidden\" (ex: password), if the hidden param is not provided it is assumed the input is \"normal\" (not hidden) failed_when_contains: list of strings that, if present in final output, represent a failed command/interaction privilege_level: ignored in this base class; for LSP reasons for subclasses timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER COMMAND sent, not for the total of the commands being sent! interaction_complete_patterns: list of patterns, that if seen, indicate the interactive \"session\" has ended and we should exit the interactive session. Returns: Response: scrapli Response object Raises: ScrapliValueError: if _base_transport_args is None for some reason \"\"\" # decorator cares about timeout_ops, but nothing else does, assign to _ to appease linters _ = timeout_ops # privilege level only matters \"up\" in the network driver layer _ = privilege_level if not self._base_transport_args: # should not happen! :) raise ScrapliValueError(\"driver _base_transport_args not set for some reason\") response = self._pre_send_interactive( host=self._base_transport_args.host, interact_events=interact_events, failed_when_contains=failed_when_contains, ) raw_response, processed_response = self.channel.send_inputs_interact( interact_events=interact_events, interaction_complete_patterns=interaction_complete_patterns, ) return self._post_send_command( raw_response=raw_response, processed_response=processed_response, response=response ) def read_callback( self, callbacks: List[\"ReadCallback\"], initial_input: Optional[str] = None, read_output: bytes = b\"\", read_delay: float = 0.1, read_timeout: float = -1.0, ) -> \"ReadCallbackReturnable\": r\"\"\" Read from a channel and react to the output with some callback. This method is kind of like an \"advanced\" send_interactive -- the idea is simple: send some \"stuff\" to the channel (optionally), and then read from the channel. Based on the output do something. The callbacks is a list of `ReadCallback` which is an object containing the actual callback to execute, some info about when to trigger that callback (also when *not* to trigger that callback), as well as some attributes to control the next (if desired) iteration of read_callback. You could in theory do basically everything with this method by chaining callbacks forever, but you probably don't want to do that for real! Example usage: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 from scrapli.driver.core import IOSXEDriver from scrapli.driver.generic.base_driver import ReadCallback from scrapli.driver.generic.sync_driver import GenericDriver device = { \"host\": \"rtr1\", \"auth_strict_key\": False, \"ssh_config_file\": True, } def callback_one(cls: GenericDriver, read_output: str): cls.acquire_priv(\"configuration\") cls.channel.send_return() def callback_two(cls: GenericDriver, read_output: str): print(f\"previous read output : {read_output}\") r = cls.send_command(\"show run | i hostname\") print(f\"result: {r.result}\") with IOSXEDriver(**device) as conn: callbacks = [ ReadCallback( contains=\"rtr1#\", callback=callback_one, name=\"call1\", case_insensitive=False ), ReadCallback( contains_re=r\"^rtr1\\(config\\)#\", callback=callback_two, complete=True, ) ] conn.read_callback(callbacks=callbacks, initial_input=\"show run | i hostname\") Args: callbacks: a list of ReadCallback objects initial_input: optional string to send to \"kick off\" the read_callback method read_output: optional bytes to append any new reads to read_delay: sleep interval between reads read_timeout: value to set the `transport_timeout` to for the duration of the reading portion of this method. If left default (-1.0) or set to anything below 0, the transport timeout value will be left alone (whatever the timeout_transport value is) otherwise, the provided value will be temporarily set as the timeout_transport for duration of the reading. Returns: ReadCallbackReturnable: either None or call to read_callback again Raises: ScrapliTimeout: if the read operation times out (base don the read_timeout value) during the read callback check. \"\"\" if initial_input is not None: self.channel.write(channel_input=f\"{initial_input}{self.comms_return_char}\") return self.read_callback(callbacks=callbacks, initial_input=None) original_transport_timeout = self.timeout_transport # if the read_timeout value is -1.0 or just less than 0, that indicates we should use # the \"normal\" transport timeout and not modify anything self.timeout_transport = read_timeout if read_timeout >= 0 else self.timeout_transport _read_delay = 0.1 if read_delay < = 0 else read_delay while True: try: read_output += self.channel.read() except ScrapliTimeout as exc: self.timeout_transport = original_transport_timeout raise ScrapliTimeout(\"timeout during read in read_callback operation\") from exc for callback in callbacks: _run_callback = callback.check(read_output=read_output) if ( callback.only_once is True and callback._triggered is True # pylint: disable=W0212 ): self.logger.warning( f\"callback {callback.name} matches but is set to 'only_once', \" \"skipping this callback\" ) continue if _run_callback is True: self.logger.info(f\"callback {callback.name} matched, executing\") self.timeout_transport = original_transport_timeout callback.run(driver=self) if callback.complete: self.logger.debug(\"callback complete is true, done with read_callback\") return None if callback.reset_output: read_output = b\"\" return self.read_callback( callbacks=callbacks, initial_input=None, read_output=read_output, read_delay=callback.next_delay, read_timeout=callback.next_timeout, ) time.sleep(_read_delay) Classes \u00b6 GenericDriver \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 BaseDriver Object BaseDriver is the root for all Scrapli driver classes. The synchronous and asyncio driver base driver classes can be used to provide a semi-pexpect like experience over top of whatever transport a user prefers. Generally, however, the base driver classes should not be used directly. It is best to use the GenericDriver (or AsyncGenericDriver) or NetworkDriver (or AsyncNetworkDriver) sub-classes of the base drivers. Args: host: host ip/name to connect to port: port to connect to auth_username: username for authentication auth_private_key: path to private key for authentication auth_private_key_passphrase: passphrase for decrypting ssh key if necessary auth_password: password for authentication auth_strict_key: strict host checking or not auth_bypass: bypass \"in channel\" authentication -- only supported with telnet, asynctelnet, and system transport plugins timeout_socket: timeout for establishing socket/initial connection in seconds timeout_transport: timeout for ssh|telnet transport in seconds timeout_ops: timeout for ssh channel operations comms_prompt_pattern: raw string regex pattern -- preferably use `^` and `$` anchors! this is the single most important attribute here! if this does not match a prompt, scrapli will not work! IMPORTANT: regex search uses multi-line + case insensitive flags. multi-line allows for highly reliably matching for prompts however we do NOT strip trailing whitespace for each line, so be sure to add '\\\\s?' or similar if your device needs that. This should be mostly sorted for you if using network drivers (i.e. `IOSXEDriver`). Lastly, the case insensitive is just a convenience factor so i can be lazy. comms_return_char: character to use to send returns to host ssh_config_file: string to path for ssh config file, True to use default ssh config file or False to ignore default ssh config file ssh_known_hosts_file: string to path for ssh known hosts file, True to use default known file locations. Only applicable/needed if `auth_strict_key` is set to True on_init: callable that accepts the class instance as its only argument. this callable, if provided, is executed as the last step of object instantiation -- its purpose is primarily to provide a mechanism for scrapli community platforms to have an easy way to modify initialization arguments/object attributes without needing to create a class that extends the driver, instead allowing the community platforms to simply build from the GenericDriver or NetworkDriver classes, and pass this callable to do things such as appending to a username (looking at you RouterOS!!). Note that this is *always* a synchronous function (even for asyncio drivers)! on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar transport: name of the transport plugin to use for the actual telnet/ssh/netconf connection. Available \"core\" transports are: - system - telnet - asynctelnet - ssh2 - paramiko - asyncssh Please see relevant transport plugin section for details. Additionally third party transport plugins may be available. transport_options: dictionary of options to pass to selected transport class; see docs for given transport class for details of what to pass here channel_lock: True/False to lock the channel (threading.Lock/asyncio.Lock) during any channel operations, defaults to False channel_log: True/False or a string path to a file of where to write out channel logs -- these are not \"logs\" in the normal logging module sense, but only the output that is read from the channel. In other words, the output of the channel log should look similar to what you would see as a human connecting to a device channel_log_mode: \"write\"|\"append\", all other values will raise ValueError, does what it sounds like it should by setting the channel log to the provided mode logging_uid: unique identifier (string) to associate to log messages; useful if you have multiple connections to the same device (i.e. one console, one ssh, or one to each supervisor module, etc.) Returns: None Raises: N/A Expand source code class GenericDriver(Driver, BaseGenericDriver): def __init__( self, host: str, port: Optional[int] = None, auth_username: str = \"\", auth_password: str = \"\", auth_private_key: str = \"\", auth_private_key_passphrase: str = \"\", auth_strict_key: bool = True, auth_bypass: bool = False, timeout_socket: float = 15.0, timeout_transport: float = 30.0, timeout_ops: float = 30.0, comms_prompt_pattern: str = r\"^\\S{0,48}[#>$~@:\\]]\\s*$\", comms_return_char: str = \"\\n\", ssh_config_file: Union[str, bool] = False, ssh_known_hosts_file: Union[str, bool] = False, on_init: Optional[Callable[..., Any]] = None, on_open: Optional[Callable[..., Any]] = None, on_close: Optional[Callable[..., Any]] = None, transport: str = \"system\", transport_options: Optional[Dict[str, Any]] = None, channel_log: Union[str, bool, BytesIO] = False, channel_log_mode: str = \"write\", channel_lock: bool = False, logging_uid: str = \"\", ) -> None: super().__init__( host=host, port=port, auth_username=auth_username, auth_password=auth_password, auth_private_key=auth_private_key, auth_private_key_passphrase=auth_private_key_passphrase, auth_strict_key=auth_strict_key, auth_bypass=auth_bypass, timeout_socket=timeout_socket, timeout_transport=timeout_transport, timeout_ops=timeout_ops, comms_prompt_pattern=comms_prompt_pattern, comms_return_char=comms_return_char, ssh_config_file=ssh_config_file, ssh_known_hosts_file=ssh_known_hosts_file, on_init=on_init, on_open=on_open, on_close=on_close, transport=transport, transport_options=transport_options, channel_log=channel_log, channel_log_mode=channel_log_mode, channel_lock=channel_lock, logging_uid=logging_uid, ) def get_prompt(self) -> str: \"\"\" Convenience method to fetch prompt from the underlying Channel object Args: N/A Returns: str: string of the current prompt Raises: N/A \"\"\" # assigned/typed here as decorator indicates return of Any prompt: str = self.channel.get_prompt() return prompt @timeout_modifier def _send_command( self, command: str, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, eager: bool = False, timeout_ops: Optional[float] = None, ) -> Response: \"\"\" Send a command Private method so that we can handle `eager` w/out having to have that argument showing up in all the methods that super to the \"normal\" send_command method as we only ever want eager to be used for the plural options -- i.e. send_commands not send_command! Args: command: string to send to device in privilege exec mode strip_prompt: strip prompt or not, defaults to True (yes, strip the prompt) failed_when_contains: string or list of strings indicating failure if found in response eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed Returns: Response: Scrapli Response object Raises: ScrapliValueError: if _base_transport_args is None for some reason \"\"\" # decorator cares about timeout_ops, but nothing else does, assign to _ to appease linters _ = timeout_ops if not self._base_transport_args: # should not happen! :) raise ScrapliValueError(\"driver _base_transport_args not set for some reason\") response = self._pre_send_command( host=self._base_transport_args.host, command=command, failed_when_contains=failed_when_contains, ) raw_response, processed_response = self.channel.send_input( channel_input=command, strip_prompt=strip_prompt, eager=eager ) return self._post_send_command( raw_response=raw_response, processed_response=processed_response, response=response ) def send_command( self, command: str, *, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, timeout_ops: Optional[float] = None, ) -> Response: \"\"\" Send a command Args: command: string to send to device in privilege exec mode strip_prompt: strip prompt or not, defaults to True (yes, strip the prompt) failed_when_contains: string or list of strings indicating failure if found in response timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed Returns: Response: Scrapli Response object Raises: N/A \"\"\" response: Response = self._send_command( command=command, strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, timeout_ops=timeout_ops, ) return response def send_commands( self, commands: List[str], *, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, stop_on_failed: bool = False, eager: bool = False, timeout_ops: Optional[float] = None, ) -> MultiResponse: \"\"\" Send multiple commands Args: commands: list of strings to send to device in privilege exec mode strip_prompt: strip prompt or not, defaults to True (yes, strip the prompt) failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER COMMAND sent, not for the total of the commands being sent! Returns: MultiResponse: Scrapli MultiResponse object Raises: N/A \"\"\" responses = self._pre_send_commands(commands=commands) for command in commands[:-1]: response = self._send_command( command=command, strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, timeout_ops=timeout_ops, eager=eager, ) responses.append(response) if stop_on_failed and response.failed is True: # should we find the prompt here w/ get_prompt?? or just let subsequent operations # deal w/ finding that? future us problem? :) break else: # if we did *not* break (i.e. no failure and/or no stop_on_failed) send the last command # with eager = False -- this way we *always* find the prompt at the end of the commands response = self._send_command( command=commands[-1], strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, timeout_ops=timeout_ops, eager=False, ) responses.append(response) return responses def send_commands_from_file( self, file: str, *, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, stop_on_failed: bool = False, eager: bool = False, timeout_ops: Optional[float] = None, ) -> MultiResponse: \"\"\" Send command(s) from file Args: file: string path to file strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER COMMAND sent, not for the total of the commands being sent! Returns: MultiResponse: Scrapli MultiResponse object Raises: N/A \"\"\" commands = self._pre_send_from_file(file=file, caller=\"send_commands_from_file\") return self.send_commands( commands=commands, strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, stop_on_failed=stop_on_failed, eager=eager, timeout_ops=timeout_ops, ) @timeout_modifier def send_and_read( self, channel_input: str, *, expected_outputs: Optional[List[str]] = None, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, timeout_ops: Optional[float] = None, read_duration: float = 2.5, ) -> Response: \"\"\" Send an input and read outputs. Unlike \"normal\" scrapli behavior this method reads until the prompt(normal) OR until any of a list of expected outputs is seen, OR until the read duration is exceeded. This method does not care about/understand privilege levels. This *can* cause you some potential issues if not used carefully! Args: channel_input: input to send to the channel; intentionally named \"channel_input\" instead of \"command\" or \"config\" due to this method not caring about privilege levels expected_outputs: List of outputs to look for in device response; returns as soon as any of the outputs are seen strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed read_duration: float duration to read for Returns: Response: Scrapli Response object Raises: ScrapliValueError: if _base_transport_args is None for some reason \"\"\" # decorator cares about timeout_ops, but nothing else does, assign to _ to appease linters _ = timeout_ops if not self._base_transport_args: # should not happen! :) raise ScrapliValueError(\"driver _base_transport_args not set for some reason\") response = self._pre_send_command( host=self._base_transport_args.host, command=channel_input, failed_when_contains=failed_when_contains, ) raw_response, processed_response = self.channel.send_input_and_read( channel_input=channel_input, strip_prompt=strip_prompt, expected_outputs=expected_outputs, read_duration=read_duration, ) return self._post_send_command( raw_response=raw_response, processed_response=processed_response, response=response ) @timeout_modifier def send_interactive( self, interact_events: Union[List[Tuple[str, str]], List[Tuple[str, str, bool]]], *, failed_when_contains: Optional[Union[str, List[str]]] = None, privilege_level: str = \"\", timeout_ops: Optional[float] = None, interaction_complete_patterns: Optional[List[str]] = None, ) -> Response: \"\"\" Interact with a device with changing prompts per input. Used to interact with devices where prompts change per input, and where inputs may be hidden such as in the case of a password input. This can be used to respond to challenges from devices such as the confirmation for the command \"clear logging\" on IOSXE devices for example. You may have as many elements in the \"interact_events\" list as needed, and each element of that list should be a tuple of two or three elements. The first element is always the input to send as a string, the second should be the expected response as a string, and the optional third a bool for whether or not the input is \"hidden\" (i.e. password input) An example where we need this sort of capability: 1 2 3 4 5 6 7 8 9 10 11 12 3560CX#copy flash: scp: Source filename []? test1.txt Address or name of remote host []? 172.31.254.100 Destination username [carl]? Writing test1.txt Password: Password: Sink: C0644 639 test1.txt ! 639 bytes copied in 12.066 secs (53 bytes/sec) 3560CX# To accomplish this we can use the following: 1 2 3 4 5 6 7 8 9 interact = conn.channel.send_inputs_interact( [ (\"copy flash: scp:\", \"Source filename []?\", False), (\"test1.txt\", \"Address or name of remote host []?\", False), (\"172.31.254.100\", \"Destination username [carl]?\", False), (\"carl\", \"Password:\", False), (\"super_secure_password\", prompt, True), ] ) If we needed to deal with more prompts we could simply continue adding tuples to the list of interact \"events\". Args: interact_events: list of tuples containing the \"interactions\" with the device each list element must have an input and an expected response, and may have an optional bool for the third and final element -- the optional bool specifies if the input that is sent to the device is \"hidden\" (ex: password), if the hidden param is not provided it is assumed the input is \"normal\" (not hidden) failed_when_contains: list of strings that, if present in final output, represent a failed command/interaction privilege_level: ignored in this base class; for LSP reasons for subclasses timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER COMMAND sent, not for the total of the commands being sent! interaction_complete_patterns: list of patterns, that if seen, indicate the interactive \"session\" has ended and we should exit the interactive session. Returns: Response: scrapli Response object Raises: ScrapliValueError: if _base_transport_args is None for some reason \"\"\" # decorator cares about timeout_ops, but nothing else does, assign to _ to appease linters _ = timeout_ops # privilege level only matters \"up\" in the network driver layer _ = privilege_level if not self._base_transport_args: # should not happen! :) raise ScrapliValueError(\"driver _base_transport_args not set for some reason\") response = self._pre_send_interactive( host=self._base_transport_args.host, interact_events=interact_events, failed_when_contains=failed_when_contains, ) raw_response, processed_response = self.channel.send_inputs_interact( interact_events=interact_events, interaction_complete_patterns=interaction_complete_patterns, ) return self._post_send_command( raw_response=raw_response, processed_response=processed_response, response=response ) def read_callback( self, callbacks: List[\"ReadCallback\"], initial_input: Optional[str] = None, read_output: bytes = b\"\", read_delay: float = 0.1, read_timeout: float = -1.0, ) -> \"ReadCallbackReturnable\": r\"\"\" Read from a channel and react to the output with some callback. This method is kind of like an \"advanced\" send_interactive -- the idea is simple: send some \"stuff\" to the channel (optionally), and then read from the channel. Based on the output do something. The callbacks is a list of `ReadCallback` which is an object containing the actual callback to execute, some info about when to trigger that callback (also when *not* to trigger that callback), as well as some attributes to control the next (if desired) iteration of read_callback. You could in theory do basically everything with this method by chaining callbacks forever, but you probably don't want to do that for real! Example usage: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 from scrapli.driver.core import IOSXEDriver from scrapli.driver.generic.base_driver import ReadCallback from scrapli.driver.generic.sync_driver import GenericDriver device = { \"host\": \"rtr1\", \"auth_strict_key\": False, \"ssh_config_file\": True, } def callback_one(cls: GenericDriver, read_output: str): cls.acquire_priv(\"configuration\") cls.channel.send_return() def callback_two(cls: GenericDriver, read_output: str): print(f\"previous read output : {read_output}\") r = cls.send_command(\"show run | i hostname\") print(f\"result: {r.result}\") with IOSXEDriver(**device) as conn: callbacks = [ ReadCallback( contains=\"rtr1#\", callback=callback_one, name=\"call1\", case_insensitive=False ), ReadCallback( contains_re=r\"^rtr1\\(config\\)#\", callback=callback_two, complete=True, ) ] conn.read_callback(callbacks=callbacks, initial_input=\"show run | i hostname\") Args: callbacks: a list of ReadCallback objects initial_input: optional string to send to \"kick off\" the read_callback method read_output: optional bytes to append any new reads to read_delay: sleep interval between reads read_timeout: value to set the `transport_timeout` to for the duration of the reading portion of this method. If left default (-1.0) or set to anything below 0, the transport timeout value will be left alone (whatever the timeout_transport value is) otherwise, the provided value will be temporarily set as the timeout_transport for duration of the reading. Returns: ReadCallbackReturnable: either None or call to read_callback again Raises: ScrapliTimeout: if the read operation times out (base don the read_timeout value) during the read callback check. \"\"\" if initial_input is not None: self.channel.write(channel_input=f\"{initial_input}{self.comms_return_char}\") return self.read_callback(callbacks=callbacks, initial_input=None) original_transport_timeout = self.timeout_transport # if the read_timeout value is -1.0 or just less than 0, that indicates we should use # the \"normal\" transport timeout and not modify anything self.timeout_transport = read_timeout if read_timeout >= 0 else self.timeout_transport _read_delay = 0.1 if read_delay < = 0 else read_delay while True: try: read_output += self.channel.read() except ScrapliTimeout as exc: self.timeout_transport = original_transport_timeout raise ScrapliTimeout(\"timeout during read in read_callback operation\") from exc for callback in callbacks: _run_callback = callback.check(read_output=read_output) if ( callback.only_once is True and callback._triggered is True # pylint: disable=W0212 ): self.logger.warning( f\"callback {callback.name} matches but is set to 'only_once', \" \"skipping this callback\" ) continue if _run_callback is True: self.logger.info(f\"callback {callback.name} matched, executing\") self.timeout_transport = original_transport_timeout callback.run(driver=self) if callback.complete: self.logger.debug(\"callback complete is true, done with read_callback\") return None if callback.reset_output: read_output = b\"\" return self.read_callback( callbacks=callbacks, initial_input=None, read_output=read_output, read_delay=callback.next_delay, read_timeout=callback.next_timeout, ) time.sleep(_read_delay) Ancestors (in MRO) \u00b6 scrapli.driver.base.sync_driver.Driver scrapli.driver.base.base_driver.BaseDriver scrapli.driver.generic.base_driver.BaseGenericDriver Descendants \u00b6 scrapli.driver.network.sync_driver.NetworkDriver Methods \u00b6 get_prompt \u00b6 get_prompt(self) \u2011> str 1 2 3 4 5 6 7 8 9 10 Convenience method to fetch prompt from the underlying Channel object Args: N/A Returns: str: string of the current prompt Raises: N/A read_callback \u00b6 read_callback(self, callbacks: List[ForwardRef('ReadCallback')], initial_input: Optional[str] = None, read_output: bytes = b'', read_delay: float = 0.1, read_timeout: float = -1.0) \u2011> ReadCallbackReturnable 1 2 3 4 5 6 7 8 9 10 11 Read from a channel and react to the output with some callback. This method is kind of like an \"advanced\" send_interactive -- the idea is simple: send some \"stuff\" to the channel (optionally), and then read from the channel. Based on the output do something. The callbacks is a list of `ReadCallback` which is an object containing the actual callback to execute, some info about when to trigger that callback (also when *not* to trigger that callback), as well as some attributes to control the next (if desired) iteration of read_callback. You could in theory do basically everything with this method by chaining callbacks forever, but you probably don't want to do that for real! Example usage: from scrapli.driver.core import IOSXEDriver from scrapli.driver.generic.base_driver import ReadCallback from scrapli.driver.generic.sync_driver import GenericDriver device = { \"host\": \"rtr1\", \"auth_strict_key\": False, \"ssh_config_file\": True, } def callback_one(cls: GenericDriver, read_output: str): cls.acquire_priv(\"configuration\") cls.channel.send_return() def callback_two(cls: GenericDriver, read_output: str): print(f\"previous read output : {read_output}\") r = cls . send_command ( \" show run | i hostname \" ) print ( f \" result: {r.result} \" ) with IOSXEDriver(**device) as conn: callbacks = [ ReadCallback( contains=\"rtr1#\", callback=callback_one, name=\"call1\", case_insensitive=False ), ReadCallback( contains_re=r\"^rtr1(config)#\", callback=callback_two, complete=True, ) ] conn.read_callback(callbacks=callbacks, initial_input=\"show run | i hostname\") 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 Args: callbacks: a list of ReadCallback objects initial_input: optional string to send to \"kick off\" the read_callback method read_output: optional bytes to append any new reads to read_delay: sleep interval between reads read_timeout: value to set the `transport_timeout` to for the duration of the reading portion of this method. If left default (-1.0) or set to anything below 0, the transport timeout value will be left alone (whatever the timeout_transport value is) otherwise, the provided value will be temporarily set as the timeout_transport for duration of the reading. Returns: ReadCallbackReturnable: either None or call to read_callback again Raises: ScrapliTimeout: if the read operation times out (base don the read_timeout value) during the read callback check. send_and_read \u00b6 send_and_read(self, channel_input: str, *, expected_outputs: Optional[List[str]] = None, strip_prompt: bool = True, failed_when_contains: Union[str, List[str], ForwardRef(None)] = None, timeout_ops: Optional[float] = None, read_duration: float = 2.5) \u2011> scrapli.response.Response 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 Send an input and read outputs. Unlike \"normal\" scrapli behavior this method reads until the prompt(normal) OR until any of a list of expected outputs is seen, OR until the read duration is exceeded. This method does not care about/understand privilege levels. This *can* cause you some potential issues if not used carefully! Args: channel_input: input to send to the channel; intentionally named \"channel_input\" instead of \"command\" or \"config\" due to this method not caring about privilege levels expected_outputs: List of outputs to look for in device response; returns as soon as any of the outputs are seen strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed read_duration: float duration to read for Returns: Response: Scrapli Response object Raises: ScrapliValueError: if _base_transport_args is None for some reason send_command \u00b6 send_command(self, command: str, *, strip_prompt: bool = True, failed_when_contains: Union[str, List[str], ForwardRef(None)] = None, timeout_ops: Optional[float] = None) \u2011> scrapli.response.Response 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 Send a command Args: command: string to send to device in privilege exec mode strip_prompt: strip prompt or not, defaults to True (yes, strip the prompt) failed_when_contains: string or list of strings indicating failure if found in response timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed Returns: Response: Scrapli Response object Raises: N/A send_commands \u00b6 send_commands(self, commands: List[str], *, strip_prompt: bool = True, failed_when_contains: Union[str, List[str], ForwardRef(None)] = None, stop_on_failed: bool = False, eager: bool = False, timeout_ops: Optional[float] = None) \u2011> scrapli.response.MultiResponse 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 Send multiple commands Args: commands: list of strings to send to device in privilege exec mode strip_prompt: strip prompt or not, defaults to True (yes, strip the prompt) failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER COMMAND sent, not for the total of the commands being sent! Returns: MultiResponse: Scrapli MultiResponse object Raises: N/A send_commands_from_file \u00b6 send_commands_from_file(self, file: str, *, strip_prompt: bool = True, failed_when_contains: Union[str, List[str], ForwardRef(None)] = None, stop_on_failed: bool = False, eager: bool = False, timeout_ops: Optional[float] = None) \u2011> scrapli.response.MultiResponse 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 Send command(s) from file Args: file: string path to file strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER COMMAND sent, not for the total of the commands being sent! Returns: MultiResponse: Scrapli MultiResponse object Raises: N/A send_interactive \u00b6 send_interactive(self, interact_events: Union[List[Tuple[str, str]], List[Tuple[str, str, bool]]], *, failed_when_contains: Union[str, List[str], ForwardRef(None)] = None, privilege_level: str = '', timeout_ops: Optional[float] = None, interaction_complete_patterns: Optional[List[str]] = None) \u2011> scrapli.response.Response 1 2 3 4 5 6 7 8 9 10 11 Interact with a device with changing prompts per input. Used to interact with devices where prompts change per input, and where inputs may be hidden such as in the case of a password input. This can be used to respond to challenges from devices such as the confirmation for the command \"clear logging\" on IOSXE devices for example. You may have as many elements in the \"interact_events\" list as needed, and each element of that list should be a tuple of two or three elements. The first element is always the input to send as a string, the second should be the expected response as a string, and the optional third a bool for whether or not the input is \"hidden\" (i.e. password input) An example where we need this sort of capability: 3560CX#copy flash: scp: Source filename []? test1.txt Address or name of remote host []? 172.31.254.100 Destination username [carl]? Writing test1.txt Password: Password: Sink: C0644 639 test1.txt ! 639 bytes copied in 12.066 secs (53 bytes/sec) 3560CX# 1 To accomplish this we can use the following: interact = conn.channel.send_inputs_interact( [ (\"copy flash: scp:\", \"Source filename []?\", False), (\"test1.txt\", \"Address or name of remote host []?\", False), (\"172.31.254.100\", \"Destination username [carl]?\", False), (\"carl\", \"Password:\", False), (\"super_secure_password\", prompt, True), ] ) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 If we needed to deal with more prompts we could simply continue adding tuples to the list of interact \"events\". Args: interact_events: list of tuples containing the \"interactions\" with the device each list element must have an input and an expected response, and may have an optional bool for the third and final element -- the optional bool specifies if the input that is sent to the device is \"hidden\" (ex: password), if the hidden param is not provided it is assumed the input is \"normal\" (not hidden) failed_when_contains: list of strings that, if present in final output, represent a failed command/interaction privilege_level: ignored in this base class; for LSP reasons for subclasses timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER COMMAND sent, not for the total of the commands being sent! interaction_complete_patterns: list of patterns, that if seen, indicate the interactive \"session\" has ended and we should exit the interactive session. Returns: Response: scrapli Response object Raises: ScrapliValueError: if _base_transport_args is None for some reason","title":"Sync Driver"},{"location":"api_docs/driver/generic/sync_driver/#module-scraplidrivergenericsync_driver","text":"scrapli.driver.generic.sync_driver Expand source code \"\"\"scrapli.driver.generic.sync_driver\"\"\" import time from io import BytesIO from typing import TYPE_CHECKING, Any, Callable, Dict, List, Optional, Tuple, Union from scrapli.decorators import timeout_modifier from scrapli.driver import Driver from scrapli.driver.generic.base_driver import BaseGenericDriver from scrapli.exceptions import ScrapliTimeout, ScrapliValueError from scrapli.response import MultiResponse, Response if TYPE_CHECKING: from scrapli.driver.generic.base_driver import ( # pragma: no cover ReadCallback, ReadCallbackReturnable, ) class GenericDriver(Driver, BaseGenericDriver): def __init__( self, host: str, port: Optional[int] = None, auth_username: str = \"\", auth_password: str = \"\", auth_private_key: str = \"\", auth_private_key_passphrase: str = \"\", auth_strict_key: bool = True, auth_bypass: bool = False, timeout_socket: float = 15.0, timeout_transport: float = 30.0, timeout_ops: float = 30.0, comms_prompt_pattern: str = r\"^\\S{0,48}[#>$~@:\\]]\\s*$\", comms_return_char: str = \"\\n\", ssh_config_file: Union[str, bool] = False, ssh_known_hosts_file: Union[str, bool] = False, on_init: Optional[Callable[..., Any]] = None, on_open: Optional[Callable[..., Any]] = None, on_close: Optional[Callable[..., Any]] = None, transport: str = \"system\", transport_options: Optional[Dict[str, Any]] = None, channel_log: Union[str, bool, BytesIO] = False, channel_log_mode: str = \"write\", channel_lock: bool = False, logging_uid: str = \"\", ) -> None: super().__init__( host=host, port=port, auth_username=auth_username, auth_password=auth_password, auth_private_key=auth_private_key, auth_private_key_passphrase=auth_private_key_passphrase, auth_strict_key=auth_strict_key, auth_bypass=auth_bypass, timeout_socket=timeout_socket, timeout_transport=timeout_transport, timeout_ops=timeout_ops, comms_prompt_pattern=comms_prompt_pattern, comms_return_char=comms_return_char, ssh_config_file=ssh_config_file, ssh_known_hosts_file=ssh_known_hosts_file, on_init=on_init, on_open=on_open, on_close=on_close, transport=transport, transport_options=transport_options, channel_log=channel_log, channel_log_mode=channel_log_mode, channel_lock=channel_lock, logging_uid=logging_uid, ) def get_prompt(self) -> str: \"\"\" Convenience method to fetch prompt from the underlying Channel object Args: N/A Returns: str: string of the current prompt Raises: N/A \"\"\" # assigned/typed here as decorator indicates return of Any prompt: str = self.channel.get_prompt() return prompt @timeout_modifier def _send_command( self, command: str, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, eager: bool = False, timeout_ops: Optional[float] = None, ) -> Response: \"\"\" Send a command Private method so that we can handle `eager` w/out having to have that argument showing up in all the methods that super to the \"normal\" send_command method as we only ever want eager to be used for the plural options -- i.e. send_commands not send_command! Args: command: string to send to device in privilege exec mode strip_prompt: strip prompt or not, defaults to True (yes, strip the prompt) failed_when_contains: string or list of strings indicating failure if found in response eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed Returns: Response: Scrapli Response object Raises: ScrapliValueError: if _base_transport_args is None for some reason \"\"\" # decorator cares about timeout_ops, but nothing else does, assign to _ to appease linters _ = timeout_ops if not self._base_transport_args: # should not happen! :) raise ScrapliValueError(\"driver _base_transport_args not set for some reason\") response = self._pre_send_command( host=self._base_transport_args.host, command=command, failed_when_contains=failed_when_contains, ) raw_response, processed_response = self.channel.send_input( channel_input=command, strip_prompt=strip_prompt, eager=eager ) return self._post_send_command( raw_response=raw_response, processed_response=processed_response, response=response ) def send_command( self, command: str, *, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, timeout_ops: Optional[float] = None, ) -> Response: \"\"\" Send a command Args: command: string to send to device in privilege exec mode strip_prompt: strip prompt or not, defaults to True (yes, strip the prompt) failed_when_contains: string or list of strings indicating failure if found in response timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed Returns: Response: Scrapli Response object Raises: N/A \"\"\" response: Response = self._send_command( command=command, strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, timeout_ops=timeout_ops, ) return response def send_commands( self, commands: List[str], *, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, stop_on_failed: bool = False, eager: bool = False, timeout_ops: Optional[float] = None, ) -> MultiResponse: \"\"\" Send multiple commands Args: commands: list of strings to send to device in privilege exec mode strip_prompt: strip prompt or not, defaults to True (yes, strip the prompt) failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER COMMAND sent, not for the total of the commands being sent! Returns: MultiResponse: Scrapli MultiResponse object Raises: N/A \"\"\" responses = self._pre_send_commands(commands=commands) for command in commands[:-1]: response = self._send_command( command=command, strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, timeout_ops=timeout_ops, eager=eager, ) responses.append(response) if stop_on_failed and response.failed is True: # should we find the prompt here w/ get_prompt?? or just let subsequent operations # deal w/ finding that? future us problem? :) break else: # if we did *not* break (i.e. no failure and/or no stop_on_failed) send the last command # with eager = False -- this way we *always* find the prompt at the end of the commands response = self._send_command( command=commands[-1], strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, timeout_ops=timeout_ops, eager=False, ) responses.append(response) return responses def send_commands_from_file( self, file: str, *, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, stop_on_failed: bool = False, eager: bool = False, timeout_ops: Optional[float] = None, ) -> MultiResponse: \"\"\" Send command(s) from file Args: file: string path to file strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER COMMAND sent, not for the total of the commands being sent! Returns: MultiResponse: Scrapli MultiResponse object Raises: N/A \"\"\" commands = self._pre_send_from_file(file=file, caller=\"send_commands_from_file\") return self.send_commands( commands=commands, strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, stop_on_failed=stop_on_failed, eager=eager, timeout_ops=timeout_ops, ) @timeout_modifier def send_and_read( self, channel_input: str, *, expected_outputs: Optional[List[str]] = None, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, timeout_ops: Optional[float] = None, read_duration: float = 2.5, ) -> Response: \"\"\" Send an input and read outputs. Unlike \"normal\" scrapli behavior this method reads until the prompt(normal) OR until any of a list of expected outputs is seen, OR until the read duration is exceeded. This method does not care about/understand privilege levels. This *can* cause you some potential issues if not used carefully! Args: channel_input: input to send to the channel; intentionally named \"channel_input\" instead of \"command\" or \"config\" due to this method not caring about privilege levels expected_outputs: List of outputs to look for in device response; returns as soon as any of the outputs are seen strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed read_duration: float duration to read for Returns: Response: Scrapli Response object Raises: ScrapliValueError: if _base_transport_args is None for some reason \"\"\" # decorator cares about timeout_ops, but nothing else does, assign to _ to appease linters _ = timeout_ops if not self._base_transport_args: # should not happen! :) raise ScrapliValueError(\"driver _base_transport_args not set for some reason\") response = self._pre_send_command( host=self._base_transport_args.host, command=channel_input, failed_when_contains=failed_when_contains, ) raw_response, processed_response = self.channel.send_input_and_read( channel_input=channel_input, strip_prompt=strip_prompt, expected_outputs=expected_outputs, read_duration=read_duration, ) return self._post_send_command( raw_response=raw_response, processed_response=processed_response, response=response ) @timeout_modifier def send_interactive( self, interact_events: Union[List[Tuple[str, str]], List[Tuple[str, str, bool]]], *, failed_when_contains: Optional[Union[str, List[str]]] = None, privilege_level: str = \"\", timeout_ops: Optional[float] = None, interaction_complete_patterns: Optional[List[str]] = None, ) -> Response: \"\"\" Interact with a device with changing prompts per input. Used to interact with devices where prompts change per input, and where inputs may be hidden such as in the case of a password input. This can be used to respond to challenges from devices such as the confirmation for the command \"clear logging\" on IOSXE devices for example. You may have as many elements in the \"interact_events\" list as needed, and each element of that list should be a tuple of two or three elements. The first element is always the input to send as a string, the second should be the expected response as a string, and the optional third a bool for whether or not the input is \"hidden\" (i.e. password input) An example where we need this sort of capability: 1 2 3 4 5 6 7 8 9 10 11 12 3560CX#copy flash: scp: Source filename []? test1.txt Address or name of remote host []? 172.31.254.100 Destination username [carl]? Writing test1.txt Password: Password: Sink: C0644 639 test1.txt ! 639 bytes copied in 12.066 secs (53 bytes/sec) 3560CX# To accomplish this we can use the following: 1 2 3 4 5 6 7 8 9 interact = conn.channel.send_inputs_interact( [ (\"copy flash: scp:\", \"Source filename []?\", False), (\"test1.txt\", \"Address or name of remote host []?\", False), (\"172.31.254.100\", \"Destination username [carl]?\", False), (\"carl\", \"Password:\", False), (\"super_secure_password\", prompt, True), ] ) If we needed to deal with more prompts we could simply continue adding tuples to the list of interact \"events\". Args: interact_events: list of tuples containing the \"interactions\" with the device each list element must have an input and an expected response, and may have an optional bool for the third and final element -- the optional bool specifies if the input that is sent to the device is \"hidden\" (ex: password), if the hidden param is not provided it is assumed the input is \"normal\" (not hidden) failed_when_contains: list of strings that, if present in final output, represent a failed command/interaction privilege_level: ignored in this base class; for LSP reasons for subclasses timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER COMMAND sent, not for the total of the commands being sent! interaction_complete_patterns: list of patterns, that if seen, indicate the interactive \"session\" has ended and we should exit the interactive session. Returns: Response: scrapli Response object Raises: ScrapliValueError: if _base_transport_args is None for some reason \"\"\" # decorator cares about timeout_ops, but nothing else does, assign to _ to appease linters _ = timeout_ops # privilege level only matters \"up\" in the network driver layer _ = privilege_level if not self._base_transport_args: # should not happen! :) raise ScrapliValueError(\"driver _base_transport_args not set for some reason\") response = self._pre_send_interactive( host=self._base_transport_args.host, interact_events=interact_events, failed_when_contains=failed_when_contains, ) raw_response, processed_response = self.channel.send_inputs_interact( interact_events=interact_events, interaction_complete_patterns=interaction_complete_patterns, ) return self._post_send_command( raw_response=raw_response, processed_response=processed_response, response=response ) def read_callback( self, callbacks: List[\"ReadCallback\"], initial_input: Optional[str] = None, read_output: bytes = b\"\", read_delay: float = 0.1, read_timeout: float = -1.0, ) -> \"ReadCallbackReturnable\": r\"\"\" Read from a channel and react to the output with some callback. This method is kind of like an \"advanced\" send_interactive -- the idea is simple: send some \"stuff\" to the channel (optionally), and then read from the channel. Based on the output do something. The callbacks is a list of `ReadCallback` which is an object containing the actual callback to execute, some info about when to trigger that callback (also when *not* to trigger that callback), as well as some attributes to control the next (if desired) iteration of read_callback. You could in theory do basically everything with this method by chaining callbacks forever, but you probably don't want to do that for real! Example usage: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 from scrapli.driver.core import IOSXEDriver from scrapli.driver.generic.base_driver import ReadCallback from scrapli.driver.generic.sync_driver import GenericDriver device = { \"host\": \"rtr1\", \"auth_strict_key\": False, \"ssh_config_file\": True, } def callback_one(cls: GenericDriver, read_output: str): cls.acquire_priv(\"configuration\") cls.channel.send_return() def callback_two(cls: GenericDriver, read_output: str): print(f\"previous read output : {read_output}\") r = cls.send_command(\"show run | i hostname\") print(f\"result: {r.result}\") with IOSXEDriver(**device) as conn: callbacks = [ ReadCallback( contains=\"rtr1#\", callback=callback_one, name=\"call1\", case_insensitive=False ), ReadCallback( contains_re=r\"^rtr1\\(config\\)#\", callback=callback_two, complete=True, ) ] conn.read_callback(callbacks=callbacks, initial_input=\"show run | i hostname\") Args: callbacks: a list of ReadCallback objects initial_input: optional string to send to \"kick off\" the read_callback method read_output: optional bytes to append any new reads to read_delay: sleep interval between reads read_timeout: value to set the `transport_timeout` to for the duration of the reading portion of this method. If left default (-1.0) or set to anything below 0, the transport timeout value will be left alone (whatever the timeout_transport value is) otherwise, the provided value will be temporarily set as the timeout_transport for duration of the reading. Returns: ReadCallbackReturnable: either None or call to read_callback again Raises: ScrapliTimeout: if the read operation times out (base don the read_timeout value) during the read callback check. \"\"\" if initial_input is not None: self.channel.write(channel_input=f\"{initial_input}{self.comms_return_char}\") return self.read_callback(callbacks=callbacks, initial_input=None) original_transport_timeout = self.timeout_transport # if the read_timeout value is -1.0 or just less than 0, that indicates we should use # the \"normal\" transport timeout and not modify anything self.timeout_transport = read_timeout if read_timeout >= 0 else self.timeout_transport _read_delay = 0.1 if read_delay < = 0 else read_delay while True: try: read_output += self.channel.read() except ScrapliTimeout as exc: self.timeout_transport = original_transport_timeout raise ScrapliTimeout(\"timeout during read in read_callback operation\") from exc for callback in callbacks: _run_callback = callback.check(read_output=read_output) if ( callback.only_once is True and callback._triggered is True # pylint: disable=W0212 ): self.logger.warning( f\"callback {callback.name} matches but is set to 'only_once', \" \"skipping this callback\" ) continue if _run_callback is True: self.logger.info(f\"callback {callback.name} matched, executing\") self.timeout_transport = original_transport_timeout callback.run(driver=self) if callback.complete: self.logger.debug(\"callback complete is true, done with read_callback\") return None if callback.reset_output: read_output = b\"\" return self.read_callback( callbacks=callbacks, initial_input=None, read_output=read_output, read_delay=callback.next_delay, read_timeout=callback.next_timeout, ) time.sleep(_read_delay)","title":"Module scrapli.driver.generic.sync_driver"},{"location":"api_docs/driver/generic/sync_driver/#classes","text":"","title":"Classes"},{"location":"api_docs/driver/generic/sync_driver/#genericdriver","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 BaseDriver Object BaseDriver is the root for all Scrapli driver classes. The synchronous and asyncio driver base driver classes can be used to provide a semi-pexpect like experience over top of whatever transport a user prefers. Generally, however, the base driver classes should not be used directly. It is best to use the GenericDriver (or AsyncGenericDriver) or NetworkDriver (or AsyncNetworkDriver) sub-classes of the base drivers. Args: host: host ip/name to connect to port: port to connect to auth_username: username for authentication auth_private_key: path to private key for authentication auth_private_key_passphrase: passphrase for decrypting ssh key if necessary auth_password: password for authentication auth_strict_key: strict host checking or not auth_bypass: bypass \"in channel\" authentication -- only supported with telnet, asynctelnet, and system transport plugins timeout_socket: timeout for establishing socket/initial connection in seconds timeout_transport: timeout for ssh|telnet transport in seconds timeout_ops: timeout for ssh channel operations comms_prompt_pattern: raw string regex pattern -- preferably use `^` and `$` anchors! this is the single most important attribute here! if this does not match a prompt, scrapli will not work! IMPORTANT: regex search uses multi-line + case insensitive flags. multi-line allows for highly reliably matching for prompts however we do NOT strip trailing whitespace for each line, so be sure to add '\\\\s?' or similar if your device needs that. This should be mostly sorted for you if using network drivers (i.e. `IOSXEDriver`). Lastly, the case insensitive is just a convenience factor so i can be lazy. comms_return_char: character to use to send returns to host ssh_config_file: string to path for ssh config file, True to use default ssh config file or False to ignore default ssh config file ssh_known_hosts_file: string to path for ssh known hosts file, True to use default known file locations. Only applicable/needed if `auth_strict_key` is set to True on_init: callable that accepts the class instance as its only argument. this callable, if provided, is executed as the last step of object instantiation -- its purpose is primarily to provide a mechanism for scrapli community platforms to have an easy way to modify initialization arguments/object attributes without needing to create a class that extends the driver, instead allowing the community platforms to simply build from the GenericDriver or NetworkDriver classes, and pass this callable to do things such as appending to a username (looking at you RouterOS!!). Note that this is *always* a synchronous function (even for asyncio drivers)! on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar transport: name of the transport plugin to use for the actual telnet/ssh/netconf connection. Available \"core\" transports are: - system - telnet - asynctelnet - ssh2 - paramiko - asyncssh Please see relevant transport plugin section for details. Additionally third party transport plugins may be available. transport_options: dictionary of options to pass to selected transport class; see docs for given transport class for details of what to pass here channel_lock: True/False to lock the channel (threading.Lock/asyncio.Lock) during any channel operations, defaults to False channel_log: True/False or a string path to a file of where to write out channel logs -- these are not \"logs\" in the normal logging module sense, but only the output that is read from the channel. In other words, the output of the channel log should look similar to what you would see as a human connecting to a device channel_log_mode: \"write\"|\"append\", all other values will raise ValueError, does what it sounds like it should by setting the channel log to the provided mode logging_uid: unique identifier (string) to associate to log messages; useful if you have multiple connections to the same device (i.e. one console, one ssh, or one to each supervisor module, etc.) Returns: None Raises: N/A Expand source code class GenericDriver(Driver, BaseGenericDriver): def __init__( self, host: str, port: Optional[int] = None, auth_username: str = \"\", auth_password: str = \"\", auth_private_key: str = \"\", auth_private_key_passphrase: str = \"\", auth_strict_key: bool = True, auth_bypass: bool = False, timeout_socket: float = 15.0, timeout_transport: float = 30.0, timeout_ops: float = 30.0, comms_prompt_pattern: str = r\"^\\S{0,48}[#>$~@:\\]]\\s*$\", comms_return_char: str = \"\\n\", ssh_config_file: Union[str, bool] = False, ssh_known_hosts_file: Union[str, bool] = False, on_init: Optional[Callable[..., Any]] = None, on_open: Optional[Callable[..., Any]] = None, on_close: Optional[Callable[..., Any]] = None, transport: str = \"system\", transport_options: Optional[Dict[str, Any]] = None, channel_log: Union[str, bool, BytesIO] = False, channel_log_mode: str = \"write\", channel_lock: bool = False, logging_uid: str = \"\", ) -> None: super().__init__( host=host, port=port, auth_username=auth_username, auth_password=auth_password, auth_private_key=auth_private_key, auth_private_key_passphrase=auth_private_key_passphrase, auth_strict_key=auth_strict_key, auth_bypass=auth_bypass, timeout_socket=timeout_socket, timeout_transport=timeout_transport, timeout_ops=timeout_ops, comms_prompt_pattern=comms_prompt_pattern, comms_return_char=comms_return_char, ssh_config_file=ssh_config_file, ssh_known_hosts_file=ssh_known_hosts_file, on_init=on_init, on_open=on_open, on_close=on_close, transport=transport, transport_options=transport_options, channel_log=channel_log, channel_log_mode=channel_log_mode, channel_lock=channel_lock, logging_uid=logging_uid, ) def get_prompt(self) -> str: \"\"\" Convenience method to fetch prompt from the underlying Channel object Args: N/A Returns: str: string of the current prompt Raises: N/A \"\"\" # assigned/typed here as decorator indicates return of Any prompt: str = self.channel.get_prompt() return prompt @timeout_modifier def _send_command( self, command: str, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, eager: bool = False, timeout_ops: Optional[float] = None, ) -> Response: \"\"\" Send a command Private method so that we can handle `eager` w/out having to have that argument showing up in all the methods that super to the \"normal\" send_command method as we only ever want eager to be used for the plural options -- i.e. send_commands not send_command! Args: command: string to send to device in privilege exec mode strip_prompt: strip prompt or not, defaults to True (yes, strip the prompt) failed_when_contains: string or list of strings indicating failure if found in response eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed Returns: Response: Scrapli Response object Raises: ScrapliValueError: if _base_transport_args is None for some reason \"\"\" # decorator cares about timeout_ops, but nothing else does, assign to _ to appease linters _ = timeout_ops if not self._base_transport_args: # should not happen! :) raise ScrapliValueError(\"driver _base_transport_args not set for some reason\") response = self._pre_send_command( host=self._base_transport_args.host, command=command, failed_when_contains=failed_when_contains, ) raw_response, processed_response = self.channel.send_input( channel_input=command, strip_prompt=strip_prompt, eager=eager ) return self._post_send_command( raw_response=raw_response, processed_response=processed_response, response=response ) def send_command( self, command: str, *, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, timeout_ops: Optional[float] = None, ) -> Response: \"\"\" Send a command Args: command: string to send to device in privilege exec mode strip_prompt: strip prompt or not, defaults to True (yes, strip the prompt) failed_when_contains: string or list of strings indicating failure if found in response timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed Returns: Response: Scrapli Response object Raises: N/A \"\"\" response: Response = self._send_command( command=command, strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, timeout_ops=timeout_ops, ) return response def send_commands( self, commands: List[str], *, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, stop_on_failed: bool = False, eager: bool = False, timeout_ops: Optional[float] = None, ) -> MultiResponse: \"\"\" Send multiple commands Args: commands: list of strings to send to device in privilege exec mode strip_prompt: strip prompt or not, defaults to True (yes, strip the prompt) failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER COMMAND sent, not for the total of the commands being sent! Returns: MultiResponse: Scrapli MultiResponse object Raises: N/A \"\"\" responses = self._pre_send_commands(commands=commands) for command in commands[:-1]: response = self._send_command( command=command, strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, timeout_ops=timeout_ops, eager=eager, ) responses.append(response) if stop_on_failed and response.failed is True: # should we find the prompt here w/ get_prompt?? or just let subsequent operations # deal w/ finding that? future us problem? :) break else: # if we did *not* break (i.e. no failure and/or no stop_on_failed) send the last command # with eager = False -- this way we *always* find the prompt at the end of the commands response = self._send_command( command=commands[-1], strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, timeout_ops=timeout_ops, eager=False, ) responses.append(response) return responses def send_commands_from_file( self, file: str, *, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, stop_on_failed: bool = False, eager: bool = False, timeout_ops: Optional[float] = None, ) -> MultiResponse: \"\"\" Send command(s) from file Args: file: string path to file strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER COMMAND sent, not for the total of the commands being sent! Returns: MultiResponse: Scrapli MultiResponse object Raises: N/A \"\"\" commands = self._pre_send_from_file(file=file, caller=\"send_commands_from_file\") return self.send_commands( commands=commands, strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, stop_on_failed=stop_on_failed, eager=eager, timeout_ops=timeout_ops, ) @timeout_modifier def send_and_read( self, channel_input: str, *, expected_outputs: Optional[List[str]] = None, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, timeout_ops: Optional[float] = None, read_duration: float = 2.5, ) -> Response: \"\"\" Send an input and read outputs. Unlike \"normal\" scrapli behavior this method reads until the prompt(normal) OR until any of a list of expected outputs is seen, OR until the read duration is exceeded. This method does not care about/understand privilege levels. This *can* cause you some potential issues if not used carefully! Args: channel_input: input to send to the channel; intentionally named \"channel_input\" instead of \"command\" or \"config\" due to this method not caring about privilege levels expected_outputs: List of outputs to look for in device response; returns as soon as any of the outputs are seen strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed read_duration: float duration to read for Returns: Response: Scrapli Response object Raises: ScrapliValueError: if _base_transport_args is None for some reason \"\"\" # decorator cares about timeout_ops, but nothing else does, assign to _ to appease linters _ = timeout_ops if not self._base_transport_args: # should not happen! :) raise ScrapliValueError(\"driver _base_transport_args not set for some reason\") response = self._pre_send_command( host=self._base_transport_args.host, command=channel_input, failed_when_contains=failed_when_contains, ) raw_response, processed_response = self.channel.send_input_and_read( channel_input=channel_input, strip_prompt=strip_prompt, expected_outputs=expected_outputs, read_duration=read_duration, ) return self._post_send_command( raw_response=raw_response, processed_response=processed_response, response=response ) @timeout_modifier def send_interactive( self, interact_events: Union[List[Tuple[str, str]], List[Tuple[str, str, bool]]], *, failed_when_contains: Optional[Union[str, List[str]]] = None, privilege_level: str = \"\", timeout_ops: Optional[float] = None, interaction_complete_patterns: Optional[List[str]] = None, ) -> Response: \"\"\" Interact with a device with changing prompts per input. Used to interact with devices where prompts change per input, and where inputs may be hidden such as in the case of a password input. This can be used to respond to challenges from devices such as the confirmation for the command \"clear logging\" on IOSXE devices for example. You may have as many elements in the \"interact_events\" list as needed, and each element of that list should be a tuple of two or three elements. The first element is always the input to send as a string, the second should be the expected response as a string, and the optional third a bool for whether or not the input is \"hidden\" (i.e. password input) An example where we need this sort of capability: 1 2 3 4 5 6 7 8 9 10 11 12 3560CX#copy flash: scp: Source filename []? test1.txt Address or name of remote host []? 172.31.254.100 Destination username [carl]? Writing test1.txt Password: Password: Sink: C0644 639 test1.txt ! 639 bytes copied in 12.066 secs (53 bytes/sec) 3560CX# To accomplish this we can use the following: 1 2 3 4 5 6 7 8 9 interact = conn.channel.send_inputs_interact( [ (\"copy flash: scp:\", \"Source filename []?\", False), (\"test1.txt\", \"Address or name of remote host []?\", False), (\"172.31.254.100\", \"Destination username [carl]?\", False), (\"carl\", \"Password:\", False), (\"super_secure_password\", prompt, True), ] ) If we needed to deal with more prompts we could simply continue adding tuples to the list of interact \"events\". Args: interact_events: list of tuples containing the \"interactions\" with the device each list element must have an input and an expected response, and may have an optional bool for the third and final element -- the optional bool specifies if the input that is sent to the device is \"hidden\" (ex: password), if the hidden param is not provided it is assumed the input is \"normal\" (not hidden) failed_when_contains: list of strings that, if present in final output, represent a failed command/interaction privilege_level: ignored in this base class; for LSP reasons for subclasses timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER COMMAND sent, not for the total of the commands being sent! interaction_complete_patterns: list of patterns, that if seen, indicate the interactive \"session\" has ended and we should exit the interactive session. Returns: Response: scrapli Response object Raises: ScrapliValueError: if _base_transport_args is None for some reason \"\"\" # decorator cares about timeout_ops, but nothing else does, assign to _ to appease linters _ = timeout_ops # privilege level only matters \"up\" in the network driver layer _ = privilege_level if not self._base_transport_args: # should not happen! :) raise ScrapliValueError(\"driver _base_transport_args not set for some reason\") response = self._pre_send_interactive( host=self._base_transport_args.host, interact_events=interact_events, failed_when_contains=failed_when_contains, ) raw_response, processed_response = self.channel.send_inputs_interact( interact_events=interact_events, interaction_complete_patterns=interaction_complete_patterns, ) return self._post_send_command( raw_response=raw_response, processed_response=processed_response, response=response ) def read_callback( self, callbacks: List[\"ReadCallback\"], initial_input: Optional[str] = None, read_output: bytes = b\"\", read_delay: float = 0.1, read_timeout: float = -1.0, ) -> \"ReadCallbackReturnable\": r\"\"\" Read from a channel and react to the output with some callback. This method is kind of like an \"advanced\" send_interactive -- the idea is simple: send some \"stuff\" to the channel (optionally), and then read from the channel. Based on the output do something. The callbacks is a list of `ReadCallback` which is an object containing the actual callback to execute, some info about when to trigger that callback (also when *not* to trigger that callback), as well as some attributes to control the next (if desired) iteration of read_callback. You could in theory do basically everything with this method by chaining callbacks forever, but you probably don't want to do that for real! Example usage: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 from scrapli.driver.core import IOSXEDriver from scrapli.driver.generic.base_driver import ReadCallback from scrapli.driver.generic.sync_driver import GenericDriver device = { \"host\": \"rtr1\", \"auth_strict_key\": False, \"ssh_config_file\": True, } def callback_one(cls: GenericDriver, read_output: str): cls.acquire_priv(\"configuration\") cls.channel.send_return() def callback_two(cls: GenericDriver, read_output: str): print(f\"previous read output : {read_output}\") r = cls.send_command(\"show run | i hostname\") print(f\"result: {r.result}\") with IOSXEDriver(**device) as conn: callbacks = [ ReadCallback( contains=\"rtr1#\", callback=callback_one, name=\"call1\", case_insensitive=False ), ReadCallback( contains_re=r\"^rtr1\\(config\\)#\", callback=callback_two, complete=True, ) ] conn.read_callback(callbacks=callbacks, initial_input=\"show run | i hostname\") Args: callbacks: a list of ReadCallback objects initial_input: optional string to send to \"kick off\" the read_callback method read_output: optional bytes to append any new reads to read_delay: sleep interval between reads read_timeout: value to set the `transport_timeout` to for the duration of the reading portion of this method. If left default (-1.0) or set to anything below 0, the transport timeout value will be left alone (whatever the timeout_transport value is) otherwise, the provided value will be temporarily set as the timeout_transport for duration of the reading. Returns: ReadCallbackReturnable: either None or call to read_callback again Raises: ScrapliTimeout: if the read operation times out (base don the read_timeout value) during the read callback check. \"\"\" if initial_input is not None: self.channel.write(channel_input=f\"{initial_input}{self.comms_return_char}\") return self.read_callback(callbacks=callbacks, initial_input=None) original_transport_timeout = self.timeout_transport # if the read_timeout value is -1.0 or just less than 0, that indicates we should use # the \"normal\" transport timeout and not modify anything self.timeout_transport = read_timeout if read_timeout >= 0 else self.timeout_transport _read_delay = 0.1 if read_delay < = 0 else read_delay while True: try: read_output += self.channel.read() except ScrapliTimeout as exc: self.timeout_transport = original_transport_timeout raise ScrapliTimeout(\"timeout during read in read_callback operation\") from exc for callback in callbacks: _run_callback = callback.check(read_output=read_output) if ( callback.only_once is True and callback._triggered is True # pylint: disable=W0212 ): self.logger.warning( f\"callback {callback.name} matches but is set to 'only_once', \" \"skipping this callback\" ) continue if _run_callback is True: self.logger.info(f\"callback {callback.name} matched, executing\") self.timeout_transport = original_transport_timeout callback.run(driver=self) if callback.complete: self.logger.debug(\"callback complete is true, done with read_callback\") return None if callback.reset_output: read_output = b\"\" return self.read_callback( callbacks=callbacks, initial_input=None, read_output=read_output, read_delay=callback.next_delay, read_timeout=callback.next_timeout, ) time.sleep(_read_delay)","title":"GenericDriver"},{"location":"api_docs/driver/generic/sync_driver/#ancestors-in-mro","text":"scrapli.driver.base.sync_driver.Driver scrapli.driver.base.base_driver.BaseDriver scrapli.driver.generic.base_driver.BaseGenericDriver","title":"Ancestors (in MRO)"},{"location":"api_docs/driver/generic/sync_driver/#descendants","text":"scrapli.driver.network.sync_driver.NetworkDriver","title":"Descendants"},{"location":"api_docs/driver/generic/sync_driver/#methods","text":"","title":"Methods"},{"location":"api_docs/driver/generic/sync_driver/#get_prompt","text":"get_prompt(self) \u2011> str 1 2 3 4 5 6 7 8 9 10 Convenience method to fetch prompt from the underlying Channel object Args: N/A Returns: str: string of the current prompt Raises: N/A","title":"get_prompt"},{"location":"api_docs/driver/generic/sync_driver/#read_callback","text":"read_callback(self, callbacks: List[ForwardRef('ReadCallback')], initial_input: Optional[str] = None, read_output: bytes = b'', read_delay: float = 0.1, read_timeout: float = -1.0) \u2011> ReadCallbackReturnable 1 2 3 4 5 6 7 8 9 10 11 Read from a channel and react to the output with some callback. This method is kind of like an \"advanced\" send_interactive -- the idea is simple: send some \"stuff\" to the channel (optionally), and then read from the channel. Based on the output do something. The callbacks is a list of `ReadCallback` which is an object containing the actual callback to execute, some info about when to trigger that callback (also when *not* to trigger that callback), as well as some attributes to control the next (if desired) iteration of read_callback. You could in theory do basically everything with this method by chaining callbacks forever, but you probably don't want to do that for real! Example usage: from scrapli.driver.core import IOSXEDriver from scrapli.driver.generic.base_driver import ReadCallback from scrapli.driver.generic.sync_driver import GenericDriver device = { \"host\": \"rtr1\", \"auth_strict_key\": False, \"ssh_config_file\": True, } def callback_one(cls: GenericDriver, read_output: str): cls.acquire_priv(\"configuration\") cls.channel.send_return() def callback_two(cls: GenericDriver, read_output: str): print(f\"previous read output : {read_output}\") r = cls . send_command ( \" show run | i hostname \" ) print ( f \" result: {r.result} \" ) with IOSXEDriver(**device) as conn: callbacks = [ ReadCallback( contains=\"rtr1#\", callback=callback_one, name=\"call1\", case_insensitive=False ), ReadCallback( contains_re=r\"^rtr1(config)#\", callback=callback_two, complete=True, ) ] conn.read_callback(callbacks=callbacks, initial_input=\"show run | i hostname\") 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 Args: callbacks: a list of ReadCallback objects initial_input: optional string to send to \"kick off\" the read_callback method read_output: optional bytes to append any new reads to read_delay: sleep interval between reads read_timeout: value to set the `transport_timeout` to for the duration of the reading portion of this method. If left default (-1.0) or set to anything below 0, the transport timeout value will be left alone (whatever the timeout_transport value is) otherwise, the provided value will be temporarily set as the timeout_transport for duration of the reading. Returns: ReadCallbackReturnable: either None or call to read_callback again Raises: ScrapliTimeout: if the read operation times out (base don the read_timeout value) during the read callback check.","title":"read_callback"},{"location":"api_docs/driver/generic/sync_driver/#send_and_read","text":"send_and_read(self, channel_input: str, *, expected_outputs: Optional[List[str]] = None, strip_prompt: bool = True, failed_when_contains: Union[str, List[str], ForwardRef(None)] = None, timeout_ops: Optional[float] = None, read_duration: float = 2.5) \u2011> scrapli.response.Response 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 Send an input and read outputs. Unlike \"normal\" scrapli behavior this method reads until the prompt(normal) OR until any of a list of expected outputs is seen, OR until the read duration is exceeded. This method does not care about/understand privilege levels. This *can* cause you some potential issues if not used carefully! Args: channel_input: input to send to the channel; intentionally named \"channel_input\" instead of \"command\" or \"config\" due to this method not caring about privilege levels expected_outputs: List of outputs to look for in device response; returns as soon as any of the outputs are seen strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed read_duration: float duration to read for Returns: Response: Scrapli Response object Raises: ScrapliValueError: if _base_transport_args is None for some reason","title":"send_and_read"},{"location":"api_docs/driver/generic/sync_driver/#send_command","text":"send_command(self, command: str, *, strip_prompt: bool = True, failed_when_contains: Union[str, List[str], ForwardRef(None)] = None, timeout_ops: Optional[float] = None) \u2011> scrapli.response.Response 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 Send a command Args: command: string to send to device in privilege exec mode strip_prompt: strip prompt or not, defaults to True (yes, strip the prompt) failed_when_contains: string or list of strings indicating failure if found in response timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed Returns: Response: Scrapli Response object Raises: N/A","title":"send_command"},{"location":"api_docs/driver/generic/sync_driver/#send_commands","text":"send_commands(self, commands: List[str], *, strip_prompt: bool = True, failed_when_contains: Union[str, List[str], ForwardRef(None)] = None, stop_on_failed: bool = False, eager: bool = False, timeout_ops: Optional[float] = None) \u2011> scrapli.response.MultiResponse 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 Send multiple commands Args: commands: list of strings to send to device in privilege exec mode strip_prompt: strip prompt or not, defaults to True (yes, strip the prompt) failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER COMMAND sent, not for the total of the commands being sent! Returns: MultiResponse: Scrapli MultiResponse object Raises: N/A","title":"send_commands"},{"location":"api_docs/driver/generic/sync_driver/#send_commands_from_file","text":"send_commands_from_file(self, file: str, *, strip_prompt: bool = True, failed_when_contains: Union[str, List[str], ForwardRef(None)] = None, stop_on_failed: bool = False, eager: bool = False, timeout_ops: Optional[float] = None) \u2011> scrapli.response.MultiResponse 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 Send command(s) from file Args: file: string path to file strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER COMMAND sent, not for the total of the commands being sent! Returns: MultiResponse: Scrapli MultiResponse object Raises: N/A","title":"send_commands_from_file"},{"location":"api_docs/driver/generic/sync_driver/#send_interactive","text":"send_interactive(self, interact_events: Union[List[Tuple[str, str]], List[Tuple[str, str, bool]]], *, failed_when_contains: Union[str, List[str], ForwardRef(None)] = None, privilege_level: str = '', timeout_ops: Optional[float] = None, interaction_complete_patterns: Optional[List[str]] = None) \u2011> scrapli.response.Response 1 2 3 4 5 6 7 8 9 10 11 Interact with a device with changing prompts per input. Used to interact with devices where prompts change per input, and where inputs may be hidden such as in the case of a password input. This can be used to respond to challenges from devices such as the confirmation for the command \"clear logging\" on IOSXE devices for example. You may have as many elements in the \"interact_events\" list as needed, and each element of that list should be a tuple of two or three elements. The first element is always the input to send as a string, the second should be the expected response as a string, and the optional third a bool for whether or not the input is \"hidden\" (i.e. password input) An example where we need this sort of capability: 3560CX#copy flash: scp: Source filename []? test1.txt Address or name of remote host []? 172.31.254.100 Destination username [carl]? Writing test1.txt Password: Password: Sink: C0644 639 test1.txt ! 639 bytes copied in 12.066 secs (53 bytes/sec) 3560CX# 1 To accomplish this we can use the following: interact = conn.channel.send_inputs_interact( [ (\"copy flash: scp:\", \"Source filename []?\", False), (\"test1.txt\", \"Address or name of remote host []?\", False), (\"172.31.254.100\", \"Destination username [carl]?\", False), (\"carl\", \"Password:\", False), (\"super_secure_password\", prompt, True), ] ) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 If we needed to deal with more prompts we could simply continue adding tuples to the list of interact \"events\". Args: interact_events: list of tuples containing the \"interactions\" with the device each list element must have an input and an expected response, and may have an optional bool for the third and final element -- the optional bool specifies if the input that is sent to the device is \"hidden\" (ex: password), if the hidden param is not provided it is assumed the input is \"normal\" (not hidden) failed_when_contains: list of strings that, if present in final output, represent a failed command/interaction privilege_level: ignored in this base class; for LSP reasons for subclasses timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER COMMAND sent, not for the total of the commands being sent! interaction_complete_patterns: list of patterns, that if seen, indicate the interactive \"session\" has ended and we should exit the interactive session. Returns: Response: scrapli Response object Raises: ScrapliValueError: if _base_transport_args is None for some reason","title":"send_interactive"},{"location":"api_docs/driver/network/async_driver/","text":"window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting()) Module scrapli.driver.network.async_driver \u00b6 scrapli.driver.network.async_driver Expand source code \"\"\"scrapli.driver.network.async_driver\"\"\" from collections import defaultdict from io import BytesIO from typing import Any, Callable, Dict, List, Optional, Tuple, Union from scrapli.driver.generic import AsyncGenericDriver from scrapli.driver.network.base_driver import BaseNetworkDriver, PrivilegeAction, PrivilegeLevel from scrapli.exceptions import ScrapliAuthenticationFailed, ScrapliPrivilegeError, ScrapliTimeout from scrapli.response import MultiResponse, Response class AsyncNetworkDriver(AsyncGenericDriver, BaseNetworkDriver): def __init__( self, host: str, privilege_levels: Dict[str, PrivilegeLevel], default_desired_privilege_level: str, port: Optional[int] = None, auth_username: str = \"\", auth_password: str = \"\", auth_private_key: str = \"\", auth_private_key_passphrase: str = \"\", auth_strict_key: bool = True, auth_bypass: bool = False, timeout_socket: float = 15.0, timeout_transport: float = 30.0, timeout_ops: float = 30.0, comms_return_char: str = \"\\n\", ssh_config_file: Union[str, bool] = False, ssh_known_hosts_file: Union[str, bool] = False, on_init: Optional[Callable[..., Any]] = None, on_open: Optional[Callable[..., Any]] = None, on_close: Optional[Callable[..., Any]] = None, transport: str = \"system\", transport_options: Optional[Dict[str, Any]] = None, channel_log: Union[str, bool, BytesIO] = False, channel_log_mode: str = \"write\", channel_lock: bool = False, logging_uid: str = \"\", auth_secondary: str = \"\", failed_when_contains: Optional[List[str]] = None, textfsm_platform: str = \"\", genie_platform: str = \"\", ): # ensure type for comms_prompt_pattern exists before setting it in the mixin self.comms_prompt_pattern: str super().__init__( host=host, port=port, auth_username=auth_username, auth_password=auth_password, auth_private_key=auth_private_key, auth_private_key_passphrase=auth_private_key_passphrase, auth_strict_key=auth_strict_key, auth_bypass=auth_bypass, timeout_socket=timeout_socket, timeout_transport=timeout_transport, timeout_ops=timeout_ops, comms_return_char=comms_return_char, ssh_config_file=ssh_config_file, ssh_known_hosts_file=ssh_known_hosts_file, on_init=on_init, on_open=on_open, on_close=on_close, transport=transport, transport_options=transport_options, channel_log=channel_log, channel_log_mode=channel_log_mode, channel_lock=channel_lock, logging_uid=logging_uid, ) self.auth_secondary = auth_secondary self.failed_when_contains = failed_when_contains or [] self.textfsm_platform = textfsm_platform self.genie_platform = genie_platform self.privilege_levels = privilege_levels self.default_desired_privilege_level = default_desired_privilege_level self._priv_graph = defaultdict(set) self.update_privilege_levels() async def _escalate(self, escalate_priv: PrivilegeLevel) -> None: \"\"\" Escalate to the next privilege level up Args: escalate_priv: privilege level to escalate to Returns: None Raises: ScrapliAuthenticationFailed: if auth escalation timeout \"\"\" self._pre_escalate(escalate_priv=escalate_priv) if escalate_priv.escalate_auth is False: await self.channel.send_input(channel_input=escalate_priv.escalate) else: try: await super().send_interactive( interact_events=[ (escalate_priv.escalate, escalate_priv.escalate_prompt, False), (self.auth_secondary, escalate_priv.pattern, True), ], interaction_complete_patterns=[ self.privilege_levels[escalate_priv.previous_priv].pattern, escalate_priv.pattern, ], ) except ScrapliTimeout as exc: raise ScrapliAuthenticationFailed( f\"failed escalating privilege from '{escalate_priv.previous_priv}' to \" f\"'{escalate_priv.name}'. do you need to set an 'auth_secondary' password?\" ) from exc async def _deescalate(self, current_priv: PrivilegeLevel) -> None: \"\"\" Deescalate to the next privilege level down Args: current_priv: current privilege level Returns: None Raises: N/A \"\"\" await self.channel.send_input(channel_input=current_priv.deescalate) async def acquire_priv(self, desired_priv: str) -> None: \"\"\" Acquire desired priv level Args: desired_priv: string name of desired privilege level see `scrapli.driver. .driver` for levels Returns: None Raises: ScrapliPrivilegeError: if desired_priv cannot be attained \"\"\" self._validate_privilege_level_name(privilege_level_name=desired_priv) privilege_change_count = 0 while True: current_prompt = await self.channel.get_prompt() privilege_action, target_priv = self._process_acquire_priv( destination_priv=desired_priv, current_prompt=current_prompt, ) if privilege_action == PrivilegeAction.NO_ACTION: self._current_priv_level = target_priv return if privilege_action == PrivilegeAction.DEESCALATE: await self._deescalate(current_priv=target_priv) if privilege_action == PrivilegeAction.ESCALATE: await self._escalate(escalate_priv=target_priv) privilege_change_count += 1 if privilege_change_count > len(self.privilege_levels) * 2: msg = f\"Failed to acquire requested privilege level {desired_priv}\" raise ScrapliPrivilegeError(msg) async def _acquire_appropriate_privilege_level(self, privilege_level: str = \"\") -> None: \"\"\" Acquire the appropriate priv level Acquires the \"right\" priv level based on generic_driver_mode, provided privilege level, and default desired privilege level. If in \"generic_driver_mode\" and no priv level is provided, we simply return as we are already at the \"right\" priv level (since we don't care about priv levels in this mode). If we are in \"generic_driver_mode\" and we are provided a priv level (this is only applicable in `send_interactive`) we will try to acquire that provided priv level. If a priv name is passed we try to resolve it and use that as the privilege level to acquire, otherwise if no priv leve is provided we will acquire the default_desired_privilege_level. Args: privilege_level: optional name of privilege level to acquire Returns: None Raises: N/A \"\"\" if not privilege_level and self._generic_driver_mode is True: return if privilege_level: self._validate_privilege_level_name(privilege_level_name=privilege_level) resolved_privilege_level = privilege_level else: resolved_privilege_level = self.default_desired_privilege_level if self._current_priv_level.name != resolved_privilege_level: await self.acquire_priv(desired_priv=resolved_privilege_level) async def send_command( self, command: str, *, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, timeout_ops: Optional[float] = None, ) -> Response: \"\"\" Send a command Super method will raise TypeError if anything but a string is passed here! Args: command: string to send to device in privilege exec mode strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed Returns: Response: Scrapli Response object Raises: N/A \"\"\" await self._acquire_appropriate_privilege_level() if failed_when_contains is None: failed_when_contains = self.failed_when_contains response = await super().send_command( command=command, strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, timeout_ops=timeout_ops, ) self._update_response(response) return response async def send_commands( self, commands: List[str], *, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, stop_on_failed: bool = False, eager: bool = False, timeout_ops: Optional[float] = None, ) -> MultiResponse: \"\"\" Send multiple commands Super method will raise TypeError if anything but a list of strings is passed here! Args: commands: list of strings to send to device in privilege exec mode strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER COMMAND sent, not for the total of the commands being sent! Returns: MultiResponse: Scrapli MultiResponse object Raises: N/A \"\"\" await self._acquire_appropriate_privilege_level() if failed_when_contains is None: failed_when_contains = self.failed_when_contains responses = await super().send_commands( commands=commands, strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, stop_on_failed=stop_on_failed, eager=eager, timeout_ops=timeout_ops, ) for response in responses: self._update_response(response=response) return responses async def send_commands_from_file( self, file: str, *, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, stop_on_failed: bool = False, eager: bool = False, timeout_ops: Optional[float] = None, ) -> MultiResponse: \"\"\" Send command(s) from file Args: file: string path to file strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER COMMAND sent, not for the total of the commands being sent! Returns: MultiResponse: Scrapli MultiResponse object Raises: N/A \"\"\" await self._acquire_appropriate_privilege_level() if failed_when_contains is None: failed_when_contains = self.failed_when_contains return await super().send_commands_from_file( file=file, strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, stop_on_failed=stop_on_failed, eager=eager, timeout_ops=timeout_ops, ) async def send_interactive( self, interact_events: Union[List[Tuple[str, str]], List[Tuple[str, str, bool]]], *, failed_when_contains: Optional[Union[str, List[str]]] = None, privilege_level: str = \"\", timeout_ops: Optional[float] = None, interaction_complete_patterns: Optional[List[str]] = None, ) -> Response: \"\"\" Interact with a device with changing prompts per input. Used to interact with devices where prompts change per input, and where inputs may be hidden such as in the case of a password input. This can be used to respond to challenges from devices such as the confirmation for the command \"clear logging\" on IOSXE devices for example. You may have as many elements in the \"interact_events\" list as needed, and each element of that list should be a tuple of two or three elements. The first element is always the input to send as a string, the second should be the expected response as a string, and the optional third a bool for whether or not the input is \"hidden\" (i.e. password input) An example where we need this sort of capability: ''' 3560CX#copy flash: scp: Source filename []? test1.txt Address or name of remote host []? 172.31.254.100 Destination username [carl]? Writing test1.txt Password: Password: Sink: C0644 639 test1.txt ! 639 bytes copied in 12.066 secs (53 bytes/sec) 3560CX# ''' To accomplish this we can use the following: ''' interact = conn.channel.send_inputs_interact( [ (\"copy flash: scp:\", \"Source filename []?\", False), (\"test1.txt\", \"Address or name of remote host []?\", False), (\"172.31.254.100\", \"Destination username [carl]?\", False), (\"carl\", \"Password:\", False), (\"super_secure_password\", prompt, True), ] ) ''' If we needed to deal with more prompts we could simply continue adding tuples to the list of interact \"events\". Args: interact_events: list of tuples containing the \"interactions\" with the device each list element must have an input and an expected response, and may have an optional bool for the third and final element -- the optional bool specifies if the input that is sent to the device is \"hidden\" (ex: password), if the hidden param is not provided it is assumed the input is \"normal\" (not hidden) failed_when_contains: list of strings that, if present in final output, represent a failed command/interaction privilege_level: name of the privilege level to operate in timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER COMMAND sent, not for the total of the commands being sent! interaction_complete_patterns: list of patterns, that if seen, indicate the interactive \"session\" has ended and we should exit the interactive session. Returns: Response: scrapli Response object Raises: N/A \"\"\" await self._acquire_appropriate_privilege_level(privilege_level=privilege_level) if failed_when_contains is None: failed_when_contains = self.failed_when_contains # type hint is due to the timeout_modifier wrapper returning `Any` so that we dont anger the # asyncio parts (which will get an awaitable not a Response returned) response: Response = await super().send_interactive( interact_events=interact_events, failed_when_contains=failed_when_contains, timeout_ops=timeout_ops, interaction_complete_patterns=interaction_complete_patterns, ) self._update_response(response=response) return response async def _abort_config(self) -> None: \"\"\" Abort a configuration operation/session if applicable (for config sessions like junos/iosxr) Args: N/A Returns: None Raises: N/A \"\"\" async def send_configs( self, configs: List[str], *, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, stop_on_failed: bool = False, privilege_level: str = \"\", eager: bool = False, timeout_ops: Optional[float] = None, ) -> MultiResponse: \"\"\" Send configuration(s) Args: configs: list of strings to send to device in config mode strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution; aborts configuration session if applicable (iosxr/junos or eos/nxos if using a configuration session) privilege_level: name of configuration privilege level/type to acquire; this is platform dependent, so check the device driver for specifics. Examples of privilege_name would be \"configuration_exclusive\" for IOSXRDriver, or \"configuration_private\" for JunosDriver. You can also pass in a name of a configuration session such as \"my-config-session\" if you have registered a session using the \"register_config_session\" method of the EOSDriver or NXOSDriver. eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER CONFIG sent, not for the total of the configs being sent! Returns: MultiResponse: Scrapli MultiResponse object Raises: N/A \"\"\" resolved_privilege_level, failed_when_contains = self._pre_send_configs( configs=configs, failed_when_contains=failed_when_contains, privilege_level=privilege_level, ) if self._current_priv_level.name != resolved_privilege_level: await self.acquire_priv(desired_priv=resolved_privilege_level) responses = await super().send_commands( commands=configs, strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, stop_on_failed=stop_on_failed, eager=eager, timeout_ops=timeout_ops, ) if stop_on_failed and responses.failed: await self._abort_config() return self._post_send_configs(responses=responses) async def send_config( self, config: str, *, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, stop_on_failed: bool = False, privilege_level: str = \"\", eager: bool = False, timeout_ops: Optional[float] = None, ) -> Response: \"\"\" Send configuration string Args: config: string configuration to send to the device, supports sending multi-line strings strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution; aborts configuration session if applicable (iosxr/junos or eos/nxos if using a configuration session) privilege_level: name of configuration privilege level/type to acquire; this is platform dependent, so check the device driver for specifics. Examples of privilege_name would be \"configuration_exclusive\" for IOSXRDriver, or \"configuration_private\" for JunosDriver. You can also pass in a name of a configuration session such as \"my-config-session\" if you have registered a session using the \"register_config_session\" method of the EOSDriver or NXOSDriver. eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER CONFIG sent, not for the total of the configs being sent! Returns: Response: Scrapli Response object Raises: N/A \"\"\" split_config = self._pre_send_config(config=config) # now that we have a list of configs, just use send_configs to actually execute them multi_response = await self.send_configs( configs=split_config, strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, stop_on_failed=stop_on_failed, privilege_level=privilege_level, eager=eager, timeout_ops=timeout_ops, ) return self._post_send_config(config=config, multi_response=multi_response) async def send_configs_from_file( self, file: str, *, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, stop_on_failed: bool = False, privilege_level: str = \"\", eager: bool = False, timeout_ops: Optional[float] = None, ) -> MultiResponse: \"\"\" Send configuration(s) from a file Args: file: string path to file strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution; aborts configuration session if applicable (iosxr/junos or eos/nxos if using a configuration session) privilege_level: name of configuration privilege level/type to acquire; this is platform dependent, so check the device driver for specifics. Examples of privilege_name would be \"exclusive\" for IOSXRDriver, \"private\" for JunosDriver. You can also pass in a name of a configuration session such as \"session_mysession\" if you have registered a session using the \"register_config_session\" method of the EOSDriver or NXOSDriver. eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER CONFIG sent, not for the total of the configs being sent! Returns: MultiResponse: Scrapli MultiResponse object Raises: N/A \"\"\" configs = self._pre_send_from_file(file=file, caller=\"send_configs_from_file\") return await self.send_configs( configs=configs, strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, stop_on_failed=stop_on_failed, privilege_level=privilege_level, eager=eager, timeout_ops=timeout_ops, ) Classes \u00b6 AsyncNetworkDriver \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 BaseDriver Object BaseDriver is the root for all Scrapli driver classes. The synchronous and asyncio driver base driver classes can be used to provide a semi-pexpect like experience over top of whatever transport a user prefers. Generally, however, the base driver classes should not be used directly. It is best to use the GenericDriver (or AsyncGenericDriver) or NetworkDriver (or AsyncNetworkDriver) sub-classes of the base drivers. Args: host: host ip/name to connect to port: port to connect to auth_username: username for authentication auth_private_key: path to private key for authentication auth_private_key_passphrase: passphrase for decrypting ssh key if necessary auth_password: password for authentication auth_strict_key: strict host checking or not auth_bypass: bypass \"in channel\" authentication -- only supported with telnet, asynctelnet, and system transport plugins timeout_socket: timeout for establishing socket/initial connection in seconds timeout_transport: timeout for ssh|telnet transport in seconds timeout_ops: timeout for ssh channel operations comms_prompt_pattern: raw string regex pattern -- preferably use `^` and `$` anchors! this is the single most important attribute here! if this does not match a prompt, scrapli will not work! IMPORTANT: regex search uses multi-line + case insensitive flags. multi-line allows for highly reliably matching for prompts however we do NOT strip trailing whitespace for each line, so be sure to add '\\\\s?' or similar if your device needs that. This should be mostly sorted for you if using network drivers (i.e. `IOSXEDriver`). Lastly, the case insensitive is just a convenience factor so i can be lazy. comms_return_char: character to use to send returns to host ssh_config_file: string to path for ssh config file, True to use default ssh config file or False to ignore default ssh config file ssh_known_hosts_file: string to path for ssh known hosts file, True to use default known file locations. Only applicable/needed if `auth_strict_key` is set to True on_init: callable that accepts the class instance as its only argument. this callable, if provided, is executed as the last step of object instantiation -- its purpose is primarily to provide a mechanism for scrapli community platforms to have an easy way to modify initialization arguments/object attributes without needing to create a class that extends the driver, instead allowing the community platforms to simply build from the GenericDriver or NetworkDriver classes, and pass this callable to do things such as appending to a username (looking at you RouterOS!!). Note that this is *always* a synchronous function (even for asyncio drivers)! on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar transport: name of the transport plugin to use for the actual telnet/ssh/netconf connection. Available \"core\" transports are: - system - telnet - asynctelnet - ssh2 - paramiko - asyncssh Please see relevant transport plugin section for details. Additionally third party transport plugins may be available. transport_options: dictionary of options to pass to selected transport class; see docs for given transport class for details of what to pass here channel_lock: True/False to lock the channel (threading.Lock/asyncio.Lock) during any channel operations, defaults to False channel_log: True/False or a string path to a file of where to write out channel logs -- these are not \"logs\" in the normal logging module sense, but only the output that is read from the channel. In other words, the output of the channel log should look similar to what you would see as a human connecting to a device channel_log_mode: \"write\"|\"append\", all other values will raise ValueError, does what it sounds like it should by setting the channel log to the provided mode logging_uid: unique identifier (string) to associate to log messages; useful if you have multiple connections to the same device (i.e. one console, one ssh, or one to each supervisor module, etc.) Returns: None Raises: N/A Expand source code class AsyncNetworkDriver(AsyncGenericDriver, BaseNetworkDriver): def __init__( self, host: str, privilege_levels: Dict[str, PrivilegeLevel], default_desired_privilege_level: str, port: Optional[int] = None, auth_username: str = \"\", auth_password: str = \"\", auth_private_key: str = \"\", auth_private_key_passphrase: str = \"\", auth_strict_key: bool = True, auth_bypass: bool = False, timeout_socket: float = 15.0, timeout_transport: float = 30.0, timeout_ops: float = 30.0, comms_return_char: str = \"\\n\", ssh_config_file: Union[str, bool] = False, ssh_known_hosts_file: Union[str, bool] = False, on_init: Optional[Callable[..., Any]] = None, on_open: Optional[Callable[..., Any]] = None, on_close: Optional[Callable[..., Any]] = None, transport: str = \"system\", transport_options: Optional[Dict[str, Any]] = None, channel_log: Union[str, bool, BytesIO] = False, channel_log_mode: str = \"write\", channel_lock: bool = False, logging_uid: str = \"\", auth_secondary: str = \"\", failed_when_contains: Optional[List[str]] = None, textfsm_platform: str = \"\", genie_platform: str = \"\", ): # ensure type for comms_prompt_pattern exists before setting it in the mixin self.comms_prompt_pattern: str super().__init__( host=host, port=port, auth_username=auth_username, auth_password=auth_password, auth_private_key=auth_private_key, auth_private_key_passphrase=auth_private_key_passphrase, auth_strict_key=auth_strict_key, auth_bypass=auth_bypass, timeout_socket=timeout_socket, timeout_transport=timeout_transport, timeout_ops=timeout_ops, comms_return_char=comms_return_char, ssh_config_file=ssh_config_file, ssh_known_hosts_file=ssh_known_hosts_file, on_init=on_init, on_open=on_open, on_close=on_close, transport=transport, transport_options=transport_options, channel_log=channel_log, channel_log_mode=channel_log_mode, channel_lock=channel_lock, logging_uid=logging_uid, ) self.auth_secondary = auth_secondary self.failed_when_contains = failed_when_contains or [] self.textfsm_platform = textfsm_platform self.genie_platform = genie_platform self.privilege_levels = privilege_levels self.default_desired_privilege_level = default_desired_privilege_level self._priv_graph = defaultdict(set) self.update_privilege_levels() async def _escalate(self, escalate_priv: PrivilegeLevel) -> None: \"\"\" Escalate to the next privilege level up Args: escalate_priv: privilege level to escalate to Returns: None Raises: ScrapliAuthenticationFailed: if auth escalation timeout \"\"\" self._pre_escalate(escalate_priv=escalate_priv) if escalate_priv.escalate_auth is False: await self.channel.send_input(channel_input=escalate_priv.escalate) else: try: await super().send_interactive( interact_events=[ (escalate_priv.escalate, escalate_priv.escalate_prompt, False), (self.auth_secondary, escalate_priv.pattern, True), ], interaction_complete_patterns=[ self.privilege_levels[escalate_priv.previous_priv].pattern, escalate_priv.pattern, ], ) except ScrapliTimeout as exc: raise ScrapliAuthenticationFailed( f\"failed escalating privilege from '{escalate_priv.previous_priv}' to \" f\"'{escalate_priv.name}'. do you need to set an 'auth_secondary' password?\" ) from exc async def _deescalate(self, current_priv: PrivilegeLevel) -> None: \"\"\" Deescalate to the next privilege level down Args: current_priv: current privilege level Returns: None Raises: N/A \"\"\" await self.channel.send_input(channel_input=current_priv.deescalate) async def acquire_priv(self, desired_priv: str) -> None: \"\"\" Acquire desired priv level Args: desired_priv: string name of desired privilege level see `scrapli.driver. .driver` for levels Returns: None Raises: ScrapliPrivilegeError: if desired_priv cannot be attained \"\"\" self._validate_privilege_level_name(privilege_level_name=desired_priv) privilege_change_count = 0 while True: current_prompt = await self.channel.get_prompt() privilege_action, target_priv = self._process_acquire_priv( destination_priv=desired_priv, current_prompt=current_prompt, ) if privilege_action == PrivilegeAction.NO_ACTION: self._current_priv_level = target_priv return if privilege_action == PrivilegeAction.DEESCALATE: await self._deescalate(current_priv=target_priv) if privilege_action == PrivilegeAction.ESCALATE: await self._escalate(escalate_priv=target_priv) privilege_change_count += 1 if privilege_change_count > len(self.privilege_levels) * 2: msg = f\"Failed to acquire requested privilege level {desired_priv}\" raise ScrapliPrivilegeError(msg) async def _acquire_appropriate_privilege_level(self, privilege_level: str = \"\") -> None: \"\"\" Acquire the appropriate priv level Acquires the \"right\" priv level based on generic_driver_mode, provided privilege level, and default desired privilege level. If in \"generic_driver_mode\" and no priv level is provided, we simply return as we are already at the \"right\" priv level (since we don't care about priv levels in this mode). If we are in \"generic_driver_mode\" and we are provided a priv level (this is only applicable in `send_interactive`) we will try to acquire that provided priv level. If a priv name is passed we try to resolve it and use that as the privilege level to acquire, otherwise if no priv leve is provided we will acquire the default_desired_privilege_level. Args: privilege_level: optional name of privilege level to acquire Returns: None Raises: N/A \"\"\" if not privilege_level and self._generic_driver_mode is True: return if privilege_level: self._validate_privilege_level_name(privilege_level_name=privilege_level) resolved_privilege_level = privilege_level else: resolved_privilege_level = self.default_desired_privilege_level if self._current_priv_level.name != resolved_privilege_level: await self.acquire_priv(desired_priv=resolved_privilege_level) async def send_command( self, command: str, *, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, timeout_ops: Optional[float] = None, ) -> Response: \"\"\" Send a command Super method will raise TypeError if anything but a string is passed here! Args: command: string to send to device in privilege exec mode strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed Returns: Response: Scrapli Response object Raises: N/A \"\"\" await self._acquire_appropriate_privilege_level() if failed_when_contains is None: failed_when_contains = self.failed_when_contains response = await super().send_command( command=command, strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, timeout_ops=timeout_ops, ) self._update_response(response) return response async def send_commands( self, commands: List[str], *, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, stop_on_failed: bool = False, eager: bool = False, timeout_ops: Optional[float] = None, ) -> MultiResponse: \"\"\" Send multiple commands Super method will raise TypeError if anything but a list of strings is passed here! Args: commands: list of strings to send to device in privilege exec mode strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER COMMAND sent, not for the total of the commands being sent! Returns: MultiResponse: Scrapli MultiResponse object Raises: N/A \"\"\" await self._acquire_appropriate_privilege_level() if failed_when_contains is None: failed_when_contains = self.failed_when_contains responses = await super().send_commands( commands=commands, strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, stop_on_failed=stop_on_failed, eager=eager, timeout_ops=timeout_ops, ) for response in responses: self._update_response(response=response) return responses async def send_commands_from_file( self, file: str, *, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, stop_on_failed: bool = False, eager: bool = False, timeout_ops: Optional[float] = None, ) -> MultiResponse: \"\"\" Send command(s) from file Args: file: string path to file strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER COMMAND sent, not for the total of the commands being sent! Returns: MultiResponse: Scrapli MultiResponse object Raises: N/A \"\"\" await self._acquire_appropriate_privilege_level() if failed_when_contains is None: failed_when_contains = self.failed_when_contains return await super().send_commands_from_file( file=file, strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, stop_on_failed=stop_on_failed, eager=eager, timeout_ops=timeout_ops, ) async def send_interactive( self, interact_events: Union[List[Tuple[str, str]], List[Tuple[str, str, bool]]], *, failed_when_contains: Optional[Union[str, List[str]]] = None, privilege_level: str = \"\", timeout_ops: Optional[float] = None, interaction_complete_patterns: Optional[List[str]] = None, ) -> Response: \"\"\" Interact with a device with changing prompts per input. Used to interact with devices where prompts change per input, and where inputs may be hidden such as in the case of a password input. This can be used to respond to challenges from devices such as the confirmation for the command \"clear logging\" on IOSXE devices for example. You may have as many elements in the \"interact_events\" list as needed, and each element of that list should be a tuple of two or three elements. The first element is always the input to send as a string, the second should be the expected response as a string, and the optional third a bool for whether or not the input is \"hidden\" (i.e. password input) An example where we need this sort of capability: ''' 3560CX#copy flash: scp: Source filename []? test1.txt Address or name of remote host []? 172.31.254.100 Destination username [carl]? Writing test1.txt Password: Password: Sink: C0644 639 test1.txt ! 639 bytes copied in 12.066 secs (53 bytes/sec) 3560CX# ''' To accomplish this we can use the following: ''' interact = conn.channel.send_inputs_interact( [ (\"copy flash: scp:\", \"Source filename []?\", False), (\"test1.txt\", \"Address or name of remote host []?\", False), (\"172.31.254.100\", \"Destination username [carl]?\", False), (\"carl\", \"Password:\", False), (\"super_secure_password\", prompt, True), ] ) ''' If we needed to deal with more prompts we could simply continue adding tuples to the list of interact \"events\". Args: interact_events: list of tuples containing the \"interactions\" with the device each list element must have an input and an expected response, and may have an optional bool for the third and final element -- the optional bool specifies if the input that is sent to the device is \"hidden\" (ex: password), if the hidden param is not provided it is assumed the input is \"normal\" (not hidden) failed_when_contains: list of strings that, if present in final output, represent a failed command/interaction privilege_level: name of the privilege level to operate in timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER COMMAND sent, not for the total of the commands being sent! interaction_complete_patterns: list of patterns, that if seen, indicate the interactive \"session\" has ended and we should exit the interactive session. Returns: Response: scrapli Response object Raises: N/A \"\"\" await self._acquire_appropriate_privilege_level(privilege_level=privilege_level) if failed_when_contains is None: failed_when_contains = self.failed_when_contains # type hint is due to the timeout_modifier wrapper returning `Any` so that we dont anger the # asyncio parts (which will get an awaitable not a Response returned) response: Response = await super().send_interactive( interact_events=interact_events, failed_when_contains=failed_when_contains, timeout_ops=timeout_ops, interaction_complete_patterns=interaction_complete_patterns, ) self._update_response(response=response) return response async def _abort_config(self) -> None: \"\"\" Abort a configuration operation/session if applicable (for config sessions like junos/iosxr) Args: N/A Returns: None Raises: N/A \"\"\" async def send_configs( self, configs: List[str], *, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, stop_on_failed: bool = False, privilege_level: str = \"\", eager: bool = False, timeout_ops: Optional[float] = None, ) -> MultiResponse: \"\"\" Send configuration(s) Args: configs: list of strings to send to device in config mode strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution; aborts configuration session if applicable (iosxr/junos or eos/nxos if using a configuration session) privilege_level: name of configuration privilege level/type to acquire; this is platform dependent, so check the device driver for specifics. Examples of privilege_name would be \"configuration_exclusive\" for IOSXRDriver, or \"configuration_private\" for JunosDriver. You can also pass in a name of a configuration session such as \"my-config-session\" if you have registered a session using the \"register_config_session\" method of the EOSDriver or NXOSDriver. eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER CONFIG sent, not for the total of the configs being sent! Returns: MultiResponse: Scrapli MultiResponse object Raises: N/A \"\"\" resolved_privilege_level, failed_when_contains = self._pre_send_configs( configs=configs, failed_when_contains=failed_when_contains, privilege_level=privilege_level, ) if self._current_priv_level.name != resolved_privilege_level: await self.acquire_priv(desired_priv=resolved_privilege_level) responses = await super().send_commands( commands=configs, strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, stop_on_failed=stop_on_failed, eager=eager, timeout_ops=timeout_ops, ) if stop_on_failed and responses.failed: await self._abort_config() return self._post_send_configs(responses=responses) async def send_config( self, config: str, *, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, stop_on_failed: bool = False, privilege_level: str = \"\", eager: bool = False, timeout_ops: Optional[float] = None, ) -> Response: \"\"\" Send configuration string Args: config: string configuration to send to the device, supports sending multi-line strings strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution; aborts configuration session if applicable (iosxr/junos or eos/nxos if using a configuration session) privilege_level: name of configuration privilege level/type to acquire; this is platform dependent, so check the device driver for specifics. Examples of privilege_name would be \"configuration_exclusive\" for IOSXRDriver, or \"configuration_private\" for JunosDriver. You can also pass in a name of a configuration session such as \"my-config-session\" if you have registered a session using the \"register_config_session\" method of the EOSDriver or NXOSDriver. eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER CONFIG sent, not for the total of the configs being sent! Returns: Response: Scrapli Response object Raises: N/A \"\"\" split_config = self._pre_send_config(config=config) # now that we have a list of configs, just use send_configs to actually execute them multi_response = await self.send_configs( configs=split_config, strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, stop_on_failed=stop_on_failed, privilege_level=privilege_level, eager=eager, timeout_ops=timeout_ops, ) return self._post_send_config(config=config, multi_response=multi_response) async def send_configs_from_file( self, file: str, *, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, stop_on_failed: bool = False, privilege_level: str = \"\", eager: bool = False, timeout_ops: Optional[float] = None, ) -> MultiResponse: \"\"\" Send configuration(s) from a file Args: file: string path to file strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution; aborts configuration session if applicable (iosxr/junos or eos/nxos if using a configuration session) privilege_level: name of configuration privilege level/type to acquire; this is platform dependent, so check the device driver for specifics. Examples of privilege_name would be \"exclusive\" for IOSXRDriver, \"private\" for JunosDriver. You can also pass in a name of a configuration session such as \"session_mysession\" if you have registered a session using the \"register_config_session\" method of the EOSDriver or NXOSDriver. eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER CONFIG sent, not for the total of the configs being sent! Returns: MultiResponse: Scrapli MultiResponse object Raises: N/A \"\"\" configs = self._pre_send_from_file(file=file, caller=\"send_configs_from_file\") return await self.send_configs( configs=configs, strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, stop_on_failed=stop_on_failed, privilege_level=privilege_level, eager=eager, timeout_ops=timeout_ops, ) Ancestors (in MRO) \u00b6 scrapli.driver.generic.async_driver.AsyncGenericDriver scrapli.driver.base.async_driver.AsyncDriver scrapli.driver.base.base_driver.BaseDriver scrapli.driver.generic.base_driver.BaseGenericDriver scrapli.driver.network.base_driver.BaseNetworkDriver Descendants \u00b6 scrapli.driver.core.arista_eos.async_driver.AsyncEOSDriver scrapli.driver.core.cisco_iosxe.async_driver.AsyncIOSXEDriver scrapli.driver.core.cisco_iosxr.async_driver.AsyncIOSXRDriver scrapli.driver.core.cisco_nxos.async_driver.AsyncNXOSDriver scrapli.driver.core.juniper_junos.async_driver.AsyncJunosDriver scrapli.factory.AsyncScrapli Methods \u00b6 acquire_priv \u00b6 acquire_priv(self, desired_priv: str) \u2011> None 1 2 3 4 5 6 7 8 9 10 11 Acquire desired priv level Args: desired_priv: string name of desired privilege level see `scrapli.driver.<driver_category.device_type>.driver` for levels Returns: None Raises: ScrapliPrivilegeError: if desired_priv cannot be attained send_command \u00b6 send_command(self, command: str, *, strip_prompt: bool = True, failed_when_contains: Union[str, List[str], ForwardRef(None)] = None, timeout_ops: Optional[float] = None) \u2011> scrapli.response.Response 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 Send a command Super method will raise TypeError if anything but a string is passed here! Args: command: string to send to device in privilege exec mode strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed Returns: Response: Scrapli Response object Raises: N/A send_commands \u00b6 send_commands(self, commands: List[str], *, strip_prompt: bool = True, failed_when_contains: Union[str, List[str], ForwardRef(None)] = None, stop_on_failed: bool = False, eager: bool = False, timeout_ops: Optional[float] = None) \u2011> scrapli.response.MultiResponse 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 Send multiple commands Super method will raise TypeError if anything but a list of strings is passed here! Args: commands: list of strings to send to device in privilege exec mode strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER COMMAND sent, not for the total of the commands being sent! Returns: MultiResponse: Scrapli MultiResponse object Raises: N/A send_config \u00b6 send_config(self, config: str, *, strip_prompt: bool = True, failed_when_contains: Union[str, List[str], ForwardRef(None)] = None, stop_on_failed: bool = False, privilege_level: str = '', eager: bool = False, timeout_ops: Optional[float] = None) \u2011> scrapli.response.Response 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 Send configuration string Args: config: string configuration to send to the device, supports sending multi-line strings strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution; aborts configuration session if applicable (iosxr/junos or eos/nxos if using a configuration session) privilege_level: name of configuration privilege level/type to acquire; this is platform dependent, so check the device driver for specifics. Examples of privilege_name would be \"configuration_exclusive\" for IOSXRDriver, or \"configuration_private\" for JunosDriver. You can also pass in a name of a configuration session such as \"my-config-session\" if you have registered a session using the \"register_config_session\" method of the EOSDriver or NXOSDriver. eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER CONFIG sent, not for the total of the configs being sent! Returns: Response: Scrapli Response object Raises: N/A send_configs \u00b6 send_configs(self, configs: List[str], *, strip_prompt: bool = True, failed_when_contains: Union[str, List[str], ForwardRef(None)] = None, stop_on_failed: bool = False, privilege_level: str = '', eager: bool = False, timeout_ops: Optional[float] = None) \u2011> scrapli.response.MultiResponse 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 Send configuration(s) Args: configs: list of strings to send to device in config mode strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution; aborts configuration session if applicable (iosxr/junos or eos/nxos if using a configuration session) privilege_level: name of configuration privilege level/type to acquire; this is platform dependent, so check the device driver for specifics. Examples of privilege_name would be \"configuration_exclusive\" for IOSXRDriver, or \"configuration_private\" for JunosDriver. You can also pass in a name of a configuration session such as \"my-config-session\" if you have registered a session using the \"register_config_session\" method of the EOSDriver or NXOSDriver. eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER CONFIG sent, not for the total of the configs being sent! Returns: MultiResponse: Scrapli MultiResponse object Raises: N/A send_configs_from_file \u00b6 send_configs_from_file(self, file: str, *, strip_prompt: bool = True, failed_when_contains: Union[str, List[str], ForwardRef(None)] = None, stop_on_failed: bool = False, privilege_level: str = '', eager: bool = False, timeout_ops: Optional[float] = None) \u2011> scrapli.response.MultiResponse 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 Send configuration(s) from a file Args: file: string path to file strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution; aborts configuration session if applicable (iosxr/junos or eos/nxos if using a configuration session) privilege_level: name of configuration privilege level/type to acquire; this is platform dependent, so check the device driver for specifics. Examples of privilege_name would be \"exclusive\" for IOSXRDriver, \"private\" for JunosDriver. You can also pass in a name of a configuration session such as \"session_mysession\" if you have registered a session using the \"register_config_session\" method of the EOSDriver or NXOSDriver. eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER CONFIG sent, not for the total of the configs being sent! Returns: MultiResponse: Scrapli MultiResponse object Raises: N/A send_interactive \u00b6 send_interactive(self, interact_events: Union[List[Tuple[str, str]], List[Tuple[str, str, bool]]], *, failed_when_contains: Union[str, List[str], ForwardRef(None)] = None, privilege_level: str = '', timeout_ops: Optional[float] = None, interaction_complete_patterns: Optional[List[str]] = None) \u2011> scrapli.response.Response 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 Interact with a device with changing prompts per input. Used to interact with devices where prompts change per input, and where inputs may be hidden such as in the case of a password input. This can be used to respond to challenges from devices such as the confirmation for the command \"clear logging\" on IOSXE devices for example. You may have as many elements in the \"interact_events\" list as needed, and each element of that list should be a tuple of two or three elements. The first element is always the input to send as a string, the second should be the expected response as a string, and the optional third a bool for whether or not the input is \"hidden\" (i.e. password input) An example where we need this sort of capability: ''' 3560CX#copy flash: scp: Source filename []? test1.txt Address or name of remote host []? 172.31.254.100 Destination username [carl]? Writing test1.txt Password: Password: Sink: C0644 639 test1.txt ! 639 bytes copied in 12.066 secs (53 bytes/sec) 3560CX# ''' To accomplish this we can use the following: ''' interact = conn.channel.send_inputs_interact( [ (\"copy flash: scp:\", \"Source filename []?\", False), (\"test1.txt\", \"Address or name of remote host []?\", False), (\"172.31.254.100\", \"Destination username [carl]?\", False), (\"carl\", \"Password:\", False), (\"super_secure_password\", prompt, True), ] ) ''' If we needed to deal with more prompts we could simply continue adding tuples to the list of interact \"events\". Args: interact_events: list of tuples containing the \"interactions\" with the device each list element must have an input and an expected response, and may have an optional bool for the third and final element -- the optional bool specifies if the input that is sent to the device is \"hidden\" (ex: password), if the hidden param is not provided it is assumed the input is \"normal\" (not hidden) failed_when_contains: list of strings that, if present in final output, represent a failed command/interaction privilege_level: name of the privilege level to operate in timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER COMMAND sent, not for the total of the commands being sent! interaction_complete_patterns: list of patterns, that if seen, indicate the interactive \"session\" has ended and we should exit the interactive session. Returns: Response: scrapli Response object Raises: N/A","title":"Async Driver"},{"location":"api_docs/driver/network/async_driver/#module-scraplidrivernetworkasync_driver","text":"scrapli.driver.network.async_driver Expand source code \"\"\"scrapli.driver.network.async_driver\"\"\" from collections import defaultdict from io import BytesIO from typing import Any, Callable, Dict, List, Optional, Tuple, Union from scrapli.driver.generic import AsyncGenericDriver from scrapli.driver.network.base_driver import BaseNetworkDriver, PrivilegeAction, PrivilegeLevel from scrapli.exceptions import ScrapliAuthenticationFailed, ScrapliPrivilegeError, ScrapliTimeout from scrapli.response import MultiResponse, Response class AsyncNetworkDriver(AsyncGenericDriver, BaseNetworkDriver): def __init__( self, host: str, privilege_levels: Dict[str, PrivilegeLevel], default_desired_privilege_level: str, port: Optional[int] = None, auth_username: str = \"\", auth_password: str = \"\", auth_private_key: str = \"\", auth_private_key_passphrase: str = \"\", auth_strict_key: bool = True, auth_bypass: bool = False, timeout_socket: float = 15.0, timeout_transport: float = 30.0, timeout_ops: float = 30.0, comms_return_char: str = \"\\n\", ssh_config_file: Union[str, bool] = False, ssh_known_hosts_file: Union[str, bool] = False, on_init: Optional[Callable[..., Any]] = None, on_open: Optional[Callable[..., Any]] = None, on_close: Optional[Callable[..., Any]] = None, transport: str = \"system\", transport_options: Optional[Dict[str, Any]] = None, channel_log: Union[str, bool, BytesIO] = False, channel_log_mode: str = \"write\", channel_lock: bool = False, logging_uid: str = \"\", auth_secondary: str = \"\", failed_when_contains: Optional[List[str]] = None, textfsm_platform: str = \"\", genie_platform: str = \"\", ): # ensure type for comms_prompt_pattern exists before setting it in the mixin self.comms_prompt_pattern: str super().__init__( host=host, port=port, auth_username=auth_username, auth_password=auth_password, auth_private_key=auth_private_key, auth_private_key_passphrase=auth_private_key_passphrase, auth_strict_key=auth_strict_key, auth_bypass=auth_bypass, timeout_socket=timeout_socket, timeout_transport=timeout_transport, timeout_ops=timeout_ops, comms_return_char=comms_return_char, ssh_config_file=ssh_config_file, ssh_known_hosts_file=ssh_known_hosts_file, on_init=on_init, on_open=on_open, on_close=on_close, transport=transport, transport_options=transport_options, channel_log=channel_log, channel_log_mode=channel_log_mode, channel_lock=channel_lock, logging_uid=logging_uid, ) self.auth_secondary = auth_secondary self.failed_when_contains = failed_when_contains or [] self.textfsm_platform = textfsm_platform self.genie_platform = genie_platform self.privilege_levels = privilege_levels self.default_desired_privilege_level = default_desired_privilege_level self._priv_graph = defaultdict(set) self.update_privilege_levels() async def _escalate(self, escalate_priv: PrivilegeLevel) -> None: \"\"\" Escalate to the next privilege level up Args: escalate_priv: privilege level to escalate to Returns: None Raises: ScrapliAuthenticationFailed: if auth escalation timeout \"\"\" self._pre_escalate(escalate_priv=escalate_priv) if escalate_priv.escalate_auth is False: await self.channel.send_input(channel_input=escalate_priv.escalate) else: try: await super().send_interactive( interact_events=[ (escalate_priv.escalate, escalate_priv.escalate_prompt, False), (self.auth_secondary, escalate_priv.pattern, True), ], interaction_complete_patterns=[ self.privilege_levels[escalate_priv.previous_priv].pattern, escalate_priv.pattern, ], ) except ScrapliTimeout as exc: raise ScrapliAuthenticationFailed( f\"failed escalating privilege from '{escalate_priv.previous_priv}' to \" f\"'{escalate_priv.name}'. do you need to set an 'auth_secondary' password?\" ) from exc async def _deescalate(self, current_priv: PrivilegeLevel) -> None: \"\"\" Deescalate to the next privilege level down Args: current_priv: current privilege level Returns: None Raises: N/A \"\"\" await self.channel.send_input(channel_input=current_priv.deescalate) async def acquire_priv(self, desired_priv: str) -> None: \"\"\" Acquire desired priv level Args: desired_priv: string name of desired privilege level see `scrapli.driver. .driver` for levels Returns: None Raises: ScrapliPrivilegeError: if desired_priv cannot be attained \"\"\" self._validate_privilege_level_name(privilege_level_name=desired_priv) privilege_change_count = 0 while True: current_prompt = await self.channel.get_prompt() privilege_action, target_priv = self._process_acquire_priv( destination_priv=desired_priv, current_prompt=current_prompt, ) if privilege_action == PrivilegeAction.NO_ACTION: self._current_priv_level = target_priv return if privilege_action == PrivilegeAction.DEESCALATE: await self._deescalate(current_priv=target_priv) if privilege_action == PrivilegeAction.ESCALATE: await self._escalate(escalate_priv=target_priv) privilege_change_count += 1 if privilege_change_count > len(self.privilege_levels) * 2: msg = f\"Failed to acquire requested privilege level {desired_priv}\" raise ScrapliPrivilegeError(msg) async def _acquire_appropriate_privilege_level(self, privilege_level: str = \"\") -> None: \"\"\" Acquire the appropriate priv level Acquires the \"right\" priv level based on generic_driver_mode, provided privilege level, and default desired privilege level. If in \"generic_driver_mode\" and no priv level is provided, we simply return as we are already at the \"right\" priv level (since we don't care about priv levels in this mode). If we are in \"generic_driver_mode\" and we are provided a priv level (this is only applicable in `send_interactive`) we will try to acquire that provided priv level. If a priv name is passed we try to resolve it and use that as the privilege level to acquire, otherwise if no priv leve is provided we will acquire the default_desired_privilege_level. Args: privilege_level: optional name of privilege level to acquire Returns: None Raises: N/A \"\"\" if not privilege_level and self._generic_driver_mode is True: return if privilege_level: self._validate_privilege_level_name(privilege_level_name=privilege_level) resolved_privilege_level = privilege_level else: resolved_privilege_level = self.default_desired_privilege_level if self._current_priv_level.name != resolved_privilege_level: await self.acquire_priv(desired_priv=resolved_privilege_level) async def send_command( self, command: str, *, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, timeout_ops: Optional[float] = None, ) -> Response: \"\"\" Send a command Super method will raise TypeError if anything but a string is passed here! Args: command: string to send to device in privilege exec mode strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed Returns: Response: Scrapli Response object Raises: N/A \"\"\" await self._acquire_appropriate_privilege_level() if failed_when_contains is None: failed_when_contains = self.failed_when_contains response = await super().send_command( command=command, strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, timeout_ops=timeout_ops, ) self._update_response(response) return response async def send_commands( self, commands: List[str], *, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, stop_on_failed: bool = False, eager: bool = False, timeout_ops: Optional[float] = None, ) -> MultiResponse: \"\"\" Send multiple commands Super method will raise TypeError if anything but a list of strings is passed here! Args: commands: list of strings to send to device in privilege exec mode strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER COMMAND sent, not for the total of the commands being sent! Returns: MultiResponse: Scrapli MultiResponse object Raises: N/A \"\"\" await self._acquire_appropriate_privilege_level() if failed_when_contains is None: failed_when_contains = self.failed_when_contains responses = await super().send_commands( commands=commands, strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, stop_on_failed=stop_on_failed, eager=eager, timeout_ops=timeout_ops, ) for response in responses: self._update_response(response=response) return responses async def send_commands_from_file( self, file: str, *, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, stop_on_failed: bool = False, eager: bool = False, timeout_ops: Optional[float] = None, ) -> MultiResponse: \"\"\" Send command(s) from file Args: file: string path to file strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER COMMAND sent, not for the total of the commands being sent! Returns: MultiResponse: Scrapli MultiResponse object Raises: N/A \"\"\" await self._acquire_appropriate_privilege_level() if failed_when_contains is None: failed_when_contains = self.failed_when_contains return await super().send_commands_from_file( file=file, strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, stop_on_failed=stop_on_failed, eager=eager, timeout_ops=timeout_ops, ) async def send_interactive( self, interact_events: Union[List[Tuple[str, str]], List[Tuple[str, str, bool]]], *, failed_when_contains: Optional[Union[str, List[str]]] = None, privilege_level: str = \"\", timeout_ops: Optional[float] = None, interaction_complete_patterns: Optional[List[str]] = None, ) -> Response: \"\"\" Interact with a device with changing prompts per input. Used to interact with devices where prompts change per input, and where inputs may be hidden such as in the case of a password input. This can be used to respond to challenges from devices such as the confirmation for the command \"clear logging\" on IOSXE devices for example. You may have as many elements in the \"interact_events\" list as needed, and each element of that list should be a tuple of two or three elements. The first element is always the input to send as a string, the second should be the expected response as a string, and the optional third a bool for whether or not the input is \"hidden\" (i.e. password input) An example where we need this sort of capability: ''' 3560CX#copy flash: scp: Source filename []? test1.txt Address or name of remote host []? 172.31.254.100 Destination username [carl]? Writing test1.txt Password: Password: Sink: C0644 639 test1.txt ! 639 bytes copied in 12.066 secs (53 bytes/sec) 3560CX# ''' To accomplish this we can use the following: ''' interact = conn.channel.send_inputs_interact( [ (\"copy flash: scp:\", \"Source filename []?\", False), (\"test1.txt\", \"Address or name of remote host []?\", False), (\"172.31.254.100\", \"Destination username [carl]?\", False), (\"carl\", \"Password:\", False), (\"super_secure_password\", prompt, True), ] ) ''' If we needed to deal with more prompts we could simply continue adding tuples to the list of interact \"events\". Args: interact_events: list of tuples containing the \"interactions\" with the device each list element must have an input and an expected response, and may have an optional bool for the third and final element -- the optional bool specifies if the input that is sent to the device is \"hidden\" (ex: password), if the hidden param is not provided it is assumed the input is \"normal\" (not hidden) failed_when_contains: list of strings that, if present in final output, represent a failed command/interaction privilege_level: name of the privilege level to operate in timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER COMMAND sent, not for the total of the commands being sent! interaction_complete_patterns: list of patterns, that if seen, indicate the interactive \"session\" has ended and we should exit the interactive session. Returns: Response: scrapli Response object Raises: N/A \"\"\" await self._acquire_appropriate_privilege_level(privilege_level=privilege_level) if failed_when_contains is None: failed_when_contains = self.failed_when_contains # type hint is due to the timeout_modifier wrapper returning `Any` so that we dont anger the # asyncio parts (which will get an awaitable not a Response returned) response: Response = await super().send_interactive( interact_events=interact_events, failed_when_contains=failed_when_contains, timeout_ops=timeout_ops, interaction_complete_patterns=interaction_complete_patterns, ) self._update_response(response=response) return response async def _abort_config(self) -> None: \"\"\" Abort a configuration operation/session if applicable (for config sessions like junos/iosxr) Args: N/A Returns: None Raises: N/A \"\"\" async def send_configs( self, configs: List[str], *, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, stop_on_failed: bool = False, privilege_level: str = \"\", eager: bool = False, timeout_ops: Optional[float] = None, ) -> MultiResponse: \"\"\" Send configuration(s) Args: configs: list of strings to send to device in config mode strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution; aborts configuration session if applicable (iosxr/junos or eos/nxos if using a configuration session) privilege_level: name of configuration privilege level/type to acquire; this is platform dependent, so check the device driver for specifics. Examples of privilege_name would be \"configuration_exclusive\" for IOSXRDriver, or \"configuration_private\" for JunosDriver. You can also pass in a name of a configuration session such as \"my-config-session\" if you have registered a session using the \"register_config_session\" method of the EOSDriver or NXOSDriver. eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER CONFIG sent, not for the total of the configs being sent! Returns: MultiResponse: Scrapli MultiResponse object Raises: N/A \"\"\" resolved_privilege_level, failed_when_contains = self._pre_send_configs( configs=configs, failed_when_contains=failed_when_contains, privilege_level=privilege_level, ) if self._current_priv_level.name != resolved_privilege_level: await self.acquire_priv(desired_priv=resolved_privilege_level) responses = await super().send_commands( commands=configs, strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, stop_on_failed=stop_on_failed, eager=eager, timeout_ops=timeout_ops, ) if stop_on_failed and responses.failed: await self._abort_config() return self._post_send_configs(responses=responses) async def send_config( self, config: str, *, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, stop_on_failed: bool = False, privilege_level: str = \"\", eager: bool = False, timeout_ops: Optional[float] = None, ) -> Response: \"\"\" Send configuration string Args: config: string configuration to send to the device, supports sending multi-line strings strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution; aborts configuration session if applicable (iosxr/junos or eos/nxos if using a configuration session) privilege_level: name of configuration privilege level/type to acquire; this is platform dependent, so check the device driver for specifics. Examples of privilege_name would be \"configuration_exclusive\" for IOSXRDriver, or \"configuration_private\" for JunosDriver. You can also pass in a name of a configuration session such as \"my-config-session\" if you have registered a session using the \"register_config_session\" method of the EOSDriver or NXOSDriver. eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER CONFIG sent, not for the total of the configs being sent! Returns: Response: Scrapli Response object Raises: N/A \"\"\" split_config = self._pre_send_config(config=config) # now that we have a list of configs, just use send_configs to actually execute them multi_response = await self.send_configs( configs=split_config, strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, stop_on_failed=stop_on_failed, privilege_level=privilege_level, eager=eager, timeout_ops=timeout_ops, ) return self._post_send_config(config=config, multi_response=multi_response) async def send_configs_from_file( self, file: str, *, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, stop_on_failed: bool = False, privilege_level: str = \"\", eager: bool = False, timeout_ops: Optional[float] = None, ) -> MultiResponse: \"\"\" Send configuration(s) from a file Args: file: string path to file strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution; aborts configuration session if applicable (iosxr/junos or eos/nxos if using a configuration session) privilege_level: name of configuration privilege level/type to acquire; this is platform dependent, so check the device driver for specifics. Examples of privilege_name would be \"exclusive\" for IOSXRDriver, \"private\" for JunosDriver. You can also pass in a name of a configuration session such as \"session_mysession\" if you have registered a session using the \"register_config_session\" method of the EOSDriver or NXOSDriver. eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER CONFIG sent, not for the total of the configs being sent! Returns: MultiResponse: Scrapli MultiResponse object Raises: N/A \"\"\" configs = self._pre_send_from_file(file=file, caller=\"send_configs_from_file\") return await self.send_configs( configs=configs, strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, stop_on_failed=stop_on_failed, privilege_level=privilege_level, eager=eager, timeout_ops=timeout_ops, )","title":"Module scrapli.driver.network.async_driver"},{"location":"api_docs/driver/network/async_driver/#classes","text":"","title":"Classes"},{"location":"api_docs/driver/network/async_driver/#asyncnetworkdriver","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 BaseDriver Object BaseDriver is the root for all Scrapli driver classes. The synchronous and asyncio driver base driver classes can be used to provide a semi-pexpect like experience over top of whatever transport a user prefers. Generally, however, the base driver classes should not be used directly. It is best to use the GenericDriver (or AsyncGenericDriver) or NetworkDriver (or AsyncNetworkDriver) sub-classes of the base drivers. Args: host: host ip/name to connect to port: port to connect to auth_username: username for authentication auth_private_key: path to private key for authentication auth_private_key_passphrase: passphrase for decrypting ssh key if necessary auth_password: password for authentication auth_strict_key: strict host checking or not auth_bypass: bypass \"in channel\" authentication -- only supported with telnet, asynctelnet, and system transport plugins timeout_socket: timeout for establishing socket/initial connection in seconds timeout_transport: timeout for ssh|telnet transport in seconds timeout_ops: timeout for ssh channel operations comms_prompt_pattern: raw string regex pattern -- preferably use `^` and `$` anchors! this is the single most important attribute here! if this does not match a prompt, scrapli will not work! IMPORTANT: regex search uses multi-line + case insensitive flags. multi-line allows for highly reliably matching for prompts however we do NOT strip trailing whitespace for each line, so be sure to add '\\\\s?' or similar if your device needs that. This should be mostly sorted for you if using network drivers (i.e. `IOSXEDriver`). Lastly, the case insensitive is just a convenience factor so i can be lazy. comms_return_char: character to use to send returns to host ssh_config_file: string to path for ssh config file, True to use default ssh config file or False to ignore default ssh config file ssh_known_hosts_file: string to path for ssh known hosts file, True to use default known file locations. Only applicable/needed if `auth_strict_key` is set to True on_init: callable that accepts the class instance as its only argument. this callable, if provided, is executed as the last step of object instantiation -- its purpose is primarily to provide a mechanism for scrapli community platforms to have an easy way to modify initialization arguments/object attributes without needing to create a class that extends the driver, instead allowing the community platforms to simply build from the GenericDriver or NetworkDriver classes, and pass this callable to do things such as appending to a username (looking at you RouterOS!!). Note that this is *always* a synchronous function (even for asyncio drivers)! on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar transport: name of the transport plugin to use for the actual telnet/ssh/netconf connection. Available \"core\" transports are: - system - telnet - asynctelnet - ssh2 - paramiko - asyncssh Please see relevant transport plugin section for details. Additionally third party transport plugins may be available. transport_options: dictionary of options to pass to selected transport class; see docs for given transport class for details of what to pass here channel_lock: True/False to lock the channel (threading.Lock/asyncio.Lock) during any channel operations, defaults to False channel_log: True/False or a string path to a file of where to write out channel logs -- these are not \"logs\" in the normal logging module sense, but only the output that is read from the channel. In other words, the output of the channel log should look similar to what you would see as a human connecting to a device channel_log_mode: \"write\"|\"append\", all other values will raise ValueError, does what it sounds like it should by setting the channel log to the provided mode logging_uid: unique identifier (string) to associate to log messages; useful if you have multiple connections to the same device (i.e. one console, one ssh, or one to each supervisor module, etc.) Returns: None Raises: N/A Expand source code class AsyncNetworkDriver(AsyncGenericDriver, BaseNetworkDriver): def __init__( self, host: str, privilege_levels: Dict[str, PrivilegeLevel], default_desired_privilege_level: str, port: Optional[int] = None, auth_username: str = \"\", auth_password: str = \"\", auth_private_key: str = \"\", auth_private_key_passphrase: str = \"\", auth_strict_key: bool = True, auth_bypass: bool = False, timeout_socket: float = 15.0, timeout_transport: float = 30.0, timeout_ops: float = 30.0, comms_return_char: str = \"\\n\", ssh_config_file: Union[str, bool] = False, ssh_known_hosts_file: Union[str, bool] = False, on_init: Optional[Callable[..., Any]] = None, on_open: Optional[Callable[..., Any]] = None, on_close: Optional[Callable[..., Any]] = None, transport: str = \"system\", transport_options: Optional[Dict[str, Any]] = None, channel_log: Union[str, bool, BytesIO] = False, channel_log_mode: str = \"write\", channel_lock: bool = False, logging_uid: str = \"\", auth_secondary: str = \"\", failed_when_contains: Optional[List[str]] = None, textfsm_platform: str = \"\", genie_platform: str = \"\", ): # ensure type for comms_prompt_pattern exists before setting it in the mixin self.comms_prompt_pattern: str super().__init__( host=host, port=port, auth_username=auth_username, auth_password=auth_password, auth_private_key=auth_private_key, auth_private_key_passphrase=auth_private_key_passphrase, auth_strict_key=auth_strict_key, auth_bypass=auth_bypass, timeout_socket=timeout_socket, timeout_transport=timeout_transport, timeout_ops=timeout_ops, comms_return_char=comms_return_char, ssh_config_file=ssh_config_file, ssh_known_hosts_file=ssh_known_hosts_file, on_init=on_init, on_open=on_open, on_close=on_close, transport=transport, transport_options=transport_options, channel_log=channel_log, channel_log_mode=channel_log_mode, channel_lock=channel_lock, logging_uid=logging_uid, ) self.auth_secondary = auth_secondary self.failed_when_contains = failed_when_contains or [] self.textfsm_platform = textfsm_platform self.genie_platform = genie_platform self.privilege_levels = privilege_levels self.default_desired_privilege_level = default_desired_privilege_level self._priv_graph = defaultdict(set) self.update_privilege_levels() async def _escalate(self, escalate_priv: PrivilegeLevel) -> None: \"\"\" Escalate to the next privilege level up Args: escalate_priv: privilege level to escalate to Returns: None Raises: ScrapliAuthenticationFailed: if auth escalation timeout \"\"\" self._pre_escalate(escalate_priv=escalate_priv) if escalate_priv.escalate_auth is False: await self.channel.send_input(channel_input=escalate_priv.escalate) else: try: await super().send_interactive( interact_events=[ (escalate_priv.escalate, escalate_priv.escalate_prompt, False), (self.auth_secondary, escalate_priv.pattern, True), ], interaction_complete_patterns=[ self.privilege_levels[escalate_priv.previous_priv].pattern, escalate_priv.pattern, ], ) except ScrapliTimeout as exc: raise ScrapliAuthenticationFailed( f\"failed escalating privilege from '{escalate_priv.previous_priv}' to \" f\"'{escalate_priv.name}'. do you need to set an 'auth_secondary' password?\" ) from exc async def _deescalate(self, current_priv: PrivilegeLevel) -> None: \"\"\" Deescalate to the next privilege level down Args: current_priv: current privilege level Returns: None Raises: N/A \"\"\" await self.channel.send_input(channel_input=current_priv.deescalate) async def acquire_priv(self, desired_priv: str) -> None: \"\"\" Acquire desired priv level Args: desired_priv: string name of desired privilege level see `scrapli.driver. .driver` for levels Returns: None Raises: ScrapliPrivilegeError: if desired_priv cannot be attained \"\"\" self._validate_privilege_level_name(privilege_level_name=desired_priv) privilege_change_count = 0 while True: current_prompt = await self.channel.get_prompt() privilege_action, target_priv = self._process_acquire_priv( destination_priv=desired_priv, current_prompt=current_prompt, ) if privilege_action == PrivilegeAction.NO_ACTION: self._current_priv_level = target_priv return if privilege_action == PrivilegeAction.DEESCALATE: await self._deescalate(current_priv=target_priv) if privilege_action == PrivilegeAction.ESCALATE: await self._escalate(escalate_priv=target_priv) privilege_change_count += 1 if privilege_change_count > len(self.privilege_levels) * 2: msg = f\"Failed to acquire requested privilege level {desired_priv}\" raise ScrapliPrivilegeError(msg) async def _acquire_appropriate_privilege_level(self, privilege_level: str = \"\") -> None: \"\"\" Acquire the appropriate priv level Acquires the \"right\" priv level based on generic_driver_mode, provided privilege level, and default desired privilege level. If in \"generic_driver_mode\" and no priv level is provided, we simply return as we are already at the \"right\" priv level (since we don't care about priv levels in this mode). If we are in \"generic_driver_mode\" and we are provided a priv level (this is only applicable in `send_interactive`) we will try to acquire that provided priv level. If a priv name is passed we try to resolve it and use that as the privilege level to acquire, otherwise if no priv leve is provided we will acquire the default_desired_privilege_level. Args: privilege_level: optional name of privilege level to acquire Returns: None Raises: N/A \"\"\" if not privilege_level and self._generic_driver_mode is True: return if privilege_level: self._validate_privilege_level_name(privilege_level_name=privilege_level) resolved_privilege_level = privilege_level else: resolved_privilege_level = self.default_desired_privilege_level if self._current_priv_level.name != resolved_privilege_level: await self.acquire_priv(desired_priv=resolved_privilege_level) async def send_command( self, command: str, *, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, timeout_ops: Optional[float] = None, ) -> Response: \"\"\" Send a command Super method will raise TypeError if anything but a string is passed here! Args: command: string to send to device in privilege exec mode strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed Returns: Response: Scrapli Response object Raises: N/A \"\"\" await self._acquire_appropriate_privilege_level() if failed_when_contains is None: failed_when_contains = self.failed_when_contains response = await super().send_command( command=command, strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, timeout_ops=timeout_ops, ) self._update_response(response) return response async def send_commands( self, commands: List[str], *, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, stop_on_failed: bool = False, eager: bool = False, timeout_ops: Optional[float] = None, ) -> MultiResponse: \"\"\" Send multiple commands Super method will raise TypeError if anything but a list of strings is passed here! Args: commands: list of strings to send to device in privilege exec mode strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER COMMAND sent, not for the total of the commands being sent! Returns: MultiResponse: Scrapli MultiResponse object Raises: N/A \"\"\" await self._acquire_appropriate_privilege_level() if failed_when_contains is None: failed_when_contains = self.failed_when_contains responses = await super().send_commands( commands=commands, strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, stop_on_failed=stop_on_failed, eager=eager, timeout_ops=timeout_ops, ) for response in responses: self._update_response(response=response) return responses async def send_commands_from_file( self, file: str, *, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, stop_on_failed: bool = False, eager: bool = False, timeout_ops: Optional[float] = None, ) -> MultiResponse: \"\"\" Send command(s) from file Args: file: string path to file strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER COMMAND sent, not for the total of the commands being sent! Returns: MultiResponse: Scrapli MultiResponse object Raises: N/A \"\"\" await self._acquire_appropriate_privilege_level() if failed_when_contains is None: failed_when_contains = self.failed_when_contains return await super().send_commands_from_file( file=file, strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, stop_on_failed=stop_on_failed, eager=eager, timeout_ops=timeout_ops, ) async def send_interactive( self, interact_events: Union[List[Tuple[str, str]], List[Tuple[str, str, bool]]], *, failed_when_contains: Optional[Union[str, List[str]]] = None, privilege_level: str = \"\", timeout_ops: Optional[float] = None, interaction_complete_patterns: Optional[List[str]] = None, ) -> Response: \"\"\" Interact with a device with changing prompts per input. Used to interact with devices where prompts change per input, and where inputs may be hidden such as in the case of a password input. This can be used to respond to challenges from devices such as the confirmation for the command \"clear logging\" on IOSXE devices for example. You may have as many elements in the \"interact_events\" list as needed, and each element of that list should be a tuple of two or three elements. The first element is always the input to send as a string, the second should be the expected response as a string, and the optional third a bool for whether or not the input is \"hidden\" (i.e. password input) An example where we need this sort of capability: ''' 3560CX#copy flash: scp: Source filename []? test1.txt Address or name of remote host []? 172.31.254.100 Destination username [carl]? Writing test1.txt Password: Password: Sink: C0644 639 test1.txt ! 639 bytes copied in 12.066 secs (53 bytes/sec) 3560CX# ''' To accomplish this we can use the following: ''' interact = conn.channel.send_inputs_interact( [ (\"copy flash: scp:\", \"Source filename []?\", False), (\"test1.txt\", \"Address or name of remote host []?\", False), (\"172.31.254.100\", \"Destination username [carl]?\", False), (\"carl\", \"Password:\", False), (\"super_secure_password\", prompt, True), ] ) ''' If we needed to deal with more prompts we could simply continue adding tuples to the list of interact \"events\". Args: interact_events: list of tuples containing the \"interactions\" with the device each list element must have an input and an expected response, and may have an optional bool for the third and final element -- the optional bool specifies if the input that is sent to the device is \"hidden\" (ex: password), if the hidden param is not provided it is assumed the input is \"normal\" (not hidden) failed_when_contains: list of strings that, if present in final output, represent a failed command/interaction privilege_level: name of the privilege level to operate in timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER COMMAND sent, not for the total of the commands being sent! interaction_complete_patterns: list of patterns, that if seen, indicate the interactive \"session\" has ended and we should exit the interactive session. Returns: Response: scrapli Response object Raises: N/A \"\"\" await self._acquire_appropriate_privilege_level(privilege_level=privilege_level) if failed_when_contains is None: failed_when_contains = self.failed_when_contains # type hint is due to the timeout_modifier wrapper returning `Any` so that we dont anger the # asyncio parts (which will get an awaitable not a Response returned) response: Response = await super().send_interactive( interact_events=interact_events, failed_when_contains=failed_when_contains, timeout_ops=timeout_ops, interaction_complete_patterns=interaction_complete_patterns, ) self._update_response(response=response) return response async def _abort_config(self) -> None: \"\"\" Abort a configuration operation/session if applicable (for config sessions like junos/iosxr) Args: N/A Returns: None Raises: N/A \"\"\" async def send_configs( self, configs: List[str], *, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, stop_on_failed: bool = False, privilege_level: str = \"\", eager: bool = False, timeout_ops: Optional[float] = None, ) -> MultiResponse: \"\"\" Send configuration(s) Args: configs: list of strings to send to device in config mode strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution; aborts configuration session if applicable (iosxr/junos or eos/nxos if using a configuration session) privilege_level: name of configuration privilege level/type to acquire; this is platform dependent, so check the device driver for specifics. Examples of privilege_name would be \"configuration_exclusive\" for IOSXRDriver, or \"configuration_private\" for JunosDriver. You can also pass in a name of a configuration session such as \"my-config-session\" if you have registered a session using the \"register_config_session\" method of the EOSDriver or NXOSDriver. eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER CONFIG sent, not for the total of the configs being sent! Returns: MultiResponse: Scrapli MultiResponse object Raises: N/A \"\"\" resolved_privilege_level, failed_when_contains = self._pre_send_configs( configs=configs, failed_when_contains=failed_when_contains, privilege_level=privilege_level, ) if self._current_priv_level.name != resolved_privilege_level: await self.acquire_priv(desired_priv=resolved_privilege_level) responses = await super().send_commands( commands=configs, strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, stop_on_failed=stop_on_failed, eager=eager, timeout_ops=timeout_ops, ) if stop_on_failed and responses.failed: await self._abort_config() return self._post_send_configs(responses=responses) async def send_config( self, config: str, *, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, stop_on_failed: bool = False, privilege_level: str = \"\", eager: bool = False, timeout_ops: Optional[float] = None, ) -> Response: \"\"\" Send configuration string Args: config: string configuration to send to the device, supports sending multi-line strings strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution; aborts configuration session if applicable (iosxr/junos or eos/nxos if using a configuration session) privilege_level: name of configuration privilege level/type to acquire; this is platform dependent, so check the device driver for specifics. Examples of privilege_name would be \"configuration_exclusive\" for IOSXRDriver, or \"configuration_private\" for JunosDriver. You can also pass in a name of a configuration session such as \"my-config-session\" if you have registered a session using the \"register_config_session\" method of the EOSDriver or NXOSDriver. eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER CONFIG sent, not for the total of the configs being sent! Returns: Response: Scrapli Response object Raises: N/A \"\"\" split_config = self._pre_send_config(config=config) # now that we have a list of configs, just use send_configs to actually execute them multi_response = await self.send_configs( configs=split_config, strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, stop_on_failed=stop_on_failed, privilege_level=privilege_level, eager=eager, timeout_ops=timeout_ops, ) return self._post_send_config(config=config, multi_response=multi_response) async def send_configs_from_file( self, file: str, *, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, stop_on_failed: bool = False, privilege_level: str = \"\", eager: bool = False, timeout_ops: Optional[float] = None, ) -> MultiResponse: \"\"\" Send configuration(s) from a file Args: file: string path to file strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution; aborts configuration session if applicable (iosxr/junos or eos/nxos if using a configuration session) privilege_level: name of configuration privilege level/type to acquire; this is platform dependent, so check the device driver for specifics. Examples of privilege_name would be \"exclusive\" for IOSXRDriver, \"private\" for JunosDriver. You can also pass in a name of a configuration session such as \"session_mysession\" if you have registered a session using the \"register_config_session\" method of the EOSDriver or NXOSDriver. eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER CONFIG sent, not for the total of the configs being sent! Returns: MultiResponse: Scrapli MultiResponse object Raises: N/A \"\"\" configs = self._pre_send_from_file(file=file, caller=\"send_configs_from_file\") return await self.send_configs( configs=configs, strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, stop_on_failed=stop_on_failed, privilege_level=privilege_level, eager=eager, timeout_ops=timeout_ops, )","title":"AsyncNetworkDriver"},{"location":"api_docs/driver/network/async_driver/#ancestors-in-mro","text":"scrapli.driver.generic.async_driver.AsyncGenericDriver scrapli.driver.base.async_driver.AsyncDriver scrapli.driver.base.base_driver.BaseDriver scrapli.driver.generic.base_driver.BaseGenericDriver scrapli.driver.network.base_driver.BaseNetworkDriver","title":"Ancestors (in MRO)"},{"location":"api_docs/driver/network/async_driver/#descendants","text":"scrapli.driver.core.arista_eos.async_driver.AsyncEOSDriver scrapli.driver.core.cisco_iosxe.async_driver.AsyncIOSXEDriver scrapli.driver.core.cisco_iosxr.async_driver.AsyncIOSXRDriver scrapli.driver.core.cisco_nxos.async_driver.AsyncNXOSDriver scrapli.driver.core.juniper_junos.async_driver.AsyncJunosDriver scrapli.factory.AsyncScrapli","title":"Descendants"},{"location":"api_docs/driver/network/async_driver/#methods","text":"","title":"Methods"},{"location":"api_docs/driver/network/async_driver/#acquire_priv","text":"acquire_priv(self, desired_priv: str) \u2011> None 1 2 3 4 5 6 7 8 9 10 11 Acquire desired priv level Args: desired_priv: string name of desired privilege level see `scrapli.driver.<driver_category.device_type>.driver` for levels Returns: None Raises: ScrapliPrivilegeError: if desired_priv cannot be attained","title":"acquire_priv"},{"location":"api_docs/driver/network/async_driver/#send_command","text":"send_command(self, command: str, *, strip_prompt: bool = True, failed_when_contains: Union[str, List[str], ForwardRef(None)] = None, timeout_ops: Optional[float] = None) \u2011> scrapli.response.Response 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 Send a command Super method will raise TypeError if anything but a string is passed here! Args: command: string to send to device in privilege exec mode strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed Returns: Response: Scrapli Response object Raises: N/A","title":"send_command"},{"location":"api_docs/driver/network/async_driver/#send_commands","text":"send_commands(self, commands: List[str], *, strip_prompt: bool = True, failed_when_contains: Union[str, List[str], ForwardRef(None)] = None, stop_on_failed: bool = False, eager: bool = False, timeout_ops: Optional[float] = None) \u2011> scrapli.response.MultiResponse 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 Send multiple commands Super method will raise TypeError if anything but a list of strings is passed here! Args: commands: list of strings to send to device in privilege exec mode strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER COMMAND sent, not for the total of the commands being sent! Returns: MultiResponse: Scrapli MultiResponse object Raises: N/A","title":"send_commands"},{"location":"api_docs/driver/network/async_driver/#send_config","text":"send_config(self, config: str, *, strip_prompt: bool = True, failed_when_contains: Union[str, List[str], ForwardRef(None)] = None, stop_on_failed: bool = False, privilege_level: str = '', eager: bool = False, timeout_ops: Optional[float] = None) \u2011> scrapli.response.Response 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 Send configuration string Args: config: string configuration to send to the device, supports sending multi-line strings strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution; aborts configuration session if applicable (iosxr/junos or eos/nxos if using a configuration session) privilege_level: name of configuration privilege level/type to acquire; this is platform dependent, so check the device driver for specifics. Examples of privilege_name would be \"configuration_exclusive\" for IOSXRDriver, or \"configuration_private\" for JunosDriver. You can also pass in a name of a configuration session such as \"my-config-session\" if you have registered a session using the \"register_config_session\" method of the EOSDriver or NXOSDriver. eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER CONFIG sent, not for the total of the configs being sent! Returns: Response: Scrapli Response object Raises: N/A","title":"send_config"},{"location":"api_docs/driver/network/async_driver/#send_configs","text":"send_configs(self, configs: List[str], *, strip_prompt: bool = True, failed_when_contains: Union[str, List[str], ForwardRef(None)] = None, stop_on_failed: bool = False, privilege_level: str = '', eager: bool = False, timeout_ops: Optional[float] = None) \u2011> scrapli.response.MultiResponse 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 Send configuration(s) Args: configs: list of strings to send to device in config mode strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution; aborts configuration session if applicable (iosxr/junos or eos/nxos if using a configuration session) privilege_level: name of configuration privilege level/type to acquire; this is platform dependent, so check the device driver for specifics. Examples of privilege_name would be \"configuration_exclusive\" for IOSXRDriver, or \"configuration_private\" for JunosDriver. You can also pass in a name of a configuration session such as \"my-config-session\" if you have registered a session using the \"register_config_session\" method of the EOSDriver or NXOSDriver. eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER CONFIG sent, not for the total of the configs being sent! Returns: MultiResponse: Scrapli MultiResponse object Raises: N/A","title":"send_configs"},{"location":"api_docs/driver/network/async_driver/#send_configs_from_file","text":"send_configs_from_file(self, file: str, *, strip_prompt: bool = True, failed_when_contains: Union[str, List[str], ForwardRef(None)] = None, stop_on_failed: bool = False, privilege_level: str = '', eager: bool = False, timeout_ops: Optional[float] = None) \u2011> scrapli.response.MultiResponse 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 Send configuration(s) from a file Args: file: string path to file strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution; aborts configuration session if applicable (iosxr/junos or eos/nxos if using a configuration session) privilege_level: name of configuration privilege level/type to acquire; this is platform dependent, so check the device driver for specifics. Examples of privilege_name would be \"exclusive\" for IOSXRDriver, \"private\" for JunosDriver. You can also pass in a name of a configuration session such as \"session_mysession\" if you have registered a session using the \"register_config_session\" method of the EOSDriver or NXOSDriver. eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER CONFIG sent, not for the total of the configs being sent! Returns: MultiResponse: Scrapli MultiResponse object Raises: N/A","title":"send_configs_from_file"},{"location":"api_docs/driver/network/async_driver/#send_interactive","text":"send_interactive(self, interact_events: Union[List[Tuple[str, str]], List[Tuple[str, str, bool]]], *, failed_when_contains: Union[str, List[str], ForwardRef(None)] = None, privilege_level: str = '', timeout_ops: Optional[float] = None, interaction_complete_patterns: Optional[List[str]] = None) \u2011> scrapli.response.Response 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 Interact with a device with changing prompts per input. Used to interact with devices where prompts change per input, and where inputs may be hidden such as in the case of a password input. This can be used to respond to challenges from devices such as the confirmation for the command \"clear logging\" on IOSXE devices for example. You may have as many elements in the \"interact_events\" list as needed, and each element of that list should be a tuple of two or three elements. The first element is always the input to send as a string, the second should be the expected response as a string, and the optional third a bool for whether or not the input is \"hidden\" (i.e. password input) An example where we need this sort of capability: ''' 3560CX#copy flash: scp: Source filename []? test1.txt Address or name of remote host []? 172.31.254.100 Destination username [carl]? Writing test1.txt Password: Password: Sink: C0644 639 test1.txt ! 639 bytes copied in 12.066 secs (53 bytes/sec) 3560CX# ''' To accomplish this we can use the following: ''' interact = conn.channel.send_inputs_interact( [ (\"copy flash: scp:\", \"Source filename []?\", False), (\"test1.txt\", \"Address or name of remote host []?\", False), (\"172.31.254.100\", \"Destination username [carl]?\", False), (\"carl\", \"Password:\", False), (\"super_secure_password\", prompt, True), ] ) ''' If we needed to deal with more prompts we could simply continue adding tuples to the list of interact \"events\". Args: interact_events: list of tuples containing the \"interactions\" with the device each list element must have an input and an expected response, and may have an optional bool for the third and final element -- the optional bool specifies if the input that is sent to the device is \"hidden\" (ex: password), if the hidden param is not provided it is assumed the input is \"normal\" (not hidden) failed_when_contains: list of strings that, if present in final output, represent a failed command/interaction privilege_level: name of the privilege level to operate in timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER COMMAND sent, not for the total of the commands being sent! interaction_complete_patterns: list of patterns, that if seen, indicate the interactive \"session\" has ended and we should exit the interactive session. Returns: Response: scrapli Response object Raises: N/A","title":"send_interactive"},{"location":"api_docs/driver/network/base_driver/","text":"window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting()) Module scrapli.driver.network.base_driver \u00b6 scrapli.driver.network.base_driver Expand source code \"\"\"scrapli.driver.network.base_driver\"\"\" import re from collections import defaultdict from datetime import datetime from enum import Enum from functools import lru_cache from logging import Logger, LoggerAdapter from typing import TYPE_CHECKING, DefaultDict, Dict, List, Optional, Set, Tuple, Union from scrapli.exceptions import ScrapliPrivilegeError, ScrapliTypeError from scrapli.helper import user_warning from scrapli.response import MultiResponse, Response if TYPE_CHECKING: LoggerAdapterT = LoggerAdapter[Logger] # pragma: no cover # pylint:disable=E1136 else: LoggerAdapterT = LoggerAdapter class PrivilegeLevel: __slots__ = ( \"pattern\", \"name\", \"previous_priv\", \"deescalate\", \"escalate\", \"escalate_auth\", \"escalate_prompt\", \"not_contains\", ) def __init__( self, pattern: str, name: str, previous_priv: str, deescalate: str, escalate: str, escalate_auth: bool, escalate_prompt: str, not_contains: Optional[List[str]] = None, ): \"\"\" PrivilegeLevel Object Args: pattern: regex pattern to use to identify this privilege level by the prompt name: friendly name of this privilege level previous_priv: name of the lower/previous privilege level deescalate: how to deescalate *from* this privilege level (to the lower/previous priv) escalate: how to escalate *to* this privilege level (from the lower/previous priv) escalate_auth: True/False escalation requires authentication escalate_prompt: prompt pattern to search for during escalation if escalate auth is True not_contains: list of substrings that should *not* be seen in a prompt for this privilege level Returns: None Raises: N/A \"\"\" self.pattern = pattern self.name = name self.previous_priv = previous_priv self.deescalate = deescalate self.escalate = escalate self.escalate_auth = escalate_auth self.escalate_prompt = escalate_prompt self.not_contains: List[str] = not_contains or [] DUMMY_PRIV_LEVEL = PrivilegeLevel(\"\", \"DUMMY\", \"\", \"\", \"\", False, \"\") PRIVS: Dict[str, PrivilegeLevel] = {} class PrivilegeAction(Enum): NO_ACTION = \"no action\" ESCALATE = \"escalate\" DEESCALATE = \"deescalate\" class BaseNetworkDriver: # BaseNetworkDriver Mixin vars for typing/linting purposes logger: LoggerAdapterT auth_secondary: str failed_when_contains: List[str] textfsm_platform: str genie_platform: str privilege_levels: Dict[str, PrivilegeLevel] comms_prompt_pattern: str _current_priv_level = DUMMY_PRIV_LEVEL _priv_graph: DefaultDict[str, Set[str]] def _generate_comms_prompt_pattern(self) -> None: \"\"\" Generate the `comms_prompt_pattern` from the currently assigned privilege levels Args: N/A Returns: None Raises: N/A \"\"\" self.logger.debug(\"generating combined network comms prompt pattern\") self.comms_prompt_pattern = r\"|\".join( rf\"({priv_level_data.pattern})\" for priv_level_data in self.privilege_levels.values() ) @lru_cache(maxsize=64) def _determine_current_priv(self, current_prompt: str) -> List[str]: \"\"\" Determine current privilege level from prompt string Args: current_prompt: string of current prompt Returns: list: list of string names of matching privilege levels Raises: ScrapliPrivilegeError: if privilege level cannot be determined \"\"\" matching_priv_levels = [] for priv_level in self.privilege_levels.values(): if priv_level.not_contains: # starting at 2021.07.30 the `not_contains` field was added to privilege levels # (defaulting to an empty tuple) -- this helps us to simplify the priv patterns # greatly, as well as have no reliance on look arounds which makes the \"normal\" # scrapli privilege levels more go friendly -- useful for scrapligo! if any(not_contains in current_prompt for not_contains in priv_level.not_contains): continue search_result = re.search( pattern=priv_level.pattern, string=current_prompt, flags=re.M | re.I ) if not search_result: continue matching_priv_levels.append(priv_level.name) if not matching_priv_levels: msg = f\"could not determine privilege level from provided prompt: '{current_prompt}'\" self.logger.critical(msg) raise ScrapliPrivilegeError(msg) self.logger.debug(f\"determined current privilege level is one of '{matching_priv_levels}'\") return matching_priv_levels def _build_priv_graph(self) -> None: \"\"\" Build a graph of privilege levels `_priv_graph` is a \"graph\" of all privilege levels and how to acquire them from any given priv level. This is probably not very efficient but we should never have more than a handful of priv levels so this should never be a big issue. While at the moment priv levels are always... \"linear\" in that there is only ever one \"up\" and one \"down\" privilege from any given priv, we still have \"forks\" in the road -- for example, in IOSXR we can go from privilege exec to configuration or configuration exclusive. This method builds a graph that allows us to make intelligent decisions about how to get from where we are to where we want to be! Args: N/A Returns: None Raises: N/A \"\"\" self._priv_graph = defaultdict(set) privilege_levels = self.privilege_levels.values() for privilege_level in privilege_levels: if privilege_level.previous_priv: self._priv_graph[privilege_level.name].add(privilege_level.previous_priv) else: self._priv_graph[privilege_level.name] = set() for higher_privilege_level, privilege_level_list in self._priv_graph.items(): for privilege_level_name in privilege_level_list: self._priv_graph[privilege_level_name].add(higher_privilege_level) def _build_priv_change_map( self, starting_priv_name: str, destination_priv_name: str, priv_change_map: Optional[List[str]] = None, ) -> List[str]: \"\"\" Generate a list of priv levels from starting priv to destination priv Args: starting_priv_name: name of starting priv destination_priv_name: name of destination priv priv_change_map: current priv_change_map; should only be passed when this function calls itself Returns: list: list of strings of priv names to get from starting to destination priv level Raises: N/A \"\"\" if priv_change_map is None: priv_change_map = [] priv_change_map = priv_change_map + [starting_priv_name] if starting_priv_name == destination_priv_name: return priv_change_map for privilege_name in self._priv_graph[starting_priv_name]: if privilege_name not in priv_change_map: updated_priv_change_map = self._build_priv_change_map( starting_priv_name=privilege_name, destination_priv_name=destination_priv_name, priv_change_map=priv_change_map, ) if updated_priv_change_map: return updated_priv_change_map # shouldnt ever get to this i dont think... putting here to appease pylint and ignoring cov return [] # pragma: nocover def update_privilege_levels(self) -> None: \"\"\" Re-generate the privilege graph, and update the comms prompt pattern Args: N/A Returns: None Raises: N/A \"\"\" # build/update the priv graph self._build_priv_graph() # build/update the joined comms prompt pattern self._generate_comms_prompt_pattern() # ensure the channel has the updated prompt pattern so it knows how to match any newly # updated priv levels (such as registered configuration sessions) self.channel.comms_prompt_pattern = ( # type: ignore # pylint: disable=E1101 self.comms_prompt_pattern ) # finally, clear the lru caches as patterns may have been updated self._determine_current_priv.cache_clear() def _validate_privilege_level_name(self, privilege_level_name: str) -> None: \"\"\" Get privilege level name if provided privilege is valid Args: privilege_level_name: string name of desired privilege level Returns: None Raises: ScrapliPrivilegeError: if attempting to acquire an unknown priv \"\"\" desired_privilege_level = self.privilege_levels.get(privilege_level_name) if desired_privilege_level is None: msg = ( f\"requested privilege level '{privilege_level_name}' not a valid privilege level of\" f\" '{self.__class__.__name__}'\" ) self.logger.critical(msg) raise ScrapliPrivilegeError(msg) def _pre_escalate(self, escalate_priv: PrivilegeLevel) -> None: \"\"\" Handle pre \"_escalate\" tasks for consistency between sync/async versions Args: escalate_priv: privilege level to escalate to Returns: None Raises: N/A \"\"\" if escalate_priv.escalate_auth is True and not self.auth_secondary: title = \"Authentication Warning!\" message = ( \"scrapli will try to escalate privilege without entering a password but may \" \"fail.\\nSet an 'auth_secondary' password if your device requires a password to \" \"increase privilege, otherwise ignore this message.\" ) user_warning(title=title, message=message) def _process_acquire_priv( self, destination_priv: str, current_prompt: str, ) -> Tuple[PrivilegeAction, PrivilegeLevel]: \"\"\" Handle non channel \"acquire_priv\" tasks for consistency between sync/async versions Args: destination_priv: string name of desired privilege level current_prompt: string of the current prompt Returns: Tuple[PrivilegeAction, PrivilegeLevel]: enum set to appropriate value for no action, escalate or deescalate and privilege level object to pass to either escalate or deescalate method Raises: N/A \"\"\" self.logger.info(f\"attempting to acquire '{destination_priv}' privilege level\") # decide if we are already at the desired priv, then we don't need to do any thing! current_priv_patterns = self._determine_current_priv(current_prompt=current_prompt) if self._current_priv_level.name in current_priv_patterns: current_priv = self.privilege_levels[self._current_priv_level.name] elif destination_priv in current_priv_patterns: current_priv = self.privilege_levels[destination_priv] else: # if multiple patterns match pick the zeroith... hopefully this never happens though... # and it *shouldn't* because right now the only way to have the same priv patterns is # to be *basically* the same privilege level -- i.e. configuration and configuration # exclusive for iosxr current_priv = self.privilege_levels[current_priv_patterns[0]] if current_priv.name == destination_priv: self.logger.debug( \"determined current privilege level is target privilege level, no action needed\" ) self._current_priv_level = self.privilege_levels[destination_priv] return PrivilegeAction.NO_ACTION, self.privilege_levels[destination_priv] map_to_destination_priv = self._build_priv_change_map( starting_priv_name=current_priv.name, destination_priv_name=destination_priv ) # at this point we basically dont *know* the privilege leve we are at (or we wont/cant after # we do an escalation or deescalation, so we reset to the dummy priv level self._current_priv_level = DUMMY_PRIV_LEVEL if self.privilege_levels[map_to_destination_priv[1]].previous_priv != current_priv.name: self.logger.debug(\"determined privilege deescalation necessary\") return PrivilegeAction.DEESCALATE, current_priv self.logger.debug(\"determined privilege escalation necessary\") return PrivilegeAction.ESCALATE, self.privilege_levels[map_to_destination_priv[1]] @property def _generic_driver_mode(self) -> bool: \"\"\" Getter for `_generic_driver_mode` attribute Args: N/A Returns: bool: _generic_driver_mode value Raises: N/A \"\"\" try: return self.__generic_driver_mode except AttributeError: return False @_generic_driver_mode.setter def _generic_driver_mode(self, value: bool) -> None: \"\"\" Setter for `_generic_driver_mode` attribute Args: value: bool value for _generic_driver_mode Returns: None Raises: ScrapliTypeError: if value is not of type bool \"\"\" self.logger.debug(f\"setting '_generic_driver_mode' value to '{value}'\") if not isinstance(value, bool): raise ScrapliTypeError if value is True: # if we are setting ingore priv level we reset current priv to the dummy priv so that # once (if) a user turns ignore priv back off we know we need to reset/reacquire priv # as the user coulda done pretty much anything and we could end up at who knows what # priv level self._current_priv_level = DUMMY_PRIV_LEVEL self.__generic_driver_mode = value def _update_response(self, response: Response) -> None: \"\"\" Update response with network driver specific data This happens here as the underlying channel provides a response object but is unaware of any of the network/platform specific attributes that may need to get updated Args: response: response to update Returns: None Raises: N/A \"\"\" response.textfsm_platform = self.textfsm_platform response.genie_platform = self.genie_platform @staticmethod def _pre_send_config(config: str) -> List[str]: \"\"\" Handle pre \"send_config\" tasks for consistency between sync/async versions Args: config: string configuration to send to the device, supports sending multi-line strings Returns: list: list of config lines from provided \"config\" input Raises: ScrapliTypeError: if anything but a string is provided for `file` \"\"\" if not isinstance(config, str): raise ScrapliTypeError( f\"'send_config' expects a single string, got {type(config)}, \" \"to send a list of configs use the 'send_configs' method instead.\" ) # in order to handle multi-line strings, we split lines split_config = config.splitlines() return split_config def _post_send_config( self, config: str, multi_response: MultiResponse, ) -> Response: \"\"\" Handle post \"send_config\" tasks for consistency between sync/async versions Args: config: string configuration to send to the device, supports sending multi-line strings multi_response: multi_response object send_config got from calling self.send_configs; we need this to parse out the multi_response back into a single Response object Returns: Response: Unified response object Raises: N/A \"\"\" # capture failed_when_contains and host from zeroith multi_response element (there should # always be at least a zeroith element here!); getting host just lets us keep the mixin # class a little cleaner without having to deal with sync vs async transport classes from # a typing perspective failed_when_contains = multi_response[0].failed_when_contains host = multi_response[0].host # create a new unified response object response = Response( host=host, channel_input=config, failed_when_contains=failed_when_contains, ) response.start_time = multi_response[0].start_time response.finish_time = datetime.now() response.elapsed_time = (response.finish_time - response.start_time).total_seconds() # join all the results together into a single final result response.result = \"\\n\".join(response.result for response in multi_response) response.failed = False if any(r.failed for r in multi_response): response.failed = True self._update_response(response=response) return response def _pre_send_configs( self, configs: List[str], failed_when_contains: Optional[Union[str, List[str]]] = None, privilege_level: str = \"\", ) -> Tuple[str, Union[str, List[str]]]: \"\"\" Handle pre \"send_configs\" tasks for consistency between sync/async versions Args: configs: list of strings to send to device in config mode failed_when_contains: string or list of strings indicating failure if found in response privilege_level: name of configuration privilege level/type to acquire; this is platform dependent, so check the device driver for specifics. Examples of privilege_name would be \"configuration_exclusive\" for IOSXRDriver, or \"configuration_private\" for JunosDriver. You can also pass in a name of a configuration session such as \"my-config-session\" if you have registered a session using the \"register_config_session\" method of the EOSDriver or NXOSDriver. Returns: Tuple[str, Union[str, List[str]]]: string of resolved privilege level name, and failed when contains which may be a string or list of strings Raises: ScrapliTypeError: if configs is anything but a list ScrapliPrivilegeError: if connection is in 'generic_driver_mode' -- this should be a non-standard use case so there is no reason to complicate the config(s) methods with supporting generic driver mode (plus if there was config modes in generic driver mode that wouldn't be very generic driver like, would it!) \"\"\" if not isinstance(configs, list): raise ScrapliTypeError( f\"'send_configs' expects a list of strings, got {type(configs)}, \" \"to send a single configuration line/string use the 'send_config' method instead.\" ) if self._generic_driver_mode is True: raise ScrapliPrivilegeError( \"connection is in 'generic_driver_mode', send config(s|s_from_file) is disabled\" ) if failed_when_contains is None: final_failed_when_contains = self.failed_when_contains elif isinstance(failed_when_contains, str): final_failed_when_contains = [failed_when_contains] else: final_failed_when_contains = failed_when_contains if privilege_level: self._validate_privilege_level_name(privilege_level_name=privilege_level) resolved_privilege_level = privilege_level else: resolved_privilege_level = \"configuration\" return resolved_privilege_level, final_failed_when_contains def _post_send_configs(self, responses: MultiResponse) -> MultiResponse: \"\"\" Handle post \"send_configs\" tasks for consistency between sync/async versions Args: responses: multi_response object to update Returns: MultiResponse: Unified response object Raises: N/A \"\"\" for response in responses: self._update_response(response=response) return responses Classes \u00b6 BaseNetworkDriver \u00b6 Expand source code class BaseNetworkDriver: # BaseNetworkDriver Mixin vars for typing/linting purposes logger: LoggerAdapterT auth_secondary: str failed_when_contains: List[str] textfsm_platform: str genie_platform: str privilege_levels: Dict[str, PrivilegeLevel] comms_prompt_pattern: str _current_priv_level = DUMMY_PRIV_LEVEL _priv_graph: DefaultDict[str, Set[str]] def _generate_comms_prompt_pattern(self) -> None: \"\"\" Generate the `comms_prompt_pattern` from the currently assigned privilege levels Args: N/A Returns: None Raises: N/A \"\"\" self.logger.debug(\"generating combined network comms prompt pattern\") self.comms_prompt_pattern = r\"|\".join( rf\"({priv_level_data.pattern})\" for priv_level_data in self.privilege_levels.values() ) @lru_cache(maxsize=64) def _determine_current_priv(self, current_prompt: str) -> List[str]: \"\"\" Determine current privilege level from prompt string Args: current_prompt: string of current prompt Returns: list: list of string names of matching privilege levels Raises: ScrapliPrivilegeError: if privilege level cannot be determined \"\"\" matching_priv_levels = [] for priv_level in self.privilege_levels.values(): if priv_level.not_contains: # starting at 2021.07.30 the `not_contains` field was added to privilege levels # (defaulting to an empty tuple) -- this helps us to simplify the priv patterns # greatly, as well as have no reliance on look arounds which makes the \"normal\" # scrapli privilege levels more go friendly -- useful for scrapligo! if any(not_contains in current_prompt for not_contains in priv_level.not_contains): continue search_result = re.search( pattern=priv_level.pattern, string=current_prompt, flags=re.M | re.I ) if not search_result: continue matching_priv_levels.append(priv_level.name) if not matching_priv_levels: msg = f\"could not determine privilege level from provided prompt: '{current_prompt}'\" self.logger.critical(msg) raise ScrapliPrivilegeError(msg) self.logger.debug(f\"determined current privilege level is one of '{matching_priv_levels}'\") return matching_priv_levels def _build_priv_graph(self) -> None: \"\"\" Build a graph of privilege levels `_priv_graph` is a \"graph\" of all privilege levels and how to acquire them from any given priv level. This is probably not very efficient but we should never have more than a handful of priv levels so this should never be a big issue. While at the moment priv levels are always... \"linear\" in that there is only ever one \"up\" and one \"down\" privilege from any given priv, we still have \"forks\" in the road -- for example, in IOSXR we can go from privilege exec to configuration or configuration exclusive. This method builds a graph that allows us to make intelligent decisions about how to get from where we are to where we want to be! Args: N/A Returns: None Raises: N/A \"\"\" self._priv_graph = defaultdict(set) privilege_levels = self.privilege_levels.values() for privilege_level in privilege_levels: if privilege_level.previous_priv: self._priv_graph[privilege_level.name].add(privilege_level.previous_priv) else: self._priv_graph[privilege_level.name] = set() for higher_privilege_level, privilege_level_list in self._priv_graph.items(): for privilege_level_name in privilege_level_list: self._priv_graph[privilege_level_name].add(higher_privilege_level) def _build_priv_change_map( self, starting_priv_name: str, destination_priv_name: str, priv_change_map: Optional[List[str]] = None, ) -> List[str]: \"\"\" Generate a list of priv levels from starting priv to destination priv Args: starting_priv_name: name of starting priv destination_priv_name: name of destination priv priv_change_map: current priv_change_map; should only be passed when this function calls itself Returns: list: list of strings of priv names to get from starting to destination priv level Raises: N/A \"\"\" if priv_change_map is None: priv_change_map = [] priv_change_map = priv_change_map + [starting_priv_name] if starting_priv_name == destination_priv_name: return priv_change_map for privilege_name in self._priv_graph[starting_priv_name]: if privilege_name not in priv_change_map: updated_priv_change_map = self._build_priv_change_map( starting_priv_name=privilege_name, destination_priv_name=destination_priv_name, priv_change_map=priv_change_map, ) if updated_priv_change_map: return updated_priv_change_map # shouldnt ever get to this i dont think... putting here to appease pylint and ignoring cov return [] # pragma: nocover def update_privilege_levels(self) -> None: \"\"\" Re-generate the privilege graph, and update the comms prompt pattern Args: N/A Returns: None Raises: N/A \"\"\" # build/update the priv graph self._build_priv_graph() # build/update the joined comms prompt pattern self._generate_comms_prompt_pattern() # ensure the channel has the updated prompt pattern so it knows how to match any newly # updated priv levels (such as registered configuration sessions) self.channel.comms_prompt_pattern = ( # type: ignore # pylint: disable=E1101 self.comms_prompt_pattern ) # finally, clear the lru caches as patterns may have been updated self._determine_current_priv.cache_clear() def _validate_privilege_level_name(self, privilege_level_name: str) -> None: \"\"\" Get privilege level name if provided privilege is valid Args: privilege_level_name: string name of desired privilege level Returns: None Raises: ScrapliPrivilegeError: if attempting to acquire an unknown priv \"\"\" desired_privilege_level = self.privilege_levels.get(privilege_level_name) if desired_privilege_level is None: msg = ( f\"requested privilege level '{privilege_level_name}' not a valid privilege level of\" f\" '{self.__class__.__name__}'\" ) self.logger.critical(msg) raise ScrapliPrivilegeError(msg) def _pre_escalate(self, escalate_priv: PrivilegeLevel) -> None: \"\"\" Handle pre \"_escalate\" tasks for consistency between sync/async versions Args: escalate_priv: privilege level to escalate to Returns: None Raises: N/A \"\"\" if escalate_priv.escalate_auth is True and not self.auth_secondary: title = \"Authentication Warning!\" message = ( \"scrapli will try to escalate privilege without entering a password but may \" \"fail.\\nSet an 'auth_secondary' password if your device requires a password to \" \"increase privilege, otherwise ignore this message.\" ) user_warning(title=title, message=message) def _process_acquire_priv( self, destination_priv: str, current_prompt: str, ) -> Tuple[PrivilegeAction, PrivilegeLevel]: \"\"\" Handle non channel \"acquire_priv\" tasks for consistency between sync/async versions Args: destination_priv: string name of desired privilege level current_prompt: string of the current prompt Returns: Tuple[PrivilegeAction, PrivilegeLevel]: enum set to appropriate value for no action, escalate or deescalate and privilege level object to pass to either escalate or deescalate method Raises: N/A \"\"\" self.logger.info(f\"attempting to acquire '{destination_priv}' privilege level\") # decide if we are already at the desired priv, then we don't need to do any thing! current_priv_patterns = self._determine_current_priv(current_prompt=current_prompt) if self._current_priv_level.name in current_priv_patterns: current_priv = self.privilege_levels[self._current_priv_level.name] elif destination_priv in current_priv_patterns: current_priv = self.privilege_levels[destination_priv] else: # if multiple patterns match pick the zeroith... hopefully this never happens though... # and it *shouldn't* because right now the only way to have the same priv patterns is # to be *basically* the same privilege level -- i.e. configuration and configuration # exclusive for iosxr current_priv = self.privilege_levels[current_priv_patterns[0]] if current_priv.name == destination_priv: self.logger.debug( \"determined current privilege level is target privilege level, no action needed\" ) self._current_priv_level = self.privilege_levels[destination_priv] return PrivilegeAction.NO_ACTION, self.privilege_levels[destination_priv] map_to_destination_priv = self._build_priv_change_map( starting_priv_name=current_priv.name, destination_priv_name=destination_priv ) # at this point we basically dont *know* the privilege leve we are at (or we wont/cant after # we do an escalation or deescalation, so we reset to the dummy priv level self._current_priv_level = DUMMY_PRIV_LEVEL if self.privilege_levels[map_to_destination_priv[1]].previous_priv != current_priv.name: self.logger.debug(\"determined privilege deescalation necessary\") return PrivilegeAction.DEESCALATE, current_priv self.logger.debug(\"determined privilege escalation necessary\") return PrivilegeAction.ESCALATE, self.privilege_levels[map_to_destination_priv[1]] @property def _generic_driver_mode(self) -> bool: \"\"\" Getter for `_generic_driver_mode` attribute Args: N/A Returns: bool: _generic_driver_mode value Raises: N/A \"\"\" try: return self.__generic_driver_mode except AttributeError: return False @_generic_driver_mode.setter def _generic_driver_mode(self, value: bool) -> None: \"\"\" Setter for `_generic_driver_mode` attribute Args: value: bool value for _generic_driver_mode Returns: None Raises: ScrapliTypeError: if value is not of type bool \"\"\" self.logger.debug(f\"setting '_generic_driver_mode' value to '{value}'\") if not isinstance(value, bool): raise ScrapliTypeError if value is True: # if we are setting ingore priv level we reset current priv to the dummy priv so that # once (if) a user turns ignore priv back off we know we need to reset/reacquire priv # as the user coulda done pretty much anything and we could end up at who knows what # priv level self._current_priv_level = DUMMY_PRIV_LEVEL self.__generic_driver_mode = value def _update_response(self, response: Response) -> None: \"\"\" Update response with network driver specific data This happens here as the underlying channel provides a response object but is unaware of any of the network/platform specific attributes that may need to get updated Args: response: response to update Returns: None Raises: N/A \"\"\" response.textfsm_platform = self.textfsm_platform response.genie_platform = self.genie_platform @staticmethod def _pre_send_config(config: str) -> List[str]: \"\"\" Handle pre \"send_config\" tasks for consistency between sync/async versions Args: config: string configuration to send to the device, supports sending multi-line strings Returns: list: list of config lines from provided \"config\" input Raises: ScrapliTypeError: if anything but a string is provided for `file` \"\"\" if not isinstance(config, str): raise ScrapliTypeError( f\"'send_config' expects a single string, got {type(config)}, \" \"to send a list of configs use the 'send_configs' method instead.\" ) # in order to handle multi-line strings, we split lines split_config = config.splitlines() return split_config def _post_send_config( self, config: str, multi_response: MultiResponse, ) -> Response: \"\"\" Handle post \"send_config\" tasks for consistency between sync/async versions Args: config: string configuration to send to the device, supports sending multi-line strings multi_response: multi_response object send_config got from calling self.send_configs; we need this to parse out the multi_response back into a single Response object Returns: Response: Unified response object Raises: N/A \"\"\" # capture failed_when_contains and host from zeroith multi_response element (there should # always be at least a zeroith element here!); getting host just lets us keep the mixin # class a little cleaner without having to deal with sync vs async transport classes from # a typing perspective failed_when_contains = multi_response[0].failed_when_contains host = multi_response[0].host # create a new unified response object response = Response( host=host, channel_input=config, failed_when_contains=failed_when_contains, ) response.start_time = multi_response[0].start_time response.finish_time = datetime.now() response.elapsed_time = (response.finish_time - response.start_time).total_seconds() # join all the results together into a single final result response.result = \"\\n\".join(response.result for response in multi_response) response.failed = False if any(r.failed for r in multi_response): response.failed = True self._update_response(response=response) return response def _pre_send_configs( self, configs: List[str], failed_when_contains: Optional[Union[str, List[str]]] = None, privilege_level: str = \"\", ) -> Tuple[str, Union[str, List[str]]]: \"\"\" Handle pre \"send_configs\" tasks for consistency between sync/async versions Args: configs: list of strings to send to device in config mode failed_when_contains: string or list of strings indicating failure if found in response privilege_level: name of configuration privilege level/type to acquire; this is platform dependent, so check the device driver for specifics. Examples of privilege_name would be \"configuration_exclusive\" for IOSXRDriver, or \"configuration_private\" for JunosDriver. You can also pass in a name of a configuration session such as \"my-config-session\" if you have registered a session using the \"register_config_session\" method of the EOSDriver or NXOSDriver. Returns: Tuple[str, Union[str, List[str]]]: string of resolved privilege level name, and failed when contains which may be a string or list of strings Raises: ScrapliTypeError: if configs is anything but a list ScrapliPrivilegeError: if connection is in 'generic_driver_mode' -- this should be a non-standard use case so there is no reason to complicate the config(s) methods with supporting generic driver mode (plus if there was config modes in generic driver mode that wouldn't be very generic driver like, would it!) \"\"\" if not isinstance(configs, list): raise ScrapliTypeError( f\"'send_configs' expects a list of strings, got {type(configs)}, \" \"to send a single configuration line/string use the 'send_config' method instead.\" ) if self._generic_driver_mode is True: raise ScrapliPrivilegeError( \"connection is in 'generic_driver_mode', send config(s|s_from_file) is disabled\" ) if failed_when_contains is None: final_failed_when_contains = self.failed_when_contains elif isinstance(failed_when_contains, str): final_failed_when_contains = [failed_when_contains] else: final_failed_when_contains = failed_when_contains if privilege_level: self._validate_privilege_level_name(privilege_level_name=privilege_level) resolved_privilege_level = privilege_level else: resolved_privilege_level = \"configuration\" return resolved_privilege_level, final_failed_when_contains def _post_send_configs(self, responses: MultiResponse) -> MultiResponse: \"\"\" Handle post \"send_configs\" tasks for consistency between sync/async versions Args: responses: multi_response object to update Returns: MultiResponse: Unified response object Raises: N/A \"\"\" for response in responses: self._update_response(response=response) return responses Descendants \u00b6 scrapli.driver.network.async_driver.AsyncNetworkDriver scrapli.driver.network.sync_driver.NetworkDriver Class variables \u00b6 auth_secondary: str comms_prompt_pattern: str failed_when_contains: List[str] genie_platform: str logger: logging.LoggerAdapter privilege_levels: Dict[str, scrapli.driver.network.base_driver.PrivilegeLevel] textfsm_platform: str Methods \u00b6 update_privilege_levels \u00b6 update_privilege_levels(self) \u2011> None 1 2 3 4 5 6 7 8 9 10 Re-generate the privilege graph, and update the comms prompt pattern Args: N/A Returns: None Raises: N/A PrivilegeAction \u00b6 1 An enumeration. Expand source code class PrivilegeAction(Enum): NO_ACTION = \"no action\" ESCALATE = \"escalate\" DEESCALATE = \"deescalate\" Ancestors (in MRO) \u00b6 enum.Enum Class variables \u00b6 DEESCALATE ESCALATE NO_ACTION PrivilegeLevel \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 PrivilegeLevel Object Args: pattern: regex pattern to use to identify this privilege level by the prompt name: friendly name of this privilege level previous_priv: name of the lower/previous privilege level deescalate: how to deescalate *from* this privilege level (to the lower/previous priv) escalate: how to escalate *to* this privilege level (from the lower/previous priv) escalate_auth: True/False escalation requires authentication escalate_prompt: prompt pattern to search for during escalation if escalate auth is True not_contains: list of substrings that should *not* be seen in a prompt for this privilege level Returns: None Raises: N/A Expand source code class PrivilegeLevel: __slots__ = ( \"pattern\", \"name\", \"previous_priv\", \"deescalate\", \"escalate\", \"escalate_auth\", \"escalate_prompt\", \"not_contains\", ) def __init__( self, pattern: str, name: str, previous_priv: str, deescalate: str, escalate: str, escalate_auth: bool, escalate_prompt: str, not_contains: Optional[List[str]] = None, ): \"\"\" PrivilegeLevel Object Args: pattern: regex pattern to use to identify this privilege level by the prompt name: friendly name of this privilege level previous_priv: name of the lower/previous privilege level deescalate: how to deescalate *from* this privilege level (to the lower/previous priv) escalate: how to escalate *to* this privilege level (from the lower/previous priv) escalate_auth: True/False escalation requires authentication escalate_prompt: prompt pattern to search for during escalation if escalate auth is True not_contains: list of substrings that should *not* be seen in a prompt for this privilege level Returns: None Raises: N/A \"\"\" self.pattern = pattern self.name = name self.previous_priv = previous_priv self.deescalate = deescalate self.escalate = escalate self.escalate_auth = escalate_auth self.escalate_prompt = escalate_prompt self.not_contains: List[str] = not_contains or [] Instance variables \u00b6 deescalate 1 Return an attribute of instance, which is of type owner. escalate 1 Return an attribute of instance, which is of type owner. escalate_auth 1 Return an attribute of instance, which is of type owner. escalate_prompt 1 Return an attribute of instance, which is of type owner. name 1 Return an attribute of instance, which is of type owner. not_contains 1 Return an attribute of instance, which is of type owner. pattern 1 Return an attribute of instance, which is of type owner. previous_priv 1 Return an attribute of instance, which is of type owner.","title":"Base Driver"},{"location":"api_docs/driver/network/base_driver/#module-scraplidrivernetworkbase_driver","text":"scrapli.driver.network.base_driver Expand source code \"\"\"scrapli.driver.network.base_driver\"\"\" import re from collections import defaultdict from datetime import datetime from enum import Enum from functools import lru_cache from logging import Logger, LoggerAdapter from typing import TYPE_CHECKING, DefaultDict, Dict, List, Optional, Set, Tuple, Union from scrapli.exceptions import ScrapliPrivilegeError, ScrapliTypeError from scrapli.helper import user_warning from scrapli.response import MultiResponse, Response if TYPE_CHECKING: LoggerAdapterT = LoggerAdapter[Logger] # pragma: no cover # pylint:disable=E1136 else: LoggerAdapterT = LoggerAdapter class PrivilegeLevel: __slots__ = ( \"pattern\", \"name\", \"previous_priv\", \"deescalate\", \"escalate\", \"escalate_auth\", \"escalate_prompt\", \"not_contains\", ) def __init__( self, pattern: str, name: str, previous_priv: str, deescalate: str, escalate: str, escalate_auth: bool, escalate_prompt: str, not_contains: Optional[List[str]] = None, ): \"\"\" PrivilegeLevel Object Args: pattern: regex pattern to use to identify this privilege level by the prompt name: friendly name of this privilege level previous_priv: name of the lower/previous privilege level deescalate: how to deescalate *from* this privilege level (to the lower/previous priv) escalate: how to escalate *to* this privilege level (from the lower/previous priv) escalate_auth: True/False escalation requires authentication escalate_prompt: prompt pattern to search for during escalation if escalate auth is True not_contains: list of substrings that should *not* be seen in a prompt for this privilege level Returns: None Raises: N/A \"\"\" self.pattern = pattern self.name = name self.previous_priv = previous_priv self.deescalate = deescalate self.escalate = escalate self.escalate_auth = escalate_auth self.escalate_prompt = escalate_prompt self.not_contains: List[str] = not_contains or [] DUMMY_PRIV_LEVEL = PrivilegeLevel(\"\", \"DUMMY\", \"\", \"\", \"\", False, \"\") PRIVS: Dict[str, PrivilegeLevel] = {} class PrivilegeAction(Enum): NO_ACTION = \"no action\" ESCALATE = \"escalate\" DEESCALATE = \"deescalate\" class BaseNetworkDriver: # BaseNetworkDriver Mixin vars for typing/linting purposes logger: LoggerAdapterT auth_secondary: str failed_when_contains: List[str] textfsm_platform: str genie_platform: str privilege_levels: Dict[str, PrivilegeLevel] comms_prompt_pattern: str _current_priv_level = DUMMY_PRIV_LEVEL _priv_graph: DefaultDict[str, Set[str]] def _generate_comms_prompt_pattern(self) -> None: \"\"\" Generate the `comms_prompt_pattern` from the currently assigned privilege levels Args: N/A Returns: None Raises: N/A \"\"\" self.logger.debug(\"generating combined network comms prompt pattern\") self.comms_prompt_pattern = r\"|\".join( rf\"({priv_level_data.pattern})\" for priv_level_data in self.privilege_levels.values() ) @lru_cache(maxsize=64) def _determine_current_priv(self, current_prompt: str) -> List[str]: \"\"\" Determine current privilege level from prompt string Args: current_prompt: string of current prompt Returns: list: list of string names of matching privilege levels Raises: ScrapliPrivilegeError: if privilege level cannot be determined \"\"\" matching_priv_levels = [] for priv_level in self.privilege_levels.values(): if priv_level.not_contains: # starting at 2021.07.30 the `not_contains` field was added to privilege levels # (defaulting to an empty tuple) -- this helps us to simplify the priv patterns # greatly, as well as have no reliance on look arounds which makes the \"normal\" # scrapli privilege levels more go friendly -- useful for scrapligo! if any(not_contains in current_prompt for not_contains in priv_level.not_contains): continue search_result = re.search( pattern=priv_level.pattern, string=current_prompt, flags=re.M | re.I ) if not search_result: continue matching_priv_levels.append(priv_level.name) if not matching_priv_levels: msg = f\"could not determine privilege level from provided prompt: '{current_prompt}'\" self.logger.critical(msg) raise ScrapliPrivilegeError(msg) self.logger.debug(f\"determined current privilege level is one of '{matching_priv_levels}'\") return matching_priv_levels def _build_priv_graph(self) -> None: \"\"\" Build a graph of privilege levels `_priv_graph` is a \"graph\" of all privilege levels and how to acquire them from any given priv level. This is probably not very efficient but we should never have more than a handful of priv levels so this should never be a big issue. While at the moment priv levels are always... \"linear\" in that there is only ever one \"up\" and one \"down\" privilege from any given priv, we still have \"forks\" in the road -- for example, in IOSXR we can go from privilege exec to configuration or configuration exclusive. This method builds a graph that allows us to make intelligent decisions about how to get from where we are to where we want to be! Args: N/A Returns: None Raises: N/A \"\"\" self._priv_graph = defaultdict(set) privilege_levels = self.privilege_levels.values() for privilege_level in privilege_levels: if privilege_level.previous_priv: self._priv_graph[privilege_level.name].add(privilege_level.previous_priv) else: self._priv_graph[privilege_level.name] = set() for higher_privilege_level, privilege_level_list in self._priv_graph.items(): for privilege_level_name in privilege_level_list: self._priv_graph[privilege_level_name].add(higher_privilege_level) def _build_priv_change_map( self, starting_priv_name: str, destination_priv_name: str, priv_change_map: Optional[List[str]] = None, ) -> List[str]: \"\"\" Generate a list of priv levels from starting priv to destination priv Args: starting_priv_name: name of starting priv destination_priv_name: name of destination priv priv_change_map: current priv_change_map; should only be passed when this function calls itself Returns: list: list of strings of priv names to get from starting to destination priv level Raises: N/A \"\"\" if priv_change_map is None: priv_change_map = [] priv_change_map = priv_change_map + [starting_priv_name] if starting_priv_name == destination_priv_name: return priv_change_map for privilege_name in self._priv_graph[starting_priv_name]: if privilege_name not in priv_change_map: updated_priv_change_map = self._build_priv_change_map( starting_priv_name=privilege_name, destination_priv_name=destination_priv_name, priv_change_map=priv_change_map, ) if updated_priv_change_map: return updated_priv_change_map # shouldnt ever get to this i dont think... putting here to appease pylint and ignoring cov return [] # pragma: nocover def update_privilege_levels(self) -> None: \"\"\" Re-generate the privilege graph, and update the comms prompt pattern Args: N/A Returns: None Raises: N/A \"\"\" # build/update the priv graph self._build_priv_graph() # build/update the joined comms prompt pattern self._generate_comms_prompt_pattern() # ensure the channel has the updated prompt pattern so it knows how to match any newly # updated priv levels (such as registered configuration sessions) self.channel.comms_prompt_pattern = ( # type: ignore # pylint: disable=E1101 self.comms_prompt_pattern ) # finally, clear the lru caches as patterns may have been updated self._determine_current_priv.cache_clear() def _validate_privilege_level_name(self, privilege_level_name: str) -> None: \"\"\" Get privilege level name if provided privilege is valid Args: privilege_level_name: string name of desired privilege level Returns: None Raises: ScrapliPrivilegeError: if attempting to acquire an unknown priv \"\"\" desired_privilege_level = self.privilege_levels.get(privilege_level_name) if desired_privilege_level is None: msg = ( f\"requested privilege level '{privilege_level_name}' not a valid privilege level of\" f\" '{self.__class__.__name__}'\" ) self.logger.critical(msg) raise ScrapliPrivilegeError(msg) def _pre_escalate(self, escalate_priv: PrivilegeLevel) -> None: \"\"\" Handle pre \"_escalate\" tasks for consistency between sync/async versions Args: escalate_priv: privilege level to escalate to Returns: None Raises: N/A \"\"\" if escalate_priv.escalate_auth is True and not self.auth_secondary: title = \"Authentication Warning!\" message = ( \"scrapli will try to escalate privilege without entering a password but may \" \"fail.\\nSet an 'auth_secondary' password if your device requires a password to \" \"increase privilege, otherwise ignore this message.\" ) user_warning(title=title, message=message) def _process_acquire_priv( self, destination_priv: str, current_prompt: str, ) -> Tuple[PrivilegeAction, PrivilegeLevel]: \"\"\" Handle non channel \"acquire_priv\" tasks for consistency between sync/async versions Args: destination_priv: string name of desired privilege level current_prompt: string of the current prompt Returns: Tuple[PrivilegeAction, PrivilegeLevel]: enum set to appropriate value for no action, escalate or deescalate and privilege level object to pass to either escalate or deescalate method Raises: N/A \"\"\" self.logger.info(f\"attempting to acquire '{destination_priv}' privilege level\") # decide if we are already at the desired priv, then we don't need to do any thing! current_priv_patterns = self._determine_current_priv(current_prompt=current_prompt) if self._current_priv_level.name in current_priv_patterns: current_priv = self.privilege_levels[self._current_priv_level.name] elif destination_priv in current_priv_patterns: current_priv = self.privilege_levels[destination_priv] else: # if multiple patterns match pick the zeroith... hopefully this never happens though... # and it *shouldn't* because right now the only way to have the same priv patterns is # to be *basically* the same privilege level -- i.e. configuration and configuration # exclusive for iosxr current_priv = self.privilege_levels[current_priv_patterns[0]] if current_priv.name == destination_priv: self.logger.debug( \"determined current privilege level is target privilege level, no action needed\" ) self._current_priv_level = self.privilege_levels[destination_priv] return PrivilegeAction.NO_ACTION, self.privilege_levels[destination_priv] map_to_destination_priv = self._build_priv_change_map( starting_priv_name=current_priv.name, destination_priv_name=destination_priv ) # at this point we basically dont *know* the privilege leve we are at (or we wont/cant after # we do an escalation or deescalation, so we reset to the dummy priv level self._current_priv_level = DUMMY_PRIV_LEVEL if self.privilege_levels[map_to_destination_priv[1]].previous_priv != current_priv.name: self.logger.debug(\"determined privilege deescalation necessary\") return PrivilegeAction.DEESCALATE, current_priv self.logger.debug(\"determined privilege escalation necessary\") return PrivilegeAction.ESCALATE, self.privilege_levels[map_to_destination_priv[1]] @property def _generic_driver_mode(self) -> bool: \"\"\" Getter for `_generic_driver_mode` attribute Args: N/A Returns: bool: _generic_driver_mode value Raises: N/A \"\"\" try: return self.__generic_driver_mode except AttributeError: return False @_generic_driver_mode.setter def _generic_driver_mode(self, value: bool) -> None: \"\"\" Setter for `_generic_driver_mode` attribute Args: value: bool value for _generic_driver_mode Returns: None Raises: ScrapliTypeError: if value is not of type bool \"\"\" self.logger.debug(f\"setting '_generic_driver_mode' value to '{value}'\") if not isinstance(value, bool): raise ScrapliTypeError if value is True: # if we are setting ingore priv level we reset current priv to the dummy priv so that # once (if) a user turns ignore priv back off we know we need to reset/reacquire priv # as the user coulda done pretty much anything and we could end up at who knows what # priv level self._current_priv_level = DUMMY_PRIV_LEVEL self.__generic_driver_mode = value def _update_response(self, response: Response) -> None: \"\"\" Update response with network driver specific data This happens here as the underlying channel provides a response object but is unaware of any of the network/platform specific attributes that may need to get updated Args: response: response to update Returns: None Raises: N/A \"\"\" response.textfsm_platform = self.textfsm_platform response.genie_platform = self.genie_platform @staticmethod def _pre_send_config(config: str) -> List[str]: \"\"\" Handle pre \"send_config\" tasks for consistency between sync/async versions Args: config: string configuration to send to the device, supports sending multi-line strings Returns: list: list of config lines from provided \"config\" input Raises: ScrapliTypeError: if anything but a string is provided for `file` \"\"\" if not isinstance(config, str): raise ScrapliTypeError( f\"'send_config' expects a single string, got {type(config)}, \" \"to send a list of configs use the 'send_configs' method instead.\" ) # in order to handle multi-line strings, we split lines split_config = config.splitlines() return split_config def _post_send_config( self, config: str, multi_response: MultiResponse, ) -> Response: \"\"\" Handle post \"send_config\" tasks for consistency between sync/async versions Args: config: string configuration to send to the device, supports sending multi-line strings multi_response: multi_response object send_config got from calling self.send_configs; we need this to parse out the multi_response back into a single Response object Returns: Response: Unified response object Raises: N/A \"\"\" # capture failed_when_contains and host from zeroith multi_response element (there should # always be at least a zeroith element here!); getting host just lets us keep the mixin # class a little cleaner without having to deal with sync vs async transport classes from # a typing perspective failed_when_contains = multi_response[0].failed_when_contains host = multi_response[0].host # create a new unified response object response = Response( host=host, channel_input=config, failed_when_contains=failed_when_contains, ) response.start_time = multi_response[0].start_time response.finish_time = datetime.now() response.elapsed_time = (response.finish_time - response.start_time).total_seconds() # join all the results together into a single final result response.result = \"\\n\".join(response.result for response in multi_response) response.failed = False if any(r.failed for r in multi_response): response.failed = True self._update_response(response=response) return response def _pre_send_configs( self, configs: List[str], failed_when_contains: Optional[Union[str, List[str]]] = None, privilege_level: str = \"\", ) -> Tuple[str, Union[str, List[str]]]: \"\"\" Handle pre \"send_configs\" tasks for consistency between sync/async versions Args: configs: list of strings to send to device in config mode failed_when_contains: string or list of strings indicating failure if found in response privilege_level: name of configuration privilege level/type to acquire; this is platform dependent, so check the device driver for specifics. Examples of privilege_name would be \"configuration_exclusive\" for IOSXRDriver, or \"configuration_private\" for JunosDriver. You can also pass in a name of a configuration session such as \"my-config-session\" if you have registered a session using the \"register_config_session\" method of the EOSDriver or NXOSDriver. Returns: Tuple[str, Union[str, List[str]]]: string of resolved privilege level name, and failed when contains which may be a string or list of strings Raises: ScrapliTypeError: if configs is anything but a list ScrapliPrivilegeError: if connection is in 'generic_driver_mode' -- this should be a non-standard use case so there is no reason to complicate the config(s) methods with supporting generic driver mode (plus if there was config modes in generic driver mode that wouldn't be very generic driver like, would it!) \"\"\" if not isinstance(configs, list): raise ScrapliTypeError( f\"'send_configs' expects a list of strings, got {type(configs)}, \" \"to send a single configuration line/string use the 'send_config' method instead.\" ) if self._generic_driver_mode is True: raise ScrapliPrivilegeError( \"connection is in 'generic_driver_mode', send config(s|s_from_file) is disabled\" ) if failed_when_contains is None: final_failed_when_contains = self.failed_when_contains elif isinstance(failed_when_contains, str): final_failed_when_contains = [failed_when_contains] else: final_failed_when_contains = failed_when_contains if privilege_level: self._validate_privilege_level_name(privilege_level_name=privilege_level) resolved_privilege_level = privilege_level else: resolved_privilege_level = \"configuration\" return resolved_privilege_level, final_failed_when_contains def _post_send_configs(self, responses: MultiResponse) -> MultiResponse: \"\"\" Handle post \"send_configs\" tasks for consistency between sync/async versions Args: responses: multi_response object to update Returns: MultiResponse: Unified response object Raises: N/A \"\"\" for response in responses: self._update_response(response=response) return responses","title":"Module scrapli.driver.network.base_driver"},{"location":"api_docs/driver/network/base_driver/#classes","text":"","title":"Classes"},{"location":"api_docs/driver/network/base_driver/#basenetworkdriver","text":"Expand source code class BaseNetworkDriver: # BaseNetworkDriver Mixin vars for typing/linting purposes logger: LoggerAdapterT auth_secondary: str failed_when_contains: List[str] textfsm_platform: str genie_platform: str privilege_levels: Dict[str, PrivilegeLevel] comms_prompt_pattern: str _current_priv_level = DUMMY_PRIV_LEVEL _priv_graph: DefaultDict[str, Set[str]] def _generate_comms_prompt_pattern(self) -> None: \"\"\" Generate the `comms_prompt_pattern` from the currently assigned privilege levels Args: N/A Returns: None Raises: N/A \"\"\" self.logger.debug(\"generating combined network comms prompt pattern\") self.comms_prompt_pattern = r\"|\".join( rf\"({priv_level_data.pattern})\" for priv_level_data in self.privilege_levels.values() ) @lru_cache(maxsize=64) def _determine_current_priv(self, current_prompt: str) -> List[str]: \"\"\" Determine current privilege level from prompt string Args: current_prompt: string of current prompt Returns: list: list of string names of matching privilege levels Raises: ScrapliPrivilegeError: if privilege level cannot be determined \"\"\" matching_priv_levels = [] for priv_level in self.privilege_levels.values(): if priv_level.not_contains: # starting at 2021.07.30 the `not_contains` field was added to privilege levels # (defaulting to an empty tuple) -- this helps us to simplify the priv patterns # greatly, as well as have no reliance on look arounds which makes the \"normal\" # scrapli privilege levels more go friendly -- useful for scrapligo! if any(not_contains in current_prompt for not_contains in priv_level.not_contains): continue search_result = re.search( pattern=priv_level.pattern, string=current_prompt, flags=re.M | re.I ) if not search_result: continue matching_priv_levels.append(priv_level.name) if not matching_priv_levels: msg = f\"could not determine privilege level from provided prompt: '{current_prompt}'\" self.logger.critical(msg) raise ScrapliPrivilegeError(msg) self.logger.debug(f\"determined current privilege level is one of '{matching_priv_levels}'\") return matching_priv_levels def _build_priv_graph(self) -> None: \"\"\" Build a graph of privilege levels `_priv_graph` is a \"graph\" of all privilege levels and how to acquire them from any given priv level. This is probably not very efficient but we should never have more than a handful of priv levels so this should never be a big issue. While at the moment priv levels are always... \"linear\" in that there is only ever one \"up\" and one \"down\" privilege from any given priv, we still have \"forks\" in the road -- for example, in IOSXR we can go from privilege exec to configuration or configuration exclusive. This method builds a graph that allows us to make intelligent decisions about how to get from where we are to where we want to be! Args: N/A Returns: None Raises: N/A \"\"\" self._priv_graph = defaultdict(set) privilege_levels = self.privilege_levels.values() for privilege_level in privilege_levels: if privilege_level.previous_priv: self._priv_graph[privilege_level.name].add(privilege_level.previous_priv) else: self._priv_graph[privilege_level.name] = set() for higher_privilege_level, privilege_level_list in self._priv_graph.items(): for privilege_level_name in privilege_level_list: self._priv_graph[privilege_level_name].add(higher_privilege_level) def _build_priv_change_map( self, starting_priv_name: str, destination_priv_name: str, priv_change_map: Optional[List[str]] = None, ) -> List[str]: \"\"\" Generate a list of priv levels from starting priv to destination priv Args: starting_priv_name: name of starting priv destination_priv_name: name of destination priv priv_change_map: current priv_change_map; should only be passed when this function calls itself Returns: list: list of strings of priv names to get from starting to destination priv level Raises: N/A \"\"\" if priv_change_map is None: priv_change_map = [] priv_change_map = priv_change_map + [starting_priv_name] if starting_priv_name == destination_priv_name: return priv_change_map for privilege_name in self._priv_graph[starting_priv_name]: if privilege_name not in priv_change_map: updated_priv_change_map = self._build_priv_change_map( starting_priv_name=privilege_name, destination_priv_name=destination_priv_name, priv_change_map=priv_change_map, ) if updated_priv_change_map: return updated_priv_change_map # shouldnt ever get to this i dont think... putting here to appease pylint and ignoring cov return [] # pragma: nocover def update_privilege_levels(self) -> None: \"\"\" Re-generate the privilege graph, and update the comms prompt pattern Args: N/A Returns: None Raises: N/A \"\"\" # build/update the priv graph self._build_priv_graph() # build/update the joined comms prompt pattern self._generate_comms_prompt_pattern() # ensure the channel has the updated prompt pattern so it knows how to match any newly # updated priv levels (such as registered configuration sessions) self.channel.comms_prompt_pattern = ( # type: ignore # pylint: disable=E1101 self.comms_prompt_pattern ) # finally, clear the lru caches as patterns may have been updated self._determine_current_priv.cache_clear() def _validate_privilege_level_name(self, privilege_level_name: str) -> None: \"\"\" Get privilege level name if provided privilege is valid Args: privilege_level_name: string name of desired privilege level Returns: None Raises: ScrapliPrivilegeError: if attempting to acquire an unknown priv \"\"\" desired_privilege_level = self.privilege_levels.get(privilege_level_name) if desired_privilege_level is None: msg = ( f\"requested privilege level '{privilege_level_name}' not a valid privilege level of\" f\" '{self.__class__.__name__}'\" ) self.logger.critical(msg) raise ScrapliPrivilegeError(msg) def _pre_escalate(self, escalate_priv: PrivilegeLevel) -> None: \"\"\" Handle pre \"_escalate\" tasks for consistency between sync/async versions Args: escalate_priv: privilege level to escalate to Returns: None Raises: N/A \"\"\" if escalate_priv.escalate_auth is True and not self.auth_secondary: title = \"Authentication Warning!\" message = ( \"scrapli will try to escalate privilege without entering a password but may \" \"fail.\\nSet an 'auth_secondary' password if your device requires a password to \" \"increase privilege, otherwise ignore this message.\" ) user_warning(title=title, message=message) def _process_acquire_priv( self, destination_priv: str, current_prompt: str, ) -> Tuple[PrivilegeAction, PrivilegeLevel]: \"\"\" Handle non channel \"acquire_priv\" tasks for consistency between sync/async versions Args: destination_priv: string name of desired privilege level current_prompt: string of the current prompt Returns: Tuple[PrivilegeAction, PrivilegeLevel]: enum set to appropriate value for no action, escalate or deescalate and privilege level object to pass to either escalate or deescalate method Raises: N/A \"\"\" self.logger.info(f\"attempting to acquire '{destination_priv}' privilege level\") # decide if we are already at the desired priv, then we don't need to do any thing! current_priv_patterns = self._determine_current_priv(current_prompt=current_prompt) if self._current_priv_level.name in current_priv_patterns: current_priv = self.privilege_levels[self._current_priv_level.name] elif destination_priv in current_priv_patterns: current_priv = self.privilege_levels[destination_priv] else: # if multiple patterns match pick the zeroith... hopefully this never happens though... # and it *shouldn't* because right now the only way to have the same priv patterns is # to be *basically* the same privilege level -- i.e. configuration and configuration # exclusive for iosxr current_priv = self.privilege_levels[current_priv_patterns[0]] if current_priv.name == destination_priv: self.logger.debug( \"determined current privilege level is target privilege level, no action needed\" ) self._current_priv_level = self.privilege_levels[destination_priv] return PrivilegeAction.NO_ACTION, self.privilege_levels[destination_priv] map_to_destination_priv = self._build_priv_change_map( starting_priv_name=current_priv.name, destination_priv_name=destination_priv ) # at this point we basically dont *know* the privilege leve we are at (or we wont/cant after # we do an escalation or deescalation, so we reset to the dummy priv level self._current_priv_level = DUMMY_PRIV_LEVEL if self.privilege_levels[map_to_destination_priv[1]].previous_priv != current_priv.name: self.logger.debug(\"determined privilege deescalation necessary\") return PrivilegeAction.DEESCALATE, current_priv self.logger.debug(\"determined privilege escalation necessary\") return PrivilegeAction.ESCALATE, self.privilege_levels[map_to_destination_priv[1]] @property def _generic_driver_mode(self) -> bool: \"\"\" Getter for `_generic_driver_mode` attribute Args: N/A Returns: bool: _generic_driver_mode value Raises: N/A \"\"\" try: return self.__generic_driver_mode except AttributeError: return False @_generic_driver_mode.setter def _generic_driver_mode(self, value: bool) -> None: \"\"\" Setter for `_generic_driver_mode` attribute Args: value: bool value for _generic_driver_mode Returns: None Raises: ScrapliTypeError: if value is not of type bool \"\"\" self.logger.debug(f\"setting '_generic_driver_mode' value to '{value}'\") if not isinstance(value, bool): raise ScrapliTypeError if value is True: # if we are setting ingore priv level we reset current priv to the dummy priv so that # once (if) a user turns ignore priv back off we know we need to reset/reacquire priv # as the user coulda done pretty much anything and we could end up at who knows what # priv level self._current_priv_level = DUMMY_PRIV_LEVEL self.__generic_driver_mode = value def _update_response(self, response: Response) -> None: \"\"\" Update response with network driver specific data This happens here as the underlying channel provides a response object but is unaware of any of the network/platform specific attributes that may need to get updated Args: response: response to update Returns: None Raises: N/A \"\"\" response.textfsm_platform = self.textfsm_platform response.genie_platform = self.genie_platform @staticmethod def _pre_send_config(config: str) -> List[str]: \"\"\" Handle pre \"send_config\" tasks for consistency between sync/async versions Args: config: string configuration to send to the device, supports sending multi-line strings Returns: list: list of config lines from provided \"config\" input Raises: ScrapliTypeError: if anything but a string is provided for `file` \"\"\" if not isinstance(config, str): raise ScrapliTypeError( f\"'send_config' expects a single string, got {type(config)}, \" \"to send a list of configs use the 'send_configs' method instead.\" ) # in order to handle multi-line strings, we split lines split_config = config.splitlines() return split_config def _post_send_config( self, config: str, multi_response: MultiResponse, ) -> Response: \"\"\" Handle post \"send_config\" tasks for consistency between sync/async versions Args: config: string configuration to send to the device, supports sending multi-line strings multi_response: multi_response object send_config got from calling self.send_configs; we need this to parse out the multi_response back into a single Response object Returns: Response: Unified response object Raises: N/A \"\"\" # capture failed_when_contains and host from zeroith multi_response element (there should # always be at least a zeroith element here!); getting host just lets us keep the mixin # class a little cleaner without having to deal with sync vs async transport classes from # a typing perspective failed_when_contains = multi_response[0].failed_when_contains host = multi_response[0].host # create a new unified response object response = Response( host=host, channel_input=config, failed_when_contains=failed_when_contains, ) response.start_time = multi_response[0].start_time response.finish_time = datetime.now() response.elapsed_time = (response.finish_time - response.start_time).total_seconds() # join all the results together into a single final result response.result = \"\\n\".join(response.result for response in multi_response) response.failed = False if any(r.failed for r in multi_response): response.failed = True self._update_response(response=response) return response def _pre_send_configs( self, configs: List[str], failed_when_contains: Optional[Union[str, List[str]]] = None, privilege_level: str = \"\", ) -> Tuple[str, Union[str, List[str]]]: \"\"\" Handle pre \"send_configs\" tasks for consistency between sync/async versions Args: configs: list of strings to send to device in config mode failed_when_contains: string or list of strings indicating failure if found in response privilege_level: name of configuration privilege level/type to acquire; this is platform dependent, so check the device driver for specifics. Examples of privilege_name would be \"configuration_exclusive\" for IOSXRDriver, or \"configuration_private\" for JunosDriver. You can also pass in a name of a configuration session such as \"my-config-session\" if you have registered a session using the \"register_config_session\" method of the EOSDriver or NXOSDriver. Returns: Tuple[str, Union[str, List[str]]]: string of resolved privilege level name, and failed when contains which may be a string or list of strings Raises: ScrapliTypeError: if configs is anything but a list ScrapliPrivilegeError: if connection is in 'generic_driver_mode' -- this should be a non-standard use case so there is no reason to complicate the config(s) methods with supporting generic driver mode (plus if there was config modes in generic driver mode that wouldn't be very generic driver like, would it!) \"\"\" if not isinstance(configs, list): raise ScrapliTypeError( f\"'send_configs' expects a list of strings, got {type(configs)}, \" \"to send a single configuration line/string use the 'send_config' method instead.\" ) if self._generic_driver_mode is True: raise ScrapliPrivilegeError( \"connection is in 'generic_driver_mode', send config(s|s_from_file) is disabled\" ) if failed_when_contains is None: final_failed_when_contains = self.failed_when_contains elif isinstance(failed_when_contains, str): final_failed_when_contains = [failed_when_contains] else: final_failed_when_contains = failed_when_contains if privilege_level: self._validate_privilege_level_name(privilege_level_name=privilege_level) resolved_privilege_level = privilege_level else: resolved_privilege_level = \"configuration\" return resolved_privilege_level, final_failed_when_contains def _post_send_configs(self, responses: MultiResponse) -> MultiResponse: \"\"\" Handle post \"send_configs\" tasks for consistency between sync/async versions Args: responses: multi_response object to update Returns: MultiResponse: Unified response object Raises: N/A \"\"\" for response in responses: self._update_response(response=response) return responses","title":"BaseNetworkDriver"},{"location":"api_docs/driver/network/base_driver/#descendants","text":"scrapli.driver.network.async_driver.AsyncNetworkDriver scrapli.driver.network.sync_driver.NetworkDriver","title":"Descendants"},{"location":"api_docs/driver/network/base_driver/#class-variables","text":"auth_secondary: str comms_prompt_pattern: str failed_when_contains: List[str] genie_platform: str logger: logging.LoggerAdapter privilege_levels: Dict[str, scrapli.driver.network.base_driver.PrivilegeLevel] textfsm_platform: str","title":"Class variables"},{"location":"api_docs/driver/network/base_driver/#methods","text":"","title":"Methods"},{"location":"api_docs/driver/network/base_driver/#update_privilege_levels","text":"update_privilege_levels(self) \u2011> None 1 2 3 4 5 6 7 8 9 10 Re-generate the privilege graph, and update the comms prompt pattern Args: N/A Returns: None Raises: N/A","title":"update_privilege_levels"},{"location":"api_docs/driver/network/base_driver/#privilegeaction","text":"1 An enumeration. Expand source code class PrivilegeAction(Enum): NO_ACTION = \"no action\" ESCALATE = \"escalate\" DEESCALATE = \"deescalate\"","title":"PrivilegeAction"},{"location":"api_docs/driver/network/base_driver/#ancestors-in-mro","text":"enum.Enum","title":"Ancestors (in MRO)"},{"location":"api_docs/driver/network/base_driver/#class-variables_1","text":"DEESCALATE ESCALATE NO_ACTION","title":"Class variables"},{"location":"api_docs/driver/network/base_driver/#privilegelevel","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 PrivilegeLevel Object Args: pattern: regex pattern to use to identify this privilege level by the prompt name: friendly name of this privilege level previous_priv: name of the lower/previous privilege level deescalate: how to deescalate *from* this privilege level (to the lower/previous priv) escalate: how to escalate *to* this privilege level (from the lower/previous priv) escalate_auth: True/False escalation requires authentication escalate_prompt: prompt pattern to search for during escalation if escalate auth is True not_contains: list of substrings that should *not* be seen in a prompt for this privilege level Returns: None Raises: N/A Expand source code class PrivilegeLevel: __slots__ = ( \"pattern\", \"name\", \"previous_priv\", \"deescalate\", \"escalate\", \"escalate_auth\", \"escalate_prompt\", \"not_contains\", ) def __init__( self, pattern: str, name: str, previous_priv: str, deescalate: str, escalate: str, escalate_auth: bool, escalate_prompt: str, not_contains: Optional[List[str]] = None, ): \"\"\" PrivilegeLevel Object Args: pattern: regex pattern to use to identify this privilege level by the prompt name: friendly name of this privilege level previous_priv: name of the lower/previous privilege level deescalate: how to deescalate *from* this privilege level (to the lower/previous priv) escalate: how to escalate *to* this privilege level (from the lower/previous priv) escalate_auth: True/False escalation requires authentication escalate_prompt: prompt pattern to search for during escalation if escalate auth is True not_contains: list of substrings that should *not* be seen in a prompt for this privilege level Returns: None Raises: N/A \"\"\" self.pattern = pattern self.name = name self.previous_priv = previous_priv self.deescalate = deescalate self.escalate = escalate self.escalate_auth = escalate_auth self.escalate_prompt = escalate_prompt self.not_contains: List[str] = not_contains or []","title":"PrivilegeLevel"},{"location":"api_docs/driver/network/base_driver/#instance-variables","text":"deescalate 1 Return an attribute of instance, which is of type owner. escalate 1 Return an attribute of instance, which is of type owner. escalate_auth 1 Return an attribute of instance, which is of type owner. escalate_prompt 1 Return an attribute of instance, which is of type owner. name 1 Return an attribute of instance, which is of type owner. not_contains 1 Return an attribute of instance, which is of type owner. pattern 1 Return an attribute of instance, which is of type owner. previous_priv 1 Return an attribute of instance, which is of type owner.","title":"Instance variables"},{"location":"api_docs/driver/network/sync_driver/","text":"window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting()) Module scrapli.driver.network.sync_driver \u00b6 scrapli.driver.network.sync_driver Expand source code \"\"\"scrapli.driver.network.sync_driver\"\"\" from collections import defaultdict from io import BytesIO from typing import Any, Callable, Dict, List, Optional, Tuple, Union from scrapli.driver.generic import GenericDriver from scrapli.driver.network.base_driver import BaseNetworkDriver, PrivilegeAction, PrivilegeLevel from scrapli.exceptions import ScrapliAuthenticationFailed, ScrapliPrivilegeError, ScrapliTimeout from scrapli.response import MultiResponse, Response class NetworkDriver(GenericDriver, BaseNetworkDriver): def __init__( self, host: str, privilege_levels: Dict[str, PrivilegeLevel], default_desired_privilege_level: str, port: Optional[int] = None, auth_username: str = \"\", auth_password: str = \"\", auth_private_key: str = \"\", auth_private_key_passphrase: str = \"\", auth_strict_key: bool = True, auth_bypass: bool = False, timeout_socket: float = 15.0, timeout_transport: float = 30.0, timeout_ops: float = 30.0, comms_return_char: str = \"\\n\", ssh_config_file: Union[str, bool] = False, ssh_known_hosts_file: Union[str, bool] = False, on_init: Optional[Callable[..., Any]] = None, on_open: Optional[Callable[..., Any]] = None, on_close: Optional[Callable[..., Any]] = None, transport: str = \"system\", transport_options: Optional[Dict[str, Any]] = None, channel_log: Union[str, bool, BytesIO] = False, channel_log_mode: str = \"write\", channel_lock: bool = False, logging_uid: str = \"\", auth_secondary: str = \"\", failed_when_contains: Optional[List[str]] = None, textfsm_platform: str = \"\", genie_platform: str = \"\", ): # ensure type for comms_prompt_pattern exists before setting it in the mixin self.comms_prompt_pattern: str super().__init__( host=host, port=port, auth_username=auth_username, auth_password=auth_password, auth_private_key=auth_private_key, auth_private_key_passphrase=auth_private_key_passphrase, auth_strict_key=auth_strict_key, auth_bypass=auth_bypass, timeout_socket=timeout_socket, timeout_transport=timeout_transport, timeout_ops=timeout_ops, comms_return_char=comms_return_char, ssh_config_file=ssh_config_file, ssh_known_hosts_file=ssh_known_hosts_file, on_init=on_init, on_open=on_open, on_close=on_close, transport=transport, transport_options=transport_options, channel_log=channel_log, channel_log_mode=channel_log_mode, channel_lock=channel_lock, logging_uid=logging_uid, ) self.auth_secondary = auth_secondary self.failed_when_contains = failed_when_contains or [] self.textfsm_platform = textfsm_platform self.genie_platform = genie_platform self.privilege_levels = privilege_levels self.default_desired_privilege_level = default_desired_privilege_level self._priv_graph = defaultdict(set) self.update_privilege_levels() def _escalate(self, escalate_priv: PrivilegeLevel) -> None: \"\"\" Escalate to the next privilege level up Args: escalate_priv: privilege level to escalate to Returns: None Raises: ScrapliAuthenticationFailed: if auth escalation timeout \"\"\" self._pre_escalate(escalate_priv=escalate_priv) if escalate_priv.escalate_auth is False: self.channel.send_input(channel_input=escalate_priv.escalate) else: try: super().send_interactive( interact_events=[ (escalate_priv.escalate, escalate_priv.escalate_prompt, False), (self.auth_secondary, escalate_priv.pattern, True), ], interaction_complete_patterns=[ self.privilege_levels[escalate_priv.previous_priv].pattern, escalate_priv.pattern, ], ) except ScrapliTimeout as exc: raise ScrapliAuthenticationFailed( f\"failed escalating privilege from '{escalate_priv.previous_priv}' to \" f\"'{escalate_priv.name}'. do you need to set an 'auth_secondary' password?\" ) from exc def _deescalate(self, current_priv: PrivilegeLevel) -> None: \"\"\" Deescalate to the next privilege level down Args: current_priv: current privilege level Returns: None Raises: N/A \"\"\" self.channel.send_input(channel_input=current_priv.deescalate) def acquire_priv(self, desired_priv: str) -> None: \"\"\" Acquire desired priv level Args: desired_priv: string name of desired privilege level see `scrapli.driver. .driver` for levels Returns: None Raises: ScrapliPrivilegeError: if desired_priv cannot be attained \"\"\" self._validate_privilege_level_name(privilege_level_name=desired_priv) privilege_change_count = 0 while True: current_prompt = self.channel.get_prompt() privilege_action, target_priv = self._process_acquire_priv( destination_priv=desired_priv, current_prompt=current_prompt, ) if privilege_action == PrivilegeAction.NO_ACTION: self._current_priv_level = target_priv return if privilege_action == PrivilegeAction.DEESCALATE: self._deescalate(current_priv=target_priv) if privilege_action == PrivilegeAction.ESCALATE: self._escalate(escalate_priv=target_priv) privilege_change_count += 1 if privilege_change_count > len(self.privilege_levels) * 2: msg = f\"Failed to acquire requested privilege level {desired_priv}\" raise ScrapliPrivilegeError(msg) def _acquire_appropriate_privilege_level(self, privilege_level: str = \"\") -> None: \"\"\" Acquire the appropriate priv level Acquires the \"right\" priv level based on generic_driver_mode, provided privilege level, and default desired privilege level. If in \"generic_driver_mode\" and no priv level is provided, we simply return as we are already at the \"right\" priv level (since we don't care about priv levels in this mode). If we are in \"generic_driver_mode\" and we are provided a priv level (this is only applicable in `send_interactive`) we will try to acquire that provided priv level. If a priv name is passed we try to resolve it and use that as the privilege level to acquire, otherwise if no priv leve is provided we will acquire the default_desired_privilege_level. Args: privilege_level: optional name of privilege level to acquire Returns: None Raises: N/A \"\"\" if not privilege_level and self._generic_driver_mode is True: return if privilege_level: self._validate_privilege_level_name(privilege_level_name=privilege_level) resolved_privilege_level = privilege_level else: resolved_privilege_level = self.default_desired_privilege_level if self._current_priv_level.name != resolved_privilege_level: self.acquire_priv(desired_priv=resolved_privilege_level) def send_command( self, command: str, *, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, timeout_ops: Optional[float] = None, ) -> Response: \"\"\" Send a command Super method will raise TypeError if anything but a string is passed here! Args: command: string to send to device in privilege exec mode strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed Returns: Response: Scrapli Response object Raises: N/A \"\"\" self._acquire_appropriate_privilege_level() if failed_when_contains is None: failed_when_contains = self.failed_when_contains response: Response = super().send_command( command=command, strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, timeout_ops=timeout_ops, ) self._update_response(response) return response def send_commands( self, commands: List[str], *, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, stop_on_failed: bool = False, eager: bool = False, timeout_ops: Optional[float] = None, ) -> MultiResponse: \"\"\" Send multiple commands Super method will raise TypeError if anything but a list of strings is passed here! Args: commands: list of strings to send to device in privilege exec mode strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER COMMAND sent, not for the total of the commands being sent! Returns: MultiResponse: Scrapli MultiResponse object Raises: N/A \"\"\" self._acquire_appropriate_privilege_level() if failed_when_contains is None: failed_when_contains = self.failed_when_contains responses = super().send_commands( commands=commands, strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, stop_on_failed=stop_on_failed, eager=eager, timeout_ops=timeout_ops, ) for response in responses: self._update_response(response=response) return responses def send_commands_from_file( self, file: str, *, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, stop_on_failed: bool = False, eager: bool = False, timeout_ops: Optional[float] = None, ) -> MultiResponse: \"\"\" Send command(s) from file Args: file: string path to file strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER COMMAND sent, not for the total of the commands being sent! Returns: MultiResponse: Scrapli MultiResponse object Raises: N/A \"\"\" self._acquire_appropriate_privilege_level() if failed_when_contains is None: failed_when_contains = self.failed_when_contains return super().send_commands_from_file( file=file, strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, stop_on_failed=stop_on_failed, eager=eager, timeout_ops=timeout_ops, ) def send_interactive( self, interact_events: Union[List[Tuple[str, str]], List[Tuple[str, str, bool]]], *, failed_when_contains: Optional[Union[str, List[str]]] = None, privilege_level: str = \"\", timeout_ops: Optional[float] = None, interaction_complete_patterns: Optional[List[str]] = None, ) -> Response: \"\"\" Interact with a device with changing prompts per input. Used to interact with devices where prompts change per input, and where inputs may be hidden such as in the case of a password input. This can be used to respond to challenges from devices such as the confirmation for the command \"clear logging\" on IOSXE devices for example. You may have as many elements in the \"interact_events\" list as needed, and each element of that list should be a tuple of two or three elements. The first element is always the input to send as a string, the second should be the expected response as a string, and the optional third a bool for whether or not the input is \"hidden\" (i.e. password input) An example where we need this sort of capability: ''' 3560CX#copy flash: scp: Source filename []? test1.txt Address or name of remote host []? 172.31.254.100 Destination username [carl]? Writing test1.txt Password: Password: Sink: C0644 639 test1.txt ! 639 bytes copied in 12.066 secs (53 bytes/sec) 3560CX# ''' To accomplish this we can use the following: ''' interact = conn.channel.send_inputs_interact( [ (\"copy flash: scp:\", \"Source filename []?\", False), (\"test1.txt\", \"Address or name of remote host []?\", False), (\"172.31.254.100\", \"Destination username [carl]?\", False), (\"carl\", \"Password:\", False), (\"super_secure_password\", prompt, True), ] ) ''' If we needed to deal with more prompts we could simply continue adding tuples to the list of interact \"events\". Args: interact_events: list of tuples containing the \"interactions\" with the device each list element must have an input and an expected response, and may have an optional bool for the third and final element -- the optional bool specifies if the input that is sent to the device is \"hidden\" (ex: password), if the hidden param is not provided it is assumed the input is \"normal\" (not hidden) failed_when_contains: list of strings that, if present in final output, represent a failed command/interaction privilege_level: name of the privilege level to operate in timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER COMMAND sent, not for the total of the commands being sent! interaction_complete_patterns: list of patterns, that if seen, indicate the interactive \"session\" has ended and we should exit the interactive session. Returns: Response: scrapli Response object Raises: N/A \"\"\" self._acquire_appropriate_privilege_level(privilege_level=privilege_level) if failed_when_contains is None: failed_when_contains = self.failed_when_contains # type hint is due to the timeout_modifier wrapper returning `Any` so that we dont anger the # asyncio parts (which will get an awaitable not a Response returned) response: Response = super().send_interactive( interact_events=interact_events, failed_when_contains=failed_when_contains, timeout_ops=timeout_ops, interaction_complete_patterns=interaction_complete_patterns, ) self._update_response(response=response) return response def _abort_config(self) -> None: \"\"\" Abort a configuration operation/session if applicable (for config sessions like junos/iosxr) Args: N/A Returns: None Raises: N/A \"\"\" def send_configs( self, configs: List[str], *, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, stop_on_failed: bool = False, privilege_level: str = \"\", eager: bool = False, timeout_ops: Optional[float] = None, ) -> MultiResponse: \"\"\" Send configuration(s) Args: configs: list of strings to send to device in config mode strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution; aborts configuration session if applicable (iosxr/junos or eos/nxos if using a configuration session) privilege_level: name of configuration privilege level/type to acquire; this is platform dependent, so check the device driver for specifics. Examples of privilege_name would be \"configuration_exclusive\" for IOSXRDriver, or \"configuration_private\" for JunosDriver. You can also pass in a name of a configuration session such as \"my-config-session\" if you have registered a session using the \"register_config_session\" method of the EOSDriver or NXOSDriver. eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER CONFIG sent, not for the total of the configs being sent! Returns: MultiResponse: Scrapli MultiResponse object Raises: N/A \"\"\" resolved_privilege_level, failed_when_contains = self._pre_send_configs( configs=configs, failed_when_contains=failed_when_contains, privilege_level=privilege_level, ) if self._current_priv_level.name != resolved_privilege_level: self.acquire_priv(desired_priv=resolved_privilege_level) responses = super().send_commands( commands=configs, strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, stop_on_failed=stop_on_failed, eager=eager, timeout_ops=timeout_ops, ) if stop_on_failed and responses.failed: self._abort_config() return self._post_send_configs(responses=responses) def send_config( self, config: str, *, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, stop_on_failed: bool = False, privilege_level: str = \"\", eager: bool = False, timeout_ops: Optional[float] = None, ) -> Response: \"\"\" Send configuration string Args: config: string configuration to send to the device, supports sending multi-line strings strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution; aborts configuration session if applicable (iosxr/junos or eos/nxos if using a configuration session) privilege_level: name of configuration privilege level/type to acquire; this is platform dependent, so check the device driver for specifics. Examples of privilege_name would be \"configuration_exclusive\" for IOSXRDriver, or \"configuration_private\" for JunosDriver. You can also pass in a name of a configuration session such as \"my-config-session\" if you have registered a session using the \"register_config_session\" method of the EOSDriver or NXOSDriver. eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER CONFIG sent, not for the total of the configs being sent! Returns: Response: Scrapli Response object Raises: N/A \"\"\" split_config = self._pre_send_config(config=config) # now that we have a list of configs, just use send_configs to actually execute them multi_response = self.send_configs( configs=split_config, strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, stop_on_failed=stop_on_failed, privilege_level=privilege_level, eager=eager, timeout_ops=timeout_ops, ) return self._post_send_config(config=config, multi_response=multi_response) def send_configs_from_file( self, file: str, *, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, stop_on_failed: bool = False, privilege_level: str = \"\", eager: bool = False, timeout_ops: Optional[float] = None, ) -> MultiResponse: \"\"\" Send configuration(s) from a file Args: file: string path to file strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution; aborts configuration session if applicable (iosxr/junos or eos/nxos if using a configuration session) privilege_level: name of configuration privilege level/type to acquire; this is platform dependent, so check the device driver for specifics. Examples of privilege_name would be \"exclusive\" for IOSXRDriver, \"private\" for JunosDriver. You can also pass in a name of a configuration session such as \"session_mysession\" if you have registered a session using the \"register_config_session\" method of the EOSDriver or NXOSDriver. eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER CONFIG sent, not for the total of the configs being sent! Returns: MultiResponse: Scrapli MultiResponse object Raises: N/A \"\"\" configs = self._pre_send_from_file(file=file, caller=\"send_configs_from_file\") return self.send_configs( configs=configs, strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, stop_on_failed=stop_on_failed, privilege_level=privilege_level, eager=eager, timeout_ops=timeout_ops, ) Classes \u00b6 NetworkDriver \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 BaseDriver Object BaseDriver is the root for all Scrapli driver classes. The synchronous and asyncio driver base driver classes can be used to provide a semi-pexpect like experience over top of whatever transport a user prefers. Generally, however, the base driver classes should not be used directly. It is best to use the GenericDriver (or AsyncGenericDriver) or NetworkDriver (or AsyncNetworkDriver) sub-classes of the base drivers. Args: host: host ip/name to connect to port: port to connect to auth_username: username for authentication auth_private_key: path to private key for authentication auth_private_key_passphrase: passphrase for decrypting ssh key if necessary auth_password: password for authentication auth_strict_key: strict host checking or not auth_bypass: bypass \"in channel\" authentication -- only supported with telnet, asynctelnet, and system transport plugins timeout_socket: timeout for establishing socket/initial connection in seconds timeout_transport: timeout for ssh|telnet transport in seconds timeout_ops: timeout for ssh channel operations comms_prompt_pattern: raw string regex pattern -- preferably use `^` and `$` anchors! this is the single most important attribute here! if this does not match a prompt, scrapli will not work! IMPORTANT: regex search uses multi-line + case insensitive flags. multi-line allows for highly reliably matching for prompts however we do NOT strip trailing whitespace for each line, so be sure to add '\\\\s?' or similar if your device needs that. This should be mostly sorted for you if using network drivers (i.e. `IOSXEDriver`). Lastly, the case insensitive is just a convenience factor so i can be lazy. comms_return_char: character to use to send returns to host ssh_config_file: string to path for ssh config file, True to use default ssh config file or False to ignore default ssh config file ssh_known_hosts_file: string to path for ssh known hosts file, True to use default known file locations. Only applicable/needed if `auth_strict_key` is set to True on_init: callable that accepts the class instance as its only argument. this callable, if provided, is executed as the last step of object instantiation -- its purpose is primarily to provide a mechanism for scrapli community platforms to have an easy way to modify initialization arguments/object attributes without needing to create a class that extends the driver, instead allowing the community platforms to simply build from the GenericDriver or NetworkDriver classes, and pass this callable to do things such as appending to a username (looking at you RouterOS!!). Note that this is *always* a synchronous function (even for asyncio drivers)! on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar transport: name of the transport plugin to use for the actual telnet/ssh/netconf connection. Available \"core\" transports are: - system - telnet - asynctelnet - ssh2 - paramiko - asyncssh Please see relevant transport plugin section for details. Additionally third party transport plugins may be available. transport_options: dictionary of options to pass to selected transport class; see docs for given transport class for details of what to pass here channel_lock: True/False to lock the channel (threading.Lock/asyncio.Lock) during any channel operations, defaults to False channel_log: True/False or a string path to a file of where to write out channel logs -- these are not \"logs\" in the normal logging module sense, but only the output that is read from the channel. In other words, the output of the channel log should look similar to what you would see as a human connecting to a device channel_log_mode: \"write\"|\"append\", all other values will raise ValueError, does what it sounds like it should by setting the channel log to the provided mode logging_uid: unique identifier (string) to associate to log messages; useful if you have multiple connections to the same device (i.e. one console, one ssh, or one to each supervisor module, etc.) Returns: None Raises: N/A Expand source code class NetworkDriver(GenericDriver, BaseNetworkDriver): def __init__( self, host: str, privilege_levels: Dict[str, PrivilegeLevel], default_desired_privilege_level: str, port: Optional[int] = None, auth_username: str = \"\", auth_password: str = \"\", auth_private_key: str = \"\", auth_private_key_passphrase: str = \"\", auth_strict_key: bool = True, auth_bypass: bool = False, timeout_socket: float = 15.0, timeout_transport: float = 30.0, timeout_ops: float = 30.0, comms_return_char: str = \"\\n\", ssh_config_file: Union[str, bool] = False, ssh_known_hosts_file: Union[str, bool] = False, on_init: Optional[Callable[..., Any]] = None, on_open: Optional[Callable[..., Any]] = None, on_close: Optional[Callable[..., Any]] = None, transport: str = \"system\", transport_options: Optional[Dict[str, Any]] = None, channel_log: Union[str, bool, BytesIO] = False, channel_log_mode: str = \"write\", channel_lock: bool = False, logging_uid: str = \"\", auth_secondary: str = \"\", failed_when_contains: Optional[List[str]] = None, textfsm_platform: str = \"\", genie_platform: str = \"\", ): # ensure type for comms_prompt_pattern exists before setting it in the mixin self.comms_prompt_pattern: str super().__init__( host=host, port=port, auth_username=auth_username, auth_password=auth_password, auth_private_key=auth_private_key, auth_private_key_passphrase=auth_private_key_passphrase, auth_strict_key=auth_strict_key, auth_bypass=auth_bypass, timeout_socket=timeout_socket, timeout_transport=timeout_transport, timeout_ops=timeout_ops, comms_return_char=comms_return_char, ssh_config_file=ssh_config_file, ssh_known_hosts_file=ssh_known_hosts_file, on_init=on_init, on_open=on_open, on_close=on_close, transport=transport, transport_options=transport_options, channel_log=channel_log, channel_log_mode=channel_log_mode, channel_lock=channel_lock, logging_uid=logging_uid, ) self.auth_secondary = auth_secondary self.failed_when_contains = failed_when_contains or [] self.textfsm_platform = textfsm_platform self.genie_platform = genie_platform self.privilege_levels = privilege_levels self.default_desired_privilege_level = default_desired_privilege_level self._priv_graph = defaultdict(set) self.update_privilege_levels() def _escalate(self, escalate_priv: PrivilegeLevel) -> None: \"\"\" Escalate to the next privilege level up Args: escalate_priv: privilege level to escalate to Returns: None Raises: ScrapliAuthenticationFailed: if auth escalation timeout \"\"\" self._pre_escalate(escalate_priv=escalate_priv) if escalate_priv.escalate_auth is False: self.channel.send_input(channel_input=escalate_priv.escalate) else: try: super().send_interactive( interact_events=[ (escalate_priv.escalate, escalate_priv.escalate_prompt, False), (self.auth_secondary, escalate_priv.pattern, True), ], interaction_complete_patterns=[ self.privilege_levels[escalate_priv.previous_priv].pattern, escalate_priv.pattern, ], ) except ScrapliTimeout as exc: raise ScrapliAuthenticationFailed( f\"failed escalating privilege from '{escalate_priv.previous_priv}' to \" f\"'{escalate_priv.name}'. do you need to set an 'auth_secondary' password?\" ) from exc def _deescalate(self, current_priv: PrivilegeLevel) -> None: \"\"\" Deescalate to the next privilege level down Args: current_priv: current privilege level Returns: None Raises: N/A \"\"\" self.channel.send_input(channel_input=current_priv.deescalate) def acquire_priv(self, desired_priv: str) -> None: \"\"\" Acquire desired priv level Args: desired_priv: string name of desired privilege level see `scrapli.driver. .driver` for levels Returns: None Raises: ScrapliPrivilegeError: if desired_priv cannot be attained \"\"\" self._validate_privilege_level_name(privilege_level_name=desired_priv) privilege_change_count = 0 while True: current_prompt = self.channel.get_prompt() privilege_action, target_priv = self._process_acquire_priv( destination_priv=desired_priv, current_prompt=current_prompt, ) if privilege_action == PrivilegeAction.NO_ACTION: self._current_priv_level = target_priv return if privilege_action == PrivilegeAction.DEESCALATE: self._deescalate(current_priv=target_priv) if privilege_action == PrivilegeAction.ESCALATE: self._escalate(escalate_priv=target_priv) privilege_change_count += 1 if privilege_change_count > len(self.privilege_levels) * 2: msg = f\"Failed to acquire requested privilege level {desired_priv}\" raise ScrapliPrivilegeError(msg) def _acquire_appropriate_privilege_level(self, privilege_level: str = \"\") -> None: \"\"\" Acquire the appropriate priv level Acquires the \"right\" priv level based on generic_driver_mode, provided privilege level, and default desired privilege level. If in \"generic_driver_mode\" and no priv level is provided, we simply return as we are already at the \"right\" priv level (since we don't care about priv levels in this mode). If we are in \"generic_driver_mode\" and we are provided a priv level (this is only applicable in `send_interactive`) we will try to acquire that provided priv level. If a priv name is passed we try to resolve it and use that as the privilege level to acquire, otherwise if no priv leve is provided we will acquire the default_desired_privilege_level. Args: privilege_level: optional name of privilege level to acquire Returns: None Raises: N/A \"\"\" if not privilege_level and self._generic_driver_mode is True: return if privilege_level: self._validate_privilege_level_name(privilege_level_name=privilege_level) resolved_privilege_level = privilege_level else: resolved_privilege_level = self.default_desired_privilege_level if self._current_priv_level.name != resolved_privilege_level: self.acquire_priv(desired_priv=resolved_privilege_level) def send_command( self, command: str, *, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, timeout_ops: Optional[float] = None, ) -> Response: \"\"\" Send a command Super method will raise TypeError if anything but a string is passed here! Args: command: string to send to device in privilege exec mode strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed Returns: Response: Scrapli Response object Raises: N/A \"\"\" self._acquire_appropriate_privilege_level() if failed_when_contains is None: failed_when_contains = self.failed_when_contains response: Response = super().send_command( command=command, strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, timeout_ops=timeout_ops, ) self._update_response(response) return response def send_commands( self, commands: List[str], *, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, stop_on_failed: bool = False, eager: bool = False, timeout_ops: Optional[float] = None, ) -> MultiResponse: \"\"\" Send multiple commands Super method will raise TypeError if anything but a list of strings is passed here! Args: commands: list of strings to send to device in privilege exec mode strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER COMMAND sent, not for the total of the commands being sent! Returns: MultiResponse: Scrapli MultiResponse object Raises: N/A \"\"\" self._acquire_appropriate_privilege_level() if failed_when_contains is None: failed_when_contains = self.failed_when_contains responses = super().send_commands( commands=commands, strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, stop_on_failed=stop_on_failed, eager=eager, timeout_ops=timeout_ops, ) for response in responses: self._update_response(response=response) return responses def send_commands_from_file( self, file: str, *, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, stop_on_failed: bool = False, eager: bool = False, timeout_ops: Optional[float] = None, ) -> MultiResponse: \"\"\" Send command(s) from file Args: file: string path to file strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER COMMAND sent, not for the total of the commands being sent! Returns: MultiResponse: Scrapli MultiResponse object Raises: N/A \"\"\" self._acquire_appropriate_privilege_level() if failed_when_contains is None: failed_when_contains = self.failed_when_contains return super().send_commands_from_file( file=file, strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, stop_on_failed=stop_on_failed, eager=eager, timeout_ops=timeout_ops, ) def send_interactive( self, interact_events: Union[List[Tuple[str, str]], List[Tuple[str, str, bool]]], *, failed_when_contains: Optional[Union[str, List[str]]] = None, privilege_level: str = \"\", timeout_ops: Optional[float] = None, interaction_complete_patterns: Optional[List[str]] = None, ) -> Response: \"\"\" Interact with a device with changing prompts per input. Used to interact with devices where prompts change per input, and where inputs may be hidden such as in the case of a password input. This can be used to respond to challenges from devices such as the confirmation for the command \"clear logging\" on IOSXE devices for example. You may have as many elements in the \"interact_events\" list as needed, and each element of that list should be a tuple of two or three elements. The first element is always the input to send as a string, the second should be the expected response as a string, and the optional third a bool for whether or not the input is \"hidden\" (i.e. password input) An example where we need this sort of capability: ''' 3560CX#copy flash: scp: Source filename []? test1.txt Address or name of remote host []? 172.31.254.100 Destination username [carl]? Writing test1.txt Password: Password: Sink: C0644 639 test1.txt ! 639 bytes copied in 12.066 secs (53 bytes/sec) 3560CX# ''' To accomplish this we can use the following: ''' interact = conn.channel.send_inputs_interact( [ (\"copy flash: scp:\", \"Source filename []?\", False), (\"test1.txt\", \"Address or name of remote host []?\", False), (\"172.31.254.100\", \"Destination username [carl]?\", False), (\"carl\", \"Password:\", False), (\"super_secure_password\", prompt, True), ] ) ''' If we needed to deal with more prompts we could simply continue adding tuples to the list of interact \"events\". Args: interact_events: list of tuples containing the \"interactions\" with the device each list element must have an input and an expected response, and may have an optional bool for the third and final element -- the optional bool specifies if the input that is sent to the device is \"hidden\" (ex: password), if the hidden param is not provided it is assumed the input is \"normal\" (not hidden) failed_when_contains: list of strings that, if present in final output, represent a failed command/interaction privilege_level: name of the privilege level to operate in timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER COMMAND sent, not for the total of the commands being sent! interaction_complete_patterns: list of patterns, that if seen, indicate the interactive \"session\" has ended and we should exit the interactive session. Returns: Response: scrapli Response object Raises: N/A \"\"\" self._acquire_appropriate_privilege_level(privilege_level=privilege_level) if failed_when_contains is None: failed_when_contains = self.failed_when_contains # type hint is due to the timeout_modifier wrapper returning `Any` so that we dont anger the # asyncio parts (which will get an awaitable not a Response returned) response: Response = super().send_interactive( interact_events=interact_events, failed_when_contains=failed_when_contains, timeout_ops=timeout_ops, interaction_complete_patterns=interaction_complete_patterns, ) self._update_response(response=response) return response def _abort_config(self) -> None: \"\"\" Abort a configuration operation/session if applicable (for config sessions like junos/iosxr) Args: N/A Returns: None Raises: N/A \"\"\" def send_configs( self, configs: List[str], *, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, stop_on_failed: bool = False, privilege_level: str = \"\", eager: bool = False, timeout_ops: Optional[float] = None, ) -> MultiResponse: \"\"\" Send configuration(s) Args: configs: list of strings to send to device in config mode strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution; aborts configuration session if applicable (iosxr/junos or eos/nxos if using a configuration session) privilege_level: name of configuration privilege level/type to acquire; this is platform dependent, so check the device driver for specifics. Examples of privilege_name would be \"configuration_exclusive\" for IOSXRDriver, or \"configuration_private\" for JunosDriver. You can also pass in a name of a configuration session such as \"my-config-session\" if you have registered a session using the \"register_config_session\" method of the EOSDriver or NXOSDriver. eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER CONFIG sent, not for the total of the configs being sent! Returns: MultiResponse: Scrapli MultiResponse object Raises: N/A \"\"\" resolved_privilege_level, failed_when_contains = self._pre_send_configs( configs=configs, failed_when_contains=failed_when_contains, privilege_level=privilege_level, ) if self._current_priv_level.name != resolved_privilege_level: self.acquire_priv(desired_priv=resolved_privilege_level) responses = super().send_commands( commands=configs, strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, stop_on_failed=stop_on_failed, eager=eager, timeout_ops=timeout_ops, ) if stop_on_failed and responses.failed: self._abort_config() return self._post_send_configs(responses=responses) def send_config( self, config: str, *, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, stop_on_failed: bool = False, privilege_level: str = \"\", eager: bool = False, timeout_ops: Optional[float] = None, ) -> Response: \"\"\" Send configuration string Args: config: string configuration to send to the device, supports sending multi-line strings strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution; aborts configuration session if applicable (iosxr/junos or eos/nxos if using a configuration session) privilege_level: name of configuration privilege level/type to acquire; this is platform dependent, so check the device driver for specifics. Examples of privilege_name would be \"configuration_exclusive\" for IOSXRDriver, or \"configuration_private\" for JunosDriver. You can also pass in a name of a configuration session such as \"my-config-session\" if you have registered a session using the \"register_config_session\" method of the EOSDriver or NXOSDriver. eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER CONFIG sent, not for the total of the configs being sent! Returns: Response: Scrapli Response object Raises: N/A \"\"\" split_config = self._pre_send_config(config=config) # now that we have a list of configs, just use send_configs to actually execute them multi_response = self.send_configs( configs=split_config, strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, stop_on_failed=stop_on_failed, privilege_level=privilege_level, eager=eager, timeout_ops=timeout_ops, ) return self._post_send_config(config=config, multi_response=multi_response) def send_configs_from_file( self, file: str, *, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, stop_on_failed: bool = False, privilege_level: str = \"\", eager: bool = False, timeout_ops: Optional[float] = None, ) -> MultiResponse: \"\"\" Send configuration(s) from a file Args: file: string path to file strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution; aborts configuration session if applicable (iosxr/junos or eos/nxos if using a configuration session) privilege_level: name of configuration privilege level/type to acquire; this is platform dependent, so check the device driver for specifics. Examples of privilege_name would be \"exclusive\" for IOSXRDriver, \"private\" for JunosDriver. You can also pass in a name of a configuration session such as \"session_mysession\" if you have registered a session using the \"register_config_session\" method of the EOSDriver or NXOSDriver. eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER CONFIG sent, not for the total of the configs being sent! Returns: MultiResponse: Scrapli MultiResponse object Raises: N/A \"\"\" configs = self._pre_send_from_file(file=file, caller=\"send_configs_from_file\") return self.send_configs( configs=configs, strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, stop_on_failed=stop_on_failed, privilege_level=privilege_level, eager=eager, timeout_ops=timeout_ops, ) Ancestors (in MRO) \u00b6 scrapli.driver.generic.sync_driver.GenericDriver scrapli.driver.base.sync_driver.Driver scrapli.driver.base.base_driver.BaseDriver scrapli.driver.generic.base_driver.BaseGenericDriver scrapli.driver.network.base_driver.BaseNetworkDriver Descendants \u00b6 scrapli.driver.core.arista_eos.sync_driver.EOSDriver scrapli.driver.core.cisco_iosxe.sync_driver.IOSXEDriver scrapli.driver.core.cisco_iosxr.sync_driver.IOSXRDriver scrapli.driver.core.cisco_nxos.sync_driver.NXOSDriver scrapli.driver.core.juniper_junos.sync_driver.JunosDriver scrapli.factory.Scrapli Methods \u00b6 acquire_priv \u00b6 acquire_priv(self, desired_priv: str) \u2011> None 1 2 3 4 5 6 7 8 9 10 11 Acquire desired priv level Args: desired_priv: string name of desired privilege level see `scrapli.driver.<driver_category.device_type>.driver` for levels Returns: None Raises: ScrapliPrivilegeError: if desired_priv cannot be attained send_command \u00b6 send_command(self, command: str, *, strip_prompt: bool = True, failed_when_contains: Union[str, List[str], ForwardRef(None)] = None, timeout_ops: Optional[float] = None) \u2011> scrapli.response.Response 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 Send a command Super method will raise TypeError if anything but a string is passed here! Args: command: string to send to device in privilege exec mode strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed Returns: Response: Scrapli Response object Raises: N/A send_commands \u00b6 send_commands(self, commands: List[str], *, strip_prompt: bool = True, failed_when_contains: Union[str, List[str], ForwardRef(None)] = None, stop_on_failed: bool = False, eager: bool = False, timeout_ops: Optional[float] = None) \u2011> scrapli.response.MultiResponse 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 Send multiple commands Super method will raise TypeError if anything but a list of strings is passed here! Args: commands: list of strings to send to device in privilege exec mode strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER COMMAND sent, not for the total of the commands being sent! Returns: MultiResponse: Scrapli MultiResponse object Raises: N/A send_config \u00b6 send_config(self, config: str, *, strip_prompt: bool = True, failed_when_contains: Union[str, List[str], ForwardRef(None)] = None, stop_on_failed: bool = False, privilege_level: str = '', eager: bool = False, timeout_ops: Optional[float] = None) \u2011> scrapli.response.Response 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 Send configuration string Args: config: string configuration to send to the device, supports sending multi-line strings strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution; aborts configuration session if applicable (iosxr/junos or eos/nxos if using a configuration session) privilege_level: name of configuration privilege level/type to acquire; this is platform dependent, so check the device driver for specifics. Examples of privilege_name would be \"configuration_exclusive\" for IOSXRDriver, or \"configuration_private\" for JunosDriver. You can also pass in a name of a configuration session such as \"my-config-session\" if you have registered a session using the \"register_config_session\" method of the EOSDriver or NXOSDriver. eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER CONFIG sent, not for the total of the configs being sent! Returns: Response: Scrapli Response object Raises: N/A send_configs \u00b6 send_configs(self, configs: List[str], *, strip_prompt: bool = True, failed_when_contains: Union[str, List[str], ForwardRef(None)] = None, stop_on_failed: bool = False, privilege_level: str = '', eager: bool = False, timeout_ops: Optional[float] = None) \u2011> scrapli.response.MultiResponse 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 Send configuration(s) Args: configs: list of strings to send to device in config mode strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution; aborts configuration session if applicable (iosxr/junos or eos/nxos if using a configuration session) privilege_level: name of configuration privilege level/type to acquire; this is platform dependent, so check the device driver for specifics. Examples of privilege_name would be \"configuration_exclusive\" for IOSXRDriver, or \"configuration_private\" for JunosDriver. You can also pass in a name of a configuration session such as \"my-config-session\" if you have registered a session using the \"register_config_session\" method of the EOSDriver or NXOSDriver. eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER CONFIG sent, not for the total of the configs being sent! Returns: MultiResponse: Scrapli MultiResponse object Raises: N/A send_configs_from_file \u00b6 send_configs_from_file(self, file: str, *, strip_prompt: bool = True, failed_when_contains: Union[str, List[str], ForwardRef(None)] = None, stop_on_failed: bool = False, privilege_level: str = '', eager: bool = False, timeout_ops: Optional[float] = None) \u2011> scrapli.response.MultiResponse 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 Send configuration(s) from a file Args: file: string path to file strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution; aborts configuration session if applicable (iosxr/junos or eos/nxos if using a configuration session) privilege_level: name of configuration privilege level/type to acquire; this is platform dependent, so check the device driver for specifics. Examples of privilege_name would be \"exclusive\" for IOSXRDriver, \"private\" for JunosDriver. You can also pass in a name of a configuration session such as \"session_mysession\" if you have registered a session using the \"register_config_session\" method of the EOSDriver or NXOSDriver. eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER CONFIG sent, not for the total of the configs being sent! Returns: MultiResponse: Scrapli MultiResponse object Raises: N/A send_interactive \u00b6 send_interactive(self, interact_events: Union[List[Tuple[str, str]], List[Tuple[str, str, bool]]], *, failed_when_contains: Union[str, List[str], ForwardRef(None)] = None, privilege_level: str = '', timeout_ops: Optional[float] = None, interaction_complete_patterns: Optional[List[str]] = None) \u2011> scrapli.response.Response 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 Interact with a device with changing prompts per input. Used to interact with devices where prompts change per input, and where inputs may be hidden such as in the case of a password input. This can be used to respond to challenges from devices such as the confirmation for the command \"clear logging\" on IOSXE devices for example. You may have as many elements in the \"interact_events\" list as needed, and each element of that list should be a tuple of two or three elements. The first element is always the input to send as a string, the second should be the expected response as a string, and the optional third a bool for whether or not the input is \"hidden\" (i.e. password input) An example where we need this sort of capability: ''' 3560CX#copy flash: scp: Source filename []? test1.txt Address or name of remote host []? 172.31.254.100 Destination username [carl]? Writing test1.txt Password: Password: Sink: C0644 639 test1.txt ! 639 bytes copied in 12.066 secs (53 bytes/sec) 3560CX# ''' To accomplish this we can use the following: ''' interact = conn.channel.send_inputs_interact( [ (\"copy flash: scp:\", \"Source filename []?\", False), (\"test1.txt\", \"Address or name of remote host []?\", False), (\"172.31.254.100\", \"Destination username [carl]?\", False), (\"carl\", \"Password:\", False), (\"super_secure_password\", prompt, True), ] ) ''' If we needed to deal with more prompts we could simply continue adding tuples to the list of interact \"events\". Args: interact_events: list of tuples containing the \"interactions\" with the device each list element must have an input and an expected response, and may have an optional bool for the third and final element -- the optional bool specifies if the input that is sent to the device is \"hidden\" (ex: password), if the hidden param is not provided it is assumed the input is \"normal\" (not hidden) failed_when_contains: list of strings that, if present in final output, represent a failed command/interaction privilege_level: name of the privilege level to operate in timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER COMMAND sent, not for the total of the commands being sent! interaction_complete_patterns: list of patterns, that if seen, indicate the interactive \"session\" has ended and we should exit the interactive session. Returns: Response: scrapli Response object Raises: N/A","title":"Sync Driver"},{"location":"api_docs/driver/network/sync_driver/#module-scraplidrivernetworksync_driver","text":"scrapli.driver.network.sync_driver Expand source code \"\"\"scrapli.driver.network.sync_driver\"\"\" from collections import defaultdict from io import BytesIO from typing import Any, Callable, Dict, List, Optional, Tuple, Union from scrapli.driver.generic import GenericDriver from scrapli.driver.network.base_driver import BaseNetworkDriver, PrivilegeAction, PrivilegeLevel from scrapli.exceptions import ScrapliAuthenticationFailed, ScrapliPrivilegeError, ScrapliTimeout from scrapli.response import MultiResponse, Response class NetworkDriver(GenericDriver, BaseNetworkDriver): def __init__( self, host: str, privilege_levels: Dict[str, PrivilegeLevel], default_desired_privilege_level: str, port: Optional[int] = None, auth_username: str = \"\", auth_password: str = \"\", auth_private_key: str = \"\", auth_private_key_passphrase: str = \"\", auth_strict_key: bool = True, auth_bypass: bool = False, timeout_socket: float = 15.0, timeout_transport: float = 30.0, timeout_ops: float = 30.0, comms_return_char: str = \"\\n\", ssh_config_file: Union[str, bool] = False, ssh_known_hosts_file: Union[str, bool] = False, on_init: Optional[Callable[..., Any]] = None, on_open: Optional[Callable[..., Any]] = None, on_close: Optional[Callable[..., Any]] = None, transport: str = \"system\", transport_options: Optional[Dict[str, Any]] = None, channel_log: Union[str, bool, BytesIO] = False, channel_log_mode: str = \"write\", channel_lock: bool = False, logging_uid: str = \"\", auth_secondary: str = \"\", failed_when_contains: Optional[List[str]] = None, textfsm_platform: str = \"\", genie_platform: str = \"\", ): # ensure type for comms_prompt_pattern exists before setting it in the mixin self.comms_prompt_pattern: str super().__init__( host=host, port=port, auth_username=auth_username, auth_password=auth_password, auth_private_key=auth_private_key, auth_private_key_passphrase=auth_private_key_passphrase, auth_strict_key=auth_strict_key, auth_bypass=auth_bypass, timeout_socket=timeout_socket, timeout_transport=timeout_transport, timeout_ops=timeout_ops, comms_return_char=comms_return_char, ssh_config_file=ssh_config_file, ssh_known_hosts_file=ssh_known_hosts_file, on_init=on_init, on_open=on_open, on_close=on_close, transport=transport, transport_options=transport_options, channel_log=channel_log, channel_log_mode=channel_log_mode, channel_lock=channel_lock, logging_uid=logging_uid, ) self.auth_secondary = auth_secondary self.failed_when_contains = failed_when_contains or [] self.textfsm_platform = textfsm_platform self.genie_platform = genie_platform self.privilege_levels = privilege_levels self.default_desired_privilege_level = default_desired_privilege_level self._priv_graph = defaultdict(set) self.update_privilege_levels() def _escalate(self, escalate_priv: PrivilegeLevel) -> None: \"\"\" Escalate to the next privilege level up Args: escalate_priv: privilege level to escalate to Returns: None Raises: ScrapliAuthenticationFailed: if auth escalation timeout \"\"\" self._pre_escalate(escalate_priv=escalate_priv) if escalate_priv.escalate_auth is False: self.channel.send_input(channel_input=escalate_priv.escalate) else: try: super().send_interactive( interact_events=[ (escalate_priv.escalate, escalate_priv.escalate_prompt, False), (self.auth_secondary, escalate_priv.pattern, True), ], interaction_complete_patterns=[ self.privilege_levels[escalate_priv.previous_priv].pattern, escalate_priv.pattern, ], ) except ScrapliTimeout as exc: raise ScrapliAuthenticationFailed( f\"failed escalating privilege from '{escalate_priv.previous_priv}' to \" f\"'{escalate_priv.name}'. do you need to set an 'auth_secondary' password?\" ) from exc def _deescalate(self, current_priv: PrivilegeLevel) -> None: \"\"\" Deescalate to the next privilege level down Args: current_priv: current privilege level Returns: None Raises: N/A \"\"\" self.channel.send_input(channel_input=current_priv.deescalate) def acquire_priv(self, desired_priv: str) -> None: \"\"\" Acquire desired priv level Args: desired_priv: string name of desired privilege level see `scrapli.driver. .driver` for levels Returns: None Raises: ScrapliPrivilegeError: if desired_priv cannot be attained \"\"\" self._validate_privilege_level_name(privilege_level_name=desired_priv) privilege_change_count = 0 while True: current_prompt = self.channel.get_prompt() privilege_action, target_priv = self._process_acquire_priv( destination_priv=desired_priv, current_prompt=current_prompt, ) if privilege_action == PrivilegeAction.NO_ACTION: self._current_priv_level = target_priv return if privilege_action == PrivilegeAction.DEESCALATE: self._deescalate(current_priv=target_priv) if privilege_action == PrivilegeAction.ESCALATE: self._escalate(escalate_priv=target_priv) privilege_change_count += 1 if privilege_change_count > len(self.privilege_levels) * 2: msg = f\"Failed to acquire requested privilege level {desired_priv}\" raise ScrapliPrivilegeError(msg) def _acquire_appropriate_privilege_level(self, privilege_level: str = \"\") -> None: \"\"\" Acquire the appropriate priv level Acquires the \"right\" priv level based on generic_driver_mode, provided privilege level, and default desired privilege level. If in \"generic_driver_mode\" and no priv level is provided, we simply return as we are already at the \"right\" priv level (since we don't care about priv levels in this mode). If we are in \"generic_driver_mode\" and we are provided a priv level (this is only applicable in `send_interactive`) we will try to acquire that provided priv level. If a priv name is passed we try to resolve it and use that as the privilege level to acquire, otherwise if no priv leve is provided we will acquire the default_desired_privilege_level. Args: privilege_level: optional name of privilege level to acquire Returns: None Raises: N/A \"\"\" if not privilege_level and self._generic_driver_mode is True: return if privilege_level: self._validate_privilege_level_name(privilege_level_name=privilege_level) resolved_privilege_level = privilege_level else: resolved_privilege_level = self.default_desired_privilege_level if self._current_priv_level.name != resolved_privilege_level: self.acquire_priv(desired_priv=resolved_privilege_level) def send_command( self, command: str, *, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, timeout_ops: Optional[float] = None, ) -> Response: \"\"\" Send a command Super method will raise TypeError if anything but a string is passed here! Args: command: string to send to device in privilege exec mode strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed Returns: Response: Scrapli Response object Raises: N/A \"\"\" self._acquire_appropriate_privilege_level() if failed_when_contains is None: failed_when_contains = self.failed_when_contains response: Response = super().send_command( command=command, strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, timeout_ops=timeout_ops, ) self._update_response(response) return response def send_commands( self, commands: List[str], *, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, stop_on_failed: bool = False, eager: bool = False, timeout_ops: Optional[float] = None, ) -> MultiResponse: \"\"\" Send multiple commands Super method will raise TypeError if anything but a list of strings is passed here! Args: commands: list of strings to send to device in privilege exec mode strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER COMMAND sent, not for the total of the commands being sent! Returns: MultiResponse: Scrapli MultiResponse object Raises: N/A \"\"\" self._acquire_appropriate_privilege_level() if failed_when_contains is None: failed_when_contains = self.failed_when_contains responses = super().send_commands( commands=commands, strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, stop_on_failed=stop_on_failed, eager=eager, timeout_ops=timeout_ops, ) for response in responses: self._update_response(response=response) return responses def send_commands_from_file( self, file: str, *, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, stop_on_failed: bool = False, eager: bool = False, timeout_ops: Optional[float] = None, ) -> MultiResponse: \"\"\" Send command(s) from file Args: file: string path to file strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER COMMAND sent, not for the total of the commands being sent! Returns: MultiResponse: Scrapli MultiResponse object Raises: N/A \"\"\" self._acquire_appropriate_privilege_level() if failed_when_contains is None: failed_when_contains = self.failed_when_contains return super().send_commands_from_file( file=file, strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, stop_on_failed=stop_on_failed, eager=eager, timeout_ops=timeout_ops, ) def send_interactive( self, interact_events: Union[List[Tuple[str, str]], List[Tuple[str, str, bool]]], *, failed_when_contains: Optional[Union[str, List[str]]] = None, privilege_level: str = \"\", timeout_ops: Optional[float] = None, interaction_complete_patterns: Optional[List[str]] = None, ) -> Response: \"\"\" Interact with a device with changing prompts per input. Used to interact with devices where prompts change per input, and where inputs may be hidden such as in the case of a password input. This can be used to respond to challenges from devices such as the confirmation for the command \"clear logging\" on IOSXE devices for example. You may have as many elements in the \"interact_events\" list as needed, and each element of that list should be a tuple of two or three elements. The first element is always the input to send as a string, the second should be the expected response as a string, and the optional third a bool for whether or not the input is \"hidden\" (i.e. password input) An example where we need this sort of capability: ''' 3560CX#copy flash: scp: Source filename []? test1.txt Address or name of remote host []? 172.31.254.100 Destination username [carl]? Writing test1.txt Password: Password: Sink: C0644 639 test1.txt ! 639 bytes copied in 12.066 secs (53 bytes/sec) 3560CX# ''' To accomplish this we can use the following: ''' interact = conn.channel.send_inputs_interact( [ (\"copy flash: scp:\", \"Source filename []?\", False), (\"test1.txt\", \"Address or name of remote host []?\", False), (\"172.31.254.100\", \"Destination username [carl]?\", False), (\"carl\", \"Password:\", False), (\"super_secure_password\", prompt, True), ] ) ''' If we needed to deal with more prompts we could simply continue adding tuples to the list of interact \"events\". Args: interact_events: list of tuples containing the \"interactions\" with the device each list element must have an input and an expected response, and may have an optional bool for the third and final element -- the optional bool specifies if the input that is sent to the device is \"hidden\" (ex: password), if the hidden param is not provided it is assumed the input is \"normal\" (not hidden) failed_when_contains: list of strings that, if present in final output, represent a failed command/interaction privilege_level: name of the privilege level to operate in timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER COMMAND sent, not for the total of the commands being sent! interaction_complete_patterns: list of patterns, that if seen, indicate the interactive \"session\" has ended and we should exit the interactive session. Returns: Response: scrapli Response object Raises: N/A \"\"\" self._acquire_appropriate_privilege_level(privilege_level=privilege_level) if failed_when_contains is None: failed_when_contains = self.failed_when_contains # type hint is due to the timeout_modifier wrapper returning `Any` so that we dont anger the # asyncio parts (which will get an awaitable not a Response returned) response: Response = super().send_interactive( interact_events=interact_events, failed_when_contains=failed_when_contains, timeout_ops=timeout_ops, interaction_complete_patterns=interaction_complete_patterns, ) self._update_response(response=response) return response def _abort_config(self) -> None: \"\"\" Abort a configuration operation/session if applicable (for config sessions like junos/iosxr) Args: N/A Returns: None Raises: N/A \"\"\" def send_configs( self, configs: List[str], *, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, stop_on_failed: bool = False, privilege_level: str = \"\", eager: bool = False, timeout_ops: Optional[float] = None, ) -> MultiResponse: \"\"\" Send configuration(s) Args: configs: list of strings to send to device in config mode strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution; aborts configuration session if applicable (iosxr/junos or eos/nxos if using a configuration session) privilege_level: name of configuration privilege level/type to acquire; this is platform dependent, so check the device driver for specifics. Examples of privilege_name would be \"configuration_exclusive\" for IOSXRDriver, or \"configuration_private\" for JunosDriver. You can also pass in a name of a configuration session such as \"my-config-session\" if you have registered a session using the \"register_config_session\" method of the EOSDriver or NXOSDriver. eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER CONFIG sent, not for the total of the configs being sent! Returns: MultiResponse: Scrapli MultiResponse object Raises: N/A \"\"\" resolved_privilege_level, failed_when_contains = self._pre_send_configs( configs=configs, failed_when_contains=failed_when_contains, privilege_level=privilege_level, ) if self._current_priv_level.name != resolved_privilege_level: self.acquire_priv(desired_priv=resolved_privilege_level) responses = super().send_commands( commands=configs, strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, stop_on_failed=stop_on_failed, eager=eager, timeout_ops=timeout_ops, ) if stop_on_failed and responses.failed: self._abort_config() return self._post_send_configs(responses=responses) def send_config( self, config: str, *, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, stop_on_failed: bool = False, privilege_level: str = \"\", eager: bool = False, timeout_ops: Optional[float] = None, ) -> Response: \"\"\" Send configuration string Args: config: string configuration to send to the device, supports sending multi-line strings strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution; aborts configuration session if applicable (iosxr/junos or eos/nxos if using a configuration session) privilege_level: name of configuration privilege level/type to acquire; this is platform dependent, so check the device driver for specifics. Examples of privilege_name would be \"configuration_exclusive\" for IOSXRDriver, or \"configuration_private\" for JunosDriver. You can also pass in a name of a configuration session such as \"my-config-session\" if you have registered a session using the \"register_config_session\" method of the EOSDriver or NXOSDriver. eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER CONFIG sent, not for the total of the configs being sent! Returns: Response: Scrapli Response object Raises: N/A \"\"\" split_config = self._pre_send_config(config=config) # now that we have a list of configs, just use send_configs to actually execute them multi_response = self.send_configs( configs=split_config, strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, stop_on_failed=stop_on_failed, privilege_level=privilege_level, eager=eager, timeout_ops=timeout_ops, ) return self._post_send_config(config=config, multi_response=multi_response) def send_configs_from_file( self, file: str, *, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, stop_on_failed: bool = False, privilege_level: str = \"\", eager: bool = False, timeout_ops: Optional[float] = None, ) -> MultiResponse: \"\"\" Send configuration(s) from a file Args: file: string path to file strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution; aborts configuration session if applicable (iosxr/junos or eos/nxos if using a configuration session) privilege_level: name of configuration privilege level/type to acquire; this is platform dependent, so check the device driver for specifics. Examples of privilege_name would be \"exclusive\" for IOSXRDriver, \"private\" for JunosDriver. You can also pass in a name of a configuration session such as \"session_mysession\" if you have registered a session using the \"register_config_session\" method of the EOSDriver or NXOSDriver. eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER CONFIG sent, not for the total of the configs being sent! Returns: MultiResponse: Scrapli MultiResponse object Raises: N/A \"\"\" configs = self._pre_send_from_file(file=file, caller=\"send_configs_from_file\") return self.send_configs( configs=configs, strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, stop_on_failed=stop_on_failed, privilege_level=privilege_level, eager=eager, timeout_ops=timeout_ops, )","title":"Module scrapli.driver.network.sync_driver"},{"location":"api_docs/driver/network/sync_driver/#classes","text":"","title":"Classes"},{"location":"api_docs/driver/network/sync_driver/#networkdriver","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 BaseDriver Object BaseDriver is the root for all Scrapli driver classes. The synchronous and asyncio driver base driver classes can be used to provide a semi-pexpect like experience over top of whatever transport a user prefers. Generally, however, the base driver classes should not be used directly. It is best to use the GenericDriver (or AsyncGenericDriver) or NetworkDriver (or AsyncNetworkDriver) sub-classes of the base drivers. Args: host: host ip/name to connect to port: port to connect to auth_username: username for authentication auth_private_key: path to private key for authentication auth_private_key_passphrase: passphrase for decrypting ssh key if necessary auth_password: password for authentication auth_strict_key: strict host checking or not auth_bypass: bypass \"in channel\" authentication -- only supported with telnet, asynctelnet, and system transport plugins timeout_socket: timeout for establishing socket/initial connection in seconds timeout_transport: timeout for ssh|telnet transport in seconds timeout_ops: timeout for ssh channel operations comms_prompt_pattern: raw string regex pattern -- preferably use `^` and `$` anchors! this is the single most important attribute here! if this does not match a prompt, scrapli will not work! IMPORTANT: regex search uses multi-line + case insensitive flags. multi-line allows for highly reliably matching for prompts however we do NOT strip trailing whitespace for each line, so be sure to add '\\\\s?' or similar if your device needs that. This should be mostly sorted for you if using network drivers (i.e. `IOSXEDriver`). Lastly, the case insensitive is just a convenience factor so i can be lazy. comms_return_char: character to use to send returns to host ssh_config_file: string to path for ssh config file, True to use default ssh config file or False to ignore default ssh config file ssh_known_hosts_file: string to path for ssh known hosts file, True to use default known file locations. Only applicable/needed if `auth_strict_key` is set to True on_init: callable that accepts the class instance as its only argument. this callable, if provided, is executed as the last step of object instantiation -- its purpose is primarily to provide a mechanism for scrapli community platforms to have an easy way to modify initialization arguments/object attributes without needing to create a class that extends the driver, instead allowing the community platforms to simply build from the GenericDriver or NetworkDriver classes, and pass this callable to do things such as appending to a username (looking at you RouterOS!!). Note that this is *always* a synchronous function (even for asyncio drivers)! on_open: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately after authentication is completed. Common use cases for this callable would be to disable paging or accept any kind of banner message that prompts a user upon connection on_close: callable that accepts the class instance as its only argument. this callable, if provided, is executed immediately prior to closing the underlying transport. Common use cases for this callable would be to save configurations prior to exiting, or to logout properly to free up vtys or similar transport: name of the transport plugin to use for the actual telnet/ssh/netconf connection. Available \"core\" transports are: - system - telnet - asynctelnet - ssh2 - paramiko - asyncssh Please see relevant transport plugin section for details. Additionally third party transport plugins may be available. transport_options: dictionary of options to pass to selected transport class; see docs for given transport class for details of what to pass here channel_lock: True/False to lock the channel (threading.Lock/asyncio.Lock) during any channel operations, defaults to False channel_log: True/False or a string path to a file of where to write out channel logs -- these are not \"logs\" in the normal logging module sense, but only the output that is read from the channel. In other words, the output of the channel log should look similar to what you would see as a human connecting to a device channel_log_mode: \"write\"|\"append\", all other values will raise ValueError, does what it sounds like it should by setting the channel log to the provided mode logging_uid: unique identifier (string) to associate to log messages; useful if you have multiple connections to the same device (i.e. one console, one ssh, or one to each supervisor module, etc.) Returns: None Raises: N/A Expand source code class NetworkDriver(GenericDriver, BaseNetworkDriver): def __init__( self, host: str, privilege_levels: Dict[str, PrivilegeLevel], default_desired_privilege_level: str, port: Optional[int] = None, auth_username: str = \"\", auth_password: str = \"\", auth_private_key: str = \"\", auth_private_key_passphrase: str = \"\", auth_strict_key: bool = True, auth_bypass: bool = False, timeout_socket: float = 15.0, timeout_transport: float = 30.0, timeout_ops: float = 30.0, comms_return_char: str = \"\\n\", ssh_config_file: Union[str, bool] = False, ssh_known_hosts_file: Union[str, bool] = False, on_init: Optional[Callable[..., Any]] = None, on_open: Optional[Callable[..., Any]] = None, on_close: Optional[Callable[..., Any]] = None, transport: str = \"system\", transport_options: Optional[Dict[str, Any]] = None, channel_log: Union[str, bool, BytesIO] = False, channel_log_mode: str = \"write\", channel_lock: bool = False, logging_uid: str = \"\", auth_secondary: str = \"\", failed_when_contains: Optional[List[str]] = None, textfsm_platform: str = \"\", genie_platform: str = \"\", ): # ensure type for comms_prompt_pattern exists before setting it in the mixin self.comms_prompt_pattern: str super().__init__( host=host, port=port, auth_username=auth_username, auth_password=auth_password, auth_private_key=auth_private_key, auth_private_key_passphrase=auth_private_key_passphrase, auth_strict_key=auth_strict_key, auth_bypass=auth_bypass, timeout_socket=timeout_socket, timeout_transport=timeout_transport, timeout_ops=timeout_ops, comms_return_char=comms_return_char, ssh_config_file=ssh_config_file, ssh_known_hosts_file=ssh_known_hosts_file, on_init=on_init, on_open=on_open, on_close=on_close, transport=transport, transport_options=transport_options, channel_log=channel_log, channel_log_mode=channel_log_mode, channel_lock=channel_lock, logging_uid=logging_uid, ) self.auth_secondary = auth_secondary self.failed_when_contains = failed_when_contains or [] self.textfsm_platform = textfsm_platform self.genie_platform = genie_platform self.privilege_levels = privilege_levels self.default_desired_privilege_level = default_desired_privilege_level self._priv_graph = defaultdict(set) self.update_privilege_levels() def _escalate(self, escalate_priv: PrivilegeLevel) -> None: \"\"\" Escalate to the next privilege level up Args: escalate_priv: privilege level to escalate to Returns: None Raises: ScrapliAuthenticationFailed: if auth escalation timeout \"\"\" self._pre_escalate(escalate_priv=escalate_priv) if escalate_priv.escalate_auth is False: self.channel.send_input(channel_input=escalate_priv.escalate) else: try: super().send_interactive( interact_events=[ (escalate_priv.escalate, escalate_priv.escalate_prompt, False), (self.auth_secondary, escalate_priv.pattern, True), ], interaction_complete_patterns=[ self.privilege_levels[escalate_priv.previous_priv].pattern, escalate_priv.pattern, ], ) except ScrapliTimeout as exc: raise ScrapliAuthenticationFailed( f\"failed escalating privilege from '{escalate_priv.previous_priv}' to \" f\"'{escalate_priv.name}'. do you need to set an 'auth_secondary' password?\" ) from exc def _deescalate(self, current_priv: PrivilegeLevel) -> None: \"\"\" Deescalate to the next privilege level down Args: current_priv: current privilege level Returns: None Raises: N/A \"\"\" self.channel.send_input(channel_input=current_priv.deescalate) def acquire_priv(self, desired_priv: str) -> None: \"\"\" Acquire desired priv level Args: desired_priv: string name of desired privilege level see `scrapli.driver. .driver` for levels Returns: None Raises: ScrapliPrivilegeError: if desired_priv cannot be attained \"\"\" self._validate_privilege_level_name(privilege_level_name=desired_priv) privilege_change_count = 0 while True: current_prompt = self.channel.get_prompt() privilege_action, target_priv = self._process_acquire_priv( destination_priv=desired_priv, current_prompt=current_prompt, ) if privilege_action == PrivilegeAction.NO_ACTION: self._current_priv_level = target_priv return if privilege_action == PrivilegeAction.DEESCALATE: self._deescalate(current_priv=target_priv) if privilege_action == PrivilegeAction.ESCALATE: self._escalate(escalate_priv=target_priv) privilege_change_count += 1 if privilege_change_count > len(self.privilege_levels) * 2: msg = f\"Failed to acquire requested privilege level {desired_priv}\" raise ScrapliPrivilegeError(msg) def _acquire_appropriate_privilege_level(self, privilege_level: str = \"\") -> None: \"\"\" Acquire the appropriate priv level Acquires the \"right\" priv level based on generic_driver_mode, provided privilege level, and default desired privilege level. If in \"generic_driver_mode\" and no priv level is provided, we simply return as we are already at the \"right\" priv level (since we don't care about priv levels in this mode). If we are in \"generic_driver_mode\" and we are provided a priv level (this is only applicable in `send_interactive`) we will try to acquire that provided priv level. If a priv name is passed we try to resolve it and use that as the privilege level to acquire, otherwise if no priv leve is provided we will acquire the default_desired_privilege_level. Args: privilege_level: optional name of privilege level to acquire Returns: None Raises: N/A \"\"\" if not privilege_level and self._generic_driver_mode is True: return if privilege_level: self._validate_privilege_level_name(privilege_level_name=privilege_level) resolved_privilege_level = privilege_level else: resolved_privilege_level = self.default_desired_privilege_level if self._current_priv_level.name != resolved_privilege_level: self.acquire_priv(desired_priv=resolved_privilege_level) def send_command( self, command: str, *, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, timeout_ops: Optional[float] = None, ) -> Response: \"\"\" Send a command Super method will raise TypeError if anything but a string is passed here! Args: command: string to send to device in privilege exec mode strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed Returns: Response: Scrapli Response object Raises: N/A \"\"\" self._acquire_appropriate_privilege_level() if failed_when_contains is None: failed_when_contains = self.failed_when_contains response: Response = super().send_command( command=command, strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, timeout_ops=timeout_ops, ) self._update_response(response) return response def send_commands( self, commands: List[str], *, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, stop_on_failed: bool = False, eager: bool = False, timeout_ops: Optional[float] = None, ) -> MultiResponse: \"\"\" Send multiple commands Super method will raise TypeError if anything but a list of strings is passed here! Args: commands: list of strings to send to device in privilege exec mode strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER COMMAND sent, not for the total of the commands being sent! Returns: MultiResponse: Scrapli MultiResponse object Raises: N/A \"\"\" self._acquire_appropriate_privilege_level() if failed_when_contains is None: failed_when_contains = self.failed_when_contains responses = super().send_commands( commands=commands, strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, stop_on_failed=stop_on_failed, eager=eager, timeout_ops=timeout_ops, ) for response in responses: self._update_response(response=response) return responses def send_commands_from_file( self, file: str, *, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, stop_on_failed: bool = False, eager: bool = False, timeout_ops: Optional[float] = None, ) -> MultiResponse: \"\"\" Send command(s) from file Args: file: string path to file strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER COMMAND sent, not for the total of the commands being sent! Returns: MultiResponse: Scrapli MultiResponse object Raises: N/A \"\"\" self._acquire_appropriate_privilege_level() if failed_when_contains is None: failed_when_contains = self.failed_when_contains return super().send_commands_from_file( file=file, strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, stop_on_failed=stop_on_failed, eager=eager, timeout_ops=timeout_ops, ) def send_interactive( self, interact_events: Union[List[Tuple[str, str]], List[Tuple[str, str, bool]]], *, failed_when_contains: Optional[Union[str, List[str]]] = None, privilege_level: str = \"\", timeout_ops: Optional[float] = None, interaction_complete_patterns: Optional[List[str]] = None, ) -> Response: \"\"\" Interact with a device with changing prompts per input. Used to interact with devices where prompts change per input, and where inputs may be hidden such as in the case of a password input. This can be used to respond to challenges from devices such as the confirmation for the command \"clear logging\" on IOSXE devices for example. You may have as many elements in the \"interact_events\" list as needed, and each element of that list should be a tuple of two or three elements. The first element is always the input to send as a string, the second should be the expected response as a string, and the optional third a bool for whether or not the input is \"hidden\" (i.e. password input) An example where we need this sort of capability: ''' 3560CX#copy flash: scp: Source filename []? test1.txt Address or name of remote host []? 172.31.254.100 Destination username [carl]? Writing test1.txt Password: Password: Sink: C0644 639 test1.txt ! 639 bytes copied in 12.066 secs (53 bytes/sec) 3560CX# ''' To accomplish this we can use the following: ''' interact = conn.channel.send_inputs_interact( [ (\"copy flash: scp:\", \"Source filename []?\", False), (\"test1.txt\", \"Address or name of remote host []?\", False), (\"172.31.254.100\", \"Destination username [carl]?\", False), (\"carl\", \"Password:\", False), (\"super_secure_password\", prompt, True), ] ) ''' If we needed to deal with more prompts we could simply continue adding tuples to the list of interact \"events\". Args: interact_events: list of tuples containing the \"interactions\" with the device each list element must have an input and an expected response, and may have an optional bool for the third and final element -- the optional bool specifies if the input that is sent to the device is \"hidden\" (ex: password), if the hidden param is not provided it is assumed the input is \"normal\" (not hidden) failed_when_contains: list of strings that, if present in final output, represent a failed command/interaction privilege_level: name of the privilege level to operate in timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER COMMAND sent, not for the total of the commands being sent! interaction_complete_patterns: list of patterns, that if seen, indicate the interactive \"session\" has ended and we should exit the interactive session. Returns: Response: scrapli Response object Raises: N/A \"\"\" self._acquire_appropriate_privilege_level(privilege_level=privilege_level) if failed_when_contains is None: failed_when_contains = self.failed_when_contains # type hint is due to the timeout_modifier wrapper returning `Any` so that we dont anger the # asyncio parts (which will get an awaitable not a Response returned) response: Response = super().send_interactive( interact_events=interact_events, failed_when_contains=failed_when_contains, timeout_ops=timeout_ops, interaction_complete_patterns=interaction_complete_patterns, ) self._update_response(response=response) return response def _abort_config(self) -> None: \"\"\" Abort a configuration operation/session if applicable (for config sessions like junos/iosxr) Args: N/A Returns: None Raises: N/A \"\"\" def send_configs( self, configs: List[str], *, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, stop_on_failed: bool = False, privilege_level: str = \"\", eager: bool = False, timeout_ops: Optional[float] = None, ) -> MultiResponse: \"\"\" Send configuration(s) Args: configs: list of strings to send to device in config mode strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution; aborts configuration session if applicable (iosxr/junos or eos/nxos if using a configuration session) privilege_level: name of configuration privilege level/type to acquire; this is platform dependent, so check the device driver for specifics. Examples of privilege_name would be \"configuration_exclusive\" for IOSXRDriver, or \"configuration_private\" for JunosDriver. You can also pass in a name of a configuration session such as \"my-config-session\" if you have registered a session using the \"register_config_session\" method of the EOSDriver or NXOSDriver. eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER CONFIG sent, not for the total of the configs being sent! Returns: MultiResponse: Scrapli MultiResponse object Raises: N/A \"\"\" resolved_privilege_level, failed_when_contains = self._pre_send_configs( configs=configs, failed_when_contains=failed_when_contains, privilege_level=privilege_level, ) if self._current_priv_level.name != resolved_privilege_level: self.acquire_priv(desired_priv=resolved_privilege_level) responses = super().send_commands( commands=configs, strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, stop_on_failed=stop_on_failed, eager=eager, timeout_ops=timeout_ops, ) if stop_on_failed and responses.failed: self._abort_config() return self._post_send_configs(responses=responses) def send_config( self, config: str, *, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, stop_on_failed: bool = False, privilege_level: str = \"\", eager: bool = False, timeout_ops: Optional[float] = None, ) -> Response: \"\"\" Send configuration string Args: config: string configuration to send to the device, supports sending multi-line strings strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution; aborts configuration session if applicable (iosxr/junos or eos/nxos if using a configuration session) privilege_level: name of configuration privilege level/type to acquire; this is platform dependent, so check the device driver for specifics. Examples of privilege_name would be \"configuration_exclusive\" for IOSXRDriver, or \"configuration_private\" for JunosDriver. You can also pass in a name of a configuration session such as \"my-config-session\" if you have registered a session using the \"register_config_session\" method of the EOSDriver or NXOSDriver. eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER CONFIG sent, not for the total of the configs being sent! Returns: Response: Scrapli Response object Raises: N/A \"\"\" split_config = self._pre_send_config(config=config) # now that we have a list of configs, just use send_configs to actually execute them multi_response = self.send_configs( configs=split_config, strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, stop_on_failed=stop_on_failed, privilege_level=privilege_level, eager=eager, timeout_ops=timeout_ops, ) return self._post_send_config(config=config, multi_response=multi_response) def send_configs_from_file( self, file: str, *, strip_prompt: bool = True, failed_when_contains: Optional[Union[str, List[str]]] = None, stop_on_failed: bool = False, privilege_level: str = \"\", eager: bool = False, timeout_ops: Optional[float] = None, ) -> MultiResponse: \"\"\" Send configuration(s) from a file Args: file: string path to file strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution; aborts configuration session if applicable (iosxr/junos or eos/nxos if using a configuration session) privilege_level: name of configuration privilege level/type to acquire; this is platform dependent, so check the device driver for specifics. Examples of privilege_name would be \"exclusive\" for IOSXRDriver, \"private\" for JunosDriver. You can also pass in a name of a configuration session such as \"session_mysession\" if you have registered a session using the \"register_config_session\" method of the EOSDriver or NXOSDriver. eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER CONFIG sent, not for the total of the configs being sent! Returns: MultiResponse: Scrapli MultiResponse object Raises: N/A \"\"\" configs = self._pre_send_from_file(file=file, caller=\"send_configs_from_file\") return self.send_configs( configs=configs, strip_prompt=strip_prompt, failed_when_contains=failed_when_contains, stop_on_failed=stop_on_failed, privilege_level=privilege_level, eager=eager, timeout_ops=timeout_ops, )","title":"NetworkDriver"},{"location":"api_docs/driver/network/sync_driver/#ancestors-in-mro","text":"scrapli.driver.generic.sync_driver.GenericDriver scrapli.driver.base.sync_driver.Driver scrapli.driver.base.base_driver.BaseDriver scrapli.driver.generic.base_driver.BaseGenericDriver scrapli.driver.network.base_driver.BaseNetworkDriver","title":"Ancestors (in MRO)"},{"location":"api_docs/driver/network/sync_driver/#descendants","text":"scrapli.driver.core.arista_eos.sync_driver.EOSDriver scrapli.driver.core.cisco_iosxe.sync_driver.IOSXEDriver scrapli.driver.core.cisco_iosxr.sync_driver.IOSXRDriver scrapli.driver.core.cisco_nxos.sync_driver.NXOSDriver scrapli.driver.core.juniper_junos.sync_driver.JunosDriver scrapli.factory.Scrapli","title":"Descendants"},{"location":"api_docs/driver/network/sync_driver/#methods","text":"","title":"Methods"},{"location":"api_docs/driver/network/sync_driver/#acquire_priv","text":"acquire_priv(self, desired_priv: str) \u2011> None 1 2 3 4 5 6 7 8 9 10 11 Acquire desired priv level Args: desired_priv: string name of desired privilege level see `scrapli.driver.<driver_category.device_type>.driver` for levels Returns: None Raises: ScrapliPrivilegeError: if desired_priv cannot be attained","title":"acquire_priv"},{"location":"api_docs/driver/network/sync_driver/#send_command","text":"send_command(self, command: str, *, strip_prompt: bool = True, failed_when_contains: Union[str, List[str], ForwardRef(None)] = None, timeout_ops: Optional[float] = None) \u2011> scrapli.response.Response 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 Send a command Super method will raise TypeError if anything but a string is passed here! Args: command: string to send to device in privilege exec mode strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed Returns: Response: Scrapli Response object Raises: N/A","title":"send_command"},{"location":"api_docs/driver/network/sync_driver/#send_commands","text":"send_commands(self, commands: List[str], *, strip_prompt: bool = True, failed_when_contains: Union[str, List[str], ForwardRef(None)] = None, stop_on_failed: bool = False, eager: bool = False, timeout_ops: Optional[float] = None) \u2011> scrapli.response.MultiResponse 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 Send multiple commands Super method will raise TypeError if anything but a list of strings is passed here! Args: commands: list of strings to send to device in privilege exec mode strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER COMMAND sent, not for the total of the commands being sent! Returns: MultiResponse: Scrapli MultiResponse object Raises: N/A","title":"send_commands"},{"location":"api_docs/driver/network/sync_driver/#send_config","text":"send_config(self, config: str, *, strip_prompt: bool = True, failed_when_contains: Union[str, List[str], ForwardRef(None)] = None, stop_on_failed: bool = False, privilege_level: str = '', eager: bool = False, timeout_ops: Optional[float] = None) \u2011> scrapli.response.Response 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 Send configuration string Args: config: string configuration to send to the device, supports sending multi-line strings strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution; aborts configuration session if applicable (iosxr/junos or eos/nxos if using a configuration session) privilege_level: name of configuration privilege level/type to acquire; this is platform dependent, so check the device driver for specifics. Examples of privilege_name would be \"configuration_exclusive\" for IOSXRDriver, or \"configuration_private\" for JunosDriver. You can also pass in a name of a configuration session such as \"my-config-session\" if you have registered a session using the \"register_config_session\" method of the EOSDriver or NXOSDriver. eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER CONFIG sent, not for the total of the configs being sent! Returns: Response: Scrapli Response object Raises: N/A","title":"send_config"},{"location":"api_docs/driver/network/sync_driver/#send_configs","text":"send_configs(self, configs: List[str], *, strip_prompt: bool = True, failed_when_contains: Union[str, List[str], ForwardRef(None)] = None, stop_on_failed: bool = False, privilege_level: str = '', eager: bool = False, timeout_ops: Optional[float] = None) \u2011> scrapli.response.MultiResponse 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 Send configuration(s) Args: configs: list of strings to send to device in config mode strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution; aborts configuration session if applicable (iosxr/junos or eos/nxos if using a configuration session) privilege_level: name of configuration privilege level/type to acquire; this is platform dependent, so check the device driver for specifics. Examples of privilege_name would be \"configuration_exclusive\" for IOSXRDriver, or \"configuration_private\" for JunosDriver. You can also pass in a name of a configuration session such as \"my-config-session\" if you have registered a session using the \"register_config_session\" method of the EOSDriver or NXOSDriver. eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER CONFIG sent, not for the total of the configs being sent! Returns: MultiResponse: Scrapli MultiResponse object Raises: N/A","title":"send_configs"},{"location":"api_docs/driver/network/sync_driver/#send_configs_from_file","text":"send_configs_from_file(self, file: str, *, strip_prompt: bool = True, failed_when_contains: Union[str, List[str], ForwardRef(None)] = None, stop_on_failed: bool = False, privilege_level: str = '', eager: bool = False, timeout_ops: Optional[float] = None) \u2011> scrapli.response.MultiResponse 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 Send configuration(s) from a file Args: file: string path to file strip_prompt: True/False strip prompt from returned output failed_when_contains: string or list of strings indicating failure if found in response stop_on_failed: True/False stop executing commands if a command fails, returns results as of current execution; aborts configuration session if applicable (iosxr/junos or eos/nxos if using a configuration session) privilege_level: name of configuration privilege level/type to acquire; this is platform dependent, so check the device driver for specifics. Examples of privilege_name would be \"exclusive\" for IOSXRDriver, \"private\" for JunosDriver. You can also pass in a name of a configuration session such as \"session_mysession\" if you have registered a session using the \"register_config_session\" method of the EOSDriver or NXOSDriver. eager: if eager is True we do not read until prompt is seen at each command sent to the channel. Do *not* use this unless you know what you are doing as it is possible that it can make scrapli less reliable! timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER CONFIG sent, not for the total of the configs being sent! Returns: MultiResponse: Scrapli MultiResponse object Raises: N/A","title":"send_configs_from_file"},{"location":"api_docs/driver/network/sync_driver/#send_interactive","text":"send_interactive(self, interact_events: Union[List[Tuple[str, str]], List[Tuple[str, str, bool]]], *, failed_when_contains: Union[str, List[str], ForwardRef(None)] = None, privilege_level: str = '', timeout_ops: Optional[float] = None, interaction_complete_patterns: Optional[List[str]] = None) \u2011> scrapli.response.Response 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 Interact with a device with changing prompts per input. Used to interact with devices where prompts change per input, and where inputs may be hidden such as in the case of a password input. This can be used to respond to challenges from devices such as the confirmation for the command \"clear logging\" on IOSXE devices for example. You may have as many elements in the \"interact_events\" list as needed, and each element of that list should be a tuple of two or three elements. The first element is always the input to send as a string, the second should be the expected response as a string, and the optional third a bool for whether or not the input is \"hidden\" (i.e. password input) An example where we need this sort of capability: ''' 3560CX#copy flash: scp: Source filename []? test1.txt Address or name of remote host []? 172.31.254.100 Destination username [carl]? Writing test1.txt Password: Password: Sink: C0644 639 test1.txt ! 639 bytes copied in 12.066 secs (53 bytes/sec) 3560CX# ''' To accomplish this we can use the following: ''' interact = conn.channel.send_inputs_interact( [ (\"copy flash: scp:\", \"Source filename []?\", False), (\"test1.txt\", \"Address or name of remote host []?\", False), (\"172.31.254.100\", \"Destination username [carl]?\", False), (\"carl\", \"Password:\", False), (\"super_secure_password\", prompt, True), ] ) ''' If we needed to deal with more prompts we could simply continue adding tuples to the list of interact \"events\". Args: interact_events: list of tuples containing the \"interactions\" with the device each list element must have an input and an expected response, and may have an optional bool for the third and final element -- the optional bool specifies if the input that is sent to the device is \"hidden\" (ex: password), if the hidden param is not provided it is assumed the input is \"normal\" (not hidden) failed_when_contains: list of strings that, if present in final output, represent a failed command/interaction privilege_level: name of the privilege level to operate in timeout_ops: timeout ops value for this operation; only sets the timeout_ops value for the duration of the operation, value is reset to initial value after operation is completed. Note that this is the timeout value PER COMMAND sent, not for the total of the commands being sent! interaction_complete_patterns: list of patterns, that if seen, indicate the interactive \"session\" has ended and we should exit the interactive session. Returns: Response: scrapli Response object Raises: N/A","title":"send_interactive"},{"location":"api_docs/transport/base/async_transport/","text":"window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting()) Module scrapli.transport.base.async_transport \u00b6 scrapli.transport.async_transport Expand source code \"\"\"scrapli.transport.async_transport\"\"\" from abc import ABC, abstractmethod from scrapli.transport.base.base_transport import BaseTransport class AsyncTransport(BaseTransport, ABC): @abstractmethod async def open(self) -> None: \"\"\" Open the transport session Args: N/A Returns: None Raises: N/A \"\"\" @abstractmethod async def read(self) -> bytes: \"\"\" Read data from the transport session Args: N/A Returns: None Raises: N/A \"\"\" Classes \u00b6 AsyncTransport \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 Helper class that provides a standard way to create an ABC using inheritance. Scrapli's transport base class Args: base_transport_args: base transport args dataclass Returns: None Raises: N/A Expand source code class AsyncTransport(BaseTransport, ABC): @abstractmethod async def open(self) -> None: \"\"\" Open the transport session Args: N/A Returns: None Raises: N/A \"\"\" @abstractmethod async def read(self) -> bytes: \"\"\" Read data from the transport session Args: N/A Returns: None Raises: N/A \"\"\" Ancestors (in MRO) \u00b6 scrapli.transport.base.base_transport.BaseTransport abc.ABC Descendants \u00b6 scrapli.transport.plugins.asyncssh.transport.AsyncsshTransport scrapli.transport.plugins.asynctelnet.transport.AsynctelnetTransport Methods \u00b6 open \u00b6 open(self) \u2011> None 1 2 3 4 5 6 7 8 9 10 Open the transport session Args: N/A Returns: None Raises: N/A read \u00b6 read(self) \u2011> bytes 1 2 3 4 5 6 7 8 9 10 Read data from the transport session Args: N/A Returns: None Raises: N/A","title":"Async Transport"},{"location":"api_docs/transport/base/async_transport/#module-scraplitransportbaseasync_transport","text":"scrapli.transport.async_transport Expand source code \"\"\"scrapli.transport.async_transport\"\"\" from abc import ABC, abstractmethod from scrapli.transport.base.base_transport import BaseTransport class AsyncTransport(BaseTransport, ABC): @abstractmethod async def open(self) -> None: \"\"\" Open the transport session Args: N/A Returns: None Raises: N/A \"\"\" @abstractmethod async def read(self) -> bytes: \"\"\" Read data from the transport session Args: N/A Returns: None Raises: N/A \"\"\"","title":"Module scrapli.transport.base.async_transport"},{"location":"api_docs/transport/base/async_transport/#classes","text":"","title":"Classes"},{"location":"api_docs/transport/base/async_transport/#asynctransport","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 Helper class that provides a standard way to create an ABC using inheritance. Scrapli's transport base class Args: base_transport_args: base transport args dataclass Returns: None Raises: N/A Expand source code class AsyncTransport(BaseTransport, ABC): @abstractmethod async def open(self) -> None: \"\"\" Open the transport session Args: N/A Returns: None Raises: N/A \"\"\" @abstractmethod async def read(self) -> bytes: \"\"\" Read data from the transport session Args: N/A Returns: None Raises: N/A \"\"\"","title":"AsyncTransport"},{"location":"api_docs/transport/base/async_transport/#ancestors-in-mro","text":"scrapli.transport.base.base_transport.BaseTransport abc.ABC","title":"Ancestors (in MRO)"},{"location":"api_docs/transport/base/async_transport/#descendants","text":"scrapli.transport.plugins.asyncssh.transport.AsyncsshTransport scrapli.transport.plugins.asynctelnet.transport.AsynctelnetTransport","title":"Descendants"},{"location":"api_docs/transport/base/async_transport/#methods","text":"","title":"Methods"},{"location":"api_docs/transport/base/async_transport/#open","text":"open(self) \u2011> None 1 2 3 4 5 6 7 8 9 10 Open the transport session Args: N/A Returns: None Raises: N/A","title":"open"},{"location":"api_docs/transport/base/async_transport/#read","text":"read(self) \u2011> bytes 1 2 3 4 5 6 7 8 9 10 Read data from the transport session Args: N/A Returns: None Raises: N/A","title":"read"},{"location":"api_docs/transport/base/base_socket/","text":"window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting()) Module scrapli.transport.base.base_socket \u00b6 scrapli.transport.base.base_socket Expand source code \"\"\"scrapli.transport.base.base_socket\"\"\" import socket from typing import Optional, Set from scrapli.exceptions import ScrapliConnectionNotOpened from scrapli.logging import get_instance_logger class Socket: def __init__(self, host: str, port: int, timeout: float): \"\"\" Socket object Args: host: host to connect to port: port to connect to timeout: timeout in seconds Returns: None Raises: N/A \"\"\" self.logger = get_instance_logger(instance_name=\"scrapli.socket\", host=host, port=port) self.host = host self.port = port self.timeout = timeout self.sock: Optional[socket.socket] = None def __bool__(self) -> bool: \"\"\" Magic bool method for Socket Args: N/A Returns: bool: True/False if socket is alive or not Raises: N/A \"\"\" return self.isalive() def _connect(self, socket_address_families: Set[\"socket.AddressFamily\"]) -> None: \"\"\" Try to open socket to host using all possible address families It seems that very occasionally when resolving a hostname (i.e. localhost during functional tests against vrouter devices), a v6 address family will be the first af the socket getaddrinfo returns, in this case, because the qemu hostfwd is not listening on ::1, instead only listening on 127.0.0.1 the connection will fail. Presumably this is something that can happen in real life too... something gets resolved with a v6 address but is denying connections or just not listening on that ipv6 address. This little connect wrapper is intended to deal with these weird scenarios. Args: socket_address_families: set of address families available for the provided host really only should ever be v4 AND v6 if providing a hostname that resolves with both addresses, otherwise if you just provide a v4/v6 address it will just be a single address family for that type of address Returns: None Raises: ScrapliConnectionNotOpened: if socket refuses connection on all address families ScrapliConnectionNotOpened: if socket connection times out on all address families \"\"\" for address_family_index, address_family in enumerate(socket_address_families, start=1): self.sock = socket.socket(address_family, socket.SOCK_STREAM) self.sock.settimeout(self.timeout) try: self.sock.connect((self.host, self.port)) except ConnectionRefusedError as exc: msg = ( f\"connection refused trying to open socket to {self.host} on port {self.port} \" f\"for address family {address_family.name}\" ) self.logger.warning(msg) if address_family_index == len(socket_address_families): raise ScrapliConnectionNotOpened(msg) from exc except socket.timeout as exc: msg = ( f\"timed out trying to open socket to {self.host} on port {self.port} for \" f\"address family {address_family.name}\" ) self.logger.warning(msg) if address_family_index == len(socket_address_families): raise ScrapliConnectionNotOpened(msg) from exc else: return def open(self) -> None: \"\"\" Open underlying socket Args: N/A Returns: None Raises: ScrapliConnectionNotOpened: if cant fetch socket addr info \"\"\" self.logger.debug(f\"opening socket connection to '{self.host}' on port '{self.port}'\") socket_address_families = None try: sock_info = socket.getaddrinfo(self.host, self.port) if sock_info: # get all possible address families for the provided host/port # should only ever be two... one for v4 and one for v6... i think/hope?! :)? socket_address_families = {sock[0] for sock in sock_info} except socket.gaierror: pass if not socket_address_families: # this will likely need to be clearer just dont know what failure scenarios exist for # this yet... raise ScrapliConnectionNotOpened(\"failed to determine socket address family for host\") if not self.isalive(): self._connect(socket_address_families=socket_address_families) self.logger.debug( f\"opened socket connection to '{self.host}' on port '{self.port}' successfully\" ) def close(self) -> None: \"\"\" Close socket Args: N/A Returns: None Raises: N/A \"\"\" self.logger.debug(f\"closing socket connection to '{self.host}' on port '{self.port}'\") if self.isalive() and isinstance(self.sock, socket.socket): self.sock.close() self.logger.debug( f\"closed socket connection to '{self.host}' on port '{self.port}' successfully\" ) def isalive(self) -> bool: \"\"\" Check if socket is alive Args: N/A Returns: bool True/False if socket is alive Raises: N/A \"\"\" try: if isinstance(self.sock, socket.socket): self.sock.send(b\"\") return True except OSError: self.logger.debug(f\"Socket to host {self.host} is not alive\") return False return False Classes \u00b6 Socket \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 Socket object Args: host: host to connect to port: port to connect to timeout: timeout in seconds Returns: None Raises: N/A Expand source code class Socket: def __init__(self, host: str, port: int, timeout: float): \"\"\" Socket object Args: host: host to connect to port: port to connect to timeout: timeout in seconds Returns: None Raises: N/A \"\"\" self.logger = get_instance_logger(instance_name=\"scrapli.socket\", host=host, port=port) self.host = host self.port = port self.timeout = timeout self.sock: Optional[socket.socket] = None def __bool__(self) -> bool: \"\"\" Magic bool method for Socket Args: N/A Returns: bool: True/False if socket is alive or not Raises: N/A \"\"\" return self.isalive() def _connect(self, socket_address_families: Set[\"socket.AddressFamily\"]) -> None: \"\"\" Try to open socket to host using all possible address families It seems that very occasionally when resolving a hostname (i.e. localhost during functional tests against vrouter devices), a v6 address family will be the first af the socket getaddrinfo returns, in this case, because the qemu hostfwd is not listening on ::1, instead only listening on 127.0.0.1 the connection will fail. Presumably this is something that can happen in real life too... something gets resolved with a v6 address but is denying connections or just not listening on that ipv6 address. This little connect wrapper is intended to deal with these weird scenarios. Args: socket_address_families: set of address families available for the provided host really only should ever be v4 AND v6 if providing a hostname that resolves with both addresses, otherwise if you just provide a v4/v6 address it will just be a single address family for that type of address Returns: None Raises: ScrapliConnectionNotOpened: if socket refuses connection on all address families ScrapliConnectionNotOpened: if socket connection times out on all address families \"\"\" for address_family_index, address_family in enumerate(socket_address_families, start=1): self.sock = socket.socket(address_family, socket.SOCK_STREAM) self.sock.settimeout(self.timeout) try: self.sock.connect((self.host, self.port)) except ConnectionRefusedError as exc: msg = ( f\"connection refused trying to open socket to {self.host} on port {self.port} \" f\"for address family {address_family.name}\" ) self.logger.warning(msg) if address_family_index == len(socket_address_families): raise ScrapliConnectionNotOpened(msg) from exc except socket.timeout as exc: msg = ( f\"timed out trying to open socket to {self.host} on port {self.port} for \" f\"address family {address_family.name}\" ) self.logger.warning(msg) if address_family_index == len(socket_address_families): raise ScrapliConnectionNotOpened(msg) from exc else: return def open(self) -> None: \"\"\" Open underlying socket Args: N/A Returns: None Raises: ScrapliConnectionNotOpened: if cant fetch socket addr info \"\"\" self.logger.debug(f\"opening socket connection to '{self.host}' on port '{self.port}'\") socket_address_families = None try: sock_info = socket.getaddrinfo(self.host, self.port) if sock_info: # get all possible address families for the provided host/port # should only ever be two... one for v4 and one for v6... i think/hope?! :)? socket_address_families = {sock[0] for sock in sock_info} except socket.gaierror: pass if not socket_address_families: # this will likely need to be clearer just dont know what failure scenarios exist for # this yet... raise ScrapliConnectionNotOpened(\"failed to determine socket address family for host\") if not self.isalive(): self._connect(socket_address_families=socket_address_families) self.logger.debug( f\"opened socket connection to '{self.host}' on port '{self.port}' successfully\" ) def close(self) -> None: \"\"\" Close socket Args: N/A Returns: None Raises: N/A \"\"\" self.logger.debug(f\"closing socket connection to '{self.host}' on port '{self.port}'\") if self.isalive() and isinstance(self.sock, socket.socket): self.sock.close() self.logger.debug( f\"closed socket connection to '{self.host}' on port '{self.port}' successfully\" ) def isalive(self) -> bool: \"\"\" Check if socket is alive Args: N/A Returns: bool True/False if socket is alive Raises: N/A \"\"\" try: if isinstance(self.sock, socket.socket): self.sock.send(b\"\") return True except OSError: self.logger.debug(f\"Socket to host {self.host} is not alive\") return False return False Methods \u00b6 close \u00b6 close(self) \u2011> None 1 2 3 4 5 6 7 8 9 10 Close socket Args: N/A Returns: None Raises: N/A isalive \u00b6 isalive(self) \u2011> bool 1 2 3 4 5 6 7 8 9 10 Check if socket is alive Args: N/A Returns: bool True/False if socket is alive Raises: N/A open \u00b6 open(self) \u2011> None 1 2 3 4 5 6 7 8 9 10 Open underlying socket Args: N/A Returns: None Raises: ScrapliConnectionNotOpened: if cant fetch socket addr info","title":"Socket"},{"location":"api_docs/transport/base/base_socket/#module-scraplitransportbasebase_socket","text":"scrapli.transport.base.base_socket Expand source code \"\"\"scrapli.transport.base.base_socket\"\"\" import socket from typing import Optional, Set from scrapli.exceptions import ScrapliConnectionNotOpened from scrapli.logging import get_instance_logger class Socket: def __init__(self, host: str, port: int, timeout: float): \"\"\" Socket object Args: host: host to connect to port: port to connect to timeout: timeout in seconds Returns: None Raises: N/A \"\"\" self.logger = get_instance_logger(instance_name=\"scrapli.socket\", host=host, port=port) self.host = host self.port = port self.timeout = timeout self.sock: Optional[socket.socket] = None def __bool__(self) -> bool: \"\"\" Magic bool method for Socket Args: N/A Returns: bool: True/False if socket is alive or not Raises: N/A \"\"\" return self.isalive() def _connect(self, socket_address_families: Set[\"socket.AddressFamily\"]) -> None: \"\"\" Try to open socket to host using all possible address families It seems that very occasionally when resolving a hostname (i.e. localhost during functional tests against vrouter devices), a v6 address family will be the first af the socket getaddrinfo returns, in this case, because the qemu hostfwd is not listening on ::1, instead only listening on 127.0.0.1 the connection will fail. Presumably this is something that can happen in real life too... something gets resolved with a v6 address but is denying connections or just not listening on that ipv6 address. This little connect wrapper is intended to deal with these weird scenarios. Args: socket_address_families: set of address families available for the provided host really only should ever be v4 AND v6 if providing a hostname that resolves with both addresses, otherwise if you just provide a v4/v6 address it will just be a single address family for that type of address Returns: None Raises: ScrapliConnectionNotOpened: if socket refuses connection on all address families ScrapliConnectionNotOpened: if socket connection times out on all address families \"\"\" for address_family_index, address_family in enumerate(socket_address_families, start=1): self.sock = socket.socket(address_family, socket.SOCK_STREAM) self.sock.settimeout(self.timeout) try: self.sock.connect((self.host, self.port)) except ConnectionRefusedError as exc: msg = ( f\"connection refused trying to open socket to {self.host} on port {self.port} \" f\"for address family {address_family.name}\" ) self.logger.warning(msg) if address_family_index == len(socket_address_families): raise ScrapliConnectionNotOpened(msg) from exc except socket.timeout as exc: msg = ( f\"timed out trying to open socket to {self.host} on port {self.port} for \" f\"address family {address_family.name}\" ) self.logger.warning(msg) if address_family_index == len(socket_address_families): raise ScrapliConnectionNotOpened(msg) from exc else: return def open(self) -> None: \"\"\" Open underlying socket Args: N/A Returns: None Raises: ScrapliConnectionNotOpened: if cant fetch socket addr info \"\"\" self.logger.debug(f\"opening socket connection to '{self.host}' on port '{self.port}'\") socket_address_families = None try: sock_info = socket.getaddrinfo(self.host, self.port) if sock_info: # get all possible address families for the provided host/port # should only ever be two... one for v4 and one for v6... i think/hope?! :)? socket_address_families = {sock[0] for sock in sock_info} except socket.gaierror: pass if not socket_address_families: # this will likely need to be clearer just dont know what failure scenarios exist for # this yet... raise ScrapliConnectionNotOpened(\"failed to determine socket address family for host\") if not self.isalive(): self._connect(socket_address_families=socket_address_families) self.logger.debug( f\"opened socket connection to '{self.host}' on port '{self.port}' successfully\" ) def close(self) -> None: \"\"\" Close socket Args: N/A Returns: None Raises: N/A \"\"\" self.logger.debug(f\"closing socket connection to '{self.host}' on port '{self.port}'\") if self.isalive() and isinstance(self.sock, socket.socket): self.sock.close() self.logger.debug( f\"closed socket connection to '{self.host}' on port '{self.port}' successfully\" ) def isalive(self) -> bool: \"\"\" Check if socket is alive Args: N/A Returns: bool True/False if socket is alive Raises: N/A \"\"\" try: if isinstance(self.sock, socket.socket): self.sock.send(b\"\") return True except OSError: self.logger.debug(f\"Socket to host {self.host} is not alive\") return False return False","title":"Module scrapli.transport.base.base_socket"},{"location":"api_docs/transport/base/base_socket/#classes","text":"","title":"Classes"},{"location":"api_docs/transport/base/base_socket/#socket","text":"1 2 3 4 5 6 7 8 9 10 11 12 Socket object Args: host: host to connect to port: port to connect to timeout: timeout in seconds Returns: None Raises: N/A Expand source code class Socket: def __init__(self, host: str, port: int, timeout: float): \"\"\" Socket object Args: host: host to connect to port: port to connect to timeout: timeout in seconds Returns: None Raises: N/A \"\"\" self.logger = get_instance_logger(instance_name=\"scrapli.socket\", host=host, port=port) self.host = host self.port = port self.timeout = timeout self.sock: Optional[socket.socket] = None def __bool__(self) -> bool: \"\"\" Magic bool method for Socket Args: N/A Returns: bool: True/False if socket is alive or not Raises: N/A \"\"\" return self.isalive() def _connect(self, socket_address_families: Set[\"socket.AddressFamily\"]) -> None: \"\"\" Try to open socket to host using all possible address families It seems that very occasionally when resolving a hostname (i.e. localhost during functional tests against vrouter devices), a v6 address family will be the first af the socket getaddrinfo returns, in this case, because the qemu hostfwd is not listening on ::1, instead only listening on 127.0.0.1 the connection will fail. Presumably this is something that can happen in real life too... something gets resolved with a v6 address but is denying connections or just not listening on that ipv6 address. This little connect wrapper is intended to deal with these weird scenarios. Args: socket_address_families: set of address families available for the provided host really only should ever be v4 AND v6 if providing a hostname that resolves with both addresses, otherwise if you just provide a v4/v6 address it will just be a single address family for that type of address Returns: None Raises: ScrapliConnectionNotOpened: if socket refuses connection on all address families ScrapliConnectionNotOpened: if socket connection times out on all address families \"\"\" for address_family_index, address_family in enumerate(socket_address_families, start=1): self.sock = socket.socket(address_family, socket.SOCK_STREAM) self.sock.settimeout(self.timeout) try: self.sock.connect((self.host, self.port)) except ConnectionRefusedError as exc: msg = ( f\"connection refused trying to open socket to {self.host} on port {self.port} \" f\"for address family {address_family.name}\" ) self.logger.warning(msg) if address_family_index == len(socket_address_families): raise ScrapliConnectionNotOpened(msg) from exc except socket.timeout as exc: msg = ( f\"timed out trying to open socket to {self.host} on port {self.port} for \" f\"address family {address_family.name}\" ) self.logger.warning(msg) if address_family_index == len(socket_address_families): raise ScrapliConnectionNotOpened(msg) from exc else: return def open(self) -> None: \"\"\" Open underlying socket Args: N/A Returns: None Raises: ScrapliConnectionNotOpened: if cant fetch socket addr info \"\"\" self.logger.debug(f\"opening socket connection to '{self.host}' on port '{self.port}'\") socket_address_families = None try: sock_info = socket.getaddrinfo(self.host, self.port) if sock_info: # get all possible address families for the provided host/port # should only ever be two... one for v4 and one for v6... i think/hope?! :)? socket_address_families = {sock[0] for sock in sock_info} except socket.gaierror: pass if not socket_address_families: # this will likely need to be clearer just dont know what failure scenarios exist for # this yet... raise ScrapliConnectionNotOpened(\"failed to determine socket address family for host\") if not self.isalive(): self._connect(socket_address_families=socket_address_families) self.logger.debug( f\"opened socket connection to '{self.host}' on port '{self.port}' successfully\" ) def close(self) -> None: \"\"\" Close socket Args: N/A Returns: None Raises: N/A \"\"\" self.logger.debug(f\"closing socket connection to '{self.host}' on port '{self.port}'\") if self.isalive() and isinstance(self.sock, socket.socket): self.sock.close() self.logger.debug( f\"closed socket connection to '{self.host}' on port '{self.port}' successfully\" ) def isalive(self) -> bool: \"\"\" Check if socket is alive Args: N/A Returns: bool True/False if socket is alive Raises: N/A \"\"\" try: if isinstance(self.sock, socket.socket): self.sock.send(b\"\") return True except OSError: self.logger.debug(f\"Socket to host {self.host} is not alive\") return False return False","title":"Socket"},{"location":"api_docs/transport/base/base_socket/#methods","text":"","title":"Methods"},{"location":"api_docs/transport/base/base_socket/#close","text":"close(self) \u2011> None 1 2 3 4 5 6 7 8 9 10 Close socket Args: N/A Returns: None Raises: N/A","title":"close"},{"location":"api_docs/transport/base/base_socket/#isalive","text":"isalive(self) \u2011> bool 1 2 3 4 5 6 7 8 9 10 Check if socket is alive Args: N/A Returns: bool True/False if socket is alive Raises: N/A","title":"isalive"},{"location":"api_docs/transport/base/base_socket/#open","text":"open(self) \u2011> None 1 2 3 4 5 6 7 8 9 10 Open underlying socket Args: N/A Returns: None Raises: ScrapliConnectionNotOpened: if cant fetch socket addr info","title":"open"},{"location":"api_docs/transport/base/base_transport/","text":"window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting()) Module scrapli.transport.base.base_transport \u00b6 scrapli.transport.base_transport Expand source code \"\"\"scrapli.transport.base_transport\"\"\" from abc import ABC, abstractmethod from dataclasses import dataclass from typing import Any, Dict from scrapli.logging import get_instance_logger @dataclass() class BaseTransportArgs: transport_options: Dict[str, Any] host: str port: int = 22 timeout_socket: float = 10.0 timeout_transport: float = 30.0 logging_uid: str = \"\" @dataclass() class BasePluginTransportArgs: pass class BaseTransport(ABC): def __init__(self, base_transport_args: BaseTransportArgs) -> None: \"\"\" Scrapli's transport base class Args: base_transport_args: base transport args dataclass Returns: None Raises: N/A \"\"\" self._base_transport_args = base_transport_args self.logger = get_instance_logger( instance_name=\"scrapli.transport\", host=self._base_transport_args.host, port=self._base_transport_args.port, uid=self._base_transport_args.logging_uid, ) @abstractmethod def close(self) -> None: \"\"\" Close the transport session Args: N/A Returns: None Raises: N/A \"\"\" @abstractmethod def write(self, channel_input: bytes) -> None: \"\"\" Write bytes into the transport session Args: channel_input: bytes to write to transport session Returns: None Raises: N/A \"\"\" @abstractmethod def isalive(self) -> bool: \"\"\" Check if transport is alive Args: N/A Returns: bool: True/False if transport is alive Raises: N/A \"\"\" def _pre_open_closing_log(self, closing: bool = False) -> None: \"\"\" Emit \"pre open\" log message for consistency between transports Args: closing: bool indicating if message is for closing not opening Returns: None Raises: N/A \"\"\" operation = \"closing\" if closing else \"opening\" self.logger.debug( f\"{operation} transport connection to '{self._base_transport_args.host}' on port \" f\"'{self._base_transport_args.port}'\" ) def _post_open_closing_log(self, closing: bool = False) -> None: \"\"\" Emit \"post open\" log message for consistency between transports Args: closing: bool indicating if message is for closing not opening Returns: None Raises: N/A \"\"\" operation = \"closed\" if closing else \"opened\" self.logger.debug( f\"transport connection to '{self._base_transport_args.host}' on port \" f\"'{self._base_transport_args.port}' {operation} successfully\" ) Classes \u00b6 BasePluginTransportArgs \u00b6 1 BasePluginTransportArgs() Expand source code @dataclass() class BasePluginTransportArgs: pass Descendants \u00b6 scrapli.transport.plugins.asyncssh.transport.PluginTransportArgs scrapli.transport.plugins.asynctelnet.transport.PluginTransportArgs scrapli.transport.plugins.paramiko.transport.PluginTransportArgs scrapli.transport.plugins.ssh2.transport.PluginTransportArgs scrapli.transport.plugins.system.transport.PluginTransportArgs scrapli.transport.plugins.telnet.transport.PluginTransportArgs BaseTransport \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 Helper class that provides a standard way to create an ABC using inheritance. Scrapli's transport base class Args: base_transport_args: base transport args dataclass Returns: None Raises: N/A Expand source code class BaseTransport(ABC): def __init__(self, base_transport_args: BaseTransportArgs) -> None: \"\"\" Scrapli's transport base class Args: base_transport_args: base transport args dataclass Returns: None Raises: N/A \"\"\" self._base_transport_args = base_transport_args self.logger = get_instance_logger( instance_name=\"scrapli.transport\", host=self._base_transport_args.host, port=self._base_transport_args.port, uid=self._base_transport_args.logging_uid, ) @abstractmethod def close(self) -> None: \"\"\" Close the transport session Args: N/A Returns: None Raises: N/A \"\"\" @abstractmethod def write(self, channel_input: bytes) -> None: \"\"\" Write bytes into the transport session Args: channel_input: bytes to write to transport session Returns: None Raises: N/A \"\"\" @abstractmethod def isalive(self) -> bool: \"\"\" Check if transport is alive Args: N/A Returns: bool: True/False if transport is alive Raises: N/A \"\"\" def _pre_open_closing_log(self, closing: bool = False) -> None: \"\"\" Emit \"pre open\" log message for consistency between transports Args: closing: bool indicating if message is for closing not opening Returns: None Raises: N/A \"\"\" operation = \"closing\" if closing else \"opening\" self.logger.debug( f\"{operation} transport connection to '{self._base_transport_args.host}' on port \" f\"'{self._base_transport_args.port}'\" ) def _post_open_closing_log(self, closing: bool = False) -> None: \"\"\" Emit \"post open\" log message for consistency between transports Args: closing: bool indicating if message is for closing not opening Returns: None Raises: N/A \"\"\" operation = \"closed\" if closing else \"opened\" self.logger.debug( f\"transport connection to '{self._base_transport_args.host}' on port \" f\"'{self._base_transport_args.port}' {operation} successfully\" ) Ancestors (in MRO) \u00b6 abc.ABC Descendants \u00b6 scrapli.transport.base.async_transport.AsyncTransport scrapli.transport.base.sync_transport.Transport Methods \u00b6 close \u00b6 close(self) \u2011> None 1 2 3 4 5 6 7 8 9 10 Close the transport session Args: N/A Returns: None Raises: N/A isalive \u00b6 isalive(self) \u2011> bool 1 2 3 4 5 6 7 8 9 10 Check if transport is alive Args: N/A Returns: bool: True/False if transport is alive Raises: N/A write \u00b6 write(self, channel_input: bytes) \u2011> None 1 2 3 4 5 6 7 8 9 10 Write bytes into the transport session Args: channel_input: bytes to write to transport session Returns: None Raises: N/A BaseTransportArgs \u00b6 1 BaseTransportArgs(transport_options: Dict[str, Any], host: str, port: int = 22, timeout_socket: float = 10.0, timeout_transport: float = 30.0, logging_uid: str = '') Expand source code @dataclass() class BaseTransportArgs: transport_options: Dict[str, Any] host: str port: int = 22 timeout_socket: float = 10.0 timeout_transport: float = 30.0 logging_uid: str = \"\" Class variables \u00b6 host: str logging_uid: str port: int timeout_socket: float timeout_transport: float transport_options: Dict[str, Any]","title":"Base Transport"},{"location":"api_docs/transport/base/base_transport/#module-scraplitransportbasebase_transport","text":"scrapli.transport.base_transport Expand source code \"\"\"scrapli.transport.base_transport\"\"\" from abc import ABC, abstractmethod from dataclasses import dataclass from typing import Any, Dict from scrapli.logging import get_instance_logger @dataclass() class BaseTransportArgs: transport_options: Dict[str, Any] host: str port: int = 22 timeout_socket: float = 10.0 timeout_transport: float = 30.0 logging_uid: str = \"\" @dataclass() class BasePluginTransportArgs: pass class BaseTransport(ABC): def __init__(self, base_transport_args: BaseTransportArgs) -> None: \"\"\" Scrapli's transport base class Args: base_transport_args: base transport args dataclass Returns: None Raises: N/A \"\"\" self._base_transport_args = base_transport_args self.logger = get_instance_logger( instance_name=\"scrapli.transport\", host=self._base_transport_args.host, port=self._base_transport_args.port, uid=self._base_transport_args.logging_uid, ) @abstractmethod def close(self) -> None: \"\"\" Close the transport session Args: N/A Returns: None Raises: N/A \"\"\" @abstractmethod def write(self, channel_input: bytes) -> None: \"\"\" Write bytes into the transport session Args: channel_input: bytes to write to transport session Returns: None Raises: N/A \"\"\" @abstractmethod def isalive(self) -> bool: \"\"\" Check if transport is alive Args: N/A Returns: bool: True/False if transport is alive Raises: N/A \"\"\" def _pre_open_closing_log(self, closing: bool = False) -> None: \"\"\" Emit \"pre open\" log message for consistency between transports Args: closing: bool indicating if message is for closing not opening Returns: None Raises: N/A \"\"\" operation = \"closing\" if closing else \"opening\" self.logger.debug( f\"{operation} transport connection to '{self._base_transport_args.host}' on port \" f\"'{self._base_transport_args.port}'\" ) def _post_open_closing_log(self, closing: bool = False) -> None: \"\"\" Emit \"post open\" log message for consistency between transports Args: closing: bool indicating if message is for closing not opening Returns: None Raises: N/A \"\"\" operation = \"closed\" if closing else \"opened\" self.logger.debug( f\"transport connection to '{self._base_transport_args.host}' on port \" f\"'{self._base_transport_args.port}' {operation} successfully\" )","title":"Module scrapli.transport.base.base_transport"},{"location":"api_docs/transport/base/base_transport/#classes","text":"","title":"Classes"},{"location":"api_docs/transport/base/base_transport/#baseplugintransportargs","text":"1 BasePluginTransportArgs() Expand source code @dataclass() class BasePluginTransportArgs: pass","title":"BasePluginTransportArgs"},{"location":"api_docs/transport/base/base_transport/#descendants","text":"scrapli.transport.plugins.asyncssh.transport.PluginTransportArgs scrapli.transport.plugins.asynctelnet.transport.PluginTransportArgs scrapli.transport.plugins.paramiko.transport.PluginTransportArgs scrapli.transport.plugins.ssh2.transport.PluginTransportArgs scrapli.transport.plugins.system.transport.PluginTransportArgs scrapli.transport.plugins.telnet.transport.PluginTransportArgs","title":"Descendants"},{"location":"api_docs/transport/base/base_transport/#basetransport","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 Helper class that provides a standard way to create an ABC using inheritance. Scrapli's transport base class Args: base_transport_args: base transport args dataclass Returns: None Raises: N/A Expand source code class BaseTransport(ABC): def __init__(self, base_transport_args: BaseTransportArgs) -> None: \"\"\" Scrapli's transport base class Args: base_transport_args: base transport args dataclass Returns: None Raises: N/A \"\"\" self._base_transport_args = base_transport_args self.logger = get_instance_logger( instance_name=\"scrapli.transport\", host=self._base_transport_args.host, port=self._base_transport_args.port, uid=self._base_transport_args.logging_uid, ) @abstractmethod def close(self) -> None: \"\"\" Close the transport session Args: N/A Returns: None Raises: N/A \"\"\" @abstractmethod def write(self, channel_input: bytes) -> None: \"\"\" Write bytes into the transport session Args: channel_input: bytes to write to transport session Returns: None Raises: N/A \"\"\" @abstractmethod def isalive(self) -> bool: \"\"\" Check if transport is alive Args: N/A Returns: bool: True/False if transport is alive Raises: N/A \"\"\" def _pre_open_closing_log(self, closing: bool = False) -> None: \"\"\" Emit \"pre open\" log message for consistency between transports Args: closing: bool indicating if message is for closing not opening Returns: None Raises: N/A \"\"\" operation = \"closing\" if closing else \"opening\" self.logger.debug( f\"{operation} transport connection to '{self._base_transport_args.host}' on port \" f\"'{self._base_transport_args.port}'\" ) def _post_open_closing_log(self, closing: bool = False) -> None: \"\"\" Emit \"post open\" log message for consistency between transports Args: closing: bool indicating if message is for closing not opening Returns: None Raises: N/A \"\"\" operation = \"closed\" if closing else \"opened\" self.logger.debug( f\"transport connection to '{self._base_transport_args.host}' on port \" f\"'{self._base_transport_args.port}' {operation} successfully\" )","title":"BaseTransport"},{"location":"api_docs/transport/base/base_transport/#ancestors-in-mro","text":"abc.ABC","title":"Ancestors (in MRO)"},{"location":"api_docs/transport/base/base_transport/#descendants_1","text":"scrapli.transport.base.async_transport.AsyncTransport scrapli.transport.base.sync_transport.Transport","title":"Descendants"},{"location":"api_docs/transport/base/base_transport/#methods","text":"","title":"Methods"},{"location":"api_docs/transport/base/base_transport/#close","text":"close(self) \u2011> None 1 2 3 4 5 6 7 8 9 10 Close the transport session Args: N/A Returns: None Raises: N/A","title":"close"},{"location":"api_docs/transport/base/base_transport/#isalive","text":"isalive(self) \u2011> bool 1 2 3 4 5 6 7 8 9 10 Check if transport is alive Args: N/A Returns: bool: True/False if transport is alive Raises: N/A","title":"isalive"},{"location":"api_docs/transport/base/base_transport/#write","text":"write(self, channel_input: bytes) \u2011> None 1 2 3 4 5 6 7 8 9 10 Write bytes into the transport session Args: channel_input: bytes to write to transport session Returns: None Raises: N/A","title":"write"},{"location":"api_docs/transport/base/base_transport/#basetransportargs","text":"1 BaseTransportArgs(transport_options: Dict[str, Any], host: str, port: int = 22, timeout_socket: float = 10.0, timeout_transport: float = 30.0, logging_uid: str = '') Expand source code @dataclass() class BaseTransportArgs: transport_options: Dict[str, Any] host: str port: int = 22 timeout_socket: float = 10.0 timeout_transport: float = 30.0 logging_uid: str = \"\"","title":"BaseTransportArgs"},{"location":"api_docs/transport/base/base_transport/#class-variables","text":"host: str logging_uid: str port: int timeout_socket: float timeout_transport: float transport_options: Dict[str, Any]","title":"Class variables"},{"location":"api_docs/transport/base/sync_transport/","text":"window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting()) Module scrapli.transport.base.sync_transport \u00b6 scrapli.transport.base_transport Expand source code \"\"\"scrapli.transport.base_transport\"\"\" from abc import ABC, abstractmethod from scrapli.transport.base.base_transport import BaseTransport class Transport(BaseTransport, ABC): @abstractmethod def open(self) -> None: \"\"\" Open the transport session Args: N/A Returns: None Raises: N/A \"\"\" @abstractmethod def read(self) -> bytes: \"\"\" Read data from the transport session Args: N/A Returns: None Raises: N/A \"\"\" Classes \u00b6 Transport \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 Helper class that provides a standard way to create an ABC using inheritance. Scrapli's transport base class Args: base_transport_args: base transport args dataclass Returns: None Raises: N/A Expand source code class Transport(BaseTransport, ABC): @abstractmethod def open(self) -> None: \"\"\" Open the transport session Args: N/A Returns: None Raises: N/A \"\"\" @abstractmethod def read(self) -> bytes: \"\"\" Read data from the transport session Args: N/A Returns: None Raises: N/A \"\"\" Ancestors (in MRO) \u00b6 scrapli.transport.base.base_transport.BaseTransport abc.ABC Descendants \u00b6 scrapli.transport.plugins.paramiko.transport.ParamikoTransport scrapli.transport.plugins.ssh2.transport.Ssh2Transport scrapli.transport.plugins.system.transport.SystemTransport scrapli.transport.plugins.telnet.transport.TelnetTransport Methods \u00b6 open \u00b6 open(self) \u2011> None 1 2 3 4 5 6 7 8 9 10 Open the transport session Args: N/A Returns: None Raises: N/A read \u00b6 read(self) \u2011> bytes 1 2 3 4 5 6 7 8 9 10 Read data from the transport session Args: N/A Returns: None Raises: N/A","title":"Sync Transport"},{"location":"api_docs/transport/base/sync_transport/#module-scraplitransportbasesync_transport","text":"scrapli.transport.base_transport Expand source code \"\"\"scrapli.transport.base_transport\"\"\" from abc import ABC, abstractmethod from scrapli.transport.base.base_transport import BaseTransport class Transport(BaseTransport, ABC): @abstractmethod def open(self) -> None: \"\"\" Open the transport session Args: N/A Returns: None Raises: N/A \"\"\" @abstractmethod def read(self) -> bytes: \"\"\" Read data from the transport session Args: N/A Returns: None Raises: N/A \"\"\"","title":"Module scrapli.transport.base.sync_transport"},{"location":"api_docs/transport/base/sync_transport/#classes","text":"","title":"Classes"},{"location":"api_docs/transport/base/sync_transport/#transport","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 Helper class that provides a standard way to create an ABC using inheritance. Scrapli's transport base class Args: base_transport_args: base transport args dataclass Returns: None Raises: N/A Expand source code class Transport(BaseTransport, ABC): @abstractmethod def open(self) -> None: \"\"\" Open the transport session Args: N/A Returns: None Raises: N/A \"\"\" @abstractmethod def read(self) -> bytes: \"\"\" Read data from the transport session Args: N/A Returns: None Raises: N/A \"\"\"","title":"Transport"},{"location":"api_docs/transport/base/sync_transport/#ancestors-in-mro","text":"scrapli.transport.base.base_transport.BaseTransport abc.ABC","title":"Ancestors (in MRO)"},{"location":"api_docs/transport/base/sync_transport/#descendants","text":"scrapli.transport.plugins.paramiko.transport.ParamikoTransport scrapli.transport.plugins.ssh2.transport.Ssh2Transport scrapli.transport.plugins.system.transport.SystemTransport scrapli.transport.plugins.telnet.transport.TelnetTransport","title":"Descendants"},{"location":"api_docs/transport/base/sync_transport/#methods","text":"","title":"Methods"},{"location":"api_docs/transport/base/sync_transport/#open","text":"open(self) \u2011> None 1 2 3 4 5 6 7 8 9 10 Open the transport session Args: N/A Returns: None Raises: N/A","title":"open"},{"location":"api_docs/transport/base/sync_transport/#read","text":"read(self) \u2011> bytes 1 2 3 4 5 6 7 8 9 10 Read data from the transport session Args: N/A Returns: None Raises: N/A","title":"read"},{"location":"api_docs/transport/plugins/asyncssh/","text":"window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting()) Module scrapli.transport.plugins.asyncssh.transport \u00b6 scrapli.transport.plugins.asyncssh.transport Expand source code \"\"\"scrapli.transport.plugins.asyncssh.transport\"\"\" import asyncio from dataclasses import dataclass from typing import Any, Optional from asyncssh.connection import SSHClientConnection, connect from asyncssh.misc import ConnectionLost, PermissionDenied from asyncssh.stream import SSHReader, SSHWriter from scrapli.decorators import timeout_wrapper from scrapli.exceptions import ( ScrapliAuthenticationFailed, ScrapliConnectionError, ScrapliConnectionNotOpened, ) from scrapli.ssh_config import SSHKnownHosts from scrapli.transport.base import AsyncTransport, BasePluginTransportArgs, BaseTransportArgs @dataclass() class PluginTransportArgs(BasePluginTransportArgs): auth_username: str auth_password: str = \"\" auth_private_key: str = \"\" auth_strict_key: bool = True ssh_config_file: str = \"\" ssh_known_hosts_file: str = \"\" class AsyncsshTransport(AsyncTransport): def __init__( self, base_transport_args: BaseTransportArgs, plugin_transport_args: PluginTransportArgs ) -> None: \"\"\" Asyncssh transport plugin. Important note: some ssh servers may refuse connections if too many ssh host key algorithms are passed to it during the connection opening -- Asyncssh sends a bunch by default! If you encounter this issue, you can simply update your SSH config file to set a smaller (or one) number of ssh host key algorithms to work around this like so: 1 2 Host * HostKeyAlgorithms ssh-rsa Thank you to @davaeron [https://github.com/davaeron] for reporting this in #173, see also asyncssh #323 here: https://github.com/ronf/asyncssh/issues/323. This transport supports some additional `transport_options` to control behavior -- `asyncssh` is a dictionary that contains options that are passed directly to asyncssh during connection creation, you can find the SSH Client options of asyncssh here: https://asyncssh.readthedocs.io/en/latest/api.html#sshclientconnectionoptions. Below is an example of passing in options to modify kex and encryption algorithms 1 2 3 4 5 6 7 8 9 10 11 12 device = { \"host\": \"localhost\", \"transport_options\": { \"asyncssh\": { \"kex_algs\": [\"diffie-hellman-group14-sha1\", \"diffie-hellman-group1-sha1\"], \"encryption_algs\": [\"aes256-cbc\", \"aes192-cbc\", \"aes256-ctr\", \"aes192-ctr\"], } }, \"platform\": \"cisco_iosxe\" } conn = Scrapli(**device) Args: base_transport_args: scrapli base transport plugin arguments plugin_transport_args: asyncssh ssh specific transport plugin arguments Returns: N/A Raises: N/A \"\"\" super().__init__(base_transport_args=base_transport_args) self.plugin_transport_args = plugin_transport_args self.session: Optional[SSHClientConnection] = None self.stdout: Optional[SSHReader[Any]] = None self.stdin: Optional[SSHWriter[Any]] = None def _verify_key(self) -> None: \"\"\" Verify target host public key, raise exception if invalid/unknown Args: N/A Returns: None Raises: ScrapliAuthenticationFailed: if host is not in known hosts \"\"\" known_hosts = SSHKnownHosts(self.plugin_transport_args.ssh_known_hosts_file) known_host_public_key = known_hosts.lookup(self._base_transport_args.host) if not known_host_public_key: raise ScrapliAuthenticationFailed( f\"{self._base_transport_args.host} not in known_hosts!\" ) def _verify_key_value(self) -> None: \"\"\" Verify target host public key, raise exception if invalid/unknown Args: N/A Returns: None Raises: ScrapliConnectionNotOpened: if session is unopened/None ScrapliAuthenticationFailed: if host is in known hosts but public key does not match or cannot glean remote server key from session. \"\"\" if not self.session: raise ScrapliConnectionNotOpened known_hosts = SSHKnownHosts(self.plugin_transport_args.ssh_known_hosts_file) known_host_public_key = known_hosts.lookup(self._base_transport_args.host) remote_server_key = self.session.get_server_host_key() if remote_server_key is None: raise ScrapliAuthenticationFailed( f\"failed gleaning remote server ssh key for host {self._base_transport_args.host}\" ) remote_public_key = remote_server_key.export_public_key().split()[1].decode() if known_host_public_key[\"public_key\"] != remote_public_key: raise ScrapliAuthenticationFailed( f\"{self._base_transport_args.host} in known_hosts but public key does not match!\" ) async def open(self) -> None: self._pre_open_closing_log(closing=False) if self.plugin_transport_args.auth_strict_key: self.logger.debug( f\"Attempting to validate {self._base_transport_args.host} public key is in known \" f\"hosts\" ) self._verify_key() # we already fetched host/port/user from the user input and/or the ssh config file, so we # want to use those explicitly. likewise we pass config file we already found. set known # hosts and agent to None so we can not have an agent and deal w/ known hosts ourselves common_args = { \"host\": self._base_transport_args.host, \"port\": self._base_transport_args.port, \"username\": self.plugin_transport_args.auth_username, \"known_hosts\": None, \"agent_path\": None, \"config\": self.plugin_transport_args.ssh_config_file, } # Allow passing `transport_options` to asyncssh common_args.update(self._base_transport_args.transport_options.get(\"asyncssh\", {})) try: self.session = await asyncio.wait_for( connect( client_keys=self.plugin_transport_args.auth_private_key, password=self.plugin_transport_args.auth_password, preferred_auth=( \"publickey\", \"keyboard-interactive\", \"password\", ), **common_args, ), timeout=self._base_transport_args.timeout_socket, ) except PermissionDenied as exc: msg = \"all authentication methods failed\" self.logger.critical(msg) raise ScrapliAuthenticationFailed(msg) from exc except asyncio.TimeoutError as exc: msg = \"timed out opening connection to device\" self.logger.critical(msg) raise ScrapliAuthenticationFailed(msg) from exc if not self.session: raise ScrapliConnectionNotOpened if self.plugin_transport_args.auth_strict_key: self.logger.debug( f\"Attempting to validate {self._base_transport_args.host} public key is in known \" f\"hosts and is valid\" ) self._verify_key_value() self.stdin, self.stdout, _ = await self.session.open_session( term_type=\"xterm\", encoding=None ) self._post_open_closing_log(closing=False) def close(self) -> None: self._pre_open_closing_log(closing=True) if self.session: try: self.session.close() except BrokenPipeError: # it seems it is possible for the connection transport is_closing() to be true # already in some cases... since we are closing the connection anyway we will just # ignore this note that this seemed to only happen in github actions on # ubuntu-latest w/ py3.8... pass # always reset session/stdin/stdout back to None if we are closing! self.session = None self.stdin = None self.stdout = None self._post_open_closing_log(closing=True) def isalive(self) -> bool: if not self.session: return False # this may need to be revisited in the future, but this seems to be a good check for # aliveness try: if ( self.session._auth_complete # pylint: disable=W0212 and self.session._transport is not None # pylint: disable=W0212 and self.session._transport.is_closing() is False # pylint: disable=W0212 ): return True except AttributeError: pass return False @timeout_wrapper async def read(self) -> bytes: if not self.stdout: raise ScrapliConnectionNotOpened try: buf: bytes = await self.stdout.read(65535) except ConnectionLost as exc: msg = ( \"encountered EOF reading from transport; typically means the device closed the \" \"connection\" ) self.logger.critical(msg) raise ScrapliConnectionError(msg) from exc return buf def write(self, channel_input: bytes) -> None: if not self.stdin: raise ScrapliConnectionNotOpened self.stdin.write(channel_input) Classes \u00b6 AsyncsshTransport \u00b6 1 2 3 4 5 6 7 8 9 Helper class that provides a standard way to create an ABC using inheritance. Asyncssh transport plugin. Important note: some ssh servers may refuse connections if too many ssh host key algorithms are passed to it during the connection opening -- Asyncssh sends a bunch by default! If you encounter this issue, you can simply update your SSH config file to set a smaller (or one) number of ssh host key algorithms to work around this like so: Host * HostKeyAlgorithms ssh-rsa 1 2 3 4 5 6 7 8 Thank you to @davaeron [https://github.com/davaeron] for reporting this in #173, see also asyncssh #323 here: https://github.com/ronf/asyncssh/issues/323. This transport supports some additional `transport_options` to control behavior -- `asyncssh` is a dictionary that contains options that are passed directly to asyncssh during connection creation, you can find the SSH Client options of asyncssh here: https://asyncssh.readthedocs.io/en/latest/api.html#sshclientconnectionoptions. Below is an example of passing in options to modify kex and encryption algorithms device = { \"host\": \"localhost\", \"transport_options\": { \"asyncssh\": { \"kex_algs\": [\"diffie-hellman-group14-sha1\", \"diffie-hellman-group1-sha1\"], \"encryption_algs\": [\"aes256-cbc\", \"aes192-cbc\", \"aes256-ctr\", \"aes192-ctr\"], } }, \"platform\": \"cisco_iosxe\" } conn = Scrapli(**device) 1 2 3 4 5 6 7 8 9 Args: base_transport_args: scrapli base transport plugin arguments plugin_transport_args: asyncssh ssh specific transport plugin arguments Returns: N/A Raises: N/A Expand source code class AsyncsshTransport(AsyncTransport): def __init__( self, base_transport_args: BaseTransportArgs, plugin_transport_args: PluginTransportArgs ) -> None: \"\"\" Asyncssh transport plugin. Important note: some ssh servers may refuse connections if too many ssh host key algorithms are passed to it during the connection opening -- Asyncssh sends a bunch by default! If you encounter this issue, you can simply update your SSH config file to set a smaller (or one) number of ssh host key algorithms to work around this like so: 1 2 Host * HostKeyAlgorithms ssh-rsa Thank you to @davaeron [https://github.com/davaeron] for reporting this in #173, see also asyncssh #323 here: https://github.com/ronf/asyncssh/issues/323. This transport supports some additional `transport_options` to control behavior -- `asyncssh` is a dictionary that contains options that are passed directly to asyncssh during connection creation, you can find the SSH Client options of asyncssh here: https://asyncssh.readthedocs.io/en/latest/api.html#sshclientconnectionoptions. Below is an example of passing in options to modify kex and encryption algorithms 1 2 3 4 5 6 7 8 9 10 11 12 device = { \"host\": \"localhost\", \"transport_options\": { \"asyncssh\": { \"kex_algs\": [\"diffie-hellman-group14-sha1\", \"diffie-hellman-group1-sha1\"], \"encryption_algs\": [\"aes256-cbc\", \"aes192-cbc\", \"aes256-ctr\", \"aes192-ctr\"], } }, \"platform\": \"cisco_iosxe\" } conn = Scrapli(**device) Args: base_transport_args: scrapli base transport plugin arguments plugin_transport_args: asyncssh ssh specific transport plugin arguments Returns: N/A Raises: N/A \"\"\" super().__init__(base_transport_args=base_transport_args) self.plugin_transport_args = plugin_transport_args self.session: Optional[SSHClientConnection] = None self.stdout: Optional[SSHReader[Any]] = None self.stdin: Optional[SSHWriter[Any]] = None def _verify_key(self) -> None: \"\"\" Verify target host public key, raise exception if invalid/unknown Args: N/A Returns: None Raises: ScrapliAuthenticationFailed: if host is not in known hosts \"\"\" known_hosts = SSHKnownHosts(self.plugin_transport_args.ssh_known_hosts_file) known_host_public_key = known_hosts.lookup(self._base_transport_args.host) if not known_host_public_key: raise ScrapliAuthenticationFailed( f\"{self._base_transport_args.host} not in known_hosts!\" ) def _verify_key_value(self) -> None: \"\"\" Verify target host public key, raise exception if invalid/unknown Args: N/A Returns: None Raises: ScrapliConnectionNotOpened: if session is unopened/None ScrapliAuthenticationFailed: if host is in known hosts but public key does not match or cannot glean remote server key from session. \"\"\" if not self.session: raise ScrapliConnectionNotOpened known_hosts = SSHKnownHosts(self.plugin_transport_args.ssh_known_hosts_file) known_host_public_key = known_hosts.lookup(self._base_transport_args.host) remote_server_key = self.session.get_server_host_key() if remote_server_key is None: raise ScrapliAuthenticationFailed( f\"failed gleaning remote server ssh key for host {self._base_transport_args.host}\" ) remote_public_key = remote_server_key.export_public_key().split()[1].decode() if known_host_public_key[\"public_key\"] != remote_public_key: raise ScrapliAuthenticationFailed( f\"{self._base_transport_args.host} in known_hosts but public key does not match!\" ) async def open(self) -> None: self._pre_open_closing_log(closing=False) if self.plugin_transport_args.auth_strict_key: self.logger.debug( f\"Attempting to validate {self._base_transport_args.host} public key is in known \" f\"hosts\" ) self._verify_key() # we already fetched host/port/user from the user input and/or the ssh config file, so we # want to use those explicitly. likewise we pass config file we already found. set known # hosts and agent to None so we can not have an agent and deal w/ known hosts ourselves common_args = { \"host\": self._base_transport_args.host, \"port\": self._base_transport_args.port, \"username\": self.plugin_transport_args.auth_username, \"known_hosts\": None, \"agent_path\": None, \"config\": self.plugin_transport_args.ssh_config_file, } # Allow passing `transport_options` to asyncssh common_args.update(self._base_transport_args.transport_options.get(\"asyncssh\", {})) try: self.session = await asyncio.wait_for( connect( client_keys=self.plugin_transport_args.auth_private_key, password=self.plugin_transport_args.auth_password, preferred_auth=( \"publickey\", \"keyboard-interactive\", \"password\", ), **common_args, ), timeout=self._base_transport_args.timeout_socket, ) except PermissionDenied as exc: msg = \"all authentication methods failed\" self.logger.critical(msg) raise ScrapliAuthenticationFailed(msg) from exc except asyncio.TimeoutError as exc: msg = \"timed out opening connection to device\" self.logger.critical(msg) raise ScrapliAuthenticationFailed(msg) from exc if not self.session: raise ScrapliConnectionNotOpened if self.plugin_transport_args.auth_strict_key: self.logger.debug( f\"Attempting to validate {self._base_transport_args.host} public key is in known \" f\"hosts and is valid\" ) self._verify_key_value() self.stdin, self.stdout, _ = await self.session.open_session( term_type=\"xterm\", encoding=None ) self._post_open_closing_log(closing=False) def close(self) -> None: self._pre_open_closing_log(closing=True) if self.session: try: self.session.close() except BrokenPipeError: # it seems it is possible for the connection transport is_closing() to be true # already in some cases... since we are closing the connection anyway we will just # ignore this note that this seemed to only happen in github actions on # ubuntu-latest w/ py3.8... pass # always reset session/stdin/stdout back to None if we are closing! self.session = None self.stdin = None self.stdout = None self._post_open_closing_log(closing=True) def isalive(self) -> bool: if not self.session: return False # this may need to be revisited in the future, but this seems to be a good check for # aliveness try: if ( self.session._auth_complete # pylint: disable=W0212 and self.session._transport is not None # pylint: disable=W0212 and self.session._transport.is_closing() is False # pylint: disable=W0212 ): return True except AttributeError: pass return False @timeout_wrapper async def read(self) -> bytes: if not self.stdout: raise ScrapliConnectionNotOpened try: buf: bytes = await self.stdout.read(65535) except ConnectionLost as exc: msg = ( \"encountered EOF reading from transport; typically means the device closed the \" \"connection\" ) self.logger.critical(msg) raise ScrapliConnectionError(msg) from exc return buf def write(self, channel_input: bytes) -> None: if not self.stdin: raise ScrapliConnectionNotOpened self.stdin.write(channel_input) Ancestors (in MRO) \u00b6 scrapli.transport.base.async_transport.AsyncTransport scrapli.transport.base.base_transport.BaseTransport abc.ABC PluginTransportArgs \u00b6 1 PluginTransportArgs(auth_username: str, auth_password: str = '', auth_private_key: str = '', auth_strict_key: bool = True, ssh_config_file: str = '', ssh_known_hosts_file: str = '') Expand source code @dataclass() class PluginTransportArgs(BasePluginTransportArgs): auth_username: str auth_password: str = \"\" auth_private_key: str = \"\" auth_strict_key: bool = True ssh_config_file: str = \"\" ssh_known_hosts_file: str = \"\" Ancestors (in MRO) \u00b6 scrapli.transport.base.base_transport.BasePluginTransportArgs Class variables \u00b6 auth_password: str auth_private_key: str auth_strict_key: bool auth_username: str ssh_config_file: str ssh_known_hosts_file: str","title":"Asyncssh"},{"location":"api_docs/transport/plugins/asyncssh/#module-scraplitransportpluginsasyncsshtransport","text":"scrapli.transport.plugins.asyncssh.transport Expand source code \"\"\"scrapli.transport.plugins.asyncssh.transport\"\"\" import asyncio from dataclasses import dataclass from typing import Any, Optional from asyncssh.connection import SSHClientConnection, connect from asyncssh.misc import ConnectionLost, PermissionDenied from asyncssh.stream import SSHReader, SSHWriter from scrapli.decorators import timeout_wrapper from scrapli.exceptions import ( ScrapliAuthenticationFailed, ScrapliConnectionError, ScrapliConnectionNotOpened, ) from scrapli.ssh_config import SSHKnownHosts from scrapli.transport.base import AsyncTransport, BasePluginTransportArgs, BaseTransportArgs @dataclass() class PluginTransportArgs(BasePluginTransportArgs): auth_username: str auth_password: str = \"\" auth_private_key: str = \"\" auth_strict_key: bool = True ssh_config_file: str = \"\" ssh_known_hosts_file: str = \"\" class AsyncsshTransport(AsyncTransport): def __init__( self, base_transport_args: BaseTransportArgs, plugin_transport_args: PluginTransportArgs ) -> None: \"\"\" Asyncssh transport plugin. Important note: some ssh servers may refuse connections if too many ssh host key algorithms are passed to it during the connection opening -- Asyncssh sends a bunch by default! If you encounter this issue, you can simply update your SSH config file to set a smaller (or one) number of ssh host key algorithms to work around this like so: 1 2 Host * HostKeyAlgorithms ssh-rsa Thank you to @davaeron [https://github.com/davaeron] for reporting this in #173, see also asyncssh #323 here: https://github.com/ronf/asyncssh/issues/323. This transport supports some additional `transport_options` to control behavior -- `asyncssh` is a dictionary that contains options that are passed directly to asyncssh during connection creation, you can find the SSH Client options of asyncssh here: https://asyncssh.readthedocs.io/en/latest/api.html#sshclientconnectionoptions. Below is an example of passing in options to modify kex and encryption algorithms 1 2 3 4 5 6 7 8 9 10 11 12 device = { \"host\": \"localhost\", \"transport_options\": { \"asyncssh\": { \"kex_algs\": [\"diffie-hellman-group14-sha1\", \"diffie-hellman-group1-sha1\"], \"encryption_algs\": [\"aes256-cbc\", \"aes192-cbc\", \"aes256-ctr\", \"aes192-ctr\"], } }, \"platform\": \"cisco_iosxe\" } conn = Scrapli(**device) Args: base_transport_args: scrapli base transport plugin arguments plugin_transport_args: asyncssh ssh specific transport plugin arguments Returns: N/A Raises: N/A \"\"\" super().__init__(base_transport_args=base_transport_args) self.plugin_transport_args = plugin_transport_args self.session: Optional[SSHClientConnection] = None self.stdout: Optional[SSHReader[Any]] = None self.stdin: Optional[SSHWriter[Any]] = None def _verify_key(self) -> None: \"\"\" Verify target host public key, raise exception if invalid/unknown Args: N/A Returns: None Raises: ScrapliAuthenticationFailed: if host is not in known hosts \"\"\" known_hosts = SSHKnownHosts(self.plugin_transport_args.ssh_known_hosts_file) known_host_public_key = known_hosts.lookup(self._base_transport_args.host) if not known_host_public_key: raise ScrapliAuthenticationFailed( f\"{self._base_transport_args.host} not in known_hosts!\" ) def _verify_key_value(self) -> None: \"\"\" Verify target host public key, raise exception if invalid/unknown Args: N/A Returns: None Raises: ScrapliConnectionNotOpened: if session is unopened/None ScrapliAuthenticationFailed: if host is in known hosts but public key does not match or cannot glean remote server key from session. \"\"\" if not self.session: raise ScrapliConnectionNotOpened known_hosts = SSHKnownHosts(self.plugin_transport_args.ssh_known_hosts_file) known_host_public_key = known_hosts.lookup(self._base_transport_args.host) remote_server_key = self.session.get_server_host_key() if remote_server_key is None: raise ScrapliAuthenticationFailed( f\"failed gleaning remote server ssh key for host {self._base_transport_args.host}\" ) remote_public_key = remote_server_key.export_public_key().split()[1].decode() if known_host_public_key[\"public_key\"] != remote_public_key: raise ScrapliAuthenticationFailed( f\"{self._base_transport_args.host} in known_hosts but public key does not match!\" ) async def open(self) -> None: self._pre_open_closing_log(closing=False) if self.plugin_transport_args.auth_strict_key: self.logger.debug( f\"Attempting to validate {self._base_transport_args.host} public key is in known \" f\"hosts\" ) self._verify_key() # we already fetched host/port/user from the user input and/or the ssh config file, so we # want to use those explicitly. likewise we pass config file we already found. set known # hosts and agent to None so we can not have an agent and deal w/ known hosts ourselves common_args = { \"host\": self._base_transport_args.host, \"port\": self._base_transport_args.port, \"username\": self.plugin_transport_args.auth_username, \"known_hosts\": None, \"agent_path\": None, \"config\": self.plugin_transport_args.ssh_config_file, } # Allow passing `transport_options` to asyncssh common_args.update(self._base_transport_args.transport_options.get(\"asyncssh\", {})) try: self.session = await asyncio.wait_for( connect( client_keys=self.plugin_transport_args.auth_private_key, password=self.plugin_transport_args.auth_password, preferred_auth=( \"publickey\", \"keyboard-interactive\", \"password\", ), **common_args, ), timeout=self._base_transport_args.timeout_socket, ) except PermissionDenied as exc: msg = \"all authentication methods failed\" self.logger.critical(msg) raise ScrapliAuthenticationFailed(msg) from exc except asyncio.TimeoutError as exc: msg = \"timed out opening connection to device\" self.logger.critical(msg) raise ScrapliAuthenticationFailed(msg) from exc if not self.session: raise ScrapliConnectionNotOpened if self.plugin_transport_args.auth_strict_key: self.logger.debug( f\"Attempting to validate {self._base_transport_args.host} public key is in known \" f\"hosts and is valid\" ) self._verify_key_value() self.stdin, self.stdout, _ = await self.session.open_session( term_type=\"xterm\", encoding=None ) self._post_open_closing_log(closing=False) def close(self) -> None: self._pre_open_closing_log(closing=True) if self.session: try: self.session.close() except BrokenPipeError: # it seems it is possible for the connection transport is_closing() to be true # already in some cases... since we are closing the connection anyway we will just # ignore this note that this seemed to only happen in github actions on # ubuntu-latest w/ py3.8... pass # always reset session/stdin/stdout back to None if we are closing! self.session = None self.stdin = None self.stdout = None self._post_open_closing_log(closing=True) def isalive(self) -> bool: if not self.session: return False # this may need to be revisited in the future, but this seems to be a good check for # aliveness try: if ( self.session._auth_complete # pylint: disable=W0212 and self.session._transport is not None # pylint: disable=W0212 and self.session._transport.is_closing() is False # pylint: disable=W0212 ): return True except AttributeError: pass return False @timeout_wrapper async def read(self) -> bytes: if not self.stdout: raise ScrapliConnectionNotOpened try: buf: bytes = await self.stdout.read(65535) except ConnectionLost as exc: msg = ( \"encountered EOF reading from transport; typically means the device closed the \" \"connection\" ) self.logger.critical(msg) raise ScrapliConnectionError(msg) from exc return buf def write(self, channel_input: bytes) -> None: if not self.stdin: raise ScrapliConnectionNotOpened self.stdin.write(channel_input)","title":"Module scrapli.transport.plugins.asyncssh.transport"},{"location":"api_docs/transport/plugins/asyncssh/#classes","text":"","title":"Classes"},{"location":"api_docs/transport/plugins/asyncssh/#asyncsshtransport","text":"1 2 3 4 5 6 7 8 9 Helper class that provides a standard way to create an ABC using inheritance. Asyncssh transport plugin. Important note: some ssh servers may refuse connections if too many ssh host key algorithms are passed to it during the connection opening -- Asyncssh sends a bunch by default! If you encounter this issue, you can simply update your SSH config file to set a smaller (or one) number of ssh host key algorithms to work around this like so: Host * HostKeyAlgorithms ssh-rsa 1 2 3 4 5 6 7 8 Thank you to @davaeron [https://github.com/davaeron] for reporting this in #173, see also asyncssh #323 here: https://github.com/ronf/asyncssh/issues/323. This transport supports some additional `transport_options` to control behavior -- `asyncssh` is a dictionary that contains options that are passed directly to asyncssh during connection creation, you can find the SSH Client options of asyncssh here: https://asyncssh.readthedocs.io/en/latest/api.html#sshclientconnectionoptions. Below is an example of passing in options to modify kex and encryption algorithms device = { \"host\": \"localhost\", \"transport_options\": { \"asyncssh\": { \"kex_algs\": [\"diffie-hellman-group14-sha1\", \"diffie-hellman-group1-sha1\"], \"encryption_algs\": [\"aes256-cbc\", \"aes192-cbc\", \"aes256-ctr\", \"aes192-ctr\"], } }, \"platform\": \"cisco_iosxe\" } conn = Scrapli(**device) 1 2 3 4 5 6 7 8 9 Args: base_transport_args: scrapli base transport plugin arguments plugin_transport_args: asyncssh ssh specific transport plugin arguments Returns: N/A Raises: N/A Expand source code class AsyncsshTransport(AsyncTransport): def __init__( self, base_transport_args: BaseTransportArgs, plugin_transport_args: PluginTransportArgs ) -> None: \"\"\" Asyncssh transport plugin. Important note: some ssh servers may refuse connections if too many ssh host key algorithms are passed to it during the connection opening -- Asyncssh sends a bunch by default! If you encounter this issue, you can simply update your SSH config file to set a smaller (or one) number of ssh host key algorithms to work around this like so: 1 2 Host * HostKeyAlgorithms ssh-rsa Thank you to @davaeron [https://github.com/davaeron] for reporting this in #173, see also asyncssh #323 here: https://github.com/ronf/asyncssh/issues/323. This transport supports some additional `transport_options` to control behavior -- `asyncssh` is a dictionary that contains options that are passed directly to asyncssh during connection creation, you can find the SSH Client options of asyncssh here: https://asyncssh.readthedocs.io/en/latest/api.html#sshclientconnectionoptions. Below is an example of passing in options to modify kex and encryption algorithms 1 2 3 4 5 6 7 8 9 10 11 12 device = { \"host\": \"localhost\", \"transport_options\": { \"asyncssh\": { \"kex_algs\": [\"diffie-hellman-group14-sha1\", \"diffie-hellman-group1-sha1\"], \"encryption_algs\": [\"aes256-cbc\", \"aes192-cbc\", \"aes256-ctr\", \"aes192-ctr\"], } }, \"platform\": \"cisco_iosxe\" } conn = Scrapli(**device) Args: base_transport_args: scrapli base transport plugin arguments plugin_transport_args: asyncssh ssh specific transport plugin arguments Returns: N/A Raises: N/A \"\"\" super().__init__(base_transport_args=base_transport_args) self.plugin_transport_args = plugin_transport_args self.session: Optional[SSHClientConnection] = None self.stdout: Optional[SSHReader[Any]] = None self.stdin: Optional[SSHWriter[Any]] = None def _verify_key(self) -> None: \"\"\" Verify target host public key, raise exception if invalid/unknown Args: N/A Returns: None Raises: ScrapliAuthenticationFailed: if host is not in known hosts \"\"\" known_hosts = SSHKnownHosts(self.plugin_transport_args.ssh_known_hosts_file) known_host_public_key = known_hosts.lookup(self._base_transport_args.host) if not known_host_public_key: raise ScrapliAuthenticationFailed( f\"{self._base_transport_args.host} not in known_hosts!\" ) def _verify_key_value(self) -> None: \"\"\" Verify target host public key, raise exception if invalid/unknown Args: N/A Returns: None Raises: ScrapliConnectionNotOpened: if session is unopened/None ScrapliAuthenticationFailed: if host is in known hosts but public key does not match or cannot glean remote server key from session. \"\"\" if not self.session: raise ScrapliConnectionNotOpened known_hosts = SSHKnownHosts(self.plugin_transport_args.ssh_known_hosts_file) known_host_public_key = known_hosts.lookup(self._base_transport_args.host) remote_server_key = self.session.get_server_host_key() if remote_server_key is None: raise ScrapliAuthenticationFailed( f\"failed gleaning remote server ssh key for host {self._base_transport_args.host}\" ) remote_public_key = remote_server_key.export_public_key().split()[1].decode() if known_host_public_key[\"public_key\"] != remote_public_key: raise ScrapliAuthenticationFailed( f\"{self._base_transport_args.host} in known_hosts but public key does not match!\" ) async def open(self) -> None: self._pre_open_closing_log(closing=False) if self.plugin_transport_args.auth_strict_key: self.logger.debug( f\"Attempting to validate {self._base_transport_args.host} public key is in known \" f\"hosts\" ) self._verify_key() # we already fetched host/port/user from the user input and/or the ssh config file, so we # want to use those explicitly. likewise we pass config file we already found. set known # hosts and agent to None so we can not have an agent and deal w/ known hosts ourselves common_args = { \"host\": self._base_transport_args.host, \"port\": self._base_transport_args.port, \"username\": self.plugin_transport_args.auth_username, \"known_hosts\": None, \"agent_path\": None, \"config\": self.plugin_transport_args.ssh_config_file, } # Allow passing `transport_options` to asyncssh common_args.update(self._base_transport_args.transport_options.get(\"asyncssh\", {})) try: self.session = await asyncio.wait_for( connect( client_keys=self.plugin_transport_args.auth_private_key, password=self.plugin_transport_args.auth_password, preferred_auth=( \"publickey\", \"keyboard-interactive\", \"password\", ), **common_args, ), timeout=self._base_transport_args.timeout_socket, ) except PermissionDenied as exc: msg = \"all authentication methods failed\" self.logger.critical(msg) raise ScrapliAuthenticationFailed(msg) from exc except asyncio.TimeoutError as exc: msg = \"timed out opening connection to device\" self.logger.critical(msg) raise ScrapliAuthenticationFailed(msg) from exc if not self.session: raise ScrapliConnectionNotOpened if self.plugin_transport_args.auth_strict_key: self.logger.debug( f\"Attempting to validate {self._base_transport_args.host} public key is in known \" f\"hosts and is valid\" ) self._verify_key_value() self.stdin, self.stdout, _ = await self.session.open_session( term_type=\"xterm\", encoding=None ) self._post_open_closing_log(closing=False) def close(self) -> None: self._pre_open_closing_log(closing=True) if self.session: try: self.session.close() except BrokenPipeError: # it seems it is possible for the connection transport is_closing() to be true # already in some cases... since we are closing the connection anyway we will just # ignore this note that this seemed to only happen in github actions on # ubuntu-latest w/ py3.8... pass # always reset session/stdin/stdout back to None if we are closing! self.session = None self.stdin = None self.stdout = None self._post_open_closing_log(closing=True) def isalive(self) -> bool: if not self.session: return False # this may need to be revisited in the future, but this seems to be a good check for # aliveness try: if ( self.session._auth_complete # pylint: disable=W0212 and self.session._transport is not None # pylint: disable=W0212 and self.session._transport.is_closing() is False # pylint: disable=W0212 ): return True except AttributeError: pass return False @timeout_wrapper async def read(self) -> bytes: if not self.stdout: raise ScrapliConnectionNotOpened try: buf: bytes = await self.stdout.read(65535) except ConnectionLost as exc: msg = ( \"encountered EOF reading from transport; typically means the device closed the \" \"connection\" ) self.logger.critical(msg) raise ScrapliConnectionError(msg) from exc return buf def write(self, channel_input: bytes) -> None: if not self.stdin: raise ScrapliConnectionNotOpened self.stdin.write(channel_input)","title":"AsyncsshTransport"},{"location":"api_docs/transport/plugins/asyncssh/#ancestors-in-mro","text":"scrapli.transport.base.async_transport.AsyncTransport scrapli.transport.base.base_transport.BaseTransport abc.ABC","title":"Ancestors (in MRO)"},{"location":"api_docs/transport/plugins/asyncssh/#plugintransportargs","text":"1 PluginTransportArgs(auth_username: str, auth_password: str = '', auth_private_key: str = '', auth_strict_key: bool = True, ssh_config_file: str = '', ssh_known_hosts_file: str = '') Expand source code @dataclass() class PluginTransportArgs(BasePluginTransportArgs): auth_username: str auth_password: str = \"\" auth_private_key: str = \"\" auth_strict_key: bool = True ssh_config_file: str = \"\" ssh_known_hosts_file: str = \"\"","title":"PluginTransportArgs"},{"location":"api_docs/transport/plugins/asyncssh/#ancestors-in-mro_1","text":"scrapli.transport.base.base_transport.BasePluginTransportArgs","title":"Ancestors (in MRO)"},{"location":"api_docs/transport/plugins/asyncssh/#class-variables","text":"auth_password: str auth_private_key: str auth_strict_key: bool auth_username: str ssh_config_file: str ssh_known_hosts_file: str","title":"Class variables"},{"location":"api_docs/transport/plugins/asynctelnet/","text":"window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting()) Module scrapli.transport.plugins.asynctelnet.transport \u00b6 scrapli.transport.plugins.asynctelnet.transport Expand source code \"\"\"scrapli.transport.plugins.asynctelnet.transport\"\"\" import asyncio import socket from dataclasses import dataclass from typing import Optional from scrapli.decorators import timeout_wrapper from scrapli.exceptions import ( ScrapliAuthenticationFailed, ScrapliConnectionError, ScrapliConnectionNotOpened, ) from scrapli.transport.base import AsyncTransport, BasePluginTransportArgs, BaseTransportArgs from scrapli.transport.base.telnet_common import DO, DONT, IAC, SUPPRESS_GO_AHEAD, WILL, WONT @dataclass() class PluginTransportArgs(BasePluginTransportArgs): pass class AsynctelnetTransport(AsyncTransport): def __init__( self, base_transport_args: BaseTransportArgs, plugin_transport_args: PluginTransportArgs ) -> None: super().__init__(base_transport_args=base_transport_args) self.plugin_transport_args = plugin_transport_args self.stdout: Optional[asyncio.StreamReader] = None self.stdin: Optional[asyncio.StreamWriter] = None self._eof = False self._raw_buf = b\"\" self._cooked_buf = b\"\" self._control_char_sent_counter = 0 self._control_char_sent_limit = 10 def _handle_control_chars_response(self, control_buf: bytes, c: bytes) -> bytes: \"\"\" Handle the actual response to control characters Broken up to be easier to test as well as to appease mr. mccabe Args: control_buf: current control_buf to work with c: currently read control char to process Returns: bytes: updated control_buf Raises: ScrapliConnectionNotOpened: if connection is not opened for some reason \"\"\" if not self.stdin: raise ScrapliConnectionNotOpened # control_buf is empty, lets see if we got a control character if not control_buf: if c != IAC: # add whatever character we read to the \"normal\" output buf so it gets sent off # to the auth method later (username/show prompts may show up here) self._cooked_buf += c else: # we got a control character, put it into the control_buf control_buf += c elif len(control_buf) == 1 and c in (DO, DONT, WILL, WONT): # control buf already has the IAC byte loaded, if the next char is DO/DONT/WILL/WONT # add that into the control buffer and move on control_buf += c elif len(control_buf) == 2: # control buffer is already loaded with IAC and directive, we now have an option to # deal with, create teh base command out of the existing buffer then reset the buf # for the next go around cmd = control_buf[1:2] control_buf = b\"\" if (cmd == DO) and (c == SUPPRESS_GO_AHEAD): # if server says do suppress go ahead we say will for that option self.stdin.write(IAC + WILL + c) elif cmd in (DO, DONT): # if server says do/dont we always say wont for that option self.stdin.write(IAC + WONT + c) elif cmd == WILL: # if server says will we always say do for that option self.stdin.write(IAC + DO + c) elif cmd == WONT: # if server says wont we always say dont for that option self.stdin.write(IAC + DONT + c) return control_buf def _handle_control_chars(self) -> None: \"\"\" Handle control characters -- nearly identical to CPython telnetlib Basically we want to read and \"decline\" any and all control options that the server proposes to us -- so if they say \"DO\" XYZ directive, we say \"DONT\", if they say \"WILL\" we say \"WONT\". Args: N/A Returns: None Raises: ScrapliConnectionNotOpened: if connection is not opened for some reason ScrapliConnectionNotOpened: if we read an empty byte string from the reader -- this indicates the server sent an EOF -- see #142 \"\"\" if not self.stdout: raise ScrapliConnectionNotOpened # control_buf is the buffer for control characters, we reset this after being \"done\" with # responding to a control sequence, so it always represents the \"current\" control sequence # we are working on responding to control_buf = b\"\" while self._raw_buf: c, self._raw_buf = self._raw_buf[:1], self._raw_buf[1:] if not c: raise ScrapliConnectionNotOpened(\"server returned EOF, connection not opened\") control_buf = self._handle_control_chars_response(control_buf=control_buf, c=c) async def open(self) -> None: self._pre_open_closing_log(closing=False) try: fut = asyncio.open_connection( host=self._base_transport_args.host, port=self._base_transport_args.port ) self.stdout, self.stdin = await asyncio.wait_for( fut, timeout=self._base_transport_args.timeout_socket ) except ConnectionError as exc: msg = f\"Failed to open telnet session to host {self._base_transport_args.host}\" if \"connection refused\" in str(exc).lower(): msg = ( f\"Failed to open telnet session to host {self._base_transport_args.host}, \" \"connection refused\" ) raise ScrapliConnectionError(msg) from exc except (OSError, socket.gaierror) as exc: msg = ( f\"Failed to open telnet session to host {self._base_transport_args.host} -- \" \"do you have a bad host/port?\" ) raise ScrapliConnectionError(msg) from exc except asyncio.TimeoutError as exc: msg = \"timed out opening connection to device\" self.logger.critical(msg) raise ScrapliAuthenticationFailed(msg) from exc self._post_open_closing_log(closing=False) def close(self) -> None: self._pre_open_closing_log(closing=True) if self.stdin: self.stdin.close() try: self.stdin.close() except AttributeError: # wait closed only in 3.7+... unclear if we should be doing something else for 3.6? # it doesnt seem to hurt anything... pass self.stdin = None self.stdout = None self._post_open_closing_log(closing=True) def isalive(self) -> bool: if not self.stdin or not self.stdout: return False return not self.stdout.at_eof() async def _read(self, n: int = 65535) -> None: if not self.stdout: raise ScrapliConnectionNotOpened if not self._raw_buf: try: buf = await self.stdout.read(n) self._eof = not buf if self._control_char_sent_counter < self._control_char_sent_limit: self._raw_buf += buf else: self._cooked_buf += buf except EOFError as exc: raise ScrapliConnectionError( \"encountered EOF reading from transport; typically means the device closed the \" \"connection\" ) from exc @timeout_wrapper async def read(self) -> bytes: if not self.stdout: raise ScrapliConnectionNotOpened if self._control_char_sent_counter < self._control_char_sent_limit: self._handle_control_chars() while not self._cooked_buf and not self._eof: await self._read() if self._control_char_sent_counter < self._control_char_sent_limit: self._handle_control_chars() buf = self._cooked_buf self._cooked_buf = b\"\" return buf def write(self, channel_input: bytes) -> None: if not self.stdin: raise ScrapliConnectionNotOpened self.stdin.write(channel_input) Classes \u00b6 AsynctelnetTransport \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 Helper class that provides a standard way to create an ABC using inheritance. Scrapli's transport base class Args: base_transport_args: base transport args dataclass Returns: None Raises: N/A Expand source code class AsynctelnetTransport(AsyncTransport): def __init__( self, base_transport_args: BaseTransportArgs, plugin_transport_args: PluginTransportArgs ) -> None: super().__init__(base_transport_args=base_transport_args) self.plugin_transport_args = plugin_transport_args self.stdout: Optional[asyncio.StreamReader] = None self.stdin: Optional[asyncio.StreamWriter] = None self._eof = False self._raw_buf = b\"\" self._cooked_buf = b\"\" self._control_char_sent_counter = 0 self._control_char_sent_limit = 10 def _handle_control_chars_response(self, control_buf: bytes, c: bytes) -> bytes: \"\"\" Handle the actual response to control characters Broken up to be easier to test as well as to appease mr. mccabe Args: control_buf: current control_buf to work with c: currently read control char to process Returns: bytes: updated control_buf Raises: ScrapliConnectionNotOpened: if connection is not opened for some reason \"\"\" if not self.stdin: raise ScrapliConnectionNotOpened # control_buf is empty, lets see if we got a control character if not control_buf: if c != IAC: # add whatever character we read to the \"normal\" output buf so it gets sent off # to the auth method later (username/show prompts may show up here) self._cooked_buf += c else: # we got a control character, put it into the control_buf control_buf += c elif len(control_buf) == 1 and c in (DO, DONT, WILL, WONT): # control buf already has the IAC byte loaded, if the next char is DO/DONT/WILL/WONT # add that into the control buffer and move on control_buf += c elif len(control_buf) == 2: # control buffer is already loaded with IAC and directive, we now have an option to # deal with, create teh base command out of the existing buffer then reset the buf # for the next go around cmd = control_buf[1:2] control_buf = b\"\" if (cmd == DO) and (c == SUPPRESS_GO_AHEAD): # if server says do suppress go ahead we say will for that option self.stdin.write(IAC + WILL + c) elif cmd in (DO, DONT): # if server says do/dont we always say wont for that option self.stdin.write(IAC + WONT + c) elif cmd == WILL: # if server says will we always say do for that option self.stdin.write(IAC + DO + c) elif cmd == WONT: # if server says wont we always say dont for that option self.stdin.write(IAC + DONT + c) return control_buf def _handle_control_chars(self) -> None: \"\"\" Handle control characters -- nearly identical to CPython telnetlib Basically we want to read and \"decline\" any and all control options that the server proposes to us -- so if they say \"DO\" XYZ directive, we say \"DONT\", if they say \"WILL\" we say \"WONT\". Args: N/A Returns: None Raises: ScrapliConnectionNotOpened: if connection is not opened for some reason ScrapliConnectionNotOpened: if we read an empty byte string from the reader -- this indicates the server sent an EOF -- see #142 \"\"\" if not self.stdout: raise ScrapliConnectionNotOpened # control_buf is the buffer for control characters, we reset this after being \"done\" with # responding to a control sequence, so it always represents the \"current\" control sequence # we are working on responding to control_buf = b\"\" while self._raw_buf: c, self._raw_buf = self._raw_buf[:1], self._raw_buf[1:] if not c: raise ScrapliConnectionNotOpened(\"server returned EOF, connection not opened\") control_buf = self._handle_control_chars_response(control_buf=control_buf, c=c) async def open(self) -> None: self._pre_open_closing_log(closing=False) try: fut = asyncio.open_connection( host=self._base_transport_args.host, port=self._base_transport_args.port ) self.stdout, self.stdin = await asyncio.wait_for( fut, timeout=self._base_transport_args.timeout_socket ) except ConnectionError as exc: msg = f\"Failed to open telnet session to host {self._base_transport_args.host}\" if \"connection refused\" in str(exc).lower(): msg = ( f\"Failed to open telnet session to host {self._base_transport_args.host}, \" \"connection refused\" ) raise ScrapliConnectionError(msg) from exc except (OSError, socket.gaierror) as exc: msg = ( f\"Failed to open telnet session to host {self._base_transport_args.host} -- \" \"do you have a bad host/port?\" ) raise ScrapliConnectionError(msg) from exc except asyncio.TimeoutError as exc: msg = \"timed out opening connection to device\" self.logger.critical(msg) raise ScrapliAuthenticationFailed(msg) from exc self._post_open_closing_log(closing=False) def close(self) -> None: self._pre_open_closing_log(closing=True) if self.stdin: self.stdin.close() try: self.stdin.close() except AttributeError: # wait closed only in 3.7+... unclear if we should be doing something else for 3.6? # it doesnt seem to hurt anything... pass self.stdin = None self.stdout = None self._post_open_closing_log(closing=True) def isalive(self) -> bool: if not self.stdin or not self.stdout: return False return not self.stdout.at_eof() async def _read(self, n: int = 65535) -> None: if not self.stdout: raise ScrapliConnectionNotOpened if not self._raw_buf: try: buf = await self.stdout.read(n) self._eof = not buf if self._control_char_sent_counter < self._control_char_sent_limit: self._raw_buf += buf else: self._cooked_buf += buf except EOFError as exc: raise ScrapliConnectionError( \"encountered EOF reading from transport; typically means the device closed the \" \"connection\" ) from exc @timeout_wrapper async def read(self) -> bytes: if not self.stdout: raise ScrapliConnectionNotOpened if self._control_char_sent_counter < self._control_char_sent_limit: self._handle_control_chars() while not self._cooked_buf and not self._eof: await self._read() if self._control_char_sent_counter < self._control_char_sent_limit: self._handle_control_chars() buf = self._cooked_buf self._cooked_buf = b\"\" return buf def write(self, channel_input: bytes) -> None: if not self.stdin: raise ScrapliConnectionNotOpened self.stdin.write(channel_input) Ancestors (in MRO) \u00b6 scrapli.transport.base.async_transport.AsyncTransport scrapli.transport.base.base_transport.BaseTransport abc.ABC PluginTransportArgs \u00b6 1 PluginTransportArgs() Expand source code @dataclass() class PluginTransportArgs(BasePluginTransportArgs): pass Ancestors (in MRO) \u00b6 scrapli.transport.base.base_transport.BasePluginTransportArgs","title":"Asynctelnet"},{"location":"api_docs/transport/plugins/asynctelnet/#module-scraplitransportpluginsasynctelnettransport","text":"scrapli.transport.plugins.asynctelnet.transport Expand source code \"\"\"scrapli.transport.plugins.asynctelnet.transport\"\"\" import asyncio import socket from dataclasses import dataclass from typing import Optional from scrapli.decorators import timeout_wrapper from scrapli.exceptions import ( ScrapliAuthenticationFailed, ScrapliConnectionError, ScrapliConnectionNotOpened, ) from scrapli.transport.base import AsyncTransport, BasePluginTransportArgs, BaseTransportArgs from scrapli.transport.base.telnet_common import DO, DONT, IAC, SUPPRESS_GO_AHEAD, WILL, WONT @dataclass() class PluginTransportArgs(BasePluginTransportArgs): pass class AsynctelnetTransport(AsyncTransport): def __init__( self, base_transport_args: BaseTransportArgs, plugin_transport_args: PluginTransportArgs ) -> None: super().__init__(base_transport_args=base_transport_args) self.plugin_transport_args = plugin_transport_args self.stdout: Optional[asyncio.StreamReader] = None self.stdin: Optional[asyncio.StreamWriter] = None self._eof = False self._raw_buf = b\"\" self._cooked_buf = b\"\" self._control_char_sent_counter = 0 self._control_char_sent_limit = 10 def _handle_control_chars_response(self, control_buf: bytes, c: bytes) -> bytes: \"\"\" Handle the actual response to control characters Broken up to be easier to test as well as to appease mr. mccabe Args: control_buf: current control_buf to work with c: currently read control char to process Returns: bytes: updated control_buf Raises: ScrapliConnectionNotOpened: if connection is not opened for some reason \"\"\" if not self.stdin: raise ScrapliConnectionNotOpened # control_buf is empty, lets see if we got a control character if not control_buf: if c != IAC: # add whatever character we read to the \"normal\" output buf so it gets sent off # to the auth method later (username/show prompts may show up here) self._cooked_buf += c else: # we got a control character, put it into the control_buf control_buf += c elif len(control_buf) == 1 and c in (DO, DONT, WILL, WONT): # control buf already has the IAC byte loaded, if the next char is DO/DONT/WILL/WONT # add that into the control buffer and move on control_buf += c elif len(control_buf) == 2: # control buffer is already loaded with IAC and directive, we now have an option to # deal with, create teh base command out of the existing buffer then reset the buf # for the next go around cmd = control_buf[1:2] control_buf = b\"\" if (cmd == DO) and (c == SUPPRESS_GO_AHEAD): # if server says do suppress go ahead we say will for that option self.stdin.write(IAC + WILL + c) elif cmd in (DO, DONT): # if server says do/dont we always say wont for that option self.stdin.write(IAC + WONT + c) elif cmd == WILL: # if server says will we always say do for that option self.stdin.write(IAC + DO + c) elif cmd == WONT: # if server says wont we always say dont for that option self.stdin.write(IAC + DONT + c) return control_buf def _handle_control_chars(self) -> None: \"\"\" Handle control characters -- nearly identical to CPython telnetlib Basically we want to read and \"decline\" any and all control options that the server proposes to us -- so if they say \"DO\" XYZ directive, we say \"DONT\", if they say \"WILL\" we say \"WONT\". Args: N/A Returns: None Raises: ScrapliConnectionNotOpened: if connection is not opened for some reason ScrapliConnectionNotOpened: if we read an empty byte string from the reader -- this indicates the server sent an EOF -- see #142 \"\"\" if not self.stdout: raise ScrapliConnectionNotOpened # control_buf is the buffer for control characters, we reset this after being \"done\" with # responding to a control sequence, so it always represents the \"current\" control sequence # we are working on responding to control_buf = b\"\" while self._raw_buf: c, self._raw_buf = self._raw_buf[:1], self._raw_buf[1:] if not c: raise ScrapliConnectionNotOpened(\"server returned EOF, connection not opened\") control_buf = self._handle_control_chars_response(control_buf=control_buf, c=c) async def open(self) -> None: self._pre_open_closing_log(closing=False) try: fut = asyncio.open_connection( host=self._base_transport_args.host, port=self._base_transport_args.port ) self.stdout, self.stdin = await asyncio.wait_for( fut, timeout=self._base_transport_args.timeout_socket ) except ConnectionError as exc: msg = f\"Failed to open telnet session to host {self._base_transport_args.host}\" if \"connection refused\" in str(exc).lower(): msg = ( f\"Failed to open telnet session to host {self._base_transport_args.host}, \" \"connection refused\" ) raise ScrapliConnectionError(msg) from exc except (OSError, socket.gaierror) as exc: msg = ( f\"Failed to open telnet session to host {self._base_transport_args.host} -- \" \"do you have a bad host/port?\" ) raise ScrapliConnectionError(msg) from exc except asyncio.TimeoutError as exc: msg = \"timed out opening connection to device\" self.logger.critical(msg) raise ScrapliAuthenticationFailed(msg) from exc self._post_open_closing_log(closing=False) def close(self) -> None: self._pre_open_closing_log(closing=True) if self.stdin: self.stdin.close() try: self.stdin.close() except AttributeError: # wait closed only in 3.7+... unclear if we should be doing something else for 3.6? # it doesnt seem to hurt anything... pass self.stdin = None self.stdout = None self._post_open_closing_log(closing=True) def isalive(self) -> bool: if not self.stdin or not self.stdout: return False return not self.stdout.at_eof() async def _read(self, n: int = 65535) -> None: if not self.stdout: raise ScrapliConnectionNotOpened if not self._raw_buf: try: buf = await self.stdout.read(n) self._eof = not buf if self._control_char_sent_counter < self._control_char_sent_limit: self._raw_buf += buf else: self._cooked_buf += buf except EOFError as exc: raise ScrapliConnectionError( \"encountered EOF reading from transport; typically means the device closed the \" \"connection\" ) from exc @timeout_wrapper async def read(self) -> bytes: if not self.stdout: raise ScrapliConnectionNotOpened if self._control_char_sent_counter < self._control_char_sent_limit: self._handle_control_chars() while not self._cooked_buf and not self._eof: await self._read() if self._control_char_sent_counter < self._control_char_sent_limit: self._handle_control_chars() buf = self._cooked_buf self._cooked_buf = b\"\" return buf def write(self, channel_input: bytes) -> None: if not self.stdin: raise ScrapliConnectionNotOpened self.stdin.write(channel_input)","title":"Module scrapli.transport.plugins.asynctelnet.transport"},{"location":"api_docs/transport/plugins/asynctelnet/#classes","text":"","title":"Classes"},{"location":"api_docs/transport/plugins/asynctelnet/#asynctelnettransport","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 Helper class that provides a standard way to create an ABC using inheritance. Scrapli's transport base class Args: base_transport_args: base transport args dataclass Returns: None Raises: N/A Expand source code class AsynctelnetTransport(AsyncTransport): def __init__( self, base_transport_args: BaseTransportArgs, plugin_transport_args: PluginTransportArgs ) -> None: super().__init__(base_transport_args=base_transport_args) self.plugin_transport_args = plugin_transport_args self.stdout: Optional[asyncio.StreamReader] = None self.stdin: Optional[asyncio.StreamWriter] = None self._eof = False self._raw_buf = b\"\" self._cooked_buf = b\"\" self._control_char_sent_counter = 0 self._control_char_sent_limit = 10 def _handle_control_chars_response(self, control_buf: bytes, c: bytes) -> bytes: \"\"\" Handle the actual response to control characters Broken up to be easier to test as well as to appease mr. mccabe Args: control_buf: current control_buf to work with c: currently read control char to process Returns: bytes: updated control_buf Raises: ScrapliConnectionNotOpened: if connection is not opened for some reason \"\"\" if not self.stdin: raise ScrapliConnectionNotOpened # control_buf is empty, lets see if we got a control character if not control_buf: if c != IAC: # add whatever character we read to the \"normal\" output buf so it gets sent off # to the auth method later (username/show prompts may show up here) self._cooked_buf += c else: # we got a control character, put it into the control_buf control_buf += c elif len(control_buf) == 1 and c in (DO, DONT, WILL, WONT): # control buf already has the IAC byte loaded, if the next char is DO/DONT/WILL/WONT # add that into the control buffer and move on control_buf += c elif len(control_buf) == 2: # control buffer is already loaded with IAC and directive, we now have an option to # deal with, create teh base command out of the existing buffer then reset the buf # for the next go around cmd = control_buf[1:2] control_buf = b\"\" if (cmd == DO) and (c == SUPPRESS_GO_AHEAD): # if server says do suppress go ahead we say will for that option self.stdin.write(IAC + WILL + c) elif cmd in (DO, DONT): # if server says do/dont we always say wont for that option self.stdin.write(IAC + WONT + c) elif cmd == WILL: # if server says will we always say do for that option self.stdin.write(IAC + DO + c) elif cmd == WONT: # if server says wont we always say dont for that option self.stdin.write(IAC + DONT + c) return control_buf def _handle_control_chars(self) -> None: \"\"\" Handle control characters -- nearly identical to CPython telnetlib Basically we want to read and \"decline\" any and all control options that the server proposes to us -- so if they say \"DO\" XYZ directive, we say \"DONT\", if they say \"WILL\" we say \"WONT\". Args: N/A Returns: None Raises: ScrapliConnectionNotOpened: if connection is not opened for some reason ScrapliConnectionNotOpened: if we read an empty byte string from the reader -- this indicates the server sent an EOF -- see #142 \"\"\" if not self.stdout: raise ScrapliConnectionNotOpened # control_buf is the buffer for control characters, we reset this after being \"done\" with # responding to a control sequence, so it always represents the \"current\" control sequence # we are working on responding to control_buf = b\"\" while self._raw_buf: c, self._raw_buf = self._raw_buf[:1], self._raw_buf[1:] if not c: raise ScrapliConnectionNotOpened(\"server returned EOF, connection not opened\") control_buf = self._handle_control_chars_response(control_buf=control_buf, c=c) async def open(self) -> None: self._pre_open_closing_log(closing=False) try: fut = asyncio.open_connection( host=self._base_transport_args.host, port=self._base_transport_args.port ) self.stdout, self.stdin = await asyncio.wait_for( fut, timeout=self._base_transport_args.timeout_socket ) except ConnectionError as exc: msg = f\"Failed to open telnet session to host {self._base_transport_args.host}\" if \"connection refused\" in str(exc).lower(): msg = ( f\"Failed to open telnet session to host {self._base_transport_args.host}, \" \"connection refused\" ) raise ScrapliConnectionError(msg) from exc except (OSError, socket.gaierror) as exc: msg = ( f\"Failed to open telnet session to host {self._base_transport_args.host} -- \" \"do you have a bad host/port?\" ) raise ScrapliConnectionError(msg) from exc except asyncio.TimeoutError as exc: msg = \"timed out opening connection to device\" self.logger.critical(msg) raise ScrapliAuthenticationFailed(msg) from exc self._post_open_closing_log(closing=False) def close(self) -> None: self._pre_open_closing_log(closing=True) if self.stdin: self.stdin.close() try: self.stdin.close() except AttributeError: # wait closed only in 3.7+... unclear if we should be doing something else for 3.6? # it doesnt seem to hurt anything... pass self.stdin = None self.stdout = None self._post_open_closing_log(closing=True) def isalive(self) -> bool: if not self.stdin or not self.stdout: return False return not self.stdout.at_eof() async def _read(self, n: int = 65535) -> None: if not self.stdout: raise ScrapliConnectionNotOpened if not self._raw_buf: try: buf = await self.stdout.read(n) self._eof = not buf if self._control_char_sent_counter < self._control_char_sent_limit: self._raw_buf += buf else: self._cooked_buf += buf except EOFError as exc: raise ScrapliConnectionError( \"encountered EOF reading from transport; typically means the device closed the \" \"connection\" ) from exc @timeout_wrapper async def read(self) -> bytes: if not self.stdout: raise ScrapliConnectionNotOpened if self._control_char_sent_counter < self._control_char_sent_limit: self._handle_control_chars() while not self._cooked_buf and not self._eof: await self._read() if self._control_char_sent_counter < self._control_char_sent_limit: self._handle_control_chars() buf = self._cooked_buf self._cooked_buf = b\"\" return buf def write(self, channel_input: bytes) -> None: if not self.stdin: raise ScrapliConnectionNotOpened self.stdin.write(channel_input)","title":"AsynctelnetTransport"},{"location":"api_docs/transport/plugins/asynctelnet/#ancestors-in-mro","text":"scrapli.transport.base.async_transport.AsyncTransport scrapli.transport.base.base_transport.BaseTransport abc.ABC","title":"Ancestors (in MRO)"},{"location":"api_docs/transport/plugins/asynctelnet/#plugintransportargs","text":"1 PluginTransportArgs() Expand source code @dataclass() class PluginTransportArgs(BasePluginTransportArgs): pass","title":"PluginTransportArgs"},{"location":"api_docs/transport/plugins/asynctelnet/#ancestors-in-mro_1","text":"scrapli.transport.base.base_transport.BasePluginTransportArgs","title":"Ancestors (in MRO)"},{"location":"api_docs/transport/plugins/paramiko/","text":"window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting()) Module scrapli.transport.plugins.paramiko.transport \u00b6 scrapli.transport.plugins.paramiko.transport Expand source code \"\"\"scrapli.transport.plugins.paramiko.transport\"\"\" from dataclasses import dataclass from typing import Optional from paramiko import Channel from paramiko import Transport as _ParamikoTransport from paramiko.rsakey import RSAKey from paramiko.ssh_exception import AuthenticationException from scrapli.exceptions import ( ScrapliAuthenticationFailed, ScrapliConnectionError, ScrapliConnectionNotOpened, ) from scrapli.ssh_config import SSHKnownHosts from scrapli.transport.base import BasePluginTransportArgs, BaseTransportArgs, Transport from scrapli.transport.base.base_socket import Socket @dataclass() class PluginTransportArgs(BasePluginTransportArgs): auth_username: str auth_password: str = \"\" auth_private_key: str = \"\" auth_strict_key: bool = True ssh_config_file: str = \"\" ssh_known_hosts_file: str = \"\" class ParamikoTransport(Transport): def __init__( self, base_transport_args: BaseTransportArgs, plugin_transport_args: PluginTransportArgs ) -> None: \"\"\" Paramiko transport plugin. This transport supports some additional `transport_options` to control behavior -- `enable_rsa2` is bool defaulting to `False`. Please see the paramiko changelog entry for version 2.9.0 here: https://www.paramiko.org/changelog.html. Basically, even though scrapli *tries* to default to safe/sane/secure things where possible, it is also focused on *network* devices which maybe sometimes are less up-to-date/safe/secure than we'd all hope. In this case paramiko 2.9.0 defaults to supporting only RSA2based servers, which, causes issues for the devices in the test suite, and likely for many other network devices out there. So, by default, we'll *disable* this. If you wish to enable this you can simply pass `True` to this transport option! Args: base_transport_args: scrapli base transport plugin arguments plugin_transport_args: paramiko ssh specific transport plugin arguments Returns: N/A Raises: N/A \"\"\" super().__init__(base_transport_args=base_transport_args) self.plugin_transport_args = plugin_transport_args self.socket: Optional[Socket] = None self.session: Optional[_ParamikoTransport] = None self.session_channel: Optional[Channel] = None def open(self) -> None: self._pre_open_closing_log(closing=False) if not self.socket: self.socket = Socket( host=self._base_transport_args.host, port=self._base_transport_args.port, timeout=self._base_transport_args.timeout_socket, ) if not self.socket.isalive(): self.socket.open() try: self.session = _ParamikoTransport(self.socket.sock) # type: ignore self.session.start_client() except Exception as exc: self.logger.critical(\"failed to complete handshake with host\") raise ScrapliConnectionNotOpened from exc if self.plugin_transport_args.auth_strict_key: self.logger.debug(f\"attempting to validate {self._base_transport_args.host} public key\") self._verify_key() self._authenticate() if not self.session.is_authenticated(): msg = \"all authentication methods failed\" self.logger.critical(msg) raise ScrapliAuthenticationFailed(msg) self._open_channel() self._post_open_closing_log(closing=False) def _verify_key(self) -> None: \"\"\" Verify target host public key, raise exception if invalid/unknown Args: N/A Returns: None Raises: ScrapliConnectionNotOpened: if session is unopened/None ScrapliAuthenticationFailed: if host is not in known hosts ScrapliAuthenticationFailed: if host is in known hosts but public key does not match \"\"\" if not self.session: raise ScrapliConnectionNotOpened known_hosts = SSHKnownHosts(self.plugin_transport_args.ssh_known_hosts_file) known_host_public_key = known_hosts.lookup(self._base_transport_args.host) if not known_host_public_key: raise ScrapliAuthenticationFailed( f\"{self._base_transport_args.host} not in known_hosts!\" ) remote_server_key = self.session.get_remote_server_key() remote_public_key = remote_server_key.get_base64() if known_host_public_key[\"public_key\"] != remote_public_key: raise ScrapliAuthenticationFailed( f\"{self._base_transport_args.host} in known_hosts but public key does not match!\" ) def _authenticate(self) -> None: \"\"\" Parent method to try all means of authentication Args: N/A Returns: None Raises: ScrapliConnectionNotOpened: if session is unopened/None ScrapliAuthenticationFailed: if auth fails \"\"\" if not self.session: raise ScrapliConnectionNotOpened if self.plugin_transport_args.auth_private_key: self._authenticate_public_key() if self.session.is_authenticated(): return if ( not self.plugin_transport_args.auth_password or not self.plugin_transport_args.auth_username ): msg = ( f\"Failed to authenticate to host {self._base_transport_args.host} with private \" f\"key `{self.plugin_transport_args.auth_private_key}`. Unable to continue \" \"authentication, missing username, password, or both.\" ) raise ScrapliAuthenticationFailed(msg) self._authenticate_password() def _authenticate_public_key(self) -> None: \"\"\" Attempt to authenticate with public key authentication Args: N/A Returns: None Raises: ScrapliConnectionNotOpened: if session is unopened/None \"\"\" if not self.session: raise ScrapliConnectionNotOpened if self._base_transport_args.transport_options.get(\"enable_rsa2\", False) is False: # do this for \"keys\" and \"pubkeys\": https://github.com/paramiko/paramiko/issues/1984 self.session.disabled_algorithms = { \"keys\": [\"rsa-sha2-256\", \"rsa-sha2-512\"], \"pubkeys\": [\"rsa-sha2-256\", \"rsa-sha2-512\"], } try: paramiko_key = RSAKey(filename=self.plugin_transport_args.auth_private_key) self.session.auth_publickey( username=self.plugin_transport_args.auth_username, key=paramiko_key ) except AuthenticationException: pass except Exception: # pylint: disable=W0703 pass def _authenticate_password(self) -> None: \"\"\" Attempt to authenticate with password authentication Args: N/A Returns: None Raises: ScrapliConnectionNotOpened: if session is unopened/None \"\"\" if not self.session: raise ScrapliConnectionNotOpened try: self.session.auth_password( username=self.plugin_transport_args.auth_username, password=self.plugin_transport_args.auth_password, ) return except AuthenticationException: pass def _open_channel(self) -> None: \"\"\" Open channel, acquire pty, request interactive shell Args: N/A Returns: None Raises: ScrapliConnectionNotOpened: if session is unopened/None \"\"\" if not self.session: raise ScrapliConnectionNotOpened self.session_channel = self.session.open_session() self._set_timeout(self._base_transport_args.timeout_transport) self.session_channel.get_pty() self.session_channel.invoke_shell() def close(self) -> None: self._pre_open_closing_log(closing=True) if self.session_channel: self.session_channel.close() if self.socket: self.socket.close() self.session = None self.session_channel = None self._post_open_closing_log(closing=True) def isalive(self) -> bool: if not self.session: return False _isalive: bool = self.session.is_alive() return _isalive def read(self) -> bytes: if not self.session_channel: raise ScrapliConnectionNotOpened try: buf: bytes = self.session_channel.recv(65535) except Exception as exc: msg = ( \"encountered EOF reading from transport; typically means the device closed the \" \"connection\" ) self.logger.critical(msg) raise ScrapliConnectionError(msg) from exc return buf def write(self, channel_input: bytes) -> None: if not self.session_channel: raise ScrapliConnectionNotOpened self.session_channel.send(channel_input) def _set_timeout(self, value: float) -> None: \"\"\" Set session object timeout value Args: value: timeout in seconds Returns: None Raises: ScrapliConnectionNotOpened: if session is unopened/None \"\"\" if not self.session_channel: raise ScrapliConnectionNotOpened self.session_channel.settimeout(value) Classes \u00b6 ParamikoTransport \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 Helper class that provides a standard way to create an ABC using inheritance. Paramiko transport plugin. This transport supports some additional `transport_options` to control behavior -- `enable_rsa2` is bool defaulting to `False`. Please see the paramiko changelog entry for version 2.9.0 here: https://www.paramiko.org/changelog.html. Basically, even though scrapli *tries* to default to safe/sane/secure things where possible, it is also focused on *network* devices which maybe sometimes are less up-to-date/safe/secure than we'd all hope. In this case paramiko 2.9.0 defaults to supporting only RSA2based servers, which, causes issues for the devices in the test suite, and likely for many other network devices out there. So, by default, we'll *disable* this. If you wish to enable this you can simply pass `True` to this transport option! Args: base_transport_args: scrapli base transport plugin arguments plugin_transport_args: paramiko ssh specific transport plugin arguments Returns: N/A Raises: N/A Expand source code class ParamikoTransport(Transport): def __init__( self, base_transport_args: BaseTransportArgs, plugin_transport_args: PluginTransportArgs ) -> None: \"\"\" Paramiko transport plugin. This transport supports some additional `transport_options` to control behavior -- `enable_rsa2` is bool defaulting to `False`. Please see the paramiko changelog entry for version 2.9.0 here: https://www.paramiko.org/changelog.html. Basically, even though scrapli *tries* to default to safe/sane/secure things where possible, it is also focused on *network* devices which maybe sometimes are less up-to-date/safe/secure than we'd all hope. In this case paramiko 2.9.0 defaults to supporting only RSA2based servers, which, causes issues for the devices in the test suite, and likely for many other network devices out there. So, by default, we'll *disable* this. If you wish to enable this you can simply pass `True` to this transport option! Args: base_transport_args: scrapli base transport plugin arguments plugin_transport_args: paramiko ssh specific transport plugin arguments Returns: N/A Raises: N/A \"\"\" super().__init__(base_transport_args=base_transport_args) self.plugin_transport_args = plugin_transport_args self.socket: Optional[Socket] = None self.session: Optional[_ParamikoTransport] = None self.session_channel: Optional[Channel] = None def open(self) -> None: self._pre_open_closing_log(closing=False) if not self.socket: self.socket = Socket( host=self._base_transport_args.host, port=self._base_transport_args.port, timeout=self._base_transport_args.timeout_socket, ) if not self.socket.isalive(): self.socket.open() try: self.session = _ParamikoTransport(self.socket.sock) # type: ignore self.session.start_client() except Exception as exc: self.logger.critical(\"failed to complete handshake with host\") raise ScrapliConnectionNotOpened from exc if self.plugin_transport_args.auth_strict_key: self.logger.debug(f\"attempting to validate {self._base_transport_args.host} public key\") self._verify_key() self._authenticate() if not self.session.is_authenticated(): msg = \"all authentication methods failed\" self.logger.critical(msg) raise ScrapliAuthenticationFailed(msg) self._open_channel() self._post_open_closing_log(closing=False) def _verify_key(self) -> None: \"\"\" Verify target host public key, raise exception if invalid/unknown Args: N/A Returns: None Raises: ScrapliConnectionNotOpened: if session is unopened/None ScrapliAuthenticationFailed: if host is not in known hosts ScrapliAuthenticationFailed: if host is in known hosts but public key does not match \"\"\" if not self.session: raise ScrapliConnectionNotOpened known_hosts = SSHKnownHosts(self.plugin_transport_args.ssh_known_hosts_file) known_host_public_key = known_hosts.lookup(self._base_transport_args.host) if not known_host_public_key: raise ScrapliAuthenticationFailed( f\"{self._base_transport_args.host} not in known_hosts!\" ) remote_server_key = self.session.get_remote_server_key() remote_public_key = remote_server_key.get_base64() if known_host_public_key[\"public_key\"] != remote_public_key: raise ScrapliAuthenticationFailed( f\"{self._base_transport_args.host} in known_hosts but public key does not match!\" ) def _authenticate(self) -> None: \"\"\" Parent method to try all means of authentication Args: N/A Returns: None Raises: ScrapliConnectionNotOpened: if session is unopened/None ScrapliAuthenticationFailed: if auth fails \"\"\" if not self.session: raise ScrapliConnectionNotOpened if self.plugin_transport_args.auth_private_key: self._authenticate_public_key() if self.session.is_authenticated(): return if ( not self.plugin_transport_args.auth_password or not self.plugin_transport_args.auth_username ): msg = ( f\"Failed to authenticate to host {self._base_transport_args.host} with private \" f\"key `{self.plugin_transport_args.auth_private_key}`. Unable to continue \" \"authentication, missing username, password, or both.\" ) raise ScrapliAuthenticationFailed(msg) self._authenticate_password() def _authenticate_public_key(self) -> None: \"\"\" Attempt to authenticate with public key authentication Args: N/A Returns: None Raises: ScrapliConnectionNotOpened: if session is unopened/None \"\"\" if not self.session: raise ScrapliConnectionNotOpened if self._base_transport_args.transport_options.get(\"enable_rsa2\", False) is False: # do this for \"keys\" and \"pubkeys\": https://github.com/paramiko/paramiko/issues/1984 self.session.disabled_algorithms = { \"keys\": [\"rsa-sha2-256\", \"rsa-sha2-512\"], \"pubkeys\": [\"rsa-sha2-256\", \"rsa-sha2-512\"], } try: paramiko_key = RSAKey(filename=self.plugin_transport_args.auth_private_key) self.session.auth_publickey( username=self.plugin_transport_args.auth_username, key=paramiko_key ) except AuthenticationException: pass except Exception: # pylint: disable=W0703 pass def _authenticate_password(self) -> None: \"\"\" Attempt to authenticate with password authentication Args: N/A Returns: None Raises: ScrapliConnectionNotOpened: if session is unopened/None \"\"\" if not self.session: raise ScrapliConnectionNotOpened try: self.session.auth_password( username=self.plugin_transport_args.auth_username, password=self.plugin_transport_args.auth_password, ) return except AuthenticationException: pass def _open_channel(self) -> None: \"\"\" Open channel, acquire pty, request interactive shell Args: N/A Returns: None Raises: ScrapliConnectionNotOpened: if session is unopened/None \"\"\" if not self.session: raise ScrapliConnectionNotOpened self.session_channel = self.session.open_session() self._set_timeout(self._base_transport_args.timeout_transport) self.session_channel.get_pty() self.session_channel.invoke_shell() def close(self) -> None: self._pre_open_closing_log(closing=True) if self.session_channel: self.session_channel.close() if self.socket: self.socket.close() self.session = None self.session_channel = None self._post_open_closing_log(closing=True) def isalive(self) -> bool: if not self.session: return False _isalive: bool = self.session.is_alive() return _isalive def read(self) -> bytes: if not self.session_channel: raise ScrapliConnectionNotOpened try: buf: bytes = self.session_channel.recv(65535) except Exception as exc: msg = ( \"encountered EOF reading from transport; typically means the device closed the \" \"connection\" ) self.logger.critical(msg) raise ScrapliConnectionError(msg) from exc return buf def write(self, channel_input: bytes) -> None: if not self.session_channel: raise ScrapliConnectionNotOpened self.session_channel.send(channel_input) def _set_timeout(self, value: float) -> None: \"\"\" Set session object timeout value Args: value: timeout in seconds Returns: None Raises: ScrapliConnectionNotOpened: if session is unopened/None \"\"\" if not self.session_channel: raise ScrapliConnectionNotOpened self.session_channel.settimeout(value) Ancestors (in MRO) \u00b6 scrapli.transport.base.sync_transport.Transport scrapli.transport.base.base_transport.BaseTransport abc.ABC PluginTransportArgs \u00b6 1 PluginTransportArgs(auth_username: str, auth_password: str = '', auth_private_key: str = '', auth_strict_key: bool = True, ssh_config_file: str = '', ssh_known_hosts_file: str = '') Expand source code @dataclass() class PluginTransportArgs(BasePluginTransportArgs): auth_username: str auth_password: str = \"\" auth_private_key: str = \"\" auth_strict_key: bool = True ssh_config_file: str = \"\" ssh_known_hosts_file: str = \"\" Ancestors (in MRO) \u00b6 scrapli.transport.base.base_transport.BasePluginTransportArgs Class variables \u00b6 auth_password: str auth_private_key: str auth_strict_key: bool auth_username: str ssh_config_file: str ssh_known_hosts_file: str","title":"Paramiko"},{"location":"api_docs/transport/plugins/paramiko/#module-scraplitransportpluginsparamikotransport","text":"scrapli.transport.plugins.paramiko.transport Expand source code \"\"\"scrapli.transport.plugins.paramiko.transport\"\"\" from dataclasses import dataclass from typing import Optional from paramiko import Channel from paramiko import Transport as _ParamikoTransport from paramiko.rsakey import RSAKey from paramiko.ssh_exception import AuthenticationException from scrapli.exceptions import ( ScrapliAuthenticationFailed, ScrapliConnectionError, ScrapliConnectionNotOpened, ) from scrapli.ssh_config import SSHKnownHosts from scrapli.transport.base import BasePluginTransportArgs, BaseTransportArgs, Transport from scrapli.transport.base.base_socket import Socket @dataclass() class PluginTransportArgs(BasePluginTransportArgs): auth_username: str auth_password: str = \"\" auth_private_key: str = \"\" auth_strict_key: bool = True ssh_config_file: str = \"\" ssh_known_hosts_file: str = \"\" class ParamikoTransport(Transport): def __init__( self, base_transport_args: BaseTransportArgs, plugin_transport_args: PluginTransportArgs ) -> None: \"\"\" Paramiko transport plugin. This transport supports some additional `transport_options` to control behavior -- `enable_rsa2` is bool defaulting to `False`. Please see the paramiko changelog entry for version 2.9.0 here: https://www.paramiko.org/changelog.html. Basically, even though scrapli *tries* to default to safe/sane/secure things where possible, it is also focused on *network* devices which maybe sometimes are less up-to-date/safe/secure than we'd all hope. In this case paramiko 2.9.0 defaults to supporting only RSA2based servers, which, causes issues for the devices in the test suite, and likely for many other network devices out there. So, by default, we'll *disable* this. If you wish to enable this you can simply pass `True` to this transport option! Args: base_transport_args: scrapli base transport plugin arguments plugin_transport_args: paramiko ssh specific transport plugin arguments Returns: N/A Raises: N/A \"\"\" super().__init__(base_transport_args=base_transport_args) self.plugin_transport_args = plugin_transport_args self.socket: Optional[Socket] = None self.session: Optional[_ParamikoTransport] = None self.session_channel: Optional[Channel] = None def open(self) -> None: self._pre_open_closing_log(closing=False) if not self.socket: self.socket = Socket( host=self._base_transport_args.host, port=self._base_transport_args.port, timeout=self._base_transport_args.timeout_socket, ) if not self.socket.isalive(): self.socket.open() try: self.session = _ParamikoTransport(self.socket.sock) # type: ignore self.session.start_client() except Exception as exc: self.logger.critical(\"failed to complete handshake with host\") raise ScrapliConnectionNotOpened from exc if self.plugin_transport_args.auth_strict_key: self.logger.debug(f\"attempting to validate {self._base_transport_args.host} public key\") self._verify_key() self._authenticate() if not self.session.is_authenticated(): msg = \"all authentication methods failed\" self.logger.critical(msg) raise ScrapliAuthenticationFailed(msg) self._open_channel() self._post_open_closing_log(closing=False) def _verify_key(self) -> None: \"\"\" Verify target host public key, raise exception if invalid/unknown Args: N/A Returns: None Raises: ScrapliConnectionNotOpened: if session is unopened/None ScrapliAuthenticationFailed: if host is not in known hosts ScrapliAuthenticationFailed: if host is in known hosts but public key does not match \"\"\" if not self.session: raise ScrapliConnectionNotOpened known_hosts = SSHKnownHosts(self.plugin_transport_args.ssh_known_hosts_file) known_host_public_key = known_hosts.lookup(self._base_transport_args.host) if not known_host_public_key: raise ScrapliAuthenticationFailed( f\"{self._base_transport_args.host} not in known_hosts!\" ) remote_server_key = self.session.get_remote_server_key() remote_public_key = remote_server_key.get_base64() if known_host_public_key[\"public_key\"] != remote_public_key: raise ScrapliAuthenticationFailed( f\"{self._base_transport_args.host} in known_hosts but public key does not match!\" ) def _authenticate(self) -> None: \"\"\" Parent method to try all means of authentication Args: N/A Returns: None Raises: ScrapliConnectionNotOpened: if session is unopened/None ScrapliAuthenticationFailed: if auth fails \"\"\" if not self.session: raise ScrapliConnectionNotOpened if self.plugin_transport_args.auth_private_key: self._authenticate_public_key() if self.session.is_authenticated(): return if ( not self.plugin_transport_args.auth_password or not self.plugin_transport_args.auth_username ): msg = ( f\"Failed to authenticate to host {self._base_transport_args.host} with private \" f\"key `{self.plugin_transport_args.auth_private_key}`. Unable to continue \" \"authentication, missing username, password, or both.\" ) raise ScrapliAuthenticationFailed(msg) self._authenticate_password() def _authenticate_public_key(self) -> None: \"\"\" Attempt to authenticate with public key authentication Args: N/A Returns: None Raises: ScrapliConnectionNotOpened: if session is unopened/None \"\"\" if not self.session: raise ScrapliConnectionNotOpened if self._base_transport_args.transport_options.get(\"enable_rsa2\", False) is False: # do this for \"keys\" and \"pubkeys\": https://github.com/paramiko/paramiko/issues/1984 self.session.disabled_algorithms = { \"keys\": [\"rsa-sha2-256\", \"rsa-sha2-512\"], \"pubkeys\": [\"rsa-sha2-256\", \"rsa-sha2-512\"], } try: paramiko_key = RSAKey(filename=self.plugin_transport_args.auth_private_key) self.session.auth_publickey( username=self.plugin_transport_args.auth_username, key=paramiko_key ) except AuthenticationException: pass except Exception: # pylint: disable=W0703 pass def _authenticate_password(self) -> None: \"\"\" Attempt to authenticate with password authentication Args: N/A Returns: None Raises: ScrapliConnectionNotOpened: if session is unopened/None \"\"\" if not self.session: raise ScrapliConnectionNotOpened try: self.session.auth_password( username=self.plugin_transport_args.auth_username, password=self.plugin_transport_args.auth_password, ) return except AuthenticationException: pass def _open_channel(self) -> None: \"\"\" Open channel, acquire pty, request interactive shell Args: N/A Returns: None Raises: ScrapliConnectionNotOpened: if session is unopened/None \"\"\" if not self.session: raise ScrapliConnectionNotOpened self.session_channel = self.session.open_session() self._set_timeout(self._base_transport_args.timeout_transport) self.session_channel.get_pty() self.session_channel.invoke_shell() def close(self) -> None: self._pre_open_closing_log(closing=True) if self.session_channel: self.session_channel.close() if self.socket: self.socket.close() self.session = None self.session_channel = None self._post_open_closing_log(closing=True) def isalive(self) -> bool: if not self.session: return False _isalive: bool = self.session.is_alive() return _isalive def read(self) -> bytes: if not self.session_channel: raise ScrapliConnectionNotOpened try: buf: bytes = self.session_channel.recv(65535) except Exception as exc: msg = ( \"encountered EOF reading from transport; typically means the device closed the \" \"connection\" ) self.logger.critical(msg) raise ScrapliConnectionError(msg) from exc return buf def write(self, channel_input: bytes) -> None: if not self.session_channel: raise ScrapliConnectionNotOpened self.session_channel.send(channel_input) def _set_timeout(self, value: float) -> None: \"\"\" Set session object timeout value Args: value: timeout in seconds Returns: None Raises: ScrapliConnectionNotOpened: if session is unopened/None \"\"\" if not self.session_channel: raise ScrapliConnectionNotOpened self.session_channel.settimeout(value)","title":"Module scrapli.transport.plugins.paramiko.transport"},{"location":"api_docs/transport/plugins/paramiko/#classes","text":"","title":"Classes"},{"location":"api_docs/transport/plugins/paramiko/#paramikotransport","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 Helper class that provides a standard way to create an ABC using inheritance. Paramiko transport plugin. This transport supports some additional `transport_options` to control behavior -- `enable_rsa2` is bool defaulting to `False`. Please see the paramiko changelog entry for version 2.9.0 here: https://www.paramiko.org/changelog.html. Basically, even though scrapli *tries* to default to safe/sane/secure things where possible, it is also focused on *network* devices which maybe sometimes are less up-to-date/safe/secure than we'd all hope. In this case paramiko 2.9.0 defaults to supporting only RSA2based servers, which, causes issues for the devices in the test suite, and likely for many other network devices out there. So, by default, we'll *disable* this. If you wish to enable this you can simply pass `True` to this transport option! Args: base_transport_args: scrapli base transport plugin arguments plugin_transport_args: paramiko ssh specific transport plugin arguments Returns: N/A Raises: N/A Expand source code class ParamikoTransport(Transport): def __init__( self, base_transport_args: BaseTransportArgs, plugin_transport_args: PluginTransportArgs ) -> None: \"\"\" Paramiko transport plugin. This transport supports some additional `transport_options` to control behavior -- `enable_rsa2` is bool defaulting to `False`. Please see the paramiko changelog entry for version 2.9.0 here: https://www.paramiko.org/changelog.html. Basically, even though scrapli *tries* to default to safe/sane/secure things where possible, it is also focused on *network* devices which maybe sometimes are less up-to-date/safe/secure than we'd all hope. In this case paramiko 2.9.0 defaults to supporting only RSA2based servers, which, causes issues for the devices in the test suite, and likely for many other network devices out there. So, by default, we'll *disable* this. If you wish to enable this you can simply pass `True` to this transport option! Args: base_transport_args: scrapli base transport plugin arguments plugin_transport_args: paramiko ssh specific transport plugin arguments Returns: N/A Raises: N/A \"\"\" super().__init__(base_transport_args=base_transport_args) self.plugin_transport_args = plugin_transport_args self.socket: Optional[Socket] = None self.session: Optional[_ParamikoTransport] = None self.session_channel: Optional[Channel] = None def open(self) -> None: self._pre_open_closing_log(closing=False) if not self.socket: self.socket = Socket( host=self._base_transport_args.host, port=self._base_transport_args.port, timeout=self._base_transport_args.timeout_socket, ) if not self.socket.isalive(): self.socket.open() try: self.session = _ParamikoTransport(self.socket.sock) # type: ignore self.session.start_client() except Exception as exc: self.logger.critical(\"failed to complete handshake with host\") raise ScrapliConnectionNotOpened from exc if self.plugin_transport_args.auth_strict_key: self.logger.debug(f\"attempting to validate {self._base_transport_args.host} public key\") self._verify_key() self._authenticate() if not self.session.is_authenticated(): msg = \"all authentication methods failed\" self.logger.critical(msg) raise ScrapliAuthenticationFailed(msg) self._open_channel() self._post_open_closing_log(closing=False) def _verify_key(self) -> None: \"\"\" Verify target host public key, raise exception if invalid/unknown Args: N/A Returns: None Raises: ScrapliConnectionNotOpened: if session is unopened/None ScrapliAuthenticationFailed: if host is not in known hosts ScrapliAuthenticationFailed: if host is in known hosts but public key does not match \"\"\" if not self.session: raise ScrapliConnectionNotOpened known_hosts = SSHKnownHosts(self.plugin_transport_args.ssh_known_hosts_file) known_host_public_key = known_hosts.lookup(self._base_transport_args.host) if not known_host_public_key: raise ScrapliAuthenticationFailed( f\"{self._base_transport_args.host} not in known_hosts!\" ) remote_server_key = self.session.get_remote_server_key() remote_public_key = remote_server_key.get_base64() if known_host_public_key[\"public_key\"] != remote_public_key: raise ScrapliAuthenticationFailed( f\"{self._base_transport_args.host} in known_hosts but public key does not match!\" ) def _authenticate(self) -> None: \"\"\" Parent method to try all means of authentication Args: N/A Returns: None Raises: ScrapliConnectionNotOpened: if session is unopened/None ScrapliAuthenticationFailed: if auth fails \"\"\" if not self.session: raise ScrapliConnectionNotOpened if self.plugin_transport_args.auth_private_key: self._authenticate_public_key() if self.session.is_authenticated(): return if ( not self.plugin_transport_args.auth_password or not self.plugin_transport_args.auth_username ): msg = ( f\"Failed to authenticate to host {self._base_transport_args.host} with private \" f\"key `{self.plugin_transport_args.auth_private_key}`. Unable to continue \" \"authentication, missing username, password, or both.\" ) raise ScrapliAuthenticationFailed(msg) self._authenticate_password() def _authenticate_public_key(self) -> None: \"\"\" Attempt to authenticate with public key authentication Args: N/A Returns: None Raises: ScrapliConnectionNotOpened: if session is unopened/None \"\"\" if not self.session: raise ScrapliConnectionNotOpened if self._base_transport_args.transport_options.get(\"enable_rsa2\", False) is False: # do this for \"keys\" and \"pubkeys\": https://github.com/paramiko/paramiko/issues/1984 self.session.disabled_algorithms = { \"keys\": [\"rsa-sha2-256\", \"rsa-sha2-512\"], \"pubkeys\": [\"rsa-sha2-256\", \"rsa-sha2-512\"], } try: paramiko_key = RSAKey(filename=self.plugin_transport_args.auth_private_key) self.session.auth_publickey( username=self.plugin_transport_args.auth_username, key=paramiko_key ) except AuthenticationException: pass except Exception: # pylint: disable=W0703 pass def _authenticate_password(self) -> None: \"\"\" Attempt to authenticate with password authentication Args: N/A Returns: None Raises: ScrapliConnectionNotOpened: if session is unopened/None \"\"\" if not self.session: raise ScrapliConnectionNotOpened try: self.session.auth_password( username=self.plugin_transport_args.auth_username, password=self.plugin_transport_args.auth_password, ) return except AuthenticationException: pass def _open_channel(self) -> None: \"\"\" Open channel, acquire pty, request interactive shell Args: N/A Returns: None Raises: ScrapliConnectionNotOpened: if session is unopened/None \"\"\" if not self.session: raise ScrapliConnectionNotOpened self.session_channel = self.session.open_session() self._set_timeout(self._base_transport_args.timeout_transport) self.session_channel.get_pty() self.session_channel.invoke_shell() def close(self) -> None: self._pre_open_closing_log(closing=True) if self.session_channel: self.session_channel.close() if self.socket: self.socket.close() self.session = None self.session_channel = None self._post_open_closing_log(closing=True) def isalive(self) -> bool: if not self.session: return False _isalive: bool = self.session.is_alive() return _isalive def read(self) -> bytes: if not self.session_channel: raise ScrapliConnectionNotOpened try: buf: bytes = self.session_channel.recv(65535) except Exception as exc: msg = ( \"encountered EOF reading from transport; typically means the device closed the \" \"connection\" ) self.logger.critical(msg) raise ScrapliConnectionError(msg) from exc return buf def write(self, channel_input: bytes) -> None: if not self.session_channel: raise ScrapliConnectionNotOpened self.session_channel.send(channel_input) def _set_timeout(self, value: float) -> None: \"\"\" Set session object timeout value Args: value: timeout in seconds Returns: None Raises: ScrapliConnectionNotOpened: if session is unopened/None \"\"\" if not self.session_channel: raise ScrapliConnectionNotOpened self.session_channel.settimeout(value)","title":"ParamikoTransport"},{"location":"api_docs/transport/plugins/paramiko/#ancestors-in-mro","text":"scrapli.transport.base.sync_transport.Transport scrapli.transport.base.base_transport.BaseTransport abc.ABC","title":"Ancestors (in MRO)"},{"location":"api_docs/transport/plugins/paramiko/#plugintransportargs","text":"1 PluginTransportArgs(auth_username: str, auth_password: str = '', auth_private_key: str = '', auth_strict_key: bool = True, ssh_config_file: str = '', ssh_known_hosts_file: str = '') Expand source code @dataclass() class PluginTransportArgs(BasePluginTransportArgs): auth_username: str auth_password: str = \"\" auth_private_key: str = \"\" auth_strict_key: bool = True ssh_config_file: str = \"\" ssh_known_hosts_file: str = \"\"","title":"PluginTransportArgs"},{"location":"api_docs/transport/plugins/paramiko/#ancestors-in-mro_1","text":"scrapli.transport.base.base_transport.BasePluginTransportArgs","title":"Ancestors (in MRO)"},{"location":"api_docs/transport/plugins/paramiko/#class-variables","text":"auth_password: str auth_private_key: str auth_strict_key: bool auth_username: str ssh_config_file: str ssh_known_hosts_file: str","title":"Class variables"},{"location":"api_docs/transport/plugins/ssh2/","text":"window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting()) Module scrapli.transport.plugins.ssh2.transport \u00b6 scrapli.transport.plugins.ssh2.transport Expand source code \"\"\"scrapli.transport.plugins.ssh2.transport\"\"\" import base64 from dataclasses import dataclass from typing import Optional from ssh2.channel import Channel from ssh2.exceptions import AuthenticationError, SSH2Error from ssh2.session import Session from scrapli.exceptions import ( ScrapliAuthenticationFailed, ScrapliConnectionError, ScrapliConnectionNotOpened, ) from scrapli.ssh_config import SSHKnownHosts from scrapli.transport.base import BasePluginTransportArgs, BaseTransportArgs, Transport from scrapli.transport.base.base_socket import Socket @dataclass() class PluginTransportArgs(BasePluginTransportArgs): auth_username: str auth_password: str = \"\" auth_private_key: str = \"\" auth_private_key_passphrase: str = \"\" auth_strict_key: bool = True ssh_config_file: str = \"\" ssh_known_hosts_file: str = \"\" class Ssh2Transport(Transport): def __init__( self, base_transport_args: BaseTransportArgs, plugin_transport_args: PluginTransportArgs ) -> None: super().__init__(base_transport_args=base_transport_args) self.plugin_transport_args = plugin_transport_args self.socket: Optional[Socket] = None self.session: Optional[Session] = None self.session_channel: Optional[Channel] = None def open(self) -> None: self._pre_open_closing_log(closing=False) if not self.socket: self.socket = Socket( host=self._base_transport_args.host, port=self._base_transport_args.port, timeout=self._base_transport_args.timeout_socket, ) if not self.socket.isalive(): self.socket.open() self.session = Session() self._set_timeout(value=self._base_transport_args.timeout_transport) try: self.session.handshake(self.socket.sock) except Exception as exc: self.logger.critical(\"failed to complete handshake with host\") raise ScrapliConnectionNotOpened from exc if self.plugin_transport_args.auth_strict_key: self.logger.debug(f\"attempting to validate {self._base_transport_args.host} public key\") self._verify_key() self._authenticate() if not self.session.userauth_authenticated(): msg = \"all authentication methods failed\" self.logger.critical(msg) raise ScrapliAuthenticationFailed(msg) self._open_channel() self._post_open_closing_log(closing=False) def _verify_key(self) -> None: \"\"\" Verify target host public key, raise exception if invalid/unknown Args: N/A Returns: None Raises: ScrapliConnectionNotOpened: if session is unopened/None ScrapliAuthenticationFailed: if public key verification fails \"\"\" if not self.session: raise ScrapliConnectionNotOpened known_hosts = SSHKnownHosts(self.plugin_transport_args.ssh_known_hosts_file) known_host_public_key = known_hosts.lookup(self._base_transport_args.host) if not known_host_public_key: raise ScrapliAuthenticationFailed( f\"{self._base_transport_args.host} not in known_hosts!\" ) remote_server_key_info = self.session.hostkey() encoded_remote_server_key = remote_server_key_info[0] raw_remote_public_key = base64.encodebytes(encoded_remote_server_key) remote_public_key = raw_remote_public_key.replace(b\"\\n\", b\"\").decode() if known_host_public_key[\"public_key\"] != remote_public_key: raise ScrapliAuthenticationFailed( f\"{self._base_transport_args.host} in known_hosts but public key does not match!\" ) def _authenticate(self) -> None: \"\"\" Parent method to try all means of authentication Args: N/A Returns: None Raises: ScrapliConnectionNotOpened: if session is unopened/None ScrapliAuthenticationFailed: if auth fails \"\"\" if not self.session: raise ScrapliConnectionNotOpened if self.plugin_transport_args.auth_private_key: self._authenticate_public_key() if self.session.userauth_authenticated(): return if ( not self.plugin_transport_args.auth_password or not self.plugin_transport_args.auth_username ): msg = ( f\"Failed to authenticate to host {self._base_transport_args.host} with private \" f\"key `{self.plugin_transport_args.auth_private_key}`. Unable to continue \" \"authentication, missing username, password, or both.\" ) raise ScrapliAuthenticationFailed(msg) self._authenticate_password() def _authenticate_public_key(self) -> None: \"\"\" Attempt to authenticate with public key authentication Args: N/A Returns: None Raises: ScrapliConnectionNotOpened: if session is unopened/None \"\"\" if not self.session: raise ScrapliConnectionNotOpened try: self.session.userauth_publickey_fromfile( self.plugin_transport_args.auth_username, self.plugin_transport_args.auth_private_key.encode(), self.plugin_transport_args.auth_private_key_passphrase, ) except (AuthenticationError, SSH2Error): pass def _authenticate_password(self) -> None: \"\"\" Attempt to authenticate with password authentication Args: N/A Returns: None Raises: ScrapliConnectionNotOpened: if session is unopened/None \"\"\" if not self.session: raise ScrapliConnectionNotOpened try: self.session.userauth_password( username=self.plugin_transport_args.auth_username, password=self.plugin_transport_args.auth_password, ) return except AuthenticationError: pass try: self.session.userauth_keyboardinteractive( self.plugin_transport_args.auth_username, self.plugin_transport_args.auth_password ) except AttributeError: msg = ( \"Keyboard interactive authentication may not be supported in your \" \"ssh2-python version.\" ) self.logger.warning(msg) except AuthenticationError: pass def _open_channel(self) -> None: \"\"\" Open channel, acquire pty, request interactive shell Args: N/A Returns: None Raises: ScrapliConnectionNotOpened: if session is unopened/None \"\"\" if not self.session: raise ScrapliConnectionNotOpened self.session_channel = self.session.open_session() self.session_channel.pty() self.session_channel.shell() def close(self) -> None: self._pre_open_closing_log(closing=True) if self.session_channel: self.session_channel.close() if self.socket: self.socket.close() self.session = None self.session_channel = None self._post_open_closing_log(closing=True) def isalive(self) -> bool: if not self.session_channel: return False return not self.session_channel.eof() def read(self) -> bytes: if not self.session_channel: raise ScrapliConnectionNotOpened try: buf: bytes _, buf = self.session_channel.read(65535) except Exception as exc: msg = ( \"encountered EOF reading from transport; typically means the device closed the \" \"connection\" ) self.logger.critical(msg) raise ScrapliConnectionError(msg) from exc return buf def write(self, channel_input: bytes) -> None: if not self.session_channel: raise ScrapliConnectionNotOpened self.session_channel.write(channel_input) def _set_timeout(self, value: float) -> None: \"\"\" Set session object timeout value Args: value: timeout in seconds Returns: None Raises: ScrapliConnectionNotOpened: if session is unopened/None \"\"\" if not self.session: raise ScrapliConnectionNotOpened # ssh2-python expects timeout in milliseconds self.session.set_timeout(value * 1000) Classes \u00b6 PluginTransportArgs \u00b6 1 PluginTransportArgs(auth_username: str, auth_password: str = '', auth_private_key: str = '', auth_private_key_passphrase: str = '', auth_strict_key: bool = True, ssh_config_file: str = '', ssh_known_hosts_file: str = '') Expand source code @dataclass() class PluginTransportArgs(BasePluginTransportArgs): auth_username: str auth_password: str = \"\" auth_private_key: str = \"\" auth_private_key_passphrase: str = \"\" auth_strict_key: bool = True ssh_config_file: str = \"\" ssh_known_hosts_file: str = \"\" Ancestors (in MRO) \u00b6 scrapli.transport.base.base_transport.BasePluginTransportArgs Class variables \u00b6 auth_password: str auth_private_key: str auth_private_key_passphrase: str auth_strict_key: bool auth_username: str ssh_config_file: str ssh_known_hosts_file: str Ssh2Transport \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 Helper class that provides a standard way to create an ABC using inheritance. Scrapli's transport base class Args: base_transport_args: base transport args dataclass Returns: None Raises: N/A Expand source code class Ssh2Transport(Transport): def __init__( self, base_transport_args: BaseTransportArgs, plugin_transport_args: PluginTransportArgs ) -> None: super().__init__(base_transport_args=base_transport_args) self.plugin_transport_args = plugin_transport_args self.socket: Optional[Socket] = None self.session: Optional[Session] = None self.session_channel: Optional[Channel] = None def open(self) -> None: self._pre_open_closing_log(closing=False) if not self.socket: self.socket = Socket( host=self._base_transport_args.host, port=self._base_transport_args.port, timeout=self._base_transport_args.timeout_socket, ) if not self.socket.isalive(): self.socket.open() self.session = Session() self._set_timeout(value=self._base_transport_args.timeout_transport) try: self.session.handshake(self.socket.sock) except Exception as exc: self.logger.critical(\"failed to complete handshake with host\") raise ScrapliConnectionNotOpened from exc if self.plugin_transport_args.auth_strict_key: self.logger.debug(f\"attempting to validate {self._base_transport_args.host} public key\") self._verify_key() self._authenticate() if not self.session.userauth_authenticated(): msg = \"all authentication methods failed\" self.logger.critical(msg) raise ScrapliAuthenticationFailed(msg) self._open_channel() self._post_open_closing_log(closing=False) def _verify_key(self) -> None: \"\"\" Verify target host public key, raise exception if invalid/unknown Args: N/A Returns: None Raises: ScrapliConnectionNotOpened: if session is unopened/None ScrapliAuthenticationFailed: if public key verification fails \"\"\" if not self.session: raise ScrapliConnectionNotOpened known_hosts = SSHKnownHosts(self.plugin_transport_args.ssh_known_hosts_file) known_host_public_key = known_hosts.lookup(self._base_transport_args.host) if not known_host_public_key: raise ScrapliAuthenticationFailed( f\"{self._base_transport_args.host} not in known_hosts!\" ) remote_server_key_info = self.session.hostkey() encoded_remote_server_key = remote_server_key_info[0] raw_remote_public_key = base64.encodebytes(encoded_remote_server_key) remote_public_key = raw_remote_public_key.replace(b\"\\n\", b\"\").decode() if known_host_public_key[\"public_key\"] != remote_public_key: raise ScrapliAuthenticationFailed( f\"{self._base_transport_args.host} in known_hosts but public key does not match!\" ) def _authenticate(self) -> None: \"\"\" Parent method to try all means of authentication Args: N/A Returns: None Raises: ScrapliConnectionNotOpened: if session is unopened/None ScrapliAuthenticationFailed: if auth fails \"\"\" if not self.session: raise ScrapliConnectionNotOpened if self.plugin_transport_args.auth_private_key: self._authenticate_public_key() if self.session.userauth_authenticated(): return if ( not self.plugin_transport_args.auth_password or not self.plugin_transport_args.auth_username ): msg = ( f\"Failed to authenticate to host {self._base_transport_args.host} with private \" f\"key `{self.plugin_transport_args.auth_private_key}`. Unable to continue \" \"authentication, missing username, password, or both.\" ) raise ScrapliAuthenticationFailed(msg) self._authenticate_password() def _authenticate_public_key(self) -> None: \"\"\" Attempt to authenticate with public key authentication Args: N/A Returns: None Raises: ScrapliConnectionNotOpened: if session is unopened/None \"\"\" if not self.session: raise ScrapliConnectionNotOpened try: self.session.userauth_publickey_fromfile( self.plugin_transport_args.auth_username, self.plugin_transport_args.auth_private_key.encode(), self.plugin_transport_args.auth_private_key_passphrase, ) except (AuthenticationError, SSH2Error): pass def _authenticate_password(self) -> None: \"\"\" Attempt to authenticate with password authentication Args: N/A Returns: None Raises: ScrapliConnectionNotOpened: if session is unopened/None \"\"\" if not self.session: raise ScrapliConnectionNotOpened try: self.session.userauth_password( username=self.plugin_transport_args.auth_username, password=self.plugin_transport_args.auth_password, ) return except AuthenticationError: pass try: self.session.userauth_keyboardinteractive( self.plugin_transport_args.auth_username, self.plugin_transport_args.auth_password ) except AttributeError: msg = ( \"Keyboard interactive authentication may not be supported in your \" \"ssh2-python version.\" ) self.logger.warning(msg) except AuthenticationError: pass def _open_channel(self) -> None: \"\"\" Open channel, acquire pty, request interactive shell Args: N/A Returns: None Raises: ScrapliConnectionNotOpened: if session is unopened/None \"\"\" if not self.session: raise ScrapliConnectionNotOpened self.session_channel = self.session.open_session() self.session_channel.pty() self.session_channel.shell() def close(self) -> None: self._pre_open_closing_log(closing=True) if self.session_channel: self.session_channel.close() if self.socket: self.socket.close() self.session = None self.session_channel = None self._post_open_closing_log(closing=True) def isalive(self) -> bool: if not self.session_channel: return False return not self.session_channel.eof() def read(self) -> bytes: if not self.session_channel: raise ScrapliConnectionNotOpened try: buf: bytes _, buf = self.session_channel.read(65535) except Exception as exc: msg = ( \"encountered EOF reading from transport; typically means the device closed the \" \"connection\" ) self.logger.critical(msg) raise ScrapliConnectionError(msg) from exc return buf def write(self, channel_input: bytes) -> None: if not self.session_channel: raise ScrapliConnectionNotOpened self.session_channel.write(channel_input) def _set_timeout(self, value: float) -> None: \"\"\" Set session object timeout value Args: value: timeout in seconds Returns: None Raises: ScrapliConnectionNotOpened: if session is unopened/None \"\"\" if not self.session: raise ScrapliConnectionNotOpened # ssh2-python expects timeout in milliseconds self.session.set_timeout(value * 1000) Ancestors (in MRO) \u00b6 scrapli.transport.base.sync_transport.Transport scrapli.transport.base.base_transport.BaseTransport abc.ABC","title":"SSH2"},{"location":"api_docs/transport/plugins/ssh2/#module-scraplitransportpluginsssh2transport","text":"scrapli.transport.plugins.ssh2.transport Expand source code \"\"\"scrapli.transport.plugins.ssh2.transport\"\"\" import base64 from dataclasses import dataclass from typing import Optional from ssh2.channel import Channel from ssh2.exceptions import AuthenticationError, SSH2Error from ssh2.session import Session from scrapli.exceptions import ( ScrapliAuthenticationFailed, ScrapliConnectionError, ScrapliConnectionNotOpened, ) from scrapli.ssh_config import SSHKnownHosts from scrapli.transport.base import BasePluginTransportArgs, BaseTransportArgs, Transport from scrapli.transport.base.base_socket import Socket @dataclass() class PluginTransportArgs(BasePluginTransportArgs): auth_username: str auth_password: str = \"\" auth_private_key: str = \"\" auth_private_key_passphrase: str = \"\" auth_strict_key: bool = True ssh_config_file: str = \"\" ssh_known_hosts_file: str = \"\" class Ssh2Transport(Transport): def __init__( self, base_transport_args: BaseTransportArgs, plugin_transport_args: PluginTransportArgs ) -> None: super().__init__(base_transport_args=base_transport_args) self.plugin_transport_args = plugin_transport_args self.socket: Optional[Socket] = None self.session: Optional[Session] = None self.session_channel: Optional[Channel] = None def open(self) -> None: self._pre_open_closing_log(closing=False) if not self.socket: self.socket = Socket( host=self._base_transport_args.host, port=self._base_transport_args.port, timeout=self._base_transport_args.timeout_socket, ) if not self.socket.isalive(): self.socket.open() self.session = Session() self._set_timeout(value=self._base_transport_args.timeout_transport) try: self.session.handshake(self.socket.sock) except Exception as exc: self.logger.critical(\"failed to complete handshake with host\") raise ScrapliConnectionNotOpened from exc if self.plugin_transport_args.auth_strict_key: self.logger.debug(f\"attempting to validate {self._base_transport_args.host} public key\") self._verify_key() self._authenticate() if not self.session.userauth_authenticated(): msg = \"all authentication methods failed\" self.logger.critical(msg) raise ScrapliAuthenticationFailed(msg) self._open_channel() self._post_open_closing_log(closing=False) def _verify_key(self) -> None: \"\"\" Verify target host public key, raise exception if invalid/unknown Args: N/A Returns: None Raises: ScrapliConnectionNotOpened: if session is unopened/None ScrapliAuthenticationFailed: if public key verification fails \"\"\" if not self.session: raise ScrapliConnectionNotOpened known_hosts = SSHKnownHosts(self.plugin_transport_args.ssh_known_hosts_file) known_host_public_key = known_hosts.lookup(self._base_transport_args.host) if not known_host_public_key: raise ScrapliAuthenticationFailed( f\"{self._base_transport_args.host} not in known_hosts!\" ) remote_server_key_info = self.session.hostkey() encoded_remote_server_key = remote_server_key_info[0] raw_remote_public_key = base64.encodebytes(encoded_remote_server_key) remote_public_key = raw_remote_public_key.replace(b\"\\n\", b\"\").decode() if known_host_public_key[\"public_key\"] != remote_public_key: raise ScrapliAuthenticationFailed( f\"{self._base_transport_args.host} in known_hosts but public key does not match!\" ) def _authenticate(self) -> None: \"\"\" Parent method to try all means of authentication Args: N/A Returns: None Raises: ScrapliConnectionNotOpened: if session is unopened/None ScrapliAuthenticationFailed: if auth fails \"\"\" if not self.session: raise ScrapliConnectionNotOpened if self.plugin_transport_args.auth_private_key: self._authenticate_public_key() if self.session.userauth_authenticated(): return if ( not self.plugin_transport_args.auth_password or not self.plugin_transport_args.auth_username ): msg = ( f\"Failed to authenticate to host {self._base_transport_args.host} with private \" f\"key `{self.plugin_transport_args.auth_private_key}`. Unable to continue \" \"authentication, missing username, password, or both.\" ) raise ScrapliAuthenticationFailed(msg) self._authenticate_password() def _authenticate_public_key(self) -> None: \"\"\" Attempt to authenticate with public key authentication Args: N/A Returns: None Raises: ScrapliConnectionNotOpened: if session is unopened/None \"\"\" if not self.session: raise ScrapliConnectionNotOpened try: self.session.userauth_publickey_fromfile( self.plugin_transport_args.auth_username, self.plugin_transport_args.auth_private_key.encode(), self.plugin_transport_args.auth_private_key_passphrase, ) except (AuthenticationError, SSH2Error): pass def _authenticate_password(self) -> None: \"\"\" Attempt to authenticate with password authentication Args: N/A Returns: None Raises: ScrapliConnectionNotOpened: if session is unopened/None \"\"\" if not self.session: raise ScrapliConnectionNotOpened try: self.session.userauth_password( username=self.plugin_transport_args.auth_username, password=self.plugin_transport_args.auth_password, ) return except AuthenticationError: pass try: self.session.userauth_keyboardinteractive( self.plugin_transport_args.auth_username, self.plugin_transport_args.auth_password ) except AttributeError: msg = ( \"Keyboard interactive authentication may not be supported in your \" \"ssh2-python version.\" ) self.logger.warning(msg) except AuthenticationError: pass def _open_channel(self) -> None: \"\"\" Open channel, acquire pty, request interactive shell Args: N/A Returns: None Raises: ScrapliConnectionNotOpened: if session is unopened/None \"\"\" if not self.session: raise ScrapliConnectionNotOpened self.session_channel = self.session.open_session() self.session_channel.pty() self.session_channel.shell() def close(self) -> None: self._pre_open_closing_log(closing=True) if self.session_channel: self.session_channel.close() if self.socket: self.socket.close() self.session = None self.session_channel = None self._post_open_closing_log(closing=True) def isalive(self) -> bool: if not self.session_channel: return False return not self.session_channel.eof() def read(self) -> bytes: if not self.session_channel: raise ScrapliConnectionNotOpened try: buf: bytes _, buf = self.session_channel.read(65535) except Exception as exc: msg = ( \"encountered EOF reading from transport; typically means the device closed the \" \"connection\" ) self.logger.critical(msg) raise ScrapliConnectionError(msg) from exc return buf def write(self, channel_input: bytes) -> None: if not self.session_channel: raise ScrapliConnectionNotOpened self.session_channel.write(channel_input) def _set_timeout(self, value: float) -> None: \"\"\" Set session object timeout value Args: value: timeout in seconds Returns: None Raises: ScrapliConnectionNotOpened: if session is unopened/None \"\"\" if not self.session: raise ScrapliConnectionNotOpened # ssh2-python expects timeout in milliseconds self.session.set_timeout(value * 1000)","title":"Module scrapli.transport.plugins.ssh2.transport"},{"location":"api_docs/transport/plugins/ssh2/#classes","text":"","title":"Classes"},{"location":"api_docs/transport/plugins/ssh2/#plugintransportargs","text":"1 PluginTransportArgs(auth_username: str, auth_password: str = '', auth_private_key: str = '', auth_private_key_passphrase: str = '', auth_strict_key: bool = True, ssh_config_file: str = '', ssh_known_hosts_file: str = '') Expand source code @dataclass() class PluginTransportArgs(BasePluginTransportArgs): auth_username: str auth_password: str = \"\" auth_private_key: str = \"\" auth_private_key_passphrase: str = \"\" auth_strict_key: bool = True ssh_config_file: str = \"\" ssh_known_hosts_file: str = \"\"","title":"PluginTransportArgs"},{"location":"api_docs/transport/plugins/ssh2/#ancestors-in-mro","text":"scrapli.transport.base.base_transport.BasePluginTransportArgs","title":"Ancestors (in MRO)"},{"location":"api_docs/transport/plugins/ssh2/#class-variables","text":"auth_password: str auth_private_key: str auth_private_key_passphrase: str auth_strict_key: bool auth_username: str ssh_config_file: str ssh_known_hosts_file: str","title":"Class variables"},{"location":"api_docs/transport/plugins/ssh2/#ssh2transport","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 Helper class that provides a standard way to create an ABC using inheritance. Scrapli's transport base class Args: base_transport_args: base transport args dataclass Returns: None Raises: N/A Expand source code class Ssh2Transport(Transport): def __init__( self, base_transport_args: BaseTransportArgs, plugin_transport_args: PluginTransportArgs ) -> None: super().__init__(base_transport_args=base_transport_args) self.plugin_transport_args = plugin_transport_args self.socket: Optional[Socket] = None self.session: Optional[Session] = None self.session_channel: Optional[Channel] = None def open(self) -> None: self._pre_open_closing_log(closing=False) if not self.socket: self.socket = Socket( host=self._base_transport_args.host, port=self._base_transport_args.port, timeout=self._base_transport_args.timeout_socket, ) if not self.socket.isalive(): self.socket.open() self.session = Session() self._set_timeout(value=self._base_transport_args.timeout_transport) try: self.session.handshake(self.socket.sock) except Exception as exc: self.logger.critical(\"failed to complete handshake with host\") raise ScrapliConnectionNotOpened from exc if self.plugin_transport_args.auth_strict_key: self.logger.debug(f\"attempting to validate {self._base_transport_args.host} public key\") self._verify_key() self._authenticate() if not self.session.userauth_authenticated(): msg = \"all authentication methods failed\" self.logger.critical(msg) raise ScrapliAuthenticationFailed(msg) self._open_channel() self._post_open_closing_log(closing=False) def _verify_key(self) -> None: \"\"\" Verify target host public key, raise exception if invalid/unknown Args: N/A Returns: None Raises: ScrapliConnectionNotOpened: if session is unopened/None ScrapliAuthenticationFailed: if public key verification fails \"\"\" if not self.session: raise ScrapliConnectionNotOpened known_hosts = SSHKnownHosts(self.plugin_transport_args.ssh_known_hosts_file) known_host_public_key = known_hosts.lookup(self._base_transport_args.host) if not known_host_public_key: raise ScrapliAuthenticationFailed( f\"{self._base_transport_args.host} not in known_hosts!\" ) remote_server_key_info = self.session.hostkey() encoded_remote_server_key = remote_server_key_info[0] raw_remote_public_key = base64.encodebytes(encoded_remote_server_key) remote_public_key = raw_remote_public_key.replace(b\"\\n\", b\"\").decode() if known_host_public_key[\"public_key\"] != remote_public_key: raise ScrapliAuthenticationFailed( f\"{self._base_transport_args.host} in known_hosts but public key does not match!\" ) def _authenticate(self) -> None: \"\"\" Parent method to try all means of authentication Args: N/A Returns: None Raises: ScrapliConnectionNotOpened: if session is unopened/None ScrapliAuthenticationFailed: if auth fails \"\"\" if not self.session: raise ScrapliConnectionNotOpened if self.plugin_transport_args.auth_private_key: self._authenticate_public_key() if self.session.userauth_authenticated(): return if ( not self.plugin_transport_args.auth_password or not self.plugin_transport_args.auth_username ): msg = ( f\"Failed to authenticate to host {self._base_transport_args.host} with private \" f\"key `{self.plugin_transport_args.auth_private_key}`. Unable to continue \" \"authentication, missing username, password, or both.\" ) raise ScrapliAuthenticationFailed(msg) self._authenticate_password() def _authenticate_public_key(self) -> None: \"\"\" Attempt to authenticate with public key authentication Args: N/A Returns: None Raises: ScrapliConnectionNotOpened: if session is unopened/None \"\"\" if not self.session: raise ScrapliConnectionNotOpened try: self.session.userauth_publickey_fromfile( self.plugin_transport_args.auth_username, self.plugin_transport_args.auth_private_key.encode(), self.plugin_transport_args.auth_private_key_passphrase, ) except (AuthenticationError, SSH2Error): pass def _authenticate_password(self) -> None: \"\"\" Attempt to authenticate with password authentication Args: N/A Returns: None Raises: ScrapliConnectionNotOpened: if session is unopened/None \"\"\" if not self.session: raise ScrapliConnectionNotOpened try: self.session.userauth_password( username=self.plugin_transport_args.auth_username, password=self.plugin_transport_args.auth_password, ) return except AuthenticationError: pass try: self.session.userauth_keyboardinteractive( self.plugin_transport_args.auth_username, self.plugin_transport_args.auth_password ) except AttributeError: msg = ( \"Keyboard interactive authentication may not be supported in your \" \"ssh2-python version.\" ) self.logger.warning(msg) except AuthenticationError: pass def _open_channel(self) -> None: \"\"\" Open channel, acquire pty, request interactive shell Args: N/A Returns: None Raises: ScrapliConnectionNotOpened: if session is unopened/None \"\"\" if not self.session: raise ScrapliConnectionNotOpened self.session_channel = self.session.open_session() self.session_channel.pty() self.session_channel.shell() def close(self) -> None: self._pre_open_closing_log(closing=True) if self.session_channel: self.session_channel.close() if self.socket: self.socket.close() self.session = None self.session_channel = None self._post_open_closing_log(closing=True) def isalive(self) -> bool: if not self.session_channel: return False return not self.session_channel.eof() def read(self) -> bytes: if not self.session_channel: raise ScrapliConnectionNotOpened try: buf: bytes _, buf = self.session_channel.read(65535) except Exception as exc: msg = ( \"encountered EOF reading from transport; typically means the device closed the \" \"connection\" ) self.logger.critical(msg) raise ScrapliConnectionError(msg) from exc return buf def write(self, channel_input: bytes) -> None: if not self.session_channel: raise ScrapliConnectionNotOpened self.session_channel.write(channel_input) def _set_timeout(self, value: float) -> None: \"\"\" Set session object timeout value Args: value: timeout in seconds Returns: None Raises: ScrapliConnectionNotOpened: if session is unopened/None \"\"\" if not self.session: raise ScrapliConnectionNotOpened # ssh2-python expects timeout in milliseconds self.session.set_timeout(value * 1000)","title":"Ssh2Transport"},{"location":"api_docs/transport/plugins/ssh2/#ancestors-in-mro_1","text":"scrapli.transport.base.sync_transport.Transport scrapli.transport.base.base_transport.BaseTransport abc.ABC","title":"Ancestors (in MRO)"},{"location":"api_docs/transport/plugins/system/","text":"window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting()) Module scrapli.transport.plugins.system.transport \u00b6 scrapli.transport.plugins.system.transport Expand source code \"\"\"scrapli.transport.plugins.system.transport\"\"\" import sys from dataclasses import dataclass from typing import List, Optional from scrapli.decorators import timeout_wrapper from scrapli.exceptions import ( ScrapliConnectionError, ScrapliConnectionNotOpened, ScrapliUnsupportedPlatform, ) from scrapli.transport.base import BasePluginTransportArgs, BaseTransportArgs, Transport from scrapli.transport.plugins.system.ptyprocess import PtyProcess @dataclass() class PluginTransportArgs(BasePluginTransportArgs): auth_username: str auth_private_key: str = \"\" auth_strict_key: bool = True ssh_config_file: str = \"\" ssh_known_hosts_file: str = \"\" class SystemTransport(Transport): def __init__( self, base_transport_args: BaseTransportArgs, plugin_transport_args: PluginTransportArgs ): \"\"\" System (i.e. /bin/ssh) transport plugin. This transport supports some additional `transport_options` to control behavior -- `ptyprocess` is a dictionary that has the following options: rows: integer number of rows for ptyprocess \"window\" cols: integer number of cols for ptyprocess \"window\" echo: defaults to `True`, passing `False` disables echo in the ptyprocess; should only be used with scrapli-netconf, will break scrapli! `netconf_force_pty` is a scrapli-netconf only argument. This setting defaults to `True` and allows you to *not* force a pty. This setting seems to only be necessary when connecting to juniper devices on port 830 as junos decides to not allocate a pty on that port for some reason! Args: base_transport_args: scrapli base transport plugin arguments plugin_transport_args: system ssh specific transport plugin arguments Returns: N/A Raises: ScrapliUnsupportedPlatform: if system is windows \"\"\" super().__init__(base_transport_args=base_transport_args) self.plugin_transport_args = plugin_transport_args if sys.platform.startswith(\"win\"): raise ScrapliUnsupportedPlatform(\"system transport is not supported on windows devices\") self.open_cmd: List[str] = [] self.session: Optional[PtyProcess] = None def _build_open_cmd(self) -> None: \"\"\" Method to craft command to open ssh session Args: N/A Returns: None Raises: N/A \"\"\" if self.open_cmd: self.open_cmd = [] self.open_cmd.extend([\"ssh\", self._base_transport_args.host]) self.open_cmd.extend([\"-p\", str(self._base_transport_args.port)]) self.open_cmd.extend( [\"-o\", f\"ConnectTimeout={int(self._base_transport_args.timeout_socket)}\"] ) self.open_cmd.extend( [\"-o\", f\"ServerAliveInterval={int(self._base_transport_args.timeout_transport)}\"] ) if self.plugin_transport_args.auth_private_key: self.open_cmd.extend([\"-i\", self.plugin_transport_args.auth_private_key]) if self.plugin_transport_args.auth_username: self.open_cmd.extend([\"-l\", self.plugin_transport_args.auth_username]) if self.plugin_transport_args.auth_strict_key is False: self.open_cmd.extend([\"-o\", \"StrictHostKeyChecking=no\"]) self.open_cmd.extend([\"-o\", \"UserKnownHostsFile=/dev/null\"]) else: self.open_cmd.extend([\"-o\", \"StrictHostKeyChecking=yes\"]) if self.plugin_transport_args.ssh_known_hosts_file: self.open_cmd.extend( [\"-o\", f\"UserKnownHostsFile={self.plugin_transport_args.ssh_known_hosts_file}\"] ) if self.plugin_transport_args.ssh_config_file: self.open_cmd.extend([\"-F\", self.plugin_transport_args.ssh_config_file]) else: self.open_cmd.extend([\"-F\", \"/dev/null\"]) open_cmd_user_args = self._base_transport_args.transport_options.get(\"open_cmd\", []) if isinstance(open_cmd_user_args, str): open_cmd_user_args = [open_cmd_user_args] self.open_cmd.extend(open_cmd_user_args) self.logger.debug(f\"created transport 'open_cmd': '{self.open_cmd}'\") def open(self) -> None: self._pre_open_closing_log(closing=False) if not self.open_cmd: self._build_open_cmd() self.session = PtyProcess.spawn( self.open_cmd, echo=self._base_transport_args.transport_options.get(\"ptyprocess\", {}).get( \"echo\", True ), rows=self._base_transport_args.transport_options.get(\"ptyprocess\", {}).get(\"rows\", 80), cols=self._base_transport_args.transport_options.get(\"ptyprocess\", {}).get(\"cols\", 256), ) self._post_open_closing_log(closing=False) def close(self) -> None: self._pre_open_closing_log(closing=True) if self.session: self.session.close() self.session = None self._post_open_closing_log(closing=True) def isalive(self) -> bool: if not self.session: return False if self.session.isalive() and not self.session.eof(): return True return False @timeout_wrapper def read(self) -> bytes: if not self.session: raise ScrapliConnectionNotOpened try: buf = self.session.read(65535) except EOFError as exc: msg = ( \"encountered EOF reading from transport; typically means the device closed the \" \"connection\" ) self.logger.critical(msg) raise ScrapliConnectionError(msg) from exc return buf def write(self, channel_input: bytes) -> None: if not self.session: raise ScrapliConnectionNotOpened self.session.write(channel_input) Classes \u00b6 PluginTransportArgs \u00b6 1 PluginTransportArgs(auth_username: str, auth_private_key: str = '', auth_strict_key: bool = True, ssh_config_file: str = '', ssh_known_hosts_file: str = '') Expand source code @dataclass() class PluginTransportArgs(BasePluginTransportArgs): auth_username: str auth_private_key: str = \"\" auth_strict_key: bool = True ssh_config_file: str = \"\" ssh_known_hosts_file: str = \"\" Ancestors (in MRO) \u00b6 scrapli.transport.base.base_transport.BasePluginTransportArgs Class variables \u00b6 auth_private_key: str auth_strict_key: bool auth_username: str ssh_config_file: str ssh_known_hosts_file: str SystemTransport \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 Helper class that provides a standard way to create an ABC using inheritance. System (i.e. /bin/ssh) transport plugin. This transport supports some additional `transport_options` to control behavior -- `ptyprocess` is a dictionary that has the following options: rows: integer number of rows for ptyprocess \"window\" cols: integer number of cols for ptyprocess \"window\" echo: defaults to `True`, passing `False` disables echo in the ptyprocess; should only be used with scrapli-netconf, will break scrapli! `netconf_force_pty` is a scrapli-netconf only argument. This setting defaults to `True` and allows you to *not* force a pty. This setting seems to only be necessary when connecting to juniper devices on port 830 as junos decides to not allocate a pty on that port for some reason! Args: base_transport_args: scrapli base transport plugin arguments plugin_transport_args: system ssh specific transport plugin arguments Returns: N/A Raises: ScrapliUnsupportedPlatform: if system is windows Expand source code class SystemTransport(Transport): def __init__( self, base_transport_args: BaseTransportArgs, plugin_transport_args: PluginTransportArgs ): \"\"\" System (i.e. /bin/ssh) transport plugin. This transport supports some additional `transport_options` to control behavior -- `ptyprocess` is a dictionary that has the following options: rows: integer number of rows for ptyprocess \"window\" cols: integer number of cols for ptyprocess \"window\" echo: defaults to `True`, passing `False` disables echo in the ptyprocess; should only be used with scrapli-netconf, will break scrapli! `netconf_force_pty` is a scrapli-netconf only argument. This setting defaults to `True` and allows you to *not* force a pty. This setting seems to only be necessary when connecting to juniper devices on port 830 as junos decides to not allocate a pty on that port for some reason! Args: base_transport_args: scrapli base transport plugin arguments plugin_transport_args: system ssh specific transport plugin arguments Returns: N/A Raises: ScrapliUnsupportedPlatform: if system is windows \"\"\" super().__init__(base_transport_args=base_transport_args) self.plugin_transport_args = plugin_transport_args if sys.platform.startswith(\"win\"): raise ScrapliUnsupportedPlatform(\"system transport is not supported on windows devices\") self.open_cmd: List[str] = [] self.session: Optional[PtyProcess] = None def _build_open_cmd(self) -> None: \"\"\" Method to craft command to open ssh session Args: N/A Returns: None Raises: N/A \"\"\" if self.open_cmd: self.open_cmd = [] self.open_cmd.extend([\"ssh\", self._base_transport_args.host]) self.open_cmd.extend([\"-p\", str(self._base_transport_args.port)]) self.open_cmd.extend( [\"-o\", f\"ConnectTimeout={int(self._base_transport_args.timeout_socket)}\"] ) self.open_cmd.extend( [\"-o\", f\"ServerAliveInterval={int(self._base_transport_args.timeout_transport)}\"] ) if self.plugin_transport_args.auth_private_key: self.open_cmd.extend([\"-i\", self.plugin_transport_args.auth_private_key]) if self.plugin_transport_args.auth_username: self.open_cmd.extend([\"-l\", self.plugin_transport_args.auth_username]) if self.plugin_transport_args.auth_strict_key is False: self.open_cmd.extend([\"-o\", \"StrictHostKeyChecking=no\"]) self.open_cmd.extend([\"-o\", \"UserKnownHostsFile=/dev/null\"]) else: self.open_cmd.extend([\"-o\", \"StrictHostKeyChecking=yes\"]) if self.plugin_transport_args.ssh_known_hosts_file: self.open_cmd.extend( [\"-o\", f\"UserKnownHostsFile={self.plugin_transport_args.ssh_known_hosts_file}\"] ) if self.plugin_transport_args.ssh_config_file: self.open_cmd.extend([\"-F\", self.plugin_transport_args.ssh_config_file]) else: self.open_cmd.extend([\"-F\", \"/dev/null\"]) open_cmd_user_args = self._base_transport_args.transport_options.get(\"open_cmd\", []) if isinstance(open_cmd_user_args, str): open_cmd_user_args = [open_cmd_user_args] self.open_cmd.extend(open_cmd_user_args) self.logger.debug(f\"created transport 'open_cmd': '{self.open_cmd}'\") def open(self) -> None: self._pre_open_closing_log(closing=False) if not self.open_cmd: self._build_open_cmd() self.session = PtyProcess.spawn( self.open_cmd, echo=self._base_transport_args.transport_options.get(\"ptyprocess\", {}).get( \"echo\", True ), rows=self._base_transport_args.transport_options.get(\"ptyprocess\", {}).get(\"rows\", 80), cols=self._base_transport_args.transport_options.get(\"ptyprocess\", {}).get(\"cols\", 256), ) self._post_open_closing_log(closing=False) def close(self) -> None: self._pre_open_closing_log(closing=True) if self.session: self.session.close() self.session = None self._post_open_closing_log(closing=True) def isalive(self) -> bool: if not self.session: return False if self.session.isalive() and not self.session.eof(): return True return False @timeout_wrapper def read(self) -> bytes: if not self.session: raise ScrapliConnectionNotOpened try: buf = self.session.read(65535) except EOFError as exc: msg = ( \"encountered EOF reading from transport; typically means the device closed the \" \"connection\" ) self.logger.critical(msg) raise ScrapliConnectionError(msg) from exc return buf def write(self, channel_input: bytes) -> None: if not self.session: raise ScrapliConnectionNotOpened self.session.write(channel_input) Ancestors (in MRO) \u00b6 scrapli.transport.base.sync_transport.Transport scrapli.transport.base.base_transport.BaseTransport abc.ABC","title":"System"},{"location":"api_docs/transport/plugins/system/#module-scraplitransportpluginssystemtransport","text":"scrapli.transport.plugins.system.transport Expand source code \"\"\"scrapli.transport.plugins.system.transport\"\"\" import sys from dataclasses import dataclass from typing import List, Optional from scrapli.decorators import timeout_wrapper from scrapli.exceptions import ( ScrapliConnectionError, ScrapliConnectionNotOpened, ScrapliUnsupportedPlatform, ) from scrapli.transport.base import BasePluginTransportArgs, BaseTransportArgs, Transport from scrapli.transport.plugins.system.ptyprocess import PtyProcess @dataclass() class PluginTransportArgs(BasePluginTransportArgs): auth_username: str auth_private_key: str = \"\" auth_strict_key: bool = True ssh_config_file: str = \"\" ssh_known_hosts_file: str = \"\" class SystemTransport(Transport): def __init__( self, base_transport_args: BaseTransportArgs, plugin_transport_args: PluginTransportArgs ): \"\"\" System (i.e. /bin/ssh) transport plugin. This transport supports some additional `transport_options` to control behavior -- `ptyprocess` is a dictionary that has the following options: rows: integer number of rows for ptyprocess \"window\" cols: integer number of cols for ptyprocess \"window\" echo: defaults to `True`, passing `False` disables echo in the ptyprocess; should only be used with scrapli-netconf, will break scrapli! `netconf_force_pty` is a scrapli-netconf only argument. This setting defaults to `True` and allows you to *not* force a pty. This setting seems to only be necessary when connecting to juniper devices on port 830 as junos decides to not allocate a pty on that port for some reason! Args: base_transport_args: scrapli base transport plugin arguments plugin_transport_args: system ssh specific transport plugin arguments Returns: N/A Raises: ScrapliUnsupportedPlatform: if system is windows \"\"\" super().__init__(base_transport_args=base_transport_args) self.plugin_transport_args = plugin_transport_args if sys.platform.startswith(\"win\"): raise ScrapliUnsupportedPlatform(\"system transport is not supported on windows devices\") self.open_cmd: List[str] = [] self.session: Optional[PtyProcess] = None def _build_open_cmd(self) -> None: \"\"\" Method to craft command to open ssh session Args: N/A Returns: None Raises: N/A \"\"\" if self.open_cmd: self.open_cmd = [] self.open_cmd.extend([\"ssh\", self._base_transport_args.host]) self.open_cmd.extend([\"-p\", str(self._base_transport_args.port)]) self.open_cmd.extend( [\"-o\", f\"ConnectTimeout={int(self._base_transport_args.timeout_socket)}\"] ) self.open_cmd.extend( [\"-o\", f\"ServerAliveInterval={int(self._base_transport_args.timeout_transport)}\"] ) if self.plugin_transport_args.auth_private_key: self.open_cmd.extend([\"-i\", self.plugin_transport_args.auth_private_key]) if self.plugin_transport_args.auth_username: self.open_cmd.extend([\"-l\", self.plugin_transport_args.auth_username]) if self.plugin_transport_args.auth_strict_key is False: self.open_cmd.extend([\"-o\", \"StrictHostKeyChecking=no\"]) self.open_cmd.extend([\"-o\", \"UserKnownHostsFile=/dev/null\"]) else: self.open_cmd.extend([\"-o\", \"StrictHostKeyChecking=yes\"]) if self.plugin_transport_args.ssh_known_hosts_file: self.open_cmd.extend( [\"-o\", f\"UserKnownHostsFile={self.plugin_transport_args.ssh_known_hosts_file}\"] ) if self.plugin_transport_args.ssh_config_file: self.open_cmd.extend([\"-F\", self.plugin_transport_args.ssh_config_file]) else: self.open_cmd.extend([\"-F\", \"/dev/null\"]) open_cmd_user_args = self._base_transport_args.transport_options.get(\"open_cmd\", []) if isinstance(open_cmd_user_args, str): open_cmd_user_args = [open_cmd_user_args] self.open_cmd.extend(open_cmd_user_args) self.logger.debug(f\"created transport 'open_cmd': '{self.open_cmd}'\") def open(self) -> None: self._pre_open_closing_log(closing=False) if not self.open_cmd: self._build_open_cmd() self.session = PtyProcess.spawn( self.open_cmd, echo=self._base_transport_args.transport_options.get(\"ptyprocess\", {}).get( \"echo\", True ), rows=self._base_transport_args.transport_options.get(\"ptyprocess\", {}).get(\"rows\", 80), cols=self._base_transport_args.transport_options.get(\"ptyprocess\", {}).get(\"cols\", 256), ) self._post_open_closing_log(closing=False) def close(self) -> None: self._pre_open_closing_log(closing=True) if self.session: self.session.close() self.session = None self._post_open_closing_log(closing=True) def isalive(self) -> bool: if not self.session: return False if self.session.isalive() and not self.session.eof(): return True return False @timeout_wrapper def read(self) -> bytes: if not self.session: raise ScrapliConnectionNotOpened try: buf = self.session.read(65535) except EOFError as exc: msg = ( \"encountered EOF reading from transport; typically means the device closed the \" \"connection\" ) self.logger.critical(msg) raise ScrapliConnectionError(msg) from exc return buf def write(self, channel_input: bytes) -> None: if not self.session: raise ScrapliConnectionNotOpened self.session.write(channel_input)","title":"Module scrapli.transport.plugins.system.transport"},{"location":"api_docs/transport/plugins/system/#classes","text":"","title":"Classes"},{"location":"api_docs/transport/plugins/system/#plugintransportargs","text":"1 PluginTransportArgs(auth_username: str, auth_private_key: str = '', auth_strict_key: bool = True, ssh_config_file: str = '', ssh_known_hosts_file: str = '') Expand source code @dataclass() class PluginTransportArgs(BasePluginTransportArgs): auth_username: str auth_private_key: str = \"\" auth_strict_key: bool = True ssh_config_file: str = \"\" ssh_known_hosts_file: str = \"\"","title":"PluginTransportArgs"},{"location":"api_docs/transport/plugins/system/#ancestors-in-mro","text":"scrapli.transport.base.base_transport.BasePluginTransportArgs","title":"Ancestors (in MRO)"},{"location":"api_docs/transport/plugins/system/#class-variables","text":"auth_private_key: str auth_strict_key: bool auth_username: str ssh_config_file: str ssh_known_hosts_file: str","title":"Class variables"},{"location":"api_docs/transport/plugins/system/#systemtransport","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 Helper class that provides a standard way to create an ABC using inheritance. System (i.e. /bin/ssh) transport plugin. This transport supports some additional `transport_options` to control behavior -- `ptyprocess` is a dictionary that has the following options: rows: integer number of rows for ptyprocess \"window\" cols: integer number of cols for ptyprocess \"window\" echo: defaults to `True`, passing `False` disables echo in the ptyprocess; should only be used with scrapli-netconf, will break scrapli! `netconf_force_pty` is a scrapli-netconf only argument. This setting defaults to `True` and allows you to *not* force a pty. This setting seems to only be necessary when connecting to juniper devices on port 830 as junos decides to not allocate a pty on that port for some reason! Args: base_transport_args: scrapli base transport plugin arguments plugin_transport_args: system ssh specific transport plugin arguments Returns: N/A Raises: ScrapliUnsupportedPlatform: if system is windows Expand source code class SystemTransport(Transport): def __init__( self, base_transport_args: BaseTransportArgs, plugin_transport_args: PluginTransportArgs ): \"\"\" System (i.e. /bin/ssh) transport plugin. This transport supports some additional `transport_options` to control behavior -- `ptyprocess` is a dictionary that has the following options: rows: integer number of rows for ptyprocess \"window\" cols: integer number of cols for ptyprocess \"window\" echo: defaults to `True`, passing `False` disables echo in the ptyprocess; should only be used with scrapli-netconf, will break scrapli! `netconf_force_pty` is a scrapli-netconf only argument. This setting defaults to `True` and allows you to *not* force a pty. This setting seems to only be necessary when connecting to juniper devices on port 830 as junos decides to not allocate a pty on that port for some reason! Args: base_transport_args: scrapli base transport plugin arguments plugin_transport_args: system ssh specific transport plugin arguments Returns: N/A Raises: ScrapliUnsupportedPlatform: if system is windows \"\"\" super().__init__(base_transport_args=base_transport_args) self.plugin_transport_args = plugin_transport_args if sys.platform.startswith(\"win\"): raise ScrapliUnsupportedPlatform(\"system transport is not supported on windows devices\") self.open_cmd: List[str] = [] self.session: Optional[PtyProcess] = None def _build_open_cmd(self) -> None: \"\"\" Method to craft command to open ssh session Args: N/A Returns: None Raises: N/A \"\"\" if self.open_cmd: self.open_cmd = [] self.open_cmd.extend([\"ssh\", self._base_transport_args.host]) self.open_cmd.extend([\"-p\", str(self._base_transport_args.port)]) self.open_cmd.extend( [\"-o\", f\"ConnectTimeout={int(self._base_transport_args.timeout_socket)}\"] ) self.open_cmd.extend( [\"-o\", f\"ServerAliveInterval={int(self._base_transport_args.timeout_transport)}\"] ) if self.plugin_transport_args.auth_private_key: self.open_cmd.extend([\"-i\", self.plugin_transport_args.auth_private_key]) if self.plugin_transport_args.auth_username: self.open_cmd.extend([\"-l\", self.plugin_transport_args.auth_username]) if self.plugin_transport_args.auth_strict_key is False: self.open_cmd.extend([\"-o\", \"StrictHostKeyChecking=no\"]) self.open_cmd.extend([\"-o\", \"UserKnownHostsFile=/dev/null\"]) else: self.open_cmd.extend([\"-o\", \"StrictHostKeyChecking=yes\"]) if self.plugin_transport_args.ssh_known_hosts_file: self.open_cmd.extend( [\"-o\", f\"UserKnownHostsFile={self.plugin_transport_args.ssh_known_hosts_file}\"] ) if self.plugin_transport_args.ssh_config_file: self.open_cmd.extend([\"-F\", self.plugin_transport_args.ssh_config_file]) else: self.open_cmd.extend([\"-F\", \"/dev/null\"]) open_cmd_user_args = self._base_transport_args.transport_options.get(\"open_cmd\", []) if isinstance(open_cmd_user_args, str): open_cmd_user_args = [open_cmd_user_args] self.open_cmd.extend(open_cmd_user_args) self.logger.debug(f\"created transport 'open_cmd': '{self.open_cmd}'\") def open(self) -> None: self._pre_open_closing_log(closing=False) if not self.open_cmd: self._build_open_cmd() self.session = PtyProcess.spawn( self.open_cmd, echo=self._base_transport_args.transport_options.get(\"ptyprocess\", {}).get( \"echo\", True ), rows=self._base_transport_args.transport_options.get(\"ptyprocess\", {}).get(\"rows\", 80), cols=self._base_transport_args.transport_options.get(\"ptyprocess\", {}).get(\"cols\", 256), ) self._post_open_closing_log(closing=False) def close(self) -> None: self._pre_open_closing_log(closing=True) if self.session: self.session.close() self.session = None self._post_open_closing_log(closing=True) def isalive(self) -> bool: if not self.session: return False if self.session.isalive() and not self.session.eof(): return True return False @timeout_wrapper def read(self) -> bytes: if not self.session: raise ScrapliConnectionNotOpened try: buf = self.session.read(65535) except EOFError as exc: msg = ( \"encountered EOF reading from transport; typically means the device closed the \" \"connection\" ) self.logger.critical(msg) raise ScrapliConnectionError(msg) from exc return buf def write(self, channel_input: bytes) -> None: if not self.session: raise ScrapliConnectionNotOpened self.session.write(channel_input)","title":"SystemTransport"},{"location":"api_docs/transport/plugins/system/#ancestors-in-mro_1","text":"scrapli.transport.base.sync_transport.Transport scrapli.transport.base.base_transport.BaseTransport abc.ABC","title":"Ancestors (in MRO)"},{"location":"api_docs/transport/plugins/telnet/","text":"window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting()) Module scrapli.transport.plugins.telnet.transport \u00b6 scrapli.transport.plugins.telnet.transport Expand source code \"\"\"scrapli.transport.plugins.telnet.transport\"\"\" from dataclasses import dataclass from typing import Optional from scrapli.decorators import timeout_wrapper from scrapli.exceptions import ScrapliConnectionError, ScrapliConnectionNotOpened from scrapli.transport.base import BasePluginTransportArgs, BaseTransportArgs, Transport from scrapli.transport.base.base_socket import Socket from scrapli.transport.base.telnet_common import DO, DONT, IAC, SUPPRESS_GO_AHEAD, WILL, WONT @dataclass() class PluginTransportArgs(BasePluginTransportArgs): pass class TelnetTransport(Transport): def __init__( self, base_transport_args: BaseTransportArgs, plugin_transport_args: PluginTransportArgs ) -> None: super().__init__(base_transport_args=base_transport_args) self.plugin_transport_args = plugin_transport_args self.socket: Optional[Socket] = None self._eof = False self._raw_buf = b\"\" self._cooked_buf = b\"\" self._control_char_sent_counter = 0 self._control_char_sent_limit = 10 def _set_socket_timeout(self, timeout: float) -> None: \"\"\" Set underlying socket timeout Mostly this exists just to assert that socket and socket.sock are not None to appease mypy! Args: timeout: float value to set as the timeout Returns: N/A Raises: ScrapliConnectionNotOpened: if either socket or socket.sock are None \"\"\" if self.socket is None: raise ScrapliConnectionNotOpened if self.socket.sock is None: raise ScrapliConnectionNotOpened self.socket.sock.settimeout(timeout) def _handle_control_chars_socket_timeout_update(self) -> None: \"\"\" Handle updating (if necessary) the socket timeout Args: N/A Returns: None Raises: N/A \"\"\" self._control_char_sent_counter += 1 if self._control_char_sent_counter > self._control_char_sent_limit: # connection is opened, effectively ignore socket timeout at this point as we want # the timeout socket to be \"just\" for opening the connection basically # the number 8 is fairly arbitrary -- it looks like *most* platforms send around # 8 - 12 control char/instructions on session opening, so we'll go with 8! self._set_socket_timeout(600) def _handle_control_chars_response(self, control_buf: bytes, c: bytes) -> bytes: \"\"\" Handle the actual response to control characters Broken up to be easier to test as well as to appease mr. mccabe NOTE: see the asynctelnet transport for additional comments inline about what is going on here. Args: control_buf: current control_buf to work with c: currently read control char to process Returns: bytes: updated control_buf Raises: ScrapliConnectionNotOpened: if connection is not opened for some reason \"\"\" if not self.socket: raise ScrapliConnectionNotOpened if not control_buf: if c != IAC: self._cooked_buf += c else: control_buf += c elif len(control_buf) == 1 and c in (DO, DONT, WILL, WONT): control_buf += c elif len(control_buf) == 2: cmd = control_buf[1:2] control_buf = b\"\" if (cmd == DO) and (c == SUPPRESS_GO_AHEAD): self.write(IAC + WILL + c) elif cmd in (DO, DONT): self.write(IAC + WONT + c) elif cmd == WILL: self.write(IAC + DO + c) elif cmd == WONT: self.write(IAC + DONT + c) self._handle_control_chars_socket_timeout_update() return control_buf def _handle_control_chars(self) -> None: \"\"\" Handle control characters -- nearly identical to CPython (removed in 3.11) telnetlib Basically we want to read and \"decline\" any and all control options that the server proposes to us -- so if they say \"DO\" XYZ directive, we say \"DONT\", if they say \"WILL\" we say \"WONT\". NOTE: see the asynctelnet transport for additional comments inline about what is going on here. Args: N/A Returns: None Raises: ScrapliConnectionNotOpened: if connection is not opened for some reason ScrapliConnectionNotOpened: if we read an empty byte string from the reader -- this indicates the server sent an EOF -- see #142 \"\"\" if not self.socket: raise ScrapliConnectionNotOpened control_buf = b\"\" while self._raw_buf: c, self._raw_buf = self._raw_buf[:1], self._raw_buf[1:] if not c: raise ScrapliConnectionNotOpened(\"server returned EOF, connection not opened\") control_buf = self._handle_control_chars_response(control_buf=control_buf, c=c) def open(self) -> None: self._pre_open_closing_log(closing=False) if not self.socket: self.socket = Socket( host=self._base_transport_args.host, port=self._base_transport_args.port, timeout=self._base_transport_args.timeout_socket, ) if not self.socket.isalive(): self.socket.open() self._post_open_closing_log(closing=False) def close(self) -> None: self._pre_open_closing_log(closing=True) if self.socket: self.socket.close() self.socket = None self._post_open_closing_log(closing=True) def isalive(self) -> bool: if not self.socket: return False if not self.socket.isalive(): return False return True def _read(self, n: int = 65535) -> None: \"\"\" Read n bytes from the socket and fill raw buffer Mostly this exists just to assert that socket and socket.sock are not None to appease mypy! Args: n: optional amount of bytes to try to recv from the underlying socket Returns: N/A Raises: ScrapliConnectionNotOpened: if either socket or socket.sock are None ScrapliConnectionError: if we fail to recv from the underlying socket \"\"\" if self.socket is None: raise ScrapliConnectionNotOpened if self.socket.sock is None: raise ScrapliConnectionNotOpened if not self._raw_buf: try: buf = self.socket.sock.recv(n) self._eof = not buf if self._control_char_sent_counter < self._control_char_sent_limit: self._raw_buf += buf else: self._cooked_buf += buf except Exception as exc: raise ScrapliConnectionError( \"encountered EOF reading from transport; typically means the device closed the \" \"connection\" ) from exc @timeout_wrapper def read(self) -> bytes: if not self.socket: raise ScrapliConnectionNotOpened if self._control_char_sent_counter < self._control_char_sent_limit: self._handle_control_chars() while not self._cooked_buf and not self._eof: self._read() if self._control_char_sent_counter < self._control_char_sent_limit: self._handle_control_chars() buf = self._cooked_buf self._cooked_buf = b\"\" return buf def write(self, channel_input: bytes) -> None: if self.socket is None: raise ScrapliConnectionNotOpened if self.socket.sock is None: raise ScrapliConnectionNotOpened self.socket.sock.send(channel_input) Classes \u00b6 PluginTransportArgs \u00b6 1 PluginTransportArgs() Expand source code @dataclass() class PluginTransportArgs(BasePluginTransportArgs): pass Ancestors (in MRO) \u00b6 scrapli.transport.base.base_transport.BasePluginTransportArgs TelnetTransport \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 Helper class that provides a standard way to create an ABC using inheritance. Scrapli's transport base class Args: base_transport_args: base transport args dataclass Returns: None Raises: N/A Expand source code class TelnetTransport(Transport): def __init__( self, base_transport_args: BaseTransportArgs, plugin_transport_args: PluginTransportArgs ) -> None: super().__init__(base_transport_args=base_transport_args) self.plugin_transport_args = plugin_transport_args self.socket: Optional[Socket] = None self._eof = False self._raw_buf = b\"\" self._cooked_buf = b\"\" self._control_char_sent_counter = 0 self._control_char_sent_limit = 10 def _set_socket_timeout(self, timeout: float) -> None: \"\"\" Set underlying socket timeout Mostly this exists just to assert that socket and socket.sock are not None to appease mypy! Args: timeout: float value to set as the timeout Returns: N/A Raises: ScrapliConnectionNotOpened: if either socket or socket.sock are None \"\"\" if self.socket is None: raise ScrapliConnectionNotOpened if self.socket.sock is None: raise ScrapliConnectionNotOpened self.socket.sock.settimeout(timeout) def _handle_control_chars_socket_timeout_update(self) -> None: \"\"\" Handle updating (if necessary) the socket timeout Args: N/A Returns: None Raises: N/A \"\"\" self._control_char_sent_counter += 1 if self._control_char_sent_counter > self._control_char_sent_limit: # connection is opened, effectively ignore socket timeout at this point as we want # the timeout socket to be \"just\" for opening the connection basically # the number 8 is fairly arbitrary -- it looks like *most* platforms send around # 8 - 12 control char/instructions on session opening, so we'll go with 8! self._set_socket_timeout(600) def _handle_control_chars_response(self, control_buf: bytes, c: bytes) -> bytes: \"\"\" Handle the actual response to control characters Broken up to be easier to test as well as to appease mr. mccabe NOTE: see the asynctelnet transport for additional comments inline about what is going on here. Args: control_buf: current control_buf to work with c: currently read control char to process Returns: bytes: updated control_buf Raises: ScrapliConnectionNotOpened: if connection is not opened for some reason \"\"\" if not self.socket: raise ScrapliConnectionNotOpened if not control_buf: if c != IAC: self._cooked_buf += c else: control_buf += c elif len(control_buf) == 1 and c in (DO, DONT, WILL, WONT): control_buf += c elif len(control_buf) == 2: cmd = control_buf[1:2] control_buf = b\"\" if (cmd == DO) and (c == SUPPRESS_GO_AHEAD): self.write(IAC + WILL + c) elif cmd in (DO, DONT): self.write(IAC + WONT + c) elif cmd == WILL: self.write(IAC + DO + c) elif cmd == WONT: self.write(IAC + DONT + c) self._handle_control_chars_socket_timeout_update() return control_buf def _handle_control_chars(self) -> None: \"\"\" Handle control characters -- nearly identical to CPython (removed in 3.11) telnetlib Basically we want to read and \"decline\" any and all control options that the server proposes to us -- so if they say \"DO\" XYZ directive, we say \"DONT\", if they say \"WILL\" we say \"WONT\". NOTE: see the asynctelnet transport for additional comments inline about what is going on here. Args: N/A Returns: None Raises: ScrapliConnectionNotOpened: if connection is not opened for some reason ScrapliConnectionNotOpened: if we read an empty byte string from the reader -- this indicates the server sent an EOF -- see #142 \"\"\" if not self.socket: raise ScrapliConnectionNotOpened control_buf = b\"\" while self._raw_buf: c, self._raw_buf = self._raw_buf[:1], self._raw_buf[1:] if not c: raise ScrapliConnectionNotOpened(\"server returned EOF, connection not opened\") control_buf = self._handle_control_chars_response(control_buf=control_buf, c=c) def open(self) -> None: self._pre_open_closing_log(closing=False) if not self.socket: self.socket = Socket( host=self._base_transport_args.host, port=self._base_transport_args.port, timeout=self._base_transport_args.timeout_socket, ) if not self.socket.isalive(): self.socket.open() self._post_open_closing_log(closing=False) def close(self) -> None: self._pre_open_closing_log(closing=True) if self.socket: self.socket.close() self.socket = None self._post_open_closing_log(closing=True) def isalive(self) -> bool: if not self.socket: return False if not self.socket.isalive(): return False return True def _read(self, n: int = 65535) -> None: \"\"\" Read n bytes from the socket and fill raw buffer Mostly this exists just to assert that socket and socket.sock are not None to appease mypy! Args: n: optional amount of bytes to try to recv from the underlying socket Returns: N/A Raises: ScrapliConnectionNotOpened: if either socket or socket.sock are None ScrapliConnectionError: if we fail to recv from the underlying socket \"\"\" if self.socket is None: raise ScrapliConnectionNotOpened if self.socket.sock is None: raise ScrapliConnectionNotOpened if not self._raw_buf: try: buf = self.socket.sock.recv(n) self._eof = not buf if self._control_char_sent_counter < self._control_char_sent_limit: self._raw_buf += buf else: self._cooked_buf += buf except Exception as exc: raise ScrapliConnectionError( \"encountered EOF reading from transport; typically means the device closed the \" \"connection\" ) from exc @timeout_wrapper def read(self) -> bytes: if not self.socket: raise ScrapliConnectionNotOpened if self._control_char_sent_counter < self._control_char_sent_limit: self._handle_control_chars() while not self._cooked_buf and not self._eof: self._read() if self._control_char_sent_counter < self._control_char_sent_limit: self._handle_control_chars() buf = self._cooked_buf self._cooked_buf = b\"\" return buf def write(self, channel_input: bytes) -> None: if self.socket is None: raise ScrapliConnectionNotOpened if self.socket.sock is None: raise ScrapliConnectionNotOpened self.socket.sock.send(channel_input) Ancestors (in MRO) \u00b6 scrapli.transport.base.sync_transport.Transport scrapli.transport.base.base_transport.BaseTransport abc.ABC","title":"Telnet"},{"location":"api_docs/transport/plugins/telnet/#module-scraplitransportpluginstelnettransport","text":"scrapli.transport.plugins.telnet.transport Expand source code \"\"\"scrapli.transport.plugins.telnet.transport\"\"\" from dataclasses import dataclass from typing import Optional from scrapli.decorators import timeout_wrapper from scrapli.exceptions import ScrapliConnectionError, ScrapliConnectionNotOpened from scrapli.transport.base import BasePluginTransportArgs, BaseTransportArgs, Transport from scrapli.transport.base.base_socket import Socket from scrapli.transport.base.telnet_common import DO, DONT, IAC, SUPPRESS_GO_AHEAD, WILL, WONT @dataclass() class PluginTransportArgs(BasePluginTransportArgs): pass class TelnetTransport(Transport): def __init__( self, base_transport_args: BaseTransportArgs, plugin_transport_args: PluginTransportArgs ) -> None: super().__init__(base_transport_args=base_transport_args) self.plugin_transport_args = plugin_transport_args self.socket: Optional[Socket] = None self._eof = False self._raw_buf = b\"\" self._cooked_buf = b\"\" self._control_char_sent_counter = 0 self._control_char_sent_limit = 10 def _set_socket_timeout(self, timeout: float) -> None: \"\"\" Set underlying socket timeout Mostly this exists just to assert that socket and socket.sock are not None to appease mypy! Args: timeout: float value to set as the timeout Returns: N/A Raises: ScrapliConnectionNotOpened: if either socket or socket.sock are None \"\"\" if self.socket is None: raise ScrapliConnectionNotOpened if self.socket.sock is None: raise ScrapliConnectionNotOpened self.socket.sock.settimeout(timeout) def _handle_control_chars_socket_timeout_update(self) -> None: \"\"\" Handle updating (if necessary) the socket timeout Args: N/A Returns: None Raises: N/A \"\"\" self._control_char_sent_counter += 1 if self._control_char_sent_counter > self._control_char_sent_limit: # connection is opened, effectively ignore socket timeout at this point as we want # the timeout socket to be \"just\" for opening the connection basically # the number 8 is fairly arbitrary -- it looks like *most* platforms send around # 8 - 12 control char/instructions on session opening, so we'll go with 8! self._set_socket_timeout(600) def _handle_control_chars_response(self, control_buf: bytes, c: bytes) -> bytes: \"\"\" Handle the actual response to control characters Broken up to be easier to test as well as to appease mr. mccabe NOTE: see the asynctelnet transport for additional comments inline about what is going on here. Args: control_buf: current control_buf to work with c: currently read control char to process Returns: bytes: updated control_buf Raises: ScrapliConnectionNotOpened: if connection is not opened for some reason \"\"\" if not self.socket: raise ScrapliConnectionNotOpened if not control_buf: if c != IAC: self._cooked_buf += c else: control_buf += c elif len(control_buf) == 1 and c in (DO, DONT, WILL, WONT): control_buf += c elif len(control_buf) == 2: cmd = control_buf[1:2] control_buf = b\"\" if (cmd == DO) and (c == SUPPRESS_GO_AHEAD): self.write(IAC + WILL + c) elif cmd in (DO, DONT): self.write(IAC + WONT + c) elif cmd == WILL: self.write(IAC + DO + c) elif cmd == WONT: self.write(IAC + DONT + c) self._handle_control_chars_socket_timeout_update() return control_buf def _handle_control_chars(self) -> None: \"\"\" Handle control characters -- nearly identical to CPython (removed in 3.11) telnetlib Basically we want to read and \"decline\" any and all control options that the server proposes to us -- so if they say \"DO\" XYZ directive, we say \"DONT\", if they say \"WILL\" we say \"WONT\". NOTE: see the asynctelnet transport for additional comments inline about what is going on here. Args: N/A Returns: None Raises: ScrapliConnectionNotOpened: if connection is not opened for some reason ScrapliConnectionNotOpened: if we read an empty byte string from the reader -- this indicates the server sent an EOF -- see #142 \"\"\" if not self.socket: raise ScrapliConnectionNotOpened control_buf = b\"\" while self._raw_buf: c, self._raw_buf = self._raw_buf[:1], self._raw_buf[1:] if not c: raise ScrapliConnectionNotOpened(\"server returned EOF, connection not opened\") control_buf = self._handle_control_chars_response(control_buf=control_buf, c=c) def open(self) -> None: self._pre_open_closing_log(closing=False) if not self.socket: self.socket = Socket( host=self._base_transport_args.host, port=self._base_transport_args.port, timeout=self._base_transport_args.timeout_socket, ) if not self.socket.isalive(): self.socket.open() self._post_open_closing_log(closing=False) def close(self) -> None: self._pre_open_closing_log(closing=True) if self.socket: self.socket.close() self.socket = None self._post_open_closing_log(closing=True) def isalive(self) -> bool: if not self.socket: return False if not self.socket.isalive(): return False return True def _read(self, n: int = 65535) -> None: \"\"\" Read n bytes from the socket and fill raw buffer Mostly this exists just to assert that socket and socket.sock are not None to appease mypy! Args: n: optional amount of bytes to try to recv from the underlying socket Returns: N/A Raises: ScrapliConnectionNotOpened: if either socket or socket.sock are None ScrapliConnectionError: if we fail to recv from the underlying socket \"\"\" if self.socket is None: raise ScrapliConnectionNotOpened if self.socket.sock is None: raise ScrapliConnectionNotOpened if not self._raw_buf: try: buf = self.socket.sock.recv(n) self._eof = not buf if self._control_char_sent_counter < self._control_char_sent_limit: self._raw_buf += buf else: self._cooked_buf += buf except Exception as exc: raise ScrapliConnectionError( \"encountered EOF reading from transport; typically means the device closed the \" \"connection\" ) from exc @timeout_wrapper def read(self) -> bytes: if not self.socket: raise ScrapliConnectionNotOpened if self._control_char_sent_counter < self._control_char_sent_limit: self._handle_control_chars() while not self._cooked_buf and not self._eof: self._read() if self._control_char_sent_counter < self._control_char_sent_limit: self._handle_control_chars() buf = self._cooked_buf self._cooked_buf = b\"\" return buf def write(self, channel_input: bytes) -> None: if self.socket is None: raise ScrapliConnectionNotOpened if self.socket.sock is None: raise ScrapliConnectionNotOpened self.socket.sock.send(channel_input)","title":"Module scrapli.transport.plugins.telnet.transport"},{"location":"api_docs/transport/plugins/telnet/#classes","text":"","title":"Classes"},{"location":"api_docs/transport/plugins/telnet/#plugintransportargs","text":"1 PluginTransportArgs() Expand source code @dataclass() class PluginTransportArgs(BasePluginTransportArgs): pass","title":"PluginTransportArgs"},{"location":"api_docs/transport/plugins/telnet/#ancestors-in-mro","text":"scrapli.transport.base.base_transport.BasePluginTransportArgs","title":"Ancestors (in MRO)"},{"location":"api_docs/transport/plugins/telnet/#telnettransport","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 Helper class that provides a standard way to create an ABC using inheritance. Scrapli's transport base class Args: base_transport_args: base transport args dataclass Returns: None Raises: N/A Expand source code class TelnetTransport(Transport): def __init__( self, base_transport_args: BaseTransportArgs, plugin_transport_args: PluginTransportArgs ) -> None: super().__init__(base_transport_args=base_transport_args) self.plugin_transport_args = plugin_transport_args self.socket: Optional[Socket] = None self._eof = False self._raw_buf = b\"\" self._cooked_buf = b\"\" self._control_char_sent_counter = 0 self._control_char_sent_limit = 10 def _set_socket_timeout(self, timeout: float) -> None: \"\"\" Set underlying socket timeout Mostly this exists just to assert that socket and socket.sock are not None to appease mypy! Args: timeout: float value to set as the timeout Returns: N/A Raises: ScrapliConnectionNotOpened: if either socket or socket.sock are None \"\"\" if self.socket is None: raise ScrapliConnectionNotOpened if self.socket.sock is None: raise ScrapliConnectionNotOpened self.socket.sock.settimeout(timeout) def _handle_control_chars_socket_timeout_update(self) -> None: \"\"\" Handle updating (if necessary) the socket timeout Args: N/A Returns: None Raises: N/A \"\"\" self._control_char_sent_counter += 1 if self._control_char_sent_counter > self._control_char_sent_limit: # connection is opened, effectively ignore socket timeout at this point as we want # the timeout socket to be \"just\" for opening the connection basically # the number 8 is fairly arbitrary -- it looks like *most* platforms send around # 8 - 12 control char/instructions on session opening, so we'll go with 8! self._set_socket_timeout(600) def _handle_control_chars_response(self, control_buf: bytes, c: bytes) -> bytes: \"\"\" Handle the actual response to control characters Broken up to be easier to test as well as to appease mr. mccabe NOTE: see the asynctelnet transport for additional comments inline about what is going on here. Args: control_buf: current control_buf to work with c: currently read control char to process Returns: bytes: updated control_buf Raises: ScrapliConnectionNotOpened: if connection is not opened for some reason \"\"\" if not self.socket: raise ScrapliConnectionNotOpened if not control_buf: if c != IAC: self._cooked_buf += c else: control_buf += c elif len(control_buf) == 1 and c in (DO, DONT, WILL, WONT): control_buf += c elif len(control_buf) == 2: cmd = control_buf[1:2] control_buf = b\"\" if (cmd == DO) and (c == SUPPRESS_GO_AHEAD): self.write(IAC + WILL + c) elif cmd in (DO, DONT): self.write(IAC + WONT + c) elif cmd == WILL: self.write(IAC + DO + c) elif cmd == WONT: self.write(IAC + DONT + c) self._handle_control_chars_socket_timeout_update() return control_buf def _handle_control_chars(self) -> None: \"\"\" Handle control characters -- nearly identical to CPython (removed in 3.11) telnetlib Basically we want to read and \"decline\" any and all control options that the server proposes to us -- so if they say \"DO\" XYZ directive, we say \"DONT\", if they say \"WILL\" we say \"WONT\". NOTE: see the asynctelnet transport for additional comments inline about what is going on here. Args: N/A Returns: None Raises: ScrapliConnectionNotOpened: if connection is not opened for some reason ScrapliConnectionNotOpened: if we read an empty byte string from the reader -- this indicates the server sent an EOF -- see #142 \"\"\" if not self.socket: raise ScrapliConnectionNotOpened control_buf = b\"\" while self._raw_buf: c, self._raw_buf = self._raw_buf[:1], self._raw_buf[1:] if not c: raise ScrapliConnectionNotOpened(\"server returned EOF, connection not opened\") control_buf = self._handle_control_chars_response(control_buf=control_buf, c=c) def open(self) -> None: self._pre_open_closing_log(closing=False) if not self.socket: self.socket = Socket( host=self._base_transport_args.host, port=self._base_transport_args.port, timeout=self._base_transport_args.timeout_socket, ) if not self.socket.isalive(): self.socket.open() self._post_open_closing_log(closing=False) def close(self) -> None: self._pre_open_closing_log(closing=True) if self.socket: self.socket.close() self.socket = None self._post_open_closing_log(closing=True) def isalive(self) -> bool: if not self.socket: return False if not self.socket.isalive(): return False return True def _read(self, n: int = 65535) -> None: \"\"\" Read n bytes from the socket and fill raw buffer Mostly this exists just to assert that socket and socket.sock are not None to appease mypy! Args: n: optional amount of bytes to try to recv from the underlying socket Returns: N/A Raises: ScrapliConnectionNotOpened: if either socket or socket.sock are None ScrapliConnectionError: if we fail to recv from the underlying socket \"\"\" if self.socket is None: raise ScrapliConnectionNotOpened if self.socket.sock is None: raise ScrapliConnectionNotOpened if not self._raw_buf: try: buf = self.socket.sock.recv(n) self._eof = not buf if self._control_char_sent_counter < self._control_char_sent_limit: self._raw_buf += buf else: self._cooked_buf += buf except Exception as exc: raise ScrapliConnectionError( \"encountered EOF reading from transport; typically means the device closed the \" \"connection\" ) from exc @timeout_wrapper def read(self) -> bytes: if not self.socket: raise ScrapliConnectionNotOpened if self._control_char_sent_counter < self._control_char_sent_limit: self._handle_control_chars() while not self._cooked_buf and not self._eof: self._read() if self._control_char_sent_counter < self._control_char_sent_limit: self._handle_control_chars() buf = self._cooked_buf self._cooked_buf = b\"\" return buf def write(self, channel_input: bytes) -> None: if self.socket is None: raise ScrapliConnectionNotOpened if self.socket.sock is None: raise ScrapliConnectionNotOpened self.socket.sock.send(channel_input)","title":"TelnetTransport"},{"location":"api_docs/transport/plugins/telnet/#ancestors-in-mro_1","text":"scrapli.transport.base.sync_transport.Transport scrapli.transport.base.base_transport.BaseTransport abc.ABC","title":"Ancestors (in MRO)"},{"location":"more_scrapli/nornir_scrapli/","text":"Nornir scrapli \u00b6 If you want to use scrapli, but don't want to deal with handling concurrency yourself, there is great news! The nornir_scrapli plugin allows you to use scrapli (and scrapli netconf and scrapli cfg) within the Nornir framework!","title":"Nornir Scrapli"},{"location":"more_scrapli/nornir_scrapli/#nornir-scrapli","text":"If you want to use scrapli, but don't want to deal with handling concurrency yourself, there is great news! The nornir_scrapli plugin allows you to use scrapli (and scrapli netconf and scrapli cfg) within the Nornir framework!","title":"Nornir scrapli"},{"location":"more_scrapli/scrapli_cfg/","text":"Scrapli Cfg \u00b6 scrapli_cfg ( docs ) is utility that accepts a scrapli Telnet or SSH connection and provides configuration management capabilities. scrapli_cfg allows you to load candidate configurations for merge or replace operations, generate diffs of the current vs candidate, and of course commit or abort the candidate configuration.","title":"Scrapli Cfg"},{"location":"more_scrapli/scrapli_cfg/#scrapli-cfg","text":"scrapli_cfg ( docs ) is utility that accepts a scrapli Telnet or SSH connection and provides configuration management capabilities. scrapli_cfg allows you to load candidate configurations for merge or replace operations, generate diffs of the current vs candidate, and of course commit or abort the candidate configuration.","title":"Scrapli Cfg"},{"location":"more_scrapli/scrapli_community/","text":"Scrapli Community \u00b6 If you would like to use scrapli, but the platform(s) that you work with are not supported in the \"core\" scrapli platforms, you should check out scrapli_community ! This is the place for users to share \"non-core\" scrapli platforms.","title":"Scrapli Community"},{"location":"more_scrapli/scrapli_community/#scrapli-community","text":"If you would like to use scrapli, but the platform(s) that you work with are not supported in the \"core\" scrapli platforms, you should check out scrapli_community ! This is the place for users to share \"non-core\" scrapli platforms.","title":"Scrapli Community"},{"location":"more_scrapli/scrapli_netconf/","text":"Scrapli Netconf \u00b6 scrapli_netconf ( docs ) is a netconf driver built on top of scrapli. The purpose of scrapli_netconf is to provide a fast, flexible, thoroughly tested, well typed, well documented, simple API that supports both synchronous and asynchronous usage. Working together scrapli and scrapli_netconf aim to provide a consistent (as is practical) look and feel when automating devices over telnet, SSH, or netconf (over SSH).","title":"Scrapli Netconf"},{"location":"more_scrapli/scrapli_netconf/#scrapli-netconf","text":"scrapli_netconf ( docs ) is a netconf driver built on top of scrapli. The purpose of scrapli_netconf is to provide a fast, flexible, thoroughly tested, well typed, well documented, simple API that supports both synchronous and asynchronous usage. Working together scrapli and scrapli_netconf aim to provide a consistent (as is practical) look and feel when automating devices over telnet, SSH, or netconf (over SSH).","title":"Scrapli Netconf"},{"location":"more_scrapli/scrapli_replay/","text":"Scrapli Replay \u00b6 scrapli_replay ( docs ) is a set of tools used to help test scrapli programs. scrapli_replay includes a utility to capture command input/output from real life servers and replay them in a semi-interactive fashion, as well as a pytest plugin that patches and records and replays session data (like vcr.py ) for scrapli connections.","title":"Scrapli Replay"},{"location":"more_scrapli/scrapli_replay/#scrapli-replay","text":"scrapli_replay ( docs ) is a set of tools used to help test scrapli programs. scrapli_replay includes a utility to capture command input/output from real life servers and replay them in a semi-interactive fashion, as well as a pytest plugin that patches and records and replays session data (like vcr.py ) for scrapli connections.","title":"Scrapli Replay"},{"location":"user_guide/advanced_usage/","text":"Advanced Usage \u00b6 All Driver Arguments \u00b6 The basic usage section outlined the most commonly used driver arguments, please see the following pages to see all supported driver arguments: Base Driver Arguments GenericDriver Arguments NetworkDriver Arguments Most of these attributes actually get passed from the Driver (or sub-class such as NXOSDriver ) into the Transport and Channel classes, so if you need to modify any of these values after instantiation you should do so on the appropriate object -- i.e. conn.channel.comms_prompt_pattern . Platform Regex \u00b6 Due to the nature of Telnet/SSH there is no good way to know when a command has completed execution. Put another way , when sending any command, data is returned over a socket, that socket doesn't ever tell us when it is \"done \" sending the output from the command that was executed. In order to know when the session is \"back at the base prompt/starting point\" scrapli uses a regular expression pattern to find that base prompt. This pattern is contained in the comms_prompt_pattern setting or is created by joining all possible prompt patterns in the privilege levels for a \"core\" device type. In general, you should not change the patterns unless you have a good reason to do so! The \"base\" Driver (default, but changeable) pattern is: \"^[a-z0-9.\\-@()/:]{1,48}[#>$]\\s*$\" NOTE all comms_prompt_pattern \"should\" use the start and end of line anchors as all regex searches in scrapli are multi-line (this is an important piece to making this all work!). While you don't need to use the line anchors its probably a really good idea! Also note that most devices seem to leave at least one white space after the final character of the prompt, so make sure to account for this! Last important note -- the core drivers all have reliable patterns set for you, so you hopefully don't need to bother with this too much! The above pattern works on all \"core\" platforms listed above for at the very least basic usage. Custom prompts or host names could in theory break this, so be careful! If you use a platform driver, the base prompt is set in the driver, so you don't really need to worry about this! The comms_prompt_pattern pattern can be changed at any time at or after instantiation of a scrapli object, and is done so by modifying conn.channel.comms_prompt_pattern where conn is your scrapli connection object. Changing this can break things though, so be careful! If using any NetworkDriver sub-classes you should modify the privilege level(s) if necessary, and not the comms_prompt_pattern . On Open \u00b6 Lots of times when connecting to a device there are \"things\" that need to happen immediately after getting connected . In the context of network devices the most obvious/common example would be disabling paging (i.e. sending terminal length 0 on a Cisco-type device). While scrapli Driver (the base driver) and GenericDriver do not know or care about disabling paging or any other on connect type activities, scrapli of course provides a mechanism for allowing users to handle these types of tasks. Even better yet, if you are using any of the core drivers ( IOSXEDriver , IOSXRDriver , etc.), scrapli will automatically have some sane default \"on connect\" actions (namely disabling paging). If you were so inclined to create some of your own \"on connect\" actions, you can simply pass those to the on_open argument of Scrape or any of its sub-classes ( NetworkDriver , IOSXEDriver , etc.). The value of this argument must be a callable that accepts the reference to the connection object. This allows for the user to send commands or do really anything that needs to happen prior to \"normal\" operations. The core network drivers disable paging functions all call directly into the channel object send_input method -- this is a good practice to follow as this will avoid any of the NetworkDriver overhead such as trying to attain privilege levels -- things like this may not be \"ready\" until after your on_open function is executed. Below is an example of creating an \"on connect\" function and passing it to scrapli. Immediately after authentication is handled this function will be called and disable paging (in this example): 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from scrapli.driver.core import IOSXEDriver def iosxe_disable_paging ( conn ): conn . channel . send_input ( \"term length 0\" ) my_device = { \"host\" : \"172.18.0.11\" , \"auth_username\" : \"scrapli\" , \"auth_password\" : \"scrapli\" , \"auth_strict_key\" : False , \"on_open\" : iosxe_disable_paging } with IOSXEDriver ( ** my_device ) as conn : print ( conn . get_prompt ()) Note that this section has talked almost exclusively about disabling paging, but any other \"things\" that need to happen in the channel can be handled here. If there is a prompt/banner to accept you should be able to handle it here. The goal of this \"on connect\" function is to allow for lots of flexibility for dealing with whatever needs to happen for devices -- thus decoupling the challenge of addressing all of the possible options from scrapli itself and allowing users to handle things specific for their environment. Lastly, while the on_open method should be synchronous or asyncio depending on the driver -- meaning that if using an async driver, it will await the on_open callable, so it must be asynchronous! On Close \u00b6 As you may have guessed, on_close is very similar to on_open with the obvious difference that it happens just prior to disconnecting from the device. Just like on_open , on_close functions should accept a single argument that is a reference to the object itself. As with most things scrapli, there are sane defaults for the on_close functions, but you are welcome to override them with your own function if you so chose! Timeouts \u00b6 scrapli supports several timeout options: timeout_socket timeout_transport timeout_ops timeout_socket is exactly what it sounds where possible. For the ssh2 and paramiko transports we create our own socket and pass this to the created object (paramiko or ssh2 object). The socket is created with the timeout value set in the timeout_socket attribute. For telnet and system transports we do not create a socket ourselves so this value is used slightly differently. For telnet, the timeout_socket is used as the timeout for telnet session creation. After the telnet session is created the timeout is reset to the timeout_transport value (more on that in a second). For system transport, timeout_socket governs the ConnectTimeout ssh argument -- which seems to be very similar to socket timeout in paramiko/ssh2. timeout_transport is intended to govern the timeout for the actual transport mechanism itself. For paramiko and ssh2, this is set to the respective libraries timeout attributes. For telnet, this is set to the telnetlib timeout value after the initial telnet session is stood up. For system transport, this value is used as the timeout value for read and write operations (handled by operation timeout decorator). Finally, timeout_ops sets a timeout value for individual operations -- or put another way, the timeout for each send_input operation. Driver Privilege Levels \u00b6 The \"core\" drivers understand the basic privilege levels of their respective device types. As mentioned previously , the drivers will automatically attain the \"privilege_exec\" (or equivalent) privilege level prior to executing \"show \" commands. If you don't want this \"auto-magic\" you can use the base driver ( Driver ) or the GenericDriver . The privileges for each device are outlined in the platforms driver.py file - each privilege is an object of the base PrivilegeLevel class which uses slots for the attributes. This used to be a named tuple, however as this was immutable it was a bit of a pain for users to modify things on the fly. As an example, the following privilege levels are supported by the IOSXEDriver : \"exec\" \"privilege_exec\" \"configuration\" Each privilege level has the following attributes: pattern: regex pattern to associate prompt to privilege level with name: name of the priv level, i.e. \"exec\" previous_priv: name of the \"lower\"/\"previous\" privilege level deescalate: command used to deescalate from this privilege level (or an empty string if no lower privilege) escalate: command used to escalate to this privilege level (from the lower/previous privilege) escalate_auth: True/False there is auth required to escalate to this privilege level escalate_prompt: pattern to expect when escalating to this privilege level, i.e. \"Password:\" or any empty string If you wish to manually enter a privilege level you can use the acquire_priv method, passing in the name of the privilege level you would like to enter. In general, you probably won't need this too often though as the driver should handle much of this for you. 1 2 3 4 5 6 7 8 9 10 from scrapli.driver.core import IOSXEDriver my_device = { \"host\" : \"172.18.0.11\" , \"auth_username\" : \"scrapli\" , \"auth_password\" : \"scrapli\" , \"auth_strict_key\" : False , } with IOSXEDriver ( ** my_device ) as conn : conn . acquire_priv ( \"configuration\" ) Configure Exclusive and Configure Private (IOSXR/Junos) \u00b6 IOSXR and Junos platforms have different configuration modes, such as \"configure exclusive\" or \"configure private \". These alternate configuration modes are represented as a privilege level just like the \"regular\" configuration mode. You can acquire an \"exclusive\" configuration session on IOSXR as follows: 1 2 3 4 5 6 7 8 9 10 from scrapli.driver.core import IOSXRDriver my_device = { \"host\" : \"172.18.0.11\" , \"auth_username\" : \"scrapli\" , \"auth_password\" : \"scrapli\" , \"auth_strict_key\" : False , } with IOSXRDriver ( ** my_device ) as conn : conn . acquire_priv ( \"configuration_exclusive\" ) Of course you can also pass this privilege level name to the send_configs or send_configs_from_file methods as well: 1 2 3 4 5 6 7 8 9 10 from scrapli.driver.core import IOSXRDriver my_device = { \"host\" : \"172.18.0.11\" , \"auth_username\" : \"scrapli\" , \"auth_password\" : \"scrapli\" , \"auth_strict_key\" : False , } with IOSXRDriver ( ** my_device ) as conn : conn . send_configs ( configs = [ \"configure things\" ], privilege_level = \"configuration_exclusive\" ) Note that the name of the privilege level is \"configuration_exclusive\" -- don't forget to write the whole thing out! Configure Session (EOS/NXOS) \u00b6 EOS and NXOS devices support configuration \"sessions\", these sessions are a little bit of a special case for scrapli . In order to use a configuration session, the configuration session must first be \"registered\" with scrapli -- this is so that scrapli can create a privilege level that is mapped to the given config session/config session name . The register_configuration_session method that accepts a string name of the configuration session you would like to create -- note that this method raises a NotImplementedError for platforms that do not support config sessions . The register_configuration_session method creates a new privilege level for you and updates the transport class with the appropriate information internally (see next section). An example of creating a session for an EOS device called \"my-config-session\" can be seen here: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from scrapli.driver.core import EOSDriver my_device = { \"host\" : \"172.18.0.14\" , \"auth_username\" : \"scrapli\" , \"auth_password\" : \"scrapli\" , \"auth_secondary\" : \"VR-netlab9\" , \"auth_strict_key\" : False , } with EOSDriver ( ** my_device ) as conn : conn . register_configuration_session ( session_name = \"my-config-session\" ) print ( conn . privilege_levels [ \"my-config-session\" ]) print ( conn . privilege_levels [ \"my-config-session\" ] . name ) print ( conn . privilege_levels [ \"my-config-session\" ] . pattern ) 1 2 3 <scrapli.driver.network_driver.PrivilegeLevel object at 0x7fca10070820> my-config-session ^[a-z0-9.\\-@/:]{1,32}\\(config\\-s\\-my\\-con[a-z0-9_.\\-@/:]{0,32}\\)#\\s?$ Modifying Privilege Levels \u00b6 When creating a configuration session, or modifying a privilege level during runtime, scrapli needs to update some internal arguments in order to always have a full \"map\" of how to escalate/deescalate, as well as to be able to match prompts based on any/all of the patterns available in the privilege levels dictionary. The register_configuration_session method will automatically handle updating these internal arguments, however if you modify any of the privilege levels (or add a priv level on the fly without using the register method) then you will need to manually call the update_privilege_levels method. Using Driver Directly \u00b6 All examples in this readme have shown using the \"core\" network drivers such as IOSXEDriver . These core network drivers are actually sub-classes of an ABC called NetworkDriver which itself is a sub-class of the GenericDriver which is a sub-class of the base Scrape class -- the namesake for this library. The Driver object can be used directly if you prefer to have a much less opinionated or less \"auto-magic\" type experience. Driver does not provide the same send_command / send_commands / send_configs methods, nor does it disable paging, or handle any kind of privilege escalation/de-escalation. Driver is a much more basic \"paramiko\"-like experience. Below is a brief example of using the Driver object directly: 1 2 3 4 5 6 7 8 9 10 11 12 from scrapli import Driver my_device = { \"host\" : \"172.18.0.11\" , \"auth_username\" : \"scrapli\" , \"auth_password\" : \"scrapli\" , \"auth_strict_key\" : False , } with Driver ( ** my_device ) as conn : conn . channel . send_input ( \"terminal length 0\" ) response = conn . channel . send_input ( \"show version\" ) Without the send_command and similar methods, you must directly access the Channel object when sending inputs with Scrape . Using the GenericDriver \u00b6 Using the Driver driver directly is nice enough, however you may not want to have to change the prompt pattern, or deal with accessing the channel to send commands to the device. In this case there is a GenericDriver available to you. This driver has a very broad pattern that it matches for base prompts, has no concept of disabling paging or privilege levels (like Driver ), but does provide send_command , send_commands , send_interactive , and get_prompt methods for a more NetworkDriver-like experience. Hopefully this GenericDriver can be used as a starting point for devices that don't fall under the core supported platforms list. 1 2 3 4 5 6 7 8 9 10 11 12 13 from scrapli.driver import GenericDriver my_device = { \"host\" : \"172.18.0.11\" , \"auth_username\" : \"scrapli\" , \"auth_password\" : \"scrapli\" , \"auth_strict_key\" : False , } with GenericDriver ( ** my_device ) as conn : conn . send_command ( \"terminal length 0\" ) response = conn . send_command ( \"show version\" ) responses = conn . send_commands ([ \"show version\" , \"show run\" ]) Using a Different Transport \u00b6 scrapli is built to be very flexible, including being flexible enough to use different libraries for \"transport \" -- or the actual Telnet/SSH communication. By default, scrapli uses the \"system\" transport which quite literally uses the ssh binary on your system ( /usr/bin/ssh ). This \"system\" transport means that scrapli has no external dependencies as it just relies on what is available on the machine running the scrapli script. In the spirit of being highly flexible, scrapli allows users to swap out this \"system\" transport with another transport mechanism. The other supported transport plugins are paramiko , ssh2-python , telnetlib , asyncssh , and asynctelnet . The transport selection can be made when instantiating the scrapli connection object by passing in paramiko , ssh2 , telnet , asyncssh , or asynctelnet to force scrapli to use the corresponding transport mechanism. If you are using one of the async transports you must use an async driver! While it will be a goal to ensure that these other transport mechanisms are supported and useful, the focus of scrapli development will be on the \"system\" SSH transport. Example using paramiko as the transport: 1 2 3 4 5 6 7 8 9 10 11 12 from scrapli.driver.core import IOSXEDriver my_device = { \"host\" : \"172.18.0.11\" , \"auth_username\" : \"scrapli\" , \"auth_password\" : \"scrapli\" , \"auth_strict_key\" : False , \"transport\" : \"paramiko\" } with IOSXEDriver ( ** my_device ) as conn : print ( conn . get_prompt ()) Currently, the only reason I can think of to use anything other than \"system\" as the transport would be to test scrapli on a Windows host, to use telnet, to use ssh2 for super speed, or to use asyncio. If there are other good reasons please do let me know! Auth Bypass \u00b6 NOTE only supported with system and telnet transports! Some devices, such as Cisco WLC, have no \"true\" SSH authentication, and instead prompt for credentials (or perhaps not even that) after session establishment. In order to cope with this corner case, the auth_bypass flag can be set to True which will cause scrapli to skip all authentication steps. Typically, this flag would be set and a custom on_open function set to handle whatever prompts the device has upon SSH session establishment. See the non core device example to see this in action. Transport Options \u00b6 Because each transport has different options/features available, it doesn't make sense to try to put all possible arguments in the Driver or NetworkDriver drivers, to address this an argument transport_options has been added . This is exactly what it sounds like -- arguments that can be passed to the selected transport class. As these arguments will be transport-specific, please check the docs/docstrings for your preferred transport to see what is available. A simple example of passing additional SSH arguments to the SystemSSHTransport class is available here . Raise For Status \u00b6 The scrapli Response and MultiResponse objects both contain a method called raise_for_status . This method's purpose is to provide a very simple way to raise an exception if any of the commands or configs sent in a method have failed. 1 2 3 4 5 6 7 8 9 10 11 12 from scrapli.driver.core import IOSXEDriver my_device = { \"host\" : \"172.18.0.11\" , \"auth_username\" : \"scrapli\" , \"auth_password\" : \"scrapli\" , \"auth_strict_key\" : False , } with IOSXEDriver ( ** my_device ) as conn : commands = [ \"show run\" , \"tacocat\" , \"show version\" ] responses = conn . send_commands ( commands = commands ) Inspecting the responses object from the above example, we can see that it indeed is marked as Success: False , even though the first and last commands were successful: 1 2 3 4 5 6 7 8 >>> responses MultiResponse < Success : False ; Response Elements : 3 > >>> responses [ 0 ] Response < Success : True > >>> responses [ 1 ] Response < Success : False > >>> responses [ 2 ] Response < Success : True > Finally, we can all the raise_for_status method to have scrapli raise the ScrapliCommandFailure exception if any of the configs/commands failed: 1 2 3 4 5 6 >>> responses . raise_for_status () Traceback ( most recent call last ): File \"<stdin>\" , line 1 , in < module > File \"/Users/carl/dev/github/scrapli/scrapli/response.py\" , line 270 , in raise_for_status raise ScrapliCommandFailure () scrapli . exceptions . ScrapliCommandFailure","title":"Advanced Usage"},{"location":"user_guide/advanced_usage/#advanced-usage","text":"","title":"Advanced Usage"},{"location":"user_guide/advanced_usage/#all-driver-arguments","text":"The basic usage section outlined the most commonly used driver arguments, please see the following pages to see all supported driver arguments: Base Driver Arguments GenericDriver Arguments NetworkDriver Arguments Most of these attributes actually get passed from the Driver (or sub-class such as NXOSDriver ) into the Transport and Channel classes, so if you need to modify any of these values after instantiation you should do so on the appropriate object -- i.e. conn.channel.comms_prompt_pattern .","title":"All Driver Arguments"},{"location":"user_guide/advanced_usage/#platform-regex","text":"Due to the nature of Telnet/SSH there is no good way to know when a command has completed execution. Put another way , when sending any command, data is returned over a socket, that socket doesn't ever tell us when it is \"done \" sending the output from the command that was executed. In order to know when the session is \"back at the base prompt/starting point\" scrapli uses a regular expression pattern to find that base prompt. This pattern is contained in the comms_prompt_pattern setting or is created by joining all possible prompt patterns in the privilege levels for a \"core\" device type. In general, you should not change the patterns unless you have a good reason to do so! The \"base\" Driver (default, but changeable) pattern is: \"^[a-z0-9.\\-@()/:]{1,48}[#>$]\\s*$\" NOTE all comms_prompt_pattern \"should\" use the start and end of line anchors as all regex searches in scrapli are multi-line (this is an important piece to making this all work!). While you don't need to use the line anchors its probably a really good idea! Also note that most devices seem to leave at least one white space after the final character of the prompt, so make sure to account for this! Last important note -- the core drivers all have reliable patterns set for you, so you hopefully don't need to bother with this too much! The above pattern works on all \"core\" platforms listed above for at the very least basic usage. Custom prompts or host names could in theory break this, so be careful! If you use a platform driver, the base prompt is set in the driver, so you don't really need to worry about this! The comms_prompt_pattern pattern can be changed at any time at or after instantiation of a scrapli object, and is done so by modifying conn.channel.comms_prompt_pattern where conn is your scrapli connection object. Changing this can break things though, so be careful! If using any NetworkDriver sub-classes you should modify the privilege level(s) if necessary, and not the comms_prompt_pattern .","title":"Platform Regex"},{"location":"user_guide/advanced_usage/#on-open","text":"Lots of times when connecting to a device there are \"things\" that need to happen immediately after getting connected . In the context of network devices the most obvious/common example would be disabling paging (i.e. sending terminal length 0 on a Cisco-type device). While scrapli Driver (the base driver) and GenericDriver do not know or care about disabling paging or any other on connect type activities, scrapli of course provides a mechanism for allowing users to handle these types of tasks. Even better yet, if you are using any of the core drivers ( IOSXEDriver , IOSXRDriver , etc.), scrapli will automatically have some sane default \"on connect\" actions (namely disabling paging). If you were so inclined to create some of your own \"on connect\" actions, you can simply pass those to the on_open argument of Scrape or any of its sub-classes ( NetworkDriver , IOSXEDriver , etc.). The value of this argument must be a callable that accepts the reference to the connection object. This allows for the user to send commands or do really anything that needs to happen prior to \"normal\" operations. The core network drivers disable paging functions all call directly into the channel object send_input method -- this is a good practice to follow as this will avoid any of the NetworkDriver overhead such as trying to attain privilege levels -- things like this may not be \"ready\" until after your on_open function is executed. Below is an example of creating an \"on connect\" function and passing it to scrapli. Immediately after authentication is handled this function will be called and disable paging (in this example): 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from scrapli.driver.core import IOSXEDriver def iosxe_disable_paging ( conn ): conn . channel . send_input ( \"term length 0\" ) my_device = { \"host\" : \"172.18.0.11\" , \"auth_username\" : \"scrapli\" , \"auth_password\" : \"scrapli\" , \"auth_strict_key\" : False , \"on_open\" : iosxe_disable_paging } with IOSXEDriver ( ** my_device ) as conn : print ( conn . get_prompt ()) Note that this section has talked almost exclusively about disabling paging, but any other \"things\" that need to happen in the channel can be handled here. If there is a prompt/banner to accept you should be able to handle it here. The goal of this \"on connect\" function is to allow for lots of flexibility for dealing with whatever needs to happen for devices -- thus decoupling the challenge of addressing all of the possible options from scrapli itself and allowing users to handle things specific for their environment. Lastly, while the on_open method should be synchronous or asyncio depending on the driver -- meaning that if using an async driver, it will await the on_open callable, so it must be asynchronous!","title":"On Open"},{"location":"user_guide/advanced_usage/#on-close","text":"As you may have guessed, on_close is very similar to on_open with the obvious difference that it happens just prior to disconnecting from the device. Just like on_open , on_close functions should accept a single argument that is a reference to the object itself. As with most things scrapli, there are sane defaults for the on_close functions, but you are welcome to override them with your own function if you so chose!","title":"On Close"},{"location":"user_guide/advanced_usage/#timeouts","text":"scrapli supports several timeout options: timeout_socket timeout_transport timeout_ops timeout_socket is exactly what it sounds where possible. For the ssh2 and paramiko transports we create our own socket and pass this to the created object (paramiko or ssh2 object). The socket is created with the timeout value set in the timeout_socket attribute. For telnet and system transports we do not create a socket ourselves so this value is used slightly differently. For telnet, the timeout_socket is used as the timeout for telnet session creation. After the telnet session is created the timeout is reset to the timeout_transport value (more on that in a second). For system transport, timeout_socket governs the ConnectTimeout ssh argument -- which seems to be very similar to socket timeout in paramiko/ssh2. timeout_transport is intended to govern the timeout for the actual transport mechanism itself. For paramiko and ssh2, this is set to the respective libraries timeout attributes. For telnet, this is set to the telnetlib timeout value after the initial telnet session is stood up. For system transport, this value is used as the timeout value for read and write operations (handled by operation timeout decorator). Finally, timeout_ops sets a timeout value for individual operations -- or put another way, the timeout for each send_input operation.","title":"Timeouts"},{"location":"user_guide/advanced_usage/#driver-privilege-levels","text":"The \"core\" drivers understand the basic privilege levels of their respective device types. As mentioned previously , the drivers will automatically attain the \"privilege_exec\" (or equivalent) privilege level prior to executing \"show \" commands. If you don't want this \"auto-magic\" you can use the base driver ( Driver ) or the GenericDriver . The privileges for each device are outlined in the platforms driver.py file - each privilege is an object of the base PrivilegeLevel class which uses slots for the attributes. This used to be a named tuple, however as this was immutable it was a bit of a pain for users to modify things on the fly. As an example, the following privilege levels are supported by the IOSXEDriver : \"exec\" \"privilege_exec\" \"configuration\" Each privilege level has the following attributes: pattern: regex pattern to associate prompt to privilege level with name: name of the priv level, i.e. \"exec\" previous_priv: name of the \"lower\"/\"previous\" privilege level deescalate: command used to deescalate from this privilege level (or an empty string if no lower privilege) escalate: command used to escalate to this privilege level (from the lower/previous privilege) escalate_auth: True/False there is auth required to escalate to this privilege level escalate_prompt: pattern to expect when escalating to this privilege level, i.e. \"Password:\" or any empty string If you wish to manually enter a privilege level you can use the acquire_priv method, passing in the name of the privilege level you would like to enter. In general, you probably won't need this too often though as the driver should handle much of this for you. 1 2 3 4 5 6 7 8 9 10 from scrapli.driver.core import IOSXEDriver my_device = { \"host\" : \"172.18.0.11\" , \"auth_username\" : \"scrapli\" , \"auth_password\" : \"scrapli\" , \"auth_strict_key\" : False , } with IOSXEDriver ( ** my_device ) as conn : conn . acquire_priv ( \"configuration\" )","title":"Driver Privilege Levels"},{"location":"user_guide/advanced_usage/#configure-exclusive-and-configure-private-iosxrjunos","text":"IOSXR and Junos platforms have different configuration modes, such as \"configure exclusive\" or \"configure private \". These alternate configuration modes are represented as a privilege level just like the \"regular\" configuration mode. You can acquire an \"exclusive\" configuration session on IOSXR as follows: 1 2 3 4 5 6 7 8 9 10 from scrapli.driver.core import IOSXRDriver my_device = { \"host\" : \"172.18.0.11\" , \"auth_username\" : \"scrapli\" , \"auth_password\" : \"scrapli\" , \"auth_strict_key\" : False , } with IOSXRDriver ( ** my_device ) as conn : conn . acquire_priv ( \"configuration_exclusive\" ) Of course you can also pass this privilege level name to the send_configs or send_configs_from_file methods as well: 1 2 3 4 5 6 7 8 9 10 from scrapli.driver.core import IOSXRDriver my_device = { \"host\" : \"172.18.0.11\" , \"auth_username\" : \"scrapli\" , \"auth_password\" : \"scrapli\" , \"auth_strict_key\" : False , } with IOSXRDriver ( ** my_device ) as conn : conn . send_configs ( configs = [ \"configure things\" ], privilege_level = \"configuration_exclusive\" ) Note that the name of the privilege level is \"configuration_exclusive\" -- don't forget to write the whole thing out!","title":"Configure Exclusive and Configure Private (IOSXR/Junos)"},{"location":"user_guide/advanced_usage/#configure-session-eosnxos","text":"EOS and NXOS devices support configuration \"sessions\", these sessions are a little bit of a special case for scrapli . In order to use a configuration session, the configuration session must first be \"registered\" with scrapli -- this is so that scrapli can create a privilege level that is mapped to the given config session/config session name . The register_configuration_session method that accepts a string name of the configuration session you would like to create -- note that this method raises a NotImplementedError for platforms that do not support config sessions . The register_configuration_session method creates a new privilege level for you and updates the transport class with the appropriate information internally (see next section). An example of creating a session for an EOS device called \"my-config-session\" can be seen here: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from scrapli.driver.core import EOSDriver my_device = { \"host\" : \"172.18.0.14\" , \"auth_username\" : \"scrapli\" , \"auth_password\" : \"scrapli\" , \"auth_secondary\" : \"VR-netlab9\" , \"auth_strict_key\" : False , } with EOSDriver ( ** my_device ) as conn : conn . register_configuration_session ( session_name = \"my-config-session\" ) print ( conn . privilege_levels [ \"my-config-session\" ]) print ( conn . privilege_levels [ \"my-config-session\" ] . name ) print ( conn . privilege_levels [ \"my-config-session\" ] . pattern ) 1 2 3 <scrapli.driver.network_driver.PrivilegeLevel object at 0x7fca10070820> my-config-session ^[a-z0-9.\\-@/:]{1,32}\\(config\\-s\\-my\\-con[a-z0-9_.\\-@/:]{0,32}\\)#\\s?$","title":"Configure Session (EOS/NXOS)"},{"location":"user_guide/advanced_usage/#modifying-privilege-levels","text":"When creating a configuration session, or modifying a privilege level during runtime, scrapli needs to update some internal arguments in order to always have a full \"map\" of how to escalate/deescalate, as well as to be able to match prompts based on any/all of the patterns available in the privilege levels dictionary. The register_configuration_session method will automatically handle updating these internal arguments, however if you modify any of the privilege levels (or add a priv level on the fly without using the register method) then you will need to manually call the update_privilege_levels method.","title":"Modifying Privilege Levels"},{"location":"user_guide/advanced_usage/#using-driver-directly","text":"All examples in this readme have shown using the \"core\" network drivers such as IOSXEDriver . These core network drivers are actually sub-classes of an ABC called NetworkDriver which itself is a sub-class of the GenericDriver which is a sub-class of the base Scrape class -- the namesake for this library. The Driver object can be used directly if you prefer to have a much less opinionated or less \"auto-magic\" type experience. Driver does not provide the same send_command / send_commands / send_configs methods, nor does it disable paging, or handle any kind of privilege escalation/de-escalation. Driver is a much more basic \"paramiko\"-like experience. Below is a brief example of using the Driver object directly: 1 2 3 4 5 6 7 8 9 10 11 12 from scrapli import Driver my_device = { \"host\" : \"172.18.0.11\" , \"auth_username\" : \"scrapli\" , \"auth_password\" : \"scrapli\" , \"auth_strict_key\" : False , } with Driver ( ** my_device ) as conn : conn . channel . send_input ( \"terminal length 0\" ) response = conn . channel . send_input ( \"show version\" ) Without the send_command and similar methods, you must directly access the Channel object when sending inputs with Scrape .","title":"Using Driver Directly"},{"location":"user_guide/advanced_usage/#using-the-genericdriver","text":"Using the Driver driver directly is nice enough, however you may not want to have to change the prompt pattern, or deal with accessing the channel to send commands to the device. In this case there is a GenericDriver available to you. This driver has a very broad pattern that it matches for base prompts, has no concept of disabling paging or privilege levels (like Driver ), but does provide send_command , send_commands , send_interactive , and get_prompt methods for a more NetworkDriver-like experience. Hopefully this GenericDriver can be used as a starting point for devices that don't fall under the core supported platforms list. 1 2 3 4 5 6 7 8 9 10 11 12 13 from scrapli.driver import GenericDriver my_device = { \"host\" : \"172.18.0.11\" , \"auth_username\" : \"scrapli\" , \"auth_password\" : \"scrapli\" , \"auth_strict_key\" : False , } with GenericDriver ( ** my_device ) as conn : conn . send_command ( \"terminal length 0\" ) response = conn . send_command ( \"show version\" ) responses = conn . send_commands ([ \"show version\" , \"show run\" ])","title":"Using the GenericDriver"},{"location":"user_guide/advanced_usage/#using-a-different-transport","text":"scrapli is built to be very flexible, including being flexible enough to use different libraries for \"transport \" -- or the actual Telnet/SSH communication. By default, scrapli uses the \"system\" transport which quite literally uses the ssh binary on your system ( /usr/bin/ssh ). This \"system\" transport means that scrapli has no external dependencies as it just relies on what is available on the machine running the scrapli script. In the spirit of being highly flexible, scrapli allows users to swap out this \"system\" transport with another transport mechanism. The other supported transport plugins are paramiko , ssh2-python , telnetlib , asyncssh , and asynctelnet . The transport selection can be made when instantiating the scrapli connection object by passing in paramiko , ssh2 , telnet , asyncssh , or asynctelnet to force scrapli to use the corresponding transport mechanism. If you are using one of the async transports you must use an async driver! While it will be a goal to ensure that these other transport mechanisms are supported and useful, the focus of scrapli development will be on the \"system\" SSH transport. Example using paramiko as the transport: 1 2 3 4 5 6 7 8 9 10 11 12 from scrapli.driver.core import IOSXEDriver my_device = { \"host\" : \"172.18.0.11\" , \"auth_username\" : \"scrapli\" , \"auth_password\" : \"scrapli\" , \"auth_strict_key\" : False , \"transport\" : \"paramiko\" } with IOSXEDriver ( ** my_device ) as conn : print ( conn . get_prompt ()) Currently, the only reason I can think of to use anything other than \"system\" as the transport would be to test scrapli on a Windows host, to use telnet, to use ssh2 for super speed, or to use asyncio. If there are other good reasons please do let me know!","title":"Using a Different Transport"},{"location":"user_guide/advanced_usage/#auth-bypass","text":"NOTE only supported with system and telnet transports! Some devices, such as Cisco WLC, have no \"true\" SSH authentication, and instead prompt for credentials (or perhaps not even that) after session establishment. In order to cope with this corner case, the auth_bypass flag can be set to True which will cause scrapli to skip all authentication steps. Typically, this flag would be set and a custom on_open function set to handle whatever prompts the device has upon SSH session establishment. See the non core device example to see this in action.","title":"Auth Bypass"},{"location":"user_guide/advanced_usage/#transport-options","text":"Because each transport has different options/features available, it doesn't make sense to try to put all possible arguments in the Driver or NetworkDriver drivers, to address this an argument transport_options has been added . This is exactly what it sounds like -- arguments that can be passed to the selected transport class. As these arguments will be transport-specific, please check the docs/docstrings for your preferred transport to see what is available. A simple example of passing additional SSH arguments to the SystemSSHTransport class is available here .","title":"Transport Options"},{"location":"user_guide/advanced_usage/#raise-for-status","text":"The scrapli Response and MultiResponse objects both contain a method called raise_for_status . This method's purpose is to provide a very simple way to raise an exception if any of the commands or configs sent in a method have failed. 1 2 3 4 5 6 7 8 9 10 11 12 from scrapli.driver.core import IOSXEDriver my_device = { \"host\" : \"172.18.0.11\" , \"auth_username\" : \"scrapli\" , \"auth_password\" : \"scrapli\" , \"auth_strict_key\" : False , } with IOSXEDriver ( ** my_device ) as conn : commands = [ \"show run\" , \"tacocat\" , \"show version\" ] responses = conn . send_commands ( commands = commands ) Inspecting the responses object from the above example, we can see that it indeed is marked as Success: False , even though the first and last commands were successful: 1 2 3 4 5 6 7 8 >>> responses MultiResponse < Success : False ; Response Elements : 3 > >>> responses [ 0 ] Response < Success : True > >>> responses [ 1 ] Response < Success : False > >>> responses [ 2 ] Response < Success : True > Finally, we can all the raise_for_status method to have scrapli raise the ScrapliCommandFailure exception if any of the configs/commands failed: 1 2 3 4 5 6 >>> responses . raise_for_status () Traceback ( most recent call last ): File \"<stdin>\" , line 1 , in < module > File \"/Users/carl/dev/github/scrapli/scrapli/response.py\" , line 270 , in raise_for_status raise ScrapliCommandFailure () scrapli . exceptions . ScrapliCommandFailure","title":"Raise For Status"},{"location":"user_guide/basic_usage/","text":"Basic Usage \u00b6 Picking the right Driver \u00b6 Assuming you are using scrapli to connect to one of the five \"core\" platforms, you should almost always use the provided corresponding \"core\" driver. For example if you are connecting to an Arista EOS device, you should use the EOSDriver . You can select this driver \"manually\" or using the scrapli factory Scrapli (or the async scrapli factory AsyncScrapli ). Importing your driver manually looks like this: 1 from scrapli.driver.core import EOSDriver If you are using asyncio, you can use the async variant of the driver: 1 from scrapli.driver.core import AsyncEOSDriver The core drivers and associated platforms are outlined below: Platform/OS Scrapli Driver Scrapli Async Driver Platform Name Cisco IOS-XE IOSXEDriver AsyncIOSXEDriver cisco_iosxe Cisco NX-OS NXOSDriver AsyncNXOSDriver cisco_nxos Cisco IOS-XR IOSXRDriver AsyncIOSXRDriver cisco_iosxr Arista EOS EOSDriver AsyncEOSDriver arista_eos Juniper JunOS JunosDriver AsyncJunosDriver juniper_junos All drivers can be imported from scrapli.driver.core . If you would rather use the factory class to dynamically select the appropriate driver based on a platform string (as seen in the above table), you can do so as follows: 1 2 3 4 5 6 7 8 9 10 11 12 13 from scrapli import Scrapli device = { \"host\" : \"172.18.0.11\" , \"auth_username\" : \"scrapli\" , \"auth_password\" : \"scrapli\" , \"auth_strict_key\" : False , \"platform\" : \"cisco_iosxe\" } conn = Scrapli ( ** device ) conn . open () print ( conn . get_prompt ()) Note that the Scrapli and AsyncScrapli classes inherit from the NetworkDriver and AsyncNetworkDriver classes respectively, so all editor code completion and type indicating behavior should work nicely! For non \"core \" platforms please see the scrapli_community project . If you are working with a platform not listed above (and/or is not in the scrapli community project), you have three options: You can use the (base) Driver driver directly, which you can read about here You can use the GenericDriver which you can read about here You can use the NetworkDriver which is similar to option 2 but you will need to understand/provide privilege /prompt information so scrapli can properly escalate/deescalate to/from configuration (or other) modes. In general you should probably simply create a scrapli community platform (read about adding a platform here , but failing that the GenericDriver is probably the simplest path forward. Note: if you are using async you must set the transport to asyncssh or asynctelnet ! Basic Driver Arguments \u00b6 The drivers of course need some information about the device you are trying to connect to. The most common arguments to provide to the driver are outlined below: Argument Purpose/Value host name/ip of host to connect to port port of host to connect to (defaults to port 22) auth_username username for authentication auth_password password for authentication auth_secondary password for secondary authentication (enable password) auth_private_key private key for authentication auth_strict_key strict key checking -- TRUE by default! ssh_config_file True/False or path to ssh config file to use These arguments may be passed as keyword arguments to the driver of your choice, or, commonly are passed via dictionary unpacking as show below: 1 2 3 4 5 6 7 8 9 10 11 from scrapli.driver.core import IOSXRDriver my_device = { \"host\" : \"172.18.0.11\" , \"auth_username\" : \"scrapli\" , \"auth_password\" : \"scrapli\" , \"auth_strict_key\" : False , } conn = IOSXRDriver ( ** my_device ) conn . open () NOTE that scrapli enables strict host key checking by default! Opening and Closing a Connection \u00b6 scrapli does not open the connection for you when creating your scrapli connection object in normal operations, you must manually call the open method prior to sending any commands to the device as shown below. 1 2 3 4 5 6 7 8 9 10 11 12 from scrapli.driver.core import IOSXRDriver my_device = { \"host\" : \"172.18.0.11\" , \"auth_username\" : \"scrapli\" , \"auth_password\" : \"scrapli\" , \"auth_strict_key\" : False , } conn = IOSXRDriver ( ** my_device ) conn . open () response = conn . send_command ( \"show version\" ) Connections can be closed by calling the close method: 1 conn . close () scrapli also supports using a context manager ( with block), when using the context manager the connection will be automatically opened and closed for you. 1 2 3 4 5 6 7 8 9 10 11 from scrapli.driver.core import IOSXEDriver my_device = { \"host\" : \"172.18.0.11\" , \"auth_username\" : \"scrapli\" , \"auth_password\" : \"scrapli\" , \"auth_strict_key\" : False , } with IOSXEDriver ( ** my_device ) as conn : response = conn . send_command ( \"show version\" ) Sending Commands \u00b6 When using any of the core network drivers ( JunosDriver , EOSDriver , etc.) or the GenericDriver , the send_command and send_commands methods will respectively send a single command or list of commands to the device. When using the core network drivers, the command(s) will be sent at the default_desired_privilege_level level which is typically \"privilege exec\" (or equivalent) privilege level. Please see Driver Privilege Levels in the advanced usage section for more details on privilege levels. As the GenericDriver doesn't know or care about privilege levels you would need to manually handle acquiring the appropriate privilege level for you command yourself if using that driver. Note the different methods for sending a single command versus a list of commands! 1 2 3 4 5 6 7 8 9 10 11 12 13 from scrapli.driver.core import IOSXEDriver my_device = { \"host\" : \"172.18.0.11\" , \"auth_username\" : \"scrapli\" , \"auth_password\" : \"scrapli\" , \"auth_strict_key\" : False , } conn = IOSXEDriver ( ** my_device ) conn . open () response = conn . send_command ( \"show version\" ) responses = conn . send_commands ([ \"show run\" , \"show ip int brief\" ]) Finally, if you prefer to have a file containing a list of commands to send, there is a send_commands_from_file method . This method excepts the provided file to have a single command to send per line in the file. Response Object \u00b6 All command/config operations that happen in the GenericDriver or any of the drivers inheriting from the NetworkDriver result in a Response object being created. The Response object contains attributes for the command sent ( channel_input ), start/end/elapsed time, and of course the result of the command sent. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from scrapli.driver.core import IOSXEDriver my_device = { \"host\" : \"172.18.0.11\" , \"auth_username\" : \"scrapli\" , \"auth_password\" : \"scrapli\" , \"auth_strict_key\" : False , } conn = IOSXEDriver ( ** my_device ) conn . open () response = conn . send_command ( \"show version\" ) print ( response . elapsed_time ) print ( response . result ) If using send_commands (plural!) then scrapli will return a MultiResponse object containing multiple Response objects. The MultiResponse object is for all intents and purposes just a list of Response objects (with a few very minor differences). In addition to containing the input and output of the command(s) that you sent, the Response object also contains a method textfsm_parse_output (for more on TextFSM support see Textfsm/NTC-Templates Integration ) which will attempt to parse and return the received output. If parsing fails, the value returned will be an empty list -- meaning you will always get \"structured data\" returned, however it will just be an empty object if parsing fails. 1 2 3 >>> structured_result = response . textfsm_parse_output () >>> print ( structured_result ) [[ '16.4.1' , 'IOS-XE' , 'csr1000v' , '2 days, 22 hours, 10 minutes' , 'reload' , 'packages.conf' , [ 'CSR1000V' ], [ '9FKLJWM5EB0' ], '0x2102' , []]] Sending Configurations \u00b6 When using any of the core drivers, you can send configurations via the send_config , send_configs or send_configs_from_file methods which will handle privilege escalation for you. send_config accepts a single string, send_configs accepts a list of strings, and of course send_configs_from_file accepts a string path to a file containing configurations to send. Note that send_configs_from_file -- just like with it's commands sibling -- will treat each line in the file as a configuration element, in this way it behaves much like send_configs . Lastly, it is good to know that send_config (singular!) will parse the configuration string provided and split it into lines -- this means that the underlying behavior is the same as send_configs , however this method returns a single Response object. This send_config method can be used to send entire configurations to devices in a reliable fashion. 1 2 3 4 5 6 7 8 9 10 11 from scrapli.driver.core import IOSXEDriver my_device = { \"host\" : \"172.18.0.11\" , \"auth_username\" : \"scrapli\" , \"auth_password\" : \"scrapli\" , \"auth_strict_key\" : False , } with IOSXEDriver ( ** my_device ) as conn : conn . send_configs ([ \"interface loopback123\" , \"description configured by scrapli\" ]) If you need to get into any kind of \"special\" configuration mode, such as \"configure exclusive\", \"configure private \", or \"configure session XYZ\", you can pass the name of the corresponding privilege level via the privilege_level argument. Please see the Driver Privilege Levels section for more details! Lastly, note that scrapli does not exit configuration mode at completion of a \"configuration\" event -- this is because scrapli (with the Network drivers) will automatically acquire default_desired_privilege_level before sending a \"command\" -- so there is no need, from a scrapli perspective, to explicitly exit config mode at end of the configuration session. Textfsm/NTC-Templates Integration \u00b6 scrapli supports parsing output with TextFSM and ntc-templates. This of course requires installing TextFSM and having ntc-templates somewhere on your system. When using a platform driver (i.e. IOSXEDriver ) the textfsm-platform will be set for you (based on the driver device type). If you wish to parse the output of your send commands, you can use the textfsm_parse_output method of the response object. This method will attempt to find the template for you -- based on the textfsm-platform and the channel-input (the command sent). If textfsm parsing succeeds, the structured result is returned. If textfsm parsing fails, an empty list is returned. 1 2 3 4 5 6 7 8 9 10 11 12 13 from scrapli.driver.core import IOSXEDriver my_device = { \"host\" : \"172.18.0.11\" , \"auth_username\" : \"scrapli\" , \"auth_password\" : \"scrapli\" , \"auth_strict_key\" : False , } with IOSXEDriver ( ** my_device ) as conn : response = conn . send_command ( \"show version\" ) structured_result = response . textfsm_parse_output () print ( structured_result ) scrapli also supports passing in templates manually (meaning not using the pip installed ntc-templates directory to find templates) if desired. The textfsm_parse_output method and scrapli.helper.textfsm_parse function both accepts a string or loaded (TextIOWrapper ) template and output to parse. This can be useful if you have custom or one off templates or don't want to pip install ntc-templates. 1 2 3 4 5 6 7 8 9 10 11 12 13 from scrapli.driver.core import IOSXEDriver from scrapli.helper import textfsm_parse my_device = { \"host\" : \"172.18.0.11\" , \"auth_username\" : \"scrapli\" , \"auth_password\" : \"scrapli\" , \"auth_strict_key\" : False , } with IOSXEDriver ( ** my_device ) as conn : response = conn . send_command ( \"show version\" ) structured_result = textfsm_parse ( \"/path/to/my/template\" , response . result ) NOTE : If a template does not return structured data an empty list will be returned! NOTE : Textfsm and ntc-templates is an optional extra for scrapli; you can install these modules manually or using the optional extras install via pip: pip install scrapli[textfsm] Cisco Genie Integration \u00b6 Very much the same as the textfsm/ntc-templates integration, scrapli has optional integration with Cisco's PyATS /Genie parsing library for parsing show command output. While there are parsers for non-Cisco platforms, this is currently just an option for Cisco platforms within scrapli. 1 2 3 4 5 6 7 8 9 10 11 12 13 from scrapli.driver.core import IOSXEDriver my_device = { \"host\" : \"172.18.0.11\" , \"auth_username\" : \"scrapli\" , \"auth_password\" : \"scrapli\" , \"auth_strict_key\" : False , } with IOSXEDriver ( ** my_device ) as conn : response = conn . send_command ( \"show version\" ) structured_result = response . genie_parse_output () print ( structured_result ) NOTE : If a parser does not return structured data an empty list will be returned! NOTE : PyATS and Genie is an optional extra for scrapli; you can install these modules manually or using the optional extras install via pip: pip install scrapli[genie] TTP Integration \u00b6 The scrapli response object also contains a ttp_parse_output method, that, as you may have guessed, uses the ttp library to parse output received from the device. Other than the obvious difference that this is in fact a different type of parser, the only difference from a usage perspective is that the ttp_parse_output method requires a template string, string path to a template, or loaded (TextIOWrapper ) template string to be passed. This is because there is no index or mapping of platform:command:template as there is with TextFSM/ntc-templates and genie. An example ttp file (slightly modified from the great ttp quickstart guide) - in this case we'll pretend this file is called \"my_template.ttp\": 1 2 3 interface {{ interface }} ip address {{ ip }} {{ mask }} description {{ description }} 1 2 3 4 5 6 7 8 9 10 11 12 13 from scrapli.driver.core import IOSXEDriver my_device = { \"host\" : \"172.18.0.11\" , \"auth_username\" : \"scrapli\" , \"auth_password\" : \"scrapli\" , \"auth_strict_key\" : False , } with IOSXEDriver ( ** my_device ) as conn : response = conn . send_command ( \"show run interface GigabitEthernet1\" ) structured_result = response . ttp_parse_output ( template = \"my_template.ttp\" ) print ( structured_result ) NOTE : If a parser does parse data, ttp will return an empty list (as with the other parser methods) NOTE : ttp is an optional extra for scrapli; you can install these modules manually or using the optional extras install via pip: pip install scrapli[ttp] Handling Prompts \u00b6 In some cases you may need to run an \"interactive\" command on your device. The send_interactive method of the GenericDriver or its sub-classes ( NetworkDriver and \"core\" drivers) can be used to accomplish this. This method accepts a list of \"interact_events\" -- or basically commands you would like to send, and their expected resulting prompt. A third, optional, element is available for each \"interaction\", this last element is a bool that indicates weather or not the input that you are sending to the device is \"hidden\" or obfuscated by the device. This is typically used for password prompts where the input that is sent does not show up on the screen (if you as a human are sitting on a terminal typing). This method can accept one or N \"events\" and thus can be used to deal with any number of subsequent prompts. One last important item about this method is that it accepts an argument privilege_level -- the value of this argument should be the name of the privilege level that you would like to execute the interactive command at . This is an optional argument, with a default of the default_desired_privilege_level attribute which is normally \"privilege exec\" or similar depending on the platform. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 from scrapli.driver.core import IOSXEDriver my_device = { \"host\" : \"172.18.0.11\" , \"auth_username\" : \"scrapli\" , \"auth_password\" : \"scrapli\" , \"auth_strict_key\" : False , } with IOSXEDriver ( ** my_device ) as conn : interactive = conn . send_interactive ( [ ( \"copy flash: scp:\" , \"Source filename []?\" , False ), ( \"somefile.txt\" , \"Address or name of remote host []?\" , False ), ( \"172.31.254.100\" , \"Destination username [carl]?\" , False ), ( \"scrapli\" , \"Password:\" , False ), ( \"super_secure_password\" , \"csr1000v#\" , True ), ] ) Telnet \u00b6 scrapli supports telnet as a transport driver via the standard library module telnetlib or with a custom-built async telnet transport (creatively called \"asynctelnet\") built on the standard library asycnio . A few things worth noting: You can set the username and password prompt expect string after your connection object instantiation and before calling the open method -- this means if you have non-default prompts you cannot use scrapli with a context manager and Telnet (because the context manager calls open for you). You can set the prompts using the following attributes of the Channel (or AsyncChannel ) object: telnet_username_prompt which defaults to ^(.*username:)|(.*login:)\\s?$ telnet_password_prompt which defaults to ^password:\\s?$ You can set these values by updating the appropriate attribute, for example: conn.channel.telnet_username_prompt = \"somethingneat\" . If you wish to provide custom prompt values you can provide a string to look for \"in\" the output from the device, or a regular expression pattern that starts with ^ and ends with $ -- if you don't use the line anchors the pattern will be re.escape 'd. When using telnet you may need to set the comms_return_char to \\r\\n the tests against the core platforms pass without this, however it seems that some console server type devices are looking for this \\r\\n pattern instead of the default \\n pattern. SSH Config Support \u00b6 scrapli supports using OpenSSH configuration files in a few ways. For \"system\" SSH transport (default setting ), passing a path to a config file will simply make scrapli \"point\" to that file, and therefore use that configuration files attributes (because it is just exec'ing system SSH!). You can also pass True to let scrapli search in system default locations for a ssh config file ( ~/.ssh/config and /etc/ssh/ssh_config ). SSH transports other than \"system\" transport may support some subset of the OpenSSH configuration files, but will not provide full support. Asyncssh, for example, will automatically pick up and handle proxy-jumps, SSH keys, and some other items -- this is a 100% asyncssh feature and has nothing to do with scrapli (other than the fact that scrapli allows you to use asyncssh). NOTE -- scrapli does NOT disable strict host checking by default. Obviously this is the \"smart\" behavior, but it can be overridden on a per host basis in your SSH config file, or by passing False to the \"auth_strict_key \" argument on object instantiation. 1 2 3 4 5 6 7 8 9 10 11 12 from scrapli.driver.core import IOSXEDriver my_device = { \"host\" : \"172.18.0.11\" , \"auth_username\" : \"scrapli\" , \"auth_password\" : \"scrapli\" , \"auth_strict_key\" : False , \"ssh_config_file\" : \"~/my_ssh_config\" , } with IOSXEDriver ( ** my_device ) as conn : print ( conn . get_prompt ())","title":"Basic Usage"},{"location":"user_guide/basic_usage/#basic-usage","text":"","title":"Basic Usage"},{"location":"user_guide/basic_usage/#picking-the-right-driver","text":"Assuming you are using scrapli to connect to one of the five \"core\" platforms, you should almost always use the provided corresponding \"core\" driver. For example if you are connecting to an Arista EOS device, you should use the EOSDriver . You can select this driver \"manually\" or using the scrapli factory Scrapli (or the async scrapli factory AsyncScrapli ). Importing your driver manually looks like this: 1 from scrapli.driver.core import EOSDriver If you are using asyncio, you can use the async variant of the driver: 1 from scrapli.driver.core import AsyncEOSDriver The core drivers and associated platforms are outlined below: Platform/OS Scrapli Driver Scrapli Async Driver Platform Name Cisco IOS-XE IOSXEDriver AsyncIOSXEDriver cisco_iosxe Cisco NX-OS NXOSDriver AsyncNXOSDriver cisco_nxos Cisco IOS-XR IOSXRDriver AsyncIOSXRDriver cisco_iosxr Arista EOS EOSDriver AsyncEOSDriver arista_eos Juniper JunOS JunosDriver AsyncJunosDriver juniper_junos All drivers can be imported from scrapli.driver.core . If you would rather use the factory class to dynamically select the appropriate driver based on a platform string (as seen in the above table), you can do so as follows: 1 2 3 4 5 6 7 8 9 10 11 12 13 from scrapli import Scrapli device = { \"host\" : \"172.18.0.11\" , \"auth_username\" : \"scrapli\" , \"auth_password\" : \"scrapli\" , \"auth_strict_key\" : False , \"platform\" : \"cisco_iosxe\" } conn = Scrapli ( ** device ) conn . open () print ( conn . get_prompt ()) Note that the Scrapli and AsyncScrapli classes inherit from the NetworkDriver and AsyncNetworkDriver classes respectively, so all editor code completion and type indicating behavior should work nicely! For non \"core \" platforms please see the scrapli_community project . If you are working with a platform not listed above (and/or is not in the scrapli community project), you have three options: You can use the (base) Driver driver directly, which you can read about here You can use the GenericDriver which you can read about here You can use the NetworkDriver which is similar to option 2 but you will need to understand/provide privilege /prompt information so scrapli can properly escalate/deescalate to/from configuration (or other) modes. In general you should probably simply create a scrapli community platform (read about adding a platform here , but failing that the GenericDriver is probably the simplest path forward. Note: if you are using async you must set the transport to asyncssh or asynctelnet !","title":"Picking the right Driver"},{"location":"user_guide/basic_usage/#basic-driver-arguments","text":"The drivers of course need some information about the device you are trying to connect to. The most common arguments to provide to the driver are outlined below: Argument Purpose/Value host name/ip of host to connect to port port of host to connect to (defaults to port 22) auth_username username for authentication auth_password password for authentication auth_secondary password for secondary authentication (enable password) auth_private_key private key for authentication auth_strict_key strict key checking -- TRUE by default! ssh_config_file True/False or path to ssh config file to use These arguments may be passed as keyword arguments to the driver of your choice, or, commonly are passed via dictionary unpacking as show below: 1 2 3 4 5 6 7 8 9 10 11 from scrapli.driver.core import IOSXRDriver my_device = { \"host\" : \"172.18.0.11\" , \"auth_username\" : \"scrapli\" , \"auth_password\" : \"scrapli\" , \"auth_strict_key\" : False , } conn = IOSXRDriver ( ** my_device ) conn . open () NOTE that scrapli enables strict host key checking by default!","title":"Basic Driver Arguments"},{"location":"user_guide/basic_usage/#opening-and-closing-a-connection","text":"scrapli does not open the connection for you when creating your scrapli connection object in normal operations, you must manually call the open method prior to sending any commands to the device as shown below. 1 2 3 4 5 6 7 8 9 10 11 12 from scrapli.driver.core import IOSXRDriver my_device = { \"host\" : \"172.18.0.11\" , \"auth_username\" : \"scrapli\" , \"auth_password\" : \"scrapli\" , \"auth_strict_key\" : False , } conn = IOSXRDriver ( ** my_device ) conn . open () response = conn . send_command ( \"show version\" ) Connections can be closed by calling the close method: 1 conn . close () scrapli also supports using a context manager ( with block), when using the context manager the connection will be automatically opened and closed for you. 1 2 3 4 5 6 7 8 9 10 11 from scrapli.driver.core import IOSXEDriver my_device = { \"host\" : \"172.18.0.11\" , \"auth_username\" : \"scrapli\" , \"auth_password\" : \"scrapli\" , \"auth_strict_key\" : False , } with IOSXEDriver ( ** my_device ) as conn : response = conn . send_command ( \"show version\" )","title":"Opening and Closing a Connection"},{"location":"user_guide/basic_usage/#sending-commands","text":"When using any of the core network drivers ( JunosDriver , EOSDriver , etc.) or the GenericDriver , the send_command and send_commands methods will respectively send a single command or list of commands to the device. When using the core network drivers, the command(s) will be sent at the default_desired_privilege_level level which is typically \"privilege exec\" (or equivalent) privilege level. Please see Driver Privilege Levels in the advanced usage section for more details on privilege levels. As the GenericDriver doesn't know or care about privilege levels you would need to manually handle acquiring the appropriate privilege level for you command yourself if using that driver. Note the different methods for sending a single command versus a list of commands! 1 2 3 4 5 6 7 8 9 10 11 12 13 from scrapli.driver.core import IOSXEDriver my_device = { \"host\" : \"172.18.0.11\" , \"auth_username\" : \"scrapli\" , \"auth_password\" : \"scrapli\" , \"auth_strict_key\" : False , } conn = IOSXEDriver ( ** my_device ) conn . open () response = conn . send_command ( \"show version\" ) responses = conn . send_commands ([ \"show run\" , \"show ip int brief\" ]) Finally, if you prefer to have a file containing a list of commands to send, there is a send_commands_from_file method . This method excepts the provided file to have a single command to send per line in the file.","title":"Sending Commands"},{"location":"user_guide/basic_usage/#response-object","text":"All command/config operations that happen in the GenericDriver or any of the drivers inheriting from the NetworkDriver result in a Response object being created. The Response object contains attributes for the command sent ( channel_input ), start/end/elapsed time, and of course the result of the command sent. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from scrapli.driver.core import IOSXEDriver my_device = { \"host\" : \"172.18.0.11\" , \"auth_username\" : \"scrapli\" , \"auth_password\" : \"scrapli\" , \"auth_strict_key\" : False , } conn = IOSXEDriver ( ** my_device ) conn . open () response = conn . send_command ( \"show version\" ) print ( response . elapsed_time ) print ( response . result ) If using send_commands (plural!) then scrapli will return a MultiResponse object containing multiple Response objects. The MultiResponse object is for all intents and purposes just a list of Response objects (with a few very minor differences). In addition to containing the input and output of the command(s) that you sent, the Response object also contains a method textfsm_parse_output (for more on TextFSM support see Textfsm/NTC-Templates Integration ) which will attempt to parse and return the received output. If parsing fails, the value returned will be an empty list -- meaning you will always get \"structured data\" returned, however it will just be an empty object if parsing fails. 1 2 3 >>> structured_result = response . textfsm_parse_output () >>> print ( structured_result ) [[ '16.4.1' , 'IOS-XE' , 'csr1000v' , '2 days, 22 hours, 10 minutes' , 'reload' , 'packages.conf' , [ 'CSR1000V' ], [ '9FKLJWM5EB0' ], '0x2102' , []]]","title":"Response Object"},{"location":"user_guide/basic_usage/#sending-configurations","text":"When using any of the core drivers, you can send configurations via the send_config , send_configs or send_configs_from_file methods which will handle privilege escalation for you. send_config accepts a single string, send_configs accepts a list of strings, and of course send_configs_from_file accepts a string path to a file containing configurations to send. Note that send_configs_from_file -- just like with it's commands sibling -- will treat each line in the file as a configuration element, in this way it behaves much like send_configs . Lastly, it is good to know that send_config (singular!) will parse the configuration string provided and split it into lines -- this means that the underlying behavior is the same as send_configs , however this method returns a single Response object. This send_config method can be used to send entire configurations to devices in a reliable fashion. 1 2 3 4 5 6 7 8 9 10 11 from scrapli.driver.core import IOSXEDriver my_device = { \"host\" : \"172.18.0.11\" , \"auth_username\" : \"scrapli\" , \"auth_password\" : \"scrapli\" , \"auth_strict_key\" : False , } with IOSXEDriver ( ** my_device ) as conn : conn . send_configs ([ \"interface loopback123\" , \"description configured by scrapli\" ]) If you need to get into any kind of \"special\" configuration mode, such as \"configure exclusive\", \"configure private \", or \"configure session XYZ\", you can pass the name of the corresponding privilege level via the privilege_level argument. Please see the Driver Privilege Levels section for more details! Lastly, note that scrapli does not exit configuration mode at completion of a \"configuration\" event -- this is because scrapli (with the Network drivers) will automatically acquire default_desired_privilege_level before sending a \"command\" -- so there is no need, from a scrapli perspective, to explicitly exit config mode at end of the configuration session.","title":"Sending Configurations"},{"location":"user_guide/basic_usage/#textfsmntc-templates-integration","text":"scrapli supports parsing output with TextFSM and ntc-templates. This of course requires installing TextFSM and having ntc-templates somewhere on your system. When using a platform driver (i.e. IOSXEDriver ) the textfsm-platform will be set for you (based on the driver device type). If you wish to parse the output of your send commands, you can use the textfsm_parse_output method of the response object. This method will attempt to find the template for you -- based on the textfsm-platform and the channel-input (the command sent). If textfsm parsing succeeds, the structured result is returned. If textfsm parsing fails, an empty list is returned. 1 2 3 4 5 6 7 8 9 10 11 12 13 from scrapli.driver.core import IOSXEDriver my_device = { \"host\" : \"172.18.0.11\" , \"auth_username\" : \"scrapli\" , \"auth_password\" : \"scrapli\" , \"auth_strict_key\" : False , } with IOSXEDriver ( ** my_device ) as conn : response = conn . send_command ( \"show version\" ) structured_result = response . textfsm_parse_output () print ( structured_result ) scrapli also supports passing in templates manually (meaning not using the pip installed ntc-templates directory to find templates) if desired. The textfsm_parse_output method and scrapli.helper.textfsm_parse function both accepts a string or loaded (TextIOWrapper ) template and output to parse. This can be useful if you have custom or one off templates or don't want to pip install ntc-templates. 1 2 3 4 5 6 7 8 9 10 11 12 13 from scrapli.driver.core import IOSXEDriver from scrapli.helper import textfsm_parse my_device = { \"host\" : \"172.18.0.11\" , \"auth_username\" : \"scrapli\" , \"auth_password\" : \"scrapli\" , \"auth_strict_key\" : False , } with IOSXEDriver ( ** my_device ) as conn : response = conn . send_command ( \"show version\" ) structured_result = textfsm_parse ( \"/path/to/my/template\" , response . result ) NOTE : If a template does not return structured data an empty list will be returned! NOTE : Textfsm and ntc-templates is an optional extra for scrapli; you can install these modules manually or using the optional extras install via pip: pip install scrapli[textfsm]","title":"Textfsm/NTC-Templates Integration"},{"location":"user_guide/basic_usage/#cisco-genie-integration","text":"Very much the same as the textfsm/ntc-templates integration, scrapli has optional integration with Cisco's PyATS /Genie parsing library for parsing show command output. While there are parsers for non-Cisco platforms, this is currently just an option for Cisco platforms within scrapli. 1 2 3 4 5 6 7 8 9 10 11 12 13 from scrapli.driver.core import IOSXEDriver my_device = { \"host\" : \"172.18.0.11\" , \"auth_username\" : \"scrapli\" , \"auth_password\" : \"scrapli\" , \"auth_strict_key\" : False , } with IOSXEDriver ( ** my_device ) as conn : response = conn . send_command ( \"show version\" ) structured_result = response . genie_parse_output () print ( structured_result ) NOTE : If a parser does not return structured data an empty list will be returned! NOTE : PyATS and Genie is an optional extra for scrapli; you can install these modules manually or using the optional extras install via pip: pip install scrapli[genie]","title":"Cisco Genie Integration"},{"location":"user_guide/basic_usage/#ttp-integration","text":"The scrapli response object also contains a ttp_parse_output method, that, as you may have guessed, uses the ttp library to parse output received from the device. Other than the obvious difference that this is in fact a different type of parser, the only difference from a usage perspective is that the ttp_parse_output method requires a template string, string path to a template, or loaded (TextIOWrapper ) template string to be passed. This is because there is no index or mapping of platform:command:template as there is with TextFSM/ntc-templates and genie. An example ttp file (slightly modified from the great ttp quickstart guide) - in this case we'll pretend this file is called \"my_template.ttp\": 1 2 3 interface {{ interface }} ip address {{ ip }} {{ mask }} description {{ description }} 1 2 3 4 5 6 7 8 9 10 11 12 13 from scrapli.driver.core import IOSXEDriver my_device = { \"host\" : \"172.18.0.11\" , \"auth_username\" : \"scrapli\" , \"auth_password\" : \"scrapli\" , \"auth_strict_key\" : False , } with IOSXEDriver ( ** my_device ) as conn : response = conn . send_command ( \"show run interface GigabitEthernet1\" ) structured_result = response . ttp_parse_output ( template = \"my_template.ttp\" ) print ( structured_result ) NOTE : If a parser does parse data, ttp will return an empty list (as with the other parser methods) NOTE : ttp is an optional extra for scrapli; you can install these modules manually or using the optional extras install via pip: pip install scrapli[ttp]","title":"TTP Integration"},{"location":"user_guide/basic_usage/#handling-prompts","text":"In some cases you may need to run an \"interactive\" command on your device. The send_interactive method of the GenericDriver or its sub-classes ( NetworkDriver and \"core\" drivers) can be used to accomplish this. This method accepts a list of \"interact_events\" -- or basically commands you would like to send, and their expected resulting prompt. A third, optional, element is available for each \"interaction\", this last element is a bool that indicates weather or not the input that you are sending to the device is \"hidden\" or obfuscated by the device. This is typically used for password prompts where the input that is sent does not show up on the screen (if you as a human are sitting on a terminal typing). This method can accept one or N \"events\" and thus can be used to deal with any number of subsequent prompts. One last important item about this method is that it accepts an argument privilege_level -- the value of this argument should be the name of the privilege level that you would like to execute the interactive command at . This is an optional argument, with a default of the default_desired_privilege_level attribute which is normally \"privilege exec\" or similar depending on the platform. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 from scrapli.driver.core import IOSXEDriver my_device = { \"host\" : \"172.18.0.11\" , \"auth_username\" : \"scrapli\" , \"auth_password\" : \"scrapli\" , \"auth_strict_key\" : False , } with IOSXEDriver ( ** my_device ) as conn : interactive = conn . send_interactive ( [ ( \"copy flash: scp:\" , \"Source filename []?\" , False ), ( \"somefile.txt\" , \"Address or name of remote host []?\" , False ), ( \"172.31.254.100\" , \"Destination username [carl]?\" , False ), ( \"scrapli\" , \"Password:\" , False ), ( \"super_secure_password\" , \"csr1000v#\" , True ), ] )","title":"Handling Prompts"},{"location":"user_guide/basic_usage/#telnet","text":"scrapli supports telnet as a transport driver via the standard library module telnetlib or with a custom-built async telnet transport (creatively called \"asynctelnet\") built on the standard library asycnio . A few things worth noting: You can set the username and password prompt expect string after your connection object instantiation and before calling the open method -- this means if you have non-default prompts you cannot use scrapli with a context manager and Telnet (because the context manager calls open for you). You can set the prompts using the following attributes of the Channel (or AsyncChannel ) object: telnet_username_prompt which defaults to ^(.*username:)|(.*login:)\\s?$ telnet_password_prompt which defaults to ^password:\\s?$ You can set these values by updating the appropriate attribute, for example: conn.channel.telnet_username_prompt = \"somethingneat\" . If you wish to provide custom prompt values you can provide a string to look for \"in\" the output from the device, or a regular expression pattern that starts with ^ and ends with $ -- if you don't use the line anchors the pattern will be re.escape 'd. When using telnet you may need to set the comms_return_char to \\r\\n the tests against the core platforms pass without this, however it seems that some console server type devices are looking for this \\r\\n pattern instead of the default \\n pattern.","title":"Telnet"},{"location":"user_guide/basic_usage/#ssh-config-support","text":"scrapli supports using OpenSSH configuration files in a few ways. For \"system\" SSH transport (default setting ), passing a path to a config file will simply make scrapli \"point\" to that file, and therefore use that configuration files attributes (because it is just exec'ing system SSH!). You can also pass True to let scrapli search in system default locations for a ssh config file ( ~/.ssh/config and /etc/ssh/ssh_config ). SSH transports other than \"system\" transport may support some subset of the OpenSSH configuration files, but will not provide full support. Asyncssh, for example, will automatically pick up and handle proxy-jumps, SSH keys, and some other items -- this is a 100% asyncssh feature and has nothing to do with scrapli (other than the fact that scrapli allows you to use asyncssh). NOTE -- scrapli does NOT disable strict host checking by default. Obviously this is the \"smart\" behavior, but it can be overridden on a per host basis in your SSH config file, or by passing False to the \"auth_strict_key \" argument on object instantiation. 1 2 3 4 5 6 7 8 9 10 11 12 from scrapli.driver.core import IOSXEDriver my_device = { \"host\" : \"172.18.0.11\" , \"auth_username\" : \"scrapli\" , \"auth_password\" : \"scrapli\" , \"auth_strict_key\" : False , \"ssh_config_file\" : \"~/my_ssh_config\" , } with IOSXEDriver ( ** my_device ) as conn : print ( conn . get_prompt ())","title":"SSH Config Support"},{"location":"user_guide/faq/","text":"FAQ \u00b6 Question: Why build this? Answer: I built ssh2net to learn -- to have a goal/target for writing some code. scrapli is an evolution of the lessons learned building ssh2net. About mid-way through building ssh2net I realized it may actually be kinda good at doing... stuff. So, sure there are other tools out there, but I think scrapli its pretty snazzy and fills in some of the gaps in other tools. For example scrapli is 100% compliant with strict mypy type checking, very uniformly documented/linted, contains a results object for every operation, is very very fast, is very flexible, and in general pretty awesome! Finally, while I think in general that SSH \"screen scraping\" is not \"sexy\" or even \"good\", it is the lowest common denominator for automation in the networking world. So I figured I could try to make the fastest, most flexible library around for SSH network automation! Question: Is this better than XYZ? Answer: Nope! It is different though! The main focus is just to be stupid fast. It is very much that. It should be super reliable too as the timeouts are very easy/obvious to control, and it should also be very very very easy to adapt to any other network-y type CLI by virtue of flexible prompt finding and easily modifiable on connect functions. I wanna go fast! Hmmm... not a question but I dig it. If you wanna go fast you gotta learn to drive with the fear... ok, enough Talladega Nights quoting for now. In theory using the ssh2 transport is the gateway to speed... being a very thin wrapper around libssh2 means that its basically all C and that means its probably about as fast as we're reasonably going to get. All that said, scrapli by default uses the system transport which is really just using your system ssh.... which is almost certainly libssh2/openssh which is also C. There is a thin layer of abstraction between scrapli and your system ssh but really its just reading/writing to a file which Python should be doing in C anyway I would think. In summary... while ssh2 is probably the fastest you can go with scrapli, the difference between ssh2 and system transports in limited testing is very small, and the benefits of using system transport (native ssh config file support!!) probably should outweigh the speed of ssh2 -- especially if you have control persist and can take advantage of that with system transport! Hey does this thing do SCP? Nope! But the very cool @viktorkertesz has created scrapli_scp which you should defo check out if you wanna do SCP things! Other questions? Ask away!","title":"FAQ"},{"location":"user_guide/faq/#faq","text":"Question: Why build this? Answer: I built ssh2net to learn -- to have a goal/target for writing some code. scrapli is an evolution of the lessons learned building ssh2net. About mid-way through building ssh2net I realized it may actually be kinda good at doing... stuff. So, sure there are other tools out there, but I think scrapli its pretty snazzy and fills in some of the gaps in other tools. For example scrapli is 100% compliant with strict mypy type checking, very uniformly documented/linted, contains a results object for every operation, is very very fast, is very flexible, and in general pretty awesome! Finally, while I think in general that SSH \"screen scraping\" is not \"sexy\" or even \"good\", it is the lowest common denominator for automation in the networking world. So I figured I could try to make the fastest, most flexible library around for SSH network automation! Question: Is this better than XYZ? Answer: Nope! It is different though! The main focus is just to be stupid fast. It is very much that. It should be super reliable too as the timeouts are very easy/obvious to control, and it should also be very very very easy to adapt to any other network-y type CLI by virtue of flexible prompt finding and easily modifiable on connect functions. I wanna go fast! Hmmm... not a question but I dig it. If you wanna go fast you gotta learn to drive with the fear... ok, enough Talladega Nights quoting for now. In theory using the ssh2 transport is the gateway to speed... being a very thin wrapper around libssh2 means that its basically all C and that means its probably about as fast as we're reasonably going to get. All that said, scrapli by default uses the system transport which is really just using your system ssh.... which is almost certainly libssh2/openssh which is also C. There is a thin layer of abstraction between scrapli and your system ssh but really its just reading/writing to a file which Python should be doing in C anyway I would think. In summary... while ssh2 is probably the fastest you can go with scrapli, the difference between ssh2 and system transports in limited testing is very small, and the benefits of using system transport (native ssh config file support!!) probably should outweigh the speed of ssh2 -- especially if you have control persist and can take advantage of that with system transport! Hey does this thing do SCP? Nope! But the very cool @viktorkertesz has created scrapli_scp which you should defo check out if you wanna do SCP things! Other questions? Ask away!","title":"FAQ"},{"location":"user_guide/installation/","text":"Installation \u00b6 Standard Installation \u00b6 As outlined in the quick start, you should be able to pip install scrapli \"normally\": 1 pip install scrapli Installing current main branch \u00b6 To install from the source repositories master branch: 1 pip install git+https://github.com/carlmontanari/scrapli Installing a different branch \u00b6 To install from a different branch of the source repository, for example from a branch named develop : 1 pip install -e git+https://github.com/carlmontanari/scrapli.git@develop#egg=scrapli Installation from Source \u00b6 To install from source: 1 2 3 git clone https://github.com/carlmontanari/scrapli cd scrapli python setup.py install Optional Extras \u00b6 scrapli has made an effort to have as few dependencies as possible -- in fact to have ZERO dependencies! The \"core\" of scrapli can run with nothing other than standard library! If for any reason you wish to use paramiko, ssh2-python, or asyncssh as a transport, however, you of course need to install those. These \"extras\" can be installed via pip: 1 pip install scrapli[paramiko] The available optional installation extras options are: paramiko ssh2 asyncssh textfsm (textfsm and ntc-templates) ttp (ttp template parser) genie (genie/pyats) netconf (scrapli_netconf) community (scrapli_community) If you would like to install all optional extras, you can do so with the full option: 1 pip install scrapli[full] Supported Platforms \u00b6 As for platforms to run scrapli on -- it has and will be tested on MacOS and Ubuntu regularly and should work on any POSIX system. Windows at one point was being tested very minimally via GitHub Actions builds, however this is no longer the case as it is just not worth the effort. While scrapli should work on Windows when using the paramiko or ssh2-python transport drivers, it is not \"officially\" supported. It is strongly recommended/preferred for folks to use WSL/Cygwin instead of Windows.","title":"Installation"},{"location":"user_guide/installation/#installation","text":"","title":"Installation"},{"location":"user_guide/installation/#standard-installation","text":"As outlined in the quick start, you should be able to pip install scrapli \"normally\": 1 pip install scrapli","title":"Standard Installation"},{"location":"user_guide/installation/#installing-current-main-branch","text":"To install from the source repositories master branch: 1 pip install git+https://github.com/carlmontanari/scrapli","title":"Installing current main branch"},{"location":"user_guide/installation/#installing-a-different-branch","text":"To install from a different branch of the source repository, for example from a branch named develop : 1 pip install -e git+https://github.com/carlmontanari/scrapli.git@develop#egg=scrapli","title":"Installing a different branch"},{"location":"user_guide/installation/#installation-from-source","text":"To install from source: 1 2 3 git clone https://github.com/carlmontanari/scrapli cd scrapli python setup.py install","title":"Installation from Source"},{"location":"user_guide/installation/#optional-extras","text":"scrapli has made an effort to have as few dependencies as possible -- in fact to have ZERO dependencies! The \"core\" of scrapli can run with nothing other than standard library! If for any reason you wish to use paramiko, ssh2-python, or asyncssh as a transport, however, you of course need to install those. These \"extras\" can be installed via pip: 1 pip install scrapli[paramiko] The available optional installation extras options are: paramiko ssh2 asyncssh textfsm (textfsm and ntc-templates) ttp (ttp template parser) genie (genie/pyats) netconf (scrapli_netconf) community (scrapli_community) If you would like to install all optional extras, you can do so with the full option: 1 pip install scrapli[full]","title":"Optional Extras"},{"location":"user_guide/installation/#supported-platforms","text":"As for platforms to run scrapli on -- it has and will be tested on MacOS and Ubuntu regularly and should work on any POSIX system. Windows at one point was being tested very minimally via GitHub Actions builds, however this is no longer the case as it is just not worth the effort. While scrapli should work on Windows when using the paramiko or ssh2-python transport drivers, it is not \"officially\" supported. It is strongly recommended/preferred for folks to use WSL/Cygwin instead of Windows.","title":"Supported Platforms"},{"location":"user_guide/linting_testing/","text":"Linting and Testing \u00b6 Linting \u00b6 This project uses black for auto-formatting. In addition to black, nox will execute pylama , and pydocstyle for linting purposes . Nox will also run mypy , with strict type checking. Docstring linting is handled by darglint which has been quite handy! All commits to this repository will trigger a GitHub action which runs nox, but of course its nicer to just run that before making a commit to ensure that it will pass all tests! Typing \u00b6 As stated, this project is 100% type checked and will remain that way. The value this adds for IDE auto-completion and just general sanity checking/forcing writing of more type-check-able code is worth the small overhead in effort. Testing \u00b6 Testing is broken into three main categories -- unit, integration, and functional. Unit is what you would expect -- unit testing the code. Integration tests run scrapli against auto generated ssh server that looks/feels like real network devices. Functional testing connects to virtual devices in order to more accurately test the code. Unit tests cover quite a bit of the code base due to lots of patching low level things to ensure code paths go where they should go. This gives a pretty high level of confidence that at least object instantiation and channel read/writes will generally work! Functional tests against virtual devices provide a much higher guarantee of things working as they should, and are reproducible by end users to boot! Unit Tests \u00b6 Unit tests can be executed via pytest: 1 python -m pytest tests/unit/ Or using the following make command: 1 make test_unit If you would like to see the coverage report and generate the html coverage report: 1 make cov_unit Setting up Functional Test Environment \u00b6 In order to try to be as consistent as possible when running functional testing, we rely on the very awesome containerlab project. Containerlab allows us to have a reliable and consistent testing environment and spin it up easily on any linux host (with nested virtualization capabilities). You can see the containerlab topology file in the .clab directory at the root of scrapli. The topology file in this directory outlines the container images that containerlab requires in order to spin up the topology. Unfortunately, networking vendors suck at giving us free and easy access to container images for testing (notable exception of Nokia and SR-Linux, so shout out to them!), so you are going to need to bring your own images to use. For the Arista EOS platform, you can simply create an account on the Arista website and download the cEOS container image and import it into docker. The other platforms all require you to obtain a Qcow2 disk image of the platform, and to use the boxen project to convert the disk image into a container image that containerlab can launch. The containerlab topology file indicates the version of the platforms the testing suite expects -- other versions may be fine, but try to stick to the versions here if you can so tests run exactly as expected! Once you have the Qcow files in hand, you can use boxen to build the container image -- please check out the boxen docs for how to do this. If you elect to run tests with boxen only (in \"local\" mode -- not described here, but should be straight forward enough) and not use containerlab - set the SCRAPLI_HOST_FWD environment variable to some non-empty string; this will force scrapli to connect to localhost on the ports described below rather than the clab specified (bridged) IP addresses: Device Local Port iosxe 21022 iosxr 22022 nxos 23022 eos 24022 junos 25022 Deploying/Destroying Containerlab Test Environment \u00b6 Once you have created the images, you can start containerlab with a make command: 1 make deploy_clab Conversely, you can terminate the containers: 1 make destroy_clab Ensuring Base Test Configs \u00b6 To ensure that the base test configs are enforced, run the prepare_dev_env make directive, this uses scrapli-cfg to load and replace the configurations running on these devices. This will do things like ensure telnet is enabled (which is not the case by default for most platforms in clab/boxen), etc.. Running Functional Tests \u00b6 To run functional tests you can simply use the make directive: make test_functional If you are adding tests and/or need to \"regenerate\" the expected output, you can use the --update flag like: python -m pytest tests/functional --update This flag causes the test suite to capture the output and write it into the expected directory. This expected output is then compared to the \"real\" output we get from the device during subsequent tests. Other Functional Test Info \u00b6 IOSXE is the only platform that is testing SSH key based authentication at the moment. The key is pushed via NAPALM in the setup phase. This was mostly done out of laziness, and in the future the other platforms may be tested with key based auth as well, but for now IOSXE is representative enough to provide some faith that key based auth works!","title":"Linting and Testing"},{"location":"user_guide/linting_testing/#linting-and-testing","text":"","title":"Linting and Testing"},{"location":"user_guide/linting_testing/#linting","text":"This project uses black for auto-formatting. In addition to black, nox will execute pylama , and pydocstyle for linting purposes . Nox will also run mypy , with strict type checking. Docstring linting is handled by darglint which has been quite handy! All commits to this repository will trigger a GitHub action which runs nox, but of course its nicer to just run that before making a commit to ensure that it will pass all tests!","title":"Linting"},{"location":"user_guide/linting_testing/#typing","text":"As stated, this project is 100% type checked and will remain that way. The value this adds for IDE auto-completion and just general sanity checking/forcing writing of more type-check-able code is worth the small overhead in effort.","title":"Typing"},{"location":"user_guide/linting_testing/#testing","text":"Testing is broken into three main categories -- unit, integration, and functional. Unit is what you would expect -- unit testing the code. Integration tests run scrapli against auto generated ssh server that looks/feels like real network devices. Functional testing connects to virtual devices in order to more accurately test the code. Unit tests cover quite a bit of the code base due to lots of patching low level things to ensure code paths go where they should go. This gives a pretty high level of confidence that at least object instantiation and channel read/writes will generally work! Functional tests against virtual devices provide a much higher guarantee of things working as they should, and are reproducible by end users to boot!","title":"Testing"},{"location":"user_guide/linting_testing/#unit-tests","text":"Unit tests can be executed via pytest: 1 python -m pytest tests/unit/ Or using the following make command: 1 make test_unit If you would like to see the coverage report and generate the html coverage report: 1 make cov_unit","title":"Unit Tests"},{"location":"user_guide/linting_testing/#setting-up-functional-test-environment","text":"In order to try to be as consistent as possible when running functional testing, we rely on the very awesome containerlab project. Containerlab allows us to have a reliable and consistent testing environment and spin it up easily on any linux host (with nested virtualization capabilities). You can see the containerlab topology file in the .clab directory at the root of scrapli. The topology file in this directory outlines the container images that containerlab requires in order to spin up the topology. Unfortunately, networking vendors suck at giving us free and easy access to container images for testing (notable exception of Nokia and SR-Linux, so shout out to them!), so you are going to need to bring your own images to use. For the Arista EOS platform, you can simply create an account on the Arista website and download the cEOS container image and import it into docker. The other platforms all require you to obtain a Qcow2 disk image of the platform, and to use the boxen project to convert the disk image into a container image that containerlab can launch. The containerlab topology file indicates the version of the platforms the testing suite expects -- other versions may be fine, but try to stick to the versions here if you can so tests run exactly as expected! Once you have the Qcow files in hand, you can use boxen to build the container image -- please check out the boxen docs for how to do this. If you elect to run tests with boxen only (in \"local\" mode -- not described here, but should be straight forward enough) and not use containerlab - set the SCRAPLI_HOST_FWD environment variable to some non-empty string; this will force scrapli to connect to localhost on the ports described below rather than the clab specified (bridged) IP addresses: Device Local Port iosxe 21022 iosxr 22022 nxos 23022 eos 24022 junos 25022","title":"Setting up Functional Test Environment"},{"location":"user_guide/linting_testing/#deployingdestroying-containerlab-test-environment","text":"Once you have created the images, you can start containerlab with a make command: 1 make deploy_clab Conversely, you can terminate the containers: 1 make destroy_clab","title":"Deploying/Destroying Containerlab Test Environment"},{"location":"user_guide/linting_testing/#ensuring-base-test-configs","text":"To ensure that the base test configs are enforced, run the prepare_dev_env make directive, this uses scrapli-cfg to load and replace the configurations running on these devices. This will do things like ensure telnet is enabled (which is not the case by default for most platforms in clab/boxen), etc..","title":"Ensuring Base Test Configs"},{"location":"user_guide/linting_testing/#running-functional-tests","text":"To run functional tests you can simply use the make directive: make test_functional If you are adding tests and/or need to \"regenerate\" the expected output, you can use the --update flag like: python -m pytest tests/functional --update This flag causes the test suite to capture the output and write it into the expected directory. This expected output is then compared to the \"real\" output we get from the device during subsequent tests.","title":"Running Functional Tests"},{"location":"user_guide/linting_testing/#other-functional-test-info","text":"IOSXE is the only platform that is testing SSH key based authentication at the moment. The key is pushed via NAPALM in the setup phase. This was mostly done out of laziness, and in the future the other platforms may be tested with key based auth as well, but for now IOSXE is representative enough to provide some faith that key based auth works!","title":"Other Functional Test Info"},{"location":"user_guide/project_details/","text":"Project Details \u00b6 What is scrapli \u00b6 scrapli is a python library focused on connecting to devices, specifically network devices via Telnet, SSH or NETCONF. scrapli is built primarily in three parts: transport, channel, and driver. The transport layer is responsible for providing a file-like interface to the target server. The channel layer is responsible for reading and writing to the provided file-like interface. Finally, the driver provides the user facing API/interface to scrapli. There are six available \"transports\" in scrapli \"core\" -- all of which inherit from a base transport classes and provide the same file-like interface to the upstream channel. Transports \u00b6 The available transport plugins are: system -- wrapper around OpenSSH/System available SSH binary telnet -- Python standard library telnetlib asynctelnet -- Python standard library asyncio stream asyncssh -- wrapper around asyncssh library ssh2 -- wrapper around ssh2-python library paramiko -- wrapper around paramiko library A good question to ask at this point is probably \"why?\". Why multiple transport options? Why not just use paramiko like most folks do? Historically the reason for moving away from paramiko was simply speed. ssh2-python is a wrapper around the libssh2 C library, and as such is very, very fast. In a prior project ( ssh2net ), of which scrapli is the successor/evolution, ssh2-python was used with great success, however, it is a bit feature-limited, and development had stalled around the same time scrapli was getting going. This led to moving back to paramiko, which of course is a fantastic project with tons and tons of feature support . Paramiko, however, does not provide \"direct\" OpenSSH support (as in -- auto-magically like when you ssh on your normal shell), and I don't believe it provides 100% full OpenSSH support either (ex: ControlPersist). Fully supporting an OpenSSH config file would be an ideal end goal for scrapli, something that may not be possible with Paramiko - ControlPersist in particular is very interesting to me. With the goal of supporting all OpenSSH configuration options the primary transport driver option is simply native system local SSH. The implementation of using system SSH is of course a little bit messy, however scrapli takes care of that for you so you don't need to care about it! The payoff of using system SSH is of course that OpenSSH config files simply \"work\" -- no passing it to scrapli, no selective support, no need to set username or ports or any of the other config items that may reside in your SSH config file. This driver will likely be the focus of most development for this project, though I will try to keep the other transport drivers -- in particular asyncssh -- as close to parity as is possible/practical. Adding telnet support via telnetlib was trivial, as the interface is basically the same as SystemSSH, and it turns out telnet is still actually useful for things like terminal servers and the like! Next, perhaps the most interesting scrapli transport plugin is the asyncssh transport. This transport option represented a very big change for scrapli as the entire \"backend\" was basically re-worked in order to provide the exact same API for both synchronous and asynchronous applications. Lastly, the asynctelnet transport is the latest (and perhaps last?!) transport plugin. This transport plugin was built with only the python standard library (just like system/telnet) and as such it is part of scrapli \"core\". Channel \u00b6 The \"channel\" sits between the transports and the drivers -- the channel is where much of the magic happens! The channel is responsible for all prompt finding, sending commands or configs, and generally interacting with the device. The channel essentially reads from and writes to the underlying transport for a given connection. The Channel doesn't need to know or care about which transport you pick! (except of course to know if it is async or synchronous) Drivers \u00b6 The final piece of scrapli is the actual \"driver\" -- or the component that binds the transport and channel together and deals with instantiation of a scrapli object. There is a \"base\" driver object -- Driver -- which provides essentially a \"raw\" SSH (or telnet) connection that is created by instantiating a Transport object, and a Channel object . Drive provides (via Channel) read/write methods and not much else -- this should feel familiar if you have used paramiko in the past. More specific \"drivers\" can inherit from this class to extend functionality of the driver to make it more friendly for network devices. In fact, there is a GenericDriver class that inherits from Scrape and provides a base driver to work with if you need to interact with a device not represented by one of the \"core\" drivers. Next, the NetworkDriver class inherits from GenericDriver . The NetworkDriver isn't really meant to be used directly though, but to be further extended and built upon instead. As this library is focused on interacting with network devices, an example scrapli driver (built on the NetworkDriver ) would be the IOSXEDriver -- to, as you may have guessed , interact with devices running Cisco's IOS-XE operating system. It should be noted that this is a bit of an oversimplification of the architecture of scrapli, but it is accurate . Scrapli has \"base\", \"sync\", and \"async\" versions of the core components. The \"base\" portion is made up of mixin classes that get \"mixed in\" to the sync or async versions of the component. For example there is a NetworkDriverBase class that is \"mixed in\" to the NetworkDriver and AsyncNetworkDriver classes. The mixin provides consistent helper like functions (sync functions) that can be used by the two driver classes -- this allows the sync/async components to have as little code as possible helping to keep the API consistent for both synchronous and asynchronous users. Supported Platforms \u00b6 scrapli \"core\" drivers cover basically the NAPALM platforms -- Cisco IOS-XE, IOS-XR, NX-OS, Arista EOS, and Juniper JunOS. These drivers provide an interface tailored to network device \"screen-scraping\" rather than just a generic SSH connection/channel. It is important to note that there is a synchronous and an asynchronous version of each of these drivers. Below are the core driver platforms and regularly tested version. Cisco IOS-XE (tested on: 16.12.03) Cisco NX-OS (tested on: 9.2.4) Juniper JunOS (tested on: 17.3R2.10) Cisco IOS-XR (tested on: 6.5.3) Arista EOS (tested on: 4.22.1F) It is unlikely that any additional \"core\" platforms would be added, however the scrapli_community project is available for users to contribute any other platforms they would like to see scrapli support! Please see the scrapli_community project to check out what community platforms exist! The \"driver\" pattern is pretty much exactly like the implementation in NAPALM. The driver extends the base class ( Scrape ) and the base networking driver class ( NetworkDriver ) with device specific functionality such as privilege escalation/de-escalation, setting appropriate prompts to search for, and picking out appropriate ntc templates for use with TextFSM, and so on. All of this is focused on network device type Telnet/SSH cli interfaces, but should work on pretty much any SSH connection (though there are almost certainly better options for non-network type devices!). The \"base\" ( Driver ) and GenericDriver connections do not handle any kind of device-specific operations such as privilege escalation or saving configurations, they are simply intended to be a bare-bones connection that can interact with nearly any device/platform if you are willing to send/parse inputs/outputs manually. In most cases it is assumed that users will use one of the \"core\" drivers. The goal for all \"core\" devices will be to include functional tests that can run against vrnetlab containers to ensure that the \"core\" devices are as thoroughly tested as is practical. Related Scrapli Libraries \u00b6 This repo is the \"main\" or \"core\" scrapli project, however there are other libraries/repos in the scrapli family -- here is a list/link to all of the other scrapli things! nornir_scrapli scrapli_community scrapli_cfg scrapli_replay scrapli_netconf","title":"Project Details"},{"location":"user_guide/project_details/#project-details","text":"","title":"Project Details"},{"location":"user_guide/project_details/#what-is-scrapli","text":"scrapli is a python library focused on connecting to devices, specifically network devices via Telnet, SSH or NETCONF. scrapli is built primarily in three parts: transport, channel, and driver. The transport layer is responsible for providing a file-like interface to the target server. The channel layer is responsible for reading and writing to the provided file-like interface. Finally, the driver provides the user facing API/interface to scrapli. There are six available \"transports\" in scrapli \"core\" -- all of which inherit from a base transport classes and provide the same file-like interface to the upstream channel.","title":"What is scrapli"},{"location":"user_guide/project_details/#transports","text":"The available transport plugins are: system -- wrapper around OpenSSH/System available SSH binary telnet -- Python standard library telnetlib asynctelnet -- Python standard library asyncio stream asyncssh -- wrapper around asyncssh library ssh2 -- wrapper around ssh2-python library paramiko -- wrapper around paramiko library A good question to ask at this point is probably \"why?\". Why multiple transport options? Why not just use paramiko like most folks do? Historically the reason for moving away from paramiko was simply speed. ssh2-python is a wrapper around the libssh2 C library, and as such is very, very fast. In a prior project ( ssh2net ), of which scrapli is the successor/evolution, ssh2-python was used with great success, however, it is a bit feature-limited, and development had stalled around the same time scrapli was getting going. This led to moving back to paramiko, which of course is a fantastic project with tons and tons of feature support . Paramiko, however, does not provide \"direct\" OpenSSH support (as in -- auto-magically like when you ssh on your normal shell), and I don't believe it provides 100% full OpenSSH support either (ex: ControlPersist). Fully supporting an OpenSSH config file would be an ideal end goal for scrapli, something that may not be possible with Paramiko - ControlPersist in particular is very interesting to me. With the goal of supporting all OpenSSH configuration options the primary transport driver option is simply native system local SSH. The implementation of using system SSH is of course a little bit messy, however scrapli takes care of that for you so you don't need to care about it! The payoff of using system SSH is of course that OpenSSH config files simply \"work\" -- no passing it to scrapli, no selective support, no need to set username or ports or any of the other config items that may reside in your SSH config file. This driver will likely be the focus of most development for this project, though I will try to keep the other transport drivers -- in particular asyncssh -- as close to parity as is possible/practical. Adding telnet support via telnetlib was trivial, as the interface is basically the same as SystemSSH, and it turns out telnet is still actually useful for things like terminal servers and the like! Next, perhaps the most interesting scrapli transport plugin is the asyncssh transport. This transport option represented a very big change for scrapli as the entire \"backend\" was basically re-worked in order to provide the exact same API for both synchronous and asynchronous applications. Lastly, the asynctelnet transport is the latest (and perhaps last?!) transport plugin. This transport plugin was built with only the python standard library (just like system/telnet) and as such it is part of scrapli \"core\".","title":"Transports"},{"location":"user_guide/project_details/#channel","text":"The \"channel\" sits between the transports and the drivers -- the channel is where much of the magic happens! The channel is responsible for all prompt finding, sending commands or configs, and generally interacting with the device. The channel essentially reads from and writes to the underlying transport for a given connection. The Channel doesn't need to know or care about which transport you pick! (except of course to know if it is async or synchronous)","title":"Channel"},{"location":"user_guide/project_details/#drivers","text":"The final piece of scrapli is the actual \"driver\" -- or the component that binds the transport and channel together and deals with instantiation of a scrapli object. There is a \"base\" driver object -- Driver -- which provides essentially a \"raw\" SSH (or telnet) connection that is created by instantiating a Transport object, and a Channel object . Drive provides (via Channel) read/write methods and not much else -- this should feel familiar if you have used paramiko in the past. More specific \"drivers\" can inherit from this class to extend functionality of the driver to make it more friendly for network devices. In fact, there is a GenericDriver class that inherits from Scrape and provides a base driver to work with if you need to interact with a device not represented by one of the \"core\" drivers. Next, the NetworkDriver class inherits from GenericDriver . The NetworkDriver isn't really meant to be used directly though, but to be further extended and built upon instead. As this library is focused on interacting with network devices, an example scrapli driver (built on the NetworkDriver ) would be the IOSXEDriver -- to, as you may have guessed , interact with devices running Cisco's IOS-XE operating system. It should be noted that this is a bit of an oversimplification of the architecture of scrapli, but it is accurate . Scrapli has \"base\", \"sync\", and \"async\" versions of the core components. The \"base\" portion is made up of mixin classes that get \"mixed in\" to the sync or async versions of the component. For example there is a NetworkDriverBase class that is \"mixed in\" to the NetworkDriver and AsyncNetworkDriver classes. The mixin provides consistent helper like functions (sync functions) that can be used by the two driver classes -- this allows the sync/async components to have as little code as possible helping to keep the API consistent for both synchronous and asynchronous users.","title":"Drivers"},{"location":"user_guide/project_details/#supported-platforms","text":"scrapli \"core\" drivers cover basically the NAPALM platforms -- Cisco IOS-XE, IOS-XR, NX-OS, Arista EOS, and Juniper JunOS. These drivers provide an interface tailored to network device \"screen-scraping\" rather than just a generic SSH connection/channel. It is important to note that there is a synchronous and an asynchronous version of each of these drivers. Below are the core driver platforms and regularly tested version. Cisco IOS-XE (tested on: 16.12.03) Cisco NX-OS (tested on: 9.2.4) Juniper JunOS (tested on: 17.3R2.10) Cisco IOS-XR (tested on: 6.5.3) Arista EOS (tested on: 4.22.1F) It is unlikely that any additional \"core\" platforms would be added, however the scrapli_community project is available for users to contribute any other platforms they would like to see scrapli support! Please see the scrapli_community project to check out what community platforms exist! The \"driver\" pattern is pretty much exactly like the implementation in NAPALM. The driver extends the base class ( Scrape ) and the base networking driver class ( NetworkDriver ) with device specific functionality such as privilege escalation/de-escalation, setting appropriate prompts to search for, and picking out appropriate ntc templates for use with TextFSM, and so on. All of this is focused on network device type Telnet/SSH cli interfaces, but should work on pretty much any SSH connection (though there are almost certainly better options for non-network type devices!). The \"base\" ( Driver ) and GenericDriver connections do not handle any kind of device-specific operations such as privilege escalation or saving configurations, they are simply intended to be a bare-bones connection that can interact with nearly any device/platform if you are willing to send/parse inputs/outputs manually. In most cases it is assumed that users will use one of the \"core\" drivers. The goal for all \"core\" devices will be to include functional tests that can run against vrnetlab containers to ensure that the \"core\" devices are as thoroughly tested as is practical.","title":"Supported Platforms"},{"location":"user_guide/project_details/#related-scrapli-libraries","text":"This repo is the \"main\" or \"core\" scrapli project, however there are other libraries/repos in the scrapli family -- here is a list/link to all of the other scrapli things! nornir_scrapli scrapli_community scrapli_cfg scrapli_replay scrapli_netconf","title":"Related Scrapli Libraries"},{"location":"user_guide/quickstart/","text":"Quick Start Guide \u00b6 Installation \u00b6 In most cases installation via pip is the simplest and best way to install scrapli. See here for advanced installation details. 1 pip install scrapli A Simple Example \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 from scrapli.driver.core import IOSXEDriver my_device = { \"host\" : \"172.18.0.11\" , \"auth_username\" : \"scrapli\" , \"auth_password\" : \"scrapli\" , \"auth_strict_key\" : False , } conn = IOSXEDriver ( ** my_device ) conn . open () response = conn . send_command ( \"show run\" ) print ( response . result ) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 $ python my_scrapli_script.py Building configuration... Current configuration : 7584 bytes ! ! Last configuration change at 19:24:38 PST Sat Feb 29 2020 by carl ! NVRAM config last updated at 19:00:28 PST Fri Feb 7 2020 by carl ! version 15.2 service nagle no service pad service tcp-keepalives-in service tcp-keepalives-out service timestamps debug datetime msec no service password-encryption ! <SNIP> ! end More Examples \u00b6 Basic \"native\" Scrape operations Basic \"GenericDriver\" operations Basic \"core\" Driver operations Basic async operations Async multiple connections Setting up basic logging Using SSH Key for authentication Using SSH config file Parse output with TextFSM/ntc-templates Parse output with Genie Transport Options Configuration Modes - IOSXR Configure Exclusive Configuration Modes - EOS Configure Session Banners, Macros, and other \"weird\" Things Other Stuff \u00b6 Other scrapli related docs/blogs/videos/info: Scrapli on Dmitry Figol's Network Automation Channel Scrapli Intro on Wim Wauter's blog Scrapli on the Packet Pushers Heavy Networking Podcast IPvZero's Network Automation Course (including scrapli!) on CBT Nuggets (paid resource) Rick Donato's Scrapli Course (paid resource)","title":"Quick Start Guide"},{"location":"user_guide/quickstart/#quick-start-guide","text":"","title":"Quick Start Guide"},{"location":"user_guide/quickstart/#installation","text":"In most cases installation via pip is the simplest and best way to install scrapli. See here for advanced installation details. 1 pip install scrapli","title":"Installation"},{"location":"user_guide/quickstart/#a-simple-example","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 from scrapli.driver.core import IOSXEDriver my_device = { \"host\" : \"172.18.0.11\" , \"auth_username\" : \"scrapli\" , \"auth_password\" : \"scrapli\" , \"auth_strict_key\" : False , } conn = IOSXEDriver ( ** my_device ) conn . open () response = conn . send_command ( \"show run\" ) print ( response . result ) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 $ python my_scrapli_script.py Building configuration... Current configuration : 7584 bytes ! ! Last configuration change at 19:24:38 PST Sat Feb 29 2020 by carl ! NVRAM config last updated at 19:00:28 PST Fri Feb 7 2020 by carl ! version 15.2 service nagle no service pad service tcp-keepalives-in service tcp-keepalives-out service timestamps debug datetime msec no service password-encryption ! <SNIP> ! end","title":"A Simple Example"},{"location":"user_guide/quickstart/#more-examples","text":"Basic \"native\" Scrape operations Basic \"GenericDriver\" operations Basic \"core\" Driver operations Basic async operations Async multiple connections Setting up basic logging Using SSH Key for authentication Using SSH config file Parse output with TextFSM/ntc-templates Parse output with Genie Transport Options Configuration Modes - IOSXR Configure Exclusive Configuration Modes - EOS Configure Session Banners, Macros, and other \"weird\" Things","title":"More Examples"},{"location":"user_guide/quickstart/#other-stuff","text":"Other scrapli related docs/blogs/videos/info: Scrapli on Dmitry Figol's Network Automation Channel Scrapli Intro on Wim Wauter's blog Scrapli on the Packet Pushers Heavy Networking Podcast IPvZero's Network Automation Course (including scrapli!) on CBT Nuggets (paid resource) Rick Donato's Scrapli Course (paid resource)","title":"Other Stuff"},{"location":"user_guide/versioning/","text":"Versioning \u00b6 scrapli, and all scrapli related projects use CalVer versioning standard. All release versions follow the format YYYY.MM.DD , however PyPi will shorten/standardize this to remove leading zeros. The reason for choosing CalVer is simply to make it very clear how old a given release of scrapli is. While there are clearly some potential challenges around indicating when a \"breaking\" change occurs due to there not being the concept of a \"major\" version, this is hopefully not too big a deal for scrapli, and thus far the \"core\" API has been very stable -- there are only so many things you can/need to do over SSH after all! Please also note that the CHANGELOG contains notes about each version (and is updated in develop branch while updates are happening), and the \"public\" API is documented here , and includes the date/version of each public method's creation as well as the latest updated/modified date and any relevant notes. A final note regarding versioning: scrapli updates are released as often as necessary/there are things to update . This means you should ALWAYS PIN YOUR REQUIREMENTS when using scrapli!! As stated, the \"core\" API has been very stable, but things will change over time -- always pin your requirements, and keep an eye on the changelog/api docs -- you can \"watch\" this repository to ensure you are notified of any releases.","title":"Versioning"},{"location":"user_guide/versioning/#versioning","text":"scrapli, and all scrapli related projects use CalVer versioning standard. All release versions follow the format YYYY.MM.DD , however PyPi will shorten/standardize this to remove leading zeros. The reason for choosing CalVer is simply to make it very clear how old a given release of scrapli is. While there are clearly some potential challenges around indicating when a \"breaking\" change occurs due to there not being the concept of a \"major\" version, this is hopefully not too big a deal for scrapli, and thus far the \"core\" API has been very stable -- there are only so many things you can/need to do over SSH after all! Please also note that the CHANGELOG contains notes about each version (and is updated in develop branch while updates are happening), and the \"public\" API is documented here , and includes the date/version of each public method's creation as well as the latest updated/modified date and any relevant notes. A final note regarding versioning: scrapli updates are released as often as necessary/there are things to update . This means you should ALWAYS PIN YOUR REQUIREMENTS when using scrapli!! As stated, the \"core\" API has been very stable, but things will change over time -- always pin your requirements, and keep an eye on the changelog/api docs -- you can \"watch\" this repository to ensure you are notified of any releases.","title":"Versioning"}]}
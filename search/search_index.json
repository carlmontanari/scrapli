{"config":{"lang":["en"],"separator":"[\\s\\-\\.]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Scrapli","text":"<p>scrapli -- scrap(e c)li -- is a set of libraries created to interact with devices via the CLI, and NETCONF.</p>"},{"location":"#what-scrapli-is","title":"What Scrapli Is","text":"<ul> <li>A Zig library (libscrapli) that enables interacting with servers via CLI (telnet/SSH) and NETCONF (via SSH)</li> <li>libscrapli supports multiple \"transports\" -- that is the thing that actually sends/receivces from the server:<ul> <li>telnet</li> <li>\"bin\" (wrapper around a binary, usually <code>/bin/ssh</code>, meaning, typically openssh)</li> <li>libssh2</li> </ul> </li> <li>Methods for interacting with CLIs such as <code>getPrompt</code>, <code>sendInput</code>, and <code>readWithCallbacks</code></li> <li>Customizable \"definitions\" for defining characteristics of a CLI server -- i.e. different \"modes\" of the device (i.e: configuration vs privileged exec), commands that should be invoked on connection open or close, and more</li> <li>Methods for interacting with NETCONF servers such as <code>action</code>, <code>get</code>, <code>getConfig</code>, etc.</li> <li>Python bindings to libscrapli (scrapli)</li> <li>Go bindings to libscrapli (scrapligo)</li> </ul>"},{"location":"#what-scrapli-isnt","title":"What Scrapli Isn't","text":"<ul> <li>A library/tool with explicit support for every device type -- meaning scrapli (really, libscrapli) is intended to be flexible enough that it can be adapted to work with most any CLI device (NETCONF should of course \"just work\" because \"standards\"!) through the platform definition system, however, there may be exceptions!</li> <li>An automation platform -- scrapli is a tool that can be used in an automation platform, but it is simply the client to send/receive from devices</li> <li>A Python or Go library -- the Python and Go bits are mostly wrappers around the core zig libscrapli project; if you are interested in contributing you likely need to look at libscrapli, and therefore need to work with zig</li> </ul>"},{"location":"#why-scrapli","title":"Why Scrapli","text":"<ul> <li>User experience: scrapli -- in all its flavors -- provides a pleasant developer experience with well typed, documented, and tested code</li> <li>Customizability: (CLI) platforms (unless you are writing zig) are simply YAML files -- have a device that isn't \"supported\"? Just create a simple YAML file specifying some regular expressions and maybe some inputs to send on a session open and you're set</li> <li>Small footprint: scrapli has very few dependencies regardless of \"which\" scrapli you are looking at -- for the zig core, we rely on only a few zig and C libraries (zig-yaml, zig-xml, pcre2, and libssh2), and the Python and Go bits primarily only rely on libscrapli itself (Python using ctypes, and Go using purego)</li> <li>Language support: zig, Python, or Go, your pick! scrapli is consistent and unified across these languages with only minor differences in the Python and Go variations in order to be idiomatic to the respective language. Additionally, any language that can interface with the C ABI could make use of libscrapli.</li> </ul>"},{"location":"#philosophy","title":"Philosophy","text":"<p>Some general philosophical / navel gazing type thoughts about the philospohy/thinking behind Scrapli.</p> <ul> <li>Do as much as possible in zig. This keeps all the core logic in one place</li> <li>Be idiomatic -- historically scrapligo did not use contexts for cancellation for example, that sucked! Now the Python and Go shims should be idiomatic and feel nice to developers that are used to and appreciate the respective language</li> <li>Have as few (run/compile time) dependencies as possible -- this keeps it much easier to stay up to date, and of course makes the overall footprint nice and tidy</li> <li>Be flexible, but don't say yes too often. Basically, scrapli should be useful to a broad set of folks, but it should not adopt corner-case functionality that can be accomplished fairly easily by those users who would want said functionality</li> </ul>"},{"location":"#history","title":"History","text":"<p>As the name suggests, scrapli began life as a telnet/SSH client built specifically for interacting with \"network\" devices (routers/switches/etc.). This \"original\" scrapli was written in Python. Eventually, a go version was created, aptly named \"scrapligo\". Initially these two flavors of scrapli had a fairly high degree of parity. However, as time went on the two libraries began to diverge. This created a maintainer burden, and inconsistency for those few folks who switch between scrapli and scrapligo.</p> <p>In addition to the divergence between Python and Go scrapli flavors, there has also been a bit of a divergence with respect to NETCONF -- for example NETCONF functionality exists directly in scrapligo, however was a separate library for Python (scrapli-netconf). Moreover, there were methods in scrapligo that were not supported (and could not easily be ported) in scrapli-netconf.</p> <p>Eventually, the idea of a unified scrapli became very compelling (to me, carl, at least) -- stuffing all the important logic of scrapli into a single place and providing bindings to that core library. This would obviously be useful from a maintainer perspective, but also ensure a consistent experience when perhaps using Python for prototyping, but Go for production.</p> <p>Zig was chosen as the language to write the unified scrapli (libscrapli) in. While any low level language -- or really, any language that could be compiled to shared objects -- would work, zig seemed like a nice choice. Once the zig core was in place, it was a matter of figuring out the best way for Python and Go to consume it -- this ended up being ctypes and purego respectively. For Python, it was an obvious choice. For Go, purego means that we are able to do CGO type things without the limitations of CGO (i.e. we can still cross-compile Go programs using scrapligo even though we load the zig/C libscrapli bits).</p>"},{"location":"community/","title":"Community","text":""},{"location":"community/#contributing","title":"Contributing","text":"<p>Thanks for thinking about contributing, contributions are not expected, but are quite welcome.</p> <p>Some notes/thoughts on contributing:</p> <ul> <li>Please do not open issues for \"help\" topics. Use discussions for this</li> <li>If you would like to contribute a feature, know that you will almost certainly need to be working in the zig programming language -- this is how scrapli can support Python and Go in a unified way which is pretty great, but of course this does introduce an extra layer of complexity. I'm happy to help work with you in doing this to some level, but won't be able to help you get going with zig basics</li> <li>Please try to help keep the scrapli flavors in sync when/if you contribute! For example, if we add a flag/knob to scrapli (py) we should be adding an equivalent flag to scrapligo -- this ensures that you can always have a consistent experience with scrapli regardless of the language you are using</li> <li>Please open a GitHub issue for any potential feature adds/changes to discuss them prior to opening a PR, this way everyone has a chance to chime in and make sure we're all on the same page!</li> <li>Please open an issue to discuss any bugs/bug fixes prior to opening a PR. When opening a bug, please try to have done a bit of research to confirm it is indeed a bug, and ideally how it can be reproduced, this saves me an enormous amount of time and energy and makes getting the bug fixed way faster!</li> <li>All PRs must pass tests/CI linting -- checkout the Makefile for some shortcuts for linting and testing. Yes, there are a zillion linters, some or many you may not agree with/like, tough cookies, let's try to keep things tidy!</li> </ul>"},{"location":"community/#thank-yous","title":"Thank Yous","text":"<p>Thank you to the following people who have made contributions in some form or fashion to scrapli -- and apologies to the many many others who have helped, thank you all very much!</p> <ul> <li>Kevin Landreth for always being a great sounding board and for helping out a ton in scrapli's infancy</li> <li>Dmitry Figol for really helpful guidance on how best to build the API/overall structure of things very early on, and continued support/guidance</li> <li>Javin Craig for very early testing help and extra eyes on loads of readme/docs</li> <li>John (IPvZero) McGovern for loads of testing, encouraging the nornir plugin along, and lots of great discussions</li> <li>Ryan Bradshaw for early testing and discussions on disabling paging, dealing with interactive inputs, and making the paramiko/ssh2-python transports plugins</li> <li>Eric Tedor for some interesting and challenging use cases that helped to improve some of the prompt matching decisions</li> <li>Ron Frederick for building the very awesome asyncssh library</li> <li>Brett Canter for building the very first <code>scrapli_community</code> platform! (ruckus_fastiron)</li> <li>Alex Lardschneider for great conversation, many contributions to <code>scrapli_community</code>, and helping to improve various pieces of <code>scrapli</code> with great testing and troubleshooting</li> <li>Marion for loads of testing hard to track down issues with the async transports</li> <li>Roman Dodin for all the support throughout scrapli's life in all the ways</li> <li>netixx for helping unravel some particularly fun decorator timeout shenanigans</li> <li>SimPeccaud for being awesome and helping out here and in other related(ish) endeavors like libscrapli and clabernetes</li> </ul> <p>This list has not been kept up as well as it should, apologies for that! Thank you to everyone else who has contributed in any way to scrapli!</p>"},{"location":"details/","title":"Library Details","text":"<p>This section aims to outline some core concepts about scrapli as well as outline the available methods for both Cli and NETCONF connections.</p>"},{"location":"details/#concepts","title":"Concepts","text":""},{"location":"details/#transports","title":"Transports","text":"<p>scrapli supports multiple transports -- that is, the thing that does the actual sending and receiving of data to/from the server. Those transports are <code>telnet</code>, <code>bin</code> and <code>ssh2</code>.</p> <p>The <code>telnet</code> transport is of course for connecting to Cli devices via telnet -- no surprises there. This transport is a custom telnet driver written in zig that is effectively a port of the since deprecated Python standard library <code>telnetlib</code> package.</p> <p>The default transport for everything not telnet is the <code>bin</code> transport. This transport is a pty-wrapper around a binary, typically <code>/bin/ssh</code>.  The primary benefit of this transport is that you natively get 100% support/coverage of openssh features -- things like ProxyJump, ControlPersist, handling ciphers, key exchanges, and every other flag/feature. The binary can also be swapped to something else entirely -- so you could slot in something like <code>docker exec</code> or perhaps a binary to talk to devices over some vendor serial port or something similar.</p> <p>Lastly, there is the <code>ssh2</code> transport -- this transport is a zig wrapper around the <code>libssh2</code> library compiled with openssl for crypto functionality. The biggest benefit to this transport is that there is no need to have openssh available for it to work -- so this transport can easily be ran inside of a container for example. Functionality is somewhat limited as only the minimum <code>libssh2</code> features have been exposed via the zig shim.</p>"},{"location":"details/#platform-definitions","title":"Platform Definitions","text":"<p>A platform definition defines how libscrapli should interact with a Cli device (telnet/SSH). This definition is a simple YAML file that holds some information such as the regular expression pattern used to match a prompt for the given device, some inputs that should be called upon connection (to disable pagingation for example), and possible \"modes\" the device may have (such as a \"configuration\" mode).</p> <p>Here is an annotated version of the (at time of writing) Nokia SRLinux platform definition:</p> <pre><code>---\nprompt_pattern: '(^.*[&gt;#$]\\s?+$)|(--.*--\\s*\\n[abcd]:\\S+#\\s*$)' # (1)\ndefault_mode: 'exec' # (2)\nmodes:  # (3)\n  - name: 'bash'\n    prompt_pattern: '^.*[&gt;#$]\\s?+$'\n    prompt_excludes: # (4)\n      # ensure bash doesnt match on exec/config. technically this could be in a bash prompt\n      # but seems pretty unlikely\n      - '--{'\n    accessible_modes:\n      - name: 'exec'\n        instructions: # (5)\n          - send_input:\n              input: 'exit'\n  - name: 'exec'\n    prompt_pattern: '^--{(\\s\\[[\\w\\s]+\\]){0,5}[\\+\\*\\s]{1,}running\\s}--\\[.+?\\]--\\s*\\n[abcd]:\\S+#\\s*$'\n    accessible_modes:\n      - name: 'bash'\n        instructions:\n          - send_input:\n              input: 'bash'\n      - name: 'configuration'\n        instructions:\n          - send_input:\n              input: 'enter candidate private'\n  - name: 'configuration'\n    prompt_pattern: '^--{(\\s\\[[\\w\\s]+\\]){0,5}[\\+\\*\\!\\s]{1,}candidate[\\-\\w\\s]+}--\\[.+?\\]--\\s*\\n[abcd]:\\S+#\\s*$'\n    accessible_modes:\n      - name: 'exec'\n        instructions:\n          - send_input:\n              input: 'discard now'\nfailure_indicators: # (6)\n  - 'Error:'\non_open_instructions: # (7)\n  - enter_mode:\n      requested_mode: 'exec'\n  - send_input:\n      input: 'environment cli-engine type basic'\n  - send_input:\n      input: 'environment complete-on-space false'\non_close_instructions: # (8)\n  - enter_mode:\n      requested_mode: 'exec'\n  - write:\n      input: 'quit'\n</code></pre> <ol> <li>The single most important part -- a regular expression (PCRE2) that matches any/all prompts the device may show.</li> <li>The \"mode\" to acquire and send inputs to by default.</li> <li>An array of \"modes\" that define a more explicit pattern that matches the prompt of this mode, and which other modes are accessible from the given mode (and how to access them).</li> <li>Prompts can be tricky to match with a regular expression without accidentally matching other mode prompts too -- this is a list of strings that, if a prompt contains them, would preclude a possible prompt from matching this mode.</li> <li>Instructions on how to acquire another mode from this mode -- these instructions are very simple -- send an input, send a return character, send a prompted input (for things like expecting a password prompt).</li> <li>A list of strings that when found in the output of some input will cause the result object to be marked as \"failed\" -- this is not an error scrapli will return, but is more an annotation that the given input completed successfully but likely did not succeed.</li> <li>Instructions for what libscrapli should do immediately upon successfully opening a connection to a device of this flavor. Typically this includes disabling fancy prompt things, disabling pagination, and possibly disabling console/terminal logging output.</li> <li>Instructions for what libscrapli should do before closing the connection. Usually this just means sending \"exit\", \"quit\", or \"logout\" in order to nicely close/clean-up the connection.</li> </ol> <p>Lastly, here is a lazily LLM generated schema if you're into that sort of thing (that appears to be pretty accurate):</p> Definition JSON Schema <pre><code>{\n  \"$schema\": \"https://json-schema.org/draft/2020-12/schema\",\n  \"title\": \"PlatformDefinition\",\n  \"type\": \"object\",\n  \"properties\": {\n    \"prompt_pattern\": {\n      \"type\": \"string\"\n    },\n    \"default_mode\": {\n      \"type\": \"string\"\n    },\n    \"modes\": {\n      \"type\": \"array\",\n      \"items\": {\n        \"$ref\": \"#/$defs/ModeOptions\"\n      }\n    },\n    \"failure_indicators\": {\n      \"type\": [\"array\", \"null\"],\n      \"items\": {\n        \"type\": \"array\",\n        \"items\": { \"type\": \"string\" }\n      }\n    },\n    \"on_open_instructions\": {\n      \"type\": [\"array\", \"null\"],\n      \"items\": { \"$ref\": \"#/$defs/BoundOnXCallbackInstruction\" }\n    },\n    \"on_close_instructions\": {\n      \"type\": [\"array\", \"null\"],\n      \"items\": { \"$ref\": \"#/$defs/BoundOnXCallbackInstruction\" }\n    },\n    \"force_in_session_auth\": {\n      \"type\": [\"boolean\", \"null\"]\n    },\n    \"bypass_in_session_auth\": {\n      \"type\": [\"boolean\", \"null\"]\n    },\n    \"ntc_templates_platform\": {\n      \"type\": [\"string\", \"null\"]\n    },\n    \"genie_platform\": {\n      \"type\": [\"string\", \"null\"]\n    }\n  },\n  \"required\": [\"prompt_pattern\", \"default_mode\", \"modes\"],\n  \"$defs\": {\n    \"ModeOptions\": {\n      \"description\": \"Placeholder for mode.Options definition\",\n      \"type\": \"object\"\n    },\n    \"BoundOnXCallbackInstruction\": {\n      \"oneOf\": [\n        {\n          \"type\": \"object\",\n          \"properties\": {\n            \"write\": {\n              \"type\": \"object\",\n              \"properties\": {\n                \"write\": {\n                  \"type\": \"object\",\n                  \"properties\": {\n                    \"input\": { \"type\": \"string\" }\n                  },\n                  \"required\": [\"input\"]\n                }\n              },\n              \"required\": [\"write\"]\n            }\n          },\n          \"required\": [\"write\"]\n        },\n        {\n          \"type\": \"object\",\n          \"properties\": {\n            \"enter_mode\": {\n              \"type\": \"object\",\n              \"properties\": {\n                \"enter_mode\": {\n                  \"type\": \"object\",\n                  \"properties\": {\n                    \"requested_mode\": { \"type\": \"string\" }\n                  },\n                  \"required\": [\"requested_mode\"]\n                }\n              },\n              \"required\": [\"enter_mode\"]\n            }\n          },\n          \"required\": [\"enter_mode\"]\n        },\n        {\n          \"type\": \"object\",\n          \"properties\": {\n            \"send_input\": {\n              \"type\": \"object\",\n              \"properties\": {\n                \"send_input\": {\n                  \"type\": \"object\",\n                  \"properties\": {\n                    \"input\": { \"type\": \"string\" }\n                  },\n                  \"required\": [\"input\"]\n                }\n              },\n              \"required\": [\"send_input\"]\n            }\n          },\n          \"required\": [\"send_input\"]\n        },\n        {\n          \"type\": \"object\",\n          \"properties\": {\n            \"send_prompted_input\": {\n              \"type\": \"object\",\n              \"properties\": {\n                \"send_prompted_input\": {\n                  \"type\": \"object\",\n                  \"properties\": {\n                    \"input\": { \"type\": \"string\" },\n                    \"prompt_exact\": { \"type\": [\"string\", \"null\"] },\n                    \"prompt_pattern\": { \"type\": [\"string\", \"null\"] },\n                    \"response\": { \"type\": \"string\" }\n                  },\n                  \"required\": [\"input\", \"response\"]\n                }\n              },\n              \"required\": [\"send_prompted_input\"]\n            }\n          },\n          \"required\": [\"send_prompted_input\"]\n        }\n      ]\n    }\n  }\n}\n</code></pre>"},{"location":"details/#async-io","title":"Async IO","text":"<p>Scrapli has always been an async friendly library -- the first bit of this was the native async/await support in scrapli (py), and of course scrapligo is effectively natively asynchronous thanks to the go runtime. This tradition continues in libscrapli, however the realization is a little bit different!</p> <p>libscrapli runs a pthread for the \"read loop\" -- that is the loop that is constantly consuming from the transport and staging the read bytes into a queue. The transports themselves all operate in a non-blocking fashion and leverage an epoll/kqueue waiter to await readable data. This implementation gives us the best of all worlds where we do not need to have super tight read loops to continually read bytes from a connection while still allowing us to have cancellable reads (by awakaing the epoll/kqueue waiter).</p> <p>When scrapli/scrapligo call into the libscrapli backend something similar happens -- tasks are queued and are pollable via an operation ID. In async Python operation and normal Go operations, these operations are awaited on by calling select on a file descriptor allocated to be used to notify the higher level language when an operation is complete. In synchronous Python operation, the operation is simply polled on an interval with a simple backoff timer.</p> <p>The end result is that libscrapli is reasonably efficient no matter the way you chose to consume from it -- synchronous or asynchronous Python, or natively asynchronous Go.</p>"},{"location":"details/#methods","title":"Methods","text":"<p>This section outlines the methods available on the Cli and Netconf drivers -- each section briefly outlines the usage of the method, and shows the method name for Zig, Python, and Go versions.</p>"},{"location":"details/#cli","title":"Cli","text":""},{"location":"details/#get-prompt","title":"Get Prompt","text":"<p>Fetches the current \"prompt\" from the device -- this is based on the regular expression pattern used to find the prompt for the given definition/platform you are using to connect to the server.</p> <ul> <li>zig: <code>getPrompt</code></li> <li>python: <code>get_prompt</code> / <code>get_prompt_async</code></li> <li>go: <code>GetPrompt</code></li> </ul>"},{"location":"details/#enter-mode","title":"Enter Mode","text":"<p>Enter the given \"mode\" on the server -- this can be things like \"configuration\" or \"privileged-exec\" type modes -- the modes themselves are define din the platform definition, so consult the definition for available modes.</p> <ul> <li>zig: <code>enterMode</code></li> <li>python: <code>enter_mode</code> / <code>enter_mode_async</code></li> <li>go: <code>EnterMode</code></li> </ul>"},{"location":"details/#send-input","title":"Send Input","text":"<p>Send a given input to the device. This input will be sent at the \"default\" mode for the given platform unless otherwise specified -- meaning, if you want to send a \"configuration\" you will need to use this method, and specify the configuration mode!</p> <ul> <li>zig: <code>sendInput</code></li> <li>python: <code>send_input</code> / <code>send_input_async</code></li> <li>go: <code>SendInput</code></li> </ul>"},{"location":"details/#send-inputs","title":"Send Inputs","text":"<p>The same as send input, but, for multiple inputs.</p> <ul> <li>zig: <code>sendInputs</code></li> <li>python: <code>send_inputs</code> / <code>send_inputs_async</code></li> <li>go: <code>SendInputs</code></li> </ul>"},{"location":"details/#send-prompted-input","title":"Send Prompted Input","text":"<p>Used to deal with \"prompts\" -- things like \"are you sure you want to do this enter y for yes, or n for no\" kind of things. This method accepts an input, then an exact or regular expression prompt pattern to \"expect\", finally, an input to respond to the prompt with.</p> <ul> <li>zig: <code>sendPromptedInput</code></li> <li>python: <code>send_prompted_input</code> / <code>send_prompted_input_async</code></li> <li>go: <code>SendPromptedInput</code></li> </ul>"},{"location":"details/#read-with-callbacks","title":"Read With Callbacks","text":"<p>This method is a bit more of an advanced method -- it accepts an optional input to \"start\" the operation, then a list of callbacks with information about how those callbacks should be triggered. The original impetus for this method was for connecting to devices via console server and handling initial config dialogs, however of course it can be used in other ways as well!</p> <ul> <li>zig: <code>readWithCallbacks</code></li> <li>python: <code>read_with_callbacks</code> / <code>read_with_callbacks_async</code></li> <li>go: <code>ReadWithCallbacks</code></li> </ul>"},{"location":"details/#netconf","title":"Netconf","text":""},{"location":"details/#raw-rpc","title":"Raw RPC","text":"<p>A method to send a \"raw\" rpc -- that is an rpc of your own creation. This method allows you to use scrapli for rpcs that scrapli does not natively support -- especially useful for subscriptions etc..</p> <ul> <li>zig: <code>rawRpc</code></li> <li>python: <code>raw_rpc</code> / <code>raw_rpc_async</code></li> <li>go: <code>RawRpc</code></li> </ul>"},{"location":"details/#get-config","title":"Get Config","text":"<p>The get-config RPC. Nothing too exciting to say here!</p> <ul> <li>zig: <code>getConfig</code></li> <li>python: <code>get_config</code> / <code>get_config_async</code></li> <li>go: <code>GetConfig</code></li> </ul>"},{"location":"details/#edit-config","title":"Edit Config","text":"<p>The edit-config RPC. Of course this expects the payload, optionally the target datastore and some other options.</p> <ul> <li>zig: <code>editConfig</code></li> <li>python: <code>edit_config</code> / <code>edit_config_async</code></li> <li>go: <code>EditConfig</code></li> </ul>"},{"location":"details/#copy-config","title":"Copy Config","text":"<p>Copy the config from one datastore to another.</p> <ul> <li>zig: <code>copyConfig</code></li> <li>python: <code>copy_config</code> / <code>copy_config_async</code></li> <li>go: <code>CopyConfig</code></li> </ul>"},{"location":"details/#delete-config","title":"Delete Config","text":"<p>Delete a config in a datastore.</p> <ul> <li>zig: <code>deleteConfig</code></li> <li>python: <code>delete_config</code> / <code>delete_config_async</code></li> <li>go: <code>DeleteConfig</code></li> </ul>"},{"location":"details/#lock","title":"Lock","text":"<p>Lock a given datastore.</p> <ul> <li>zig: <code>lock</code></li> <li>python: <code>lock</code> / <code>lock_async</code></li> <li>go: <code>Lock</code></li> </ul>"},{"location":"details/#unlock","title":"Unlock","text":"<p>Unlock a given datastore.</p> <ul> <li>zig: <code>unlock</code></li> <li>python: <code>unlock</code> / <code>unlock_async</code></li> <li>go: <code>Unlock</code></li> </ul>"},{"location":"details/#get","title":"Get","text":"<p>Perform a get RPC against the target server.</p> <ul> <li>zig: <code>get</code></li> <li>python: <code>get</code> / <code>get_async</code></li> <li>go: <code>Get</code></li> </ul>"},{"location":"details/#close-session","title":"Close Session","text":"<p>Nicely close the session -- typically you don't need to call this as the <code>close</code> method will handle it for you.</p> <ul> <li>zig: <code>closeSession</code></li> <li>python: <code>close_session</code> / <code>close_session_async</code></li> <li>go: <code>CloseSession</code></li> </ul>"},{"location":"details/#kill-session","title":"Kill Session","text":"<p>Kill another session, you must provide the session ID to kill.</p> <ul> <li>zig: <code>killSession</code></li> <li>python: <code>kill_session</code> / <code>kill_session_async</code></li> <li>go: <code>KillSession</code></li> </ul>"},{"location":"details/#commit","title":"Commit","text":"<p>Commit pending changes in a datastore.</p> <ul> <li>zig: <code>commit</code></li> <li>python: <code>commit</code> / <code>commit_async</code></li> <li>go: <code>Commit</code></li> </ul>"},{"location":"details/#discard","title":"Discard","text":"<p>Discard pending changes in a datastore.</p> <ul> <li>zig: <code>discard</code></li> <li>python: <code>discard</code> / <code>discard_async</code></li> <li>go: <code>Discard</code></li> </ul>"},{"location":"details/#cancel-commit","title":"Cancel Commit","text":"<p>Cancel a pending commit operation.</p> <ul> <li>zig: <code>cancelCommit</code></li> <li>python: <code>cancel_commit</code> / <code>cancel_commit_async</code></li> <li>go: <code>CancelCommit</code></li> </ul>"},{"location":"details/#validate","title":"Validate","text":"<p>Validate the contents of a datastore.</p> <ul> <li>zig: <code>validate</code></li> <li>python: <code>validate</code> / <code>validate_async</code></li> <li>go: <code>Validate</code></li> </ul>"},{"location":"details/#get-schema","title":"Get Schema","text":"<p>Fetch a schema from the server.</p> <ul> <li>zig: <code>getSchema</code></li> <li>python: <code>get_schema</code> / <code>get_schema_async</code></li> <li>go: <code>GetSchema</code></li> </ul>"},{"location":"details/#get-data","title":"Get Data","text":"<p>Execute the get-data RPC.</p> <ul> <li>zig: <code>getData</code></li> <li>python: <code>get_data</code> / <code>get_data_async</code></li> <li>go: <code>GetData</code></li> </ul>"},{"location":"details/#edit-data","title":"Edit Data","text":"<p>Execute the edit-data RPC.</p> <ul> <li>zig: <code>editData</code></li> <li>python: <code>edit_data</code> / <code>edit_data_async</code></li> <li>go: <code>EditData</code></li> </ul>"},{"location":"details/#action","title":"Action","text":"<p>Execute the action RPC on the server.</p> <ul> <li>zig: <code>action</code></li> <li>python: <code>action</code> / <code>action_async</code></li> <li>go: <code>Action</code></li> </ul>"},{"location":"installation/","title":"Installation","text":"<p>Installing scrapli varies depending on which flavor of scrapli you are wanting to use! Check out the appropriate section below based on your needs.</p>"},{"location":"installation/#python","title":"Python","text":"<p>Due to the history of scrapli (py) using calendar versioning, and modern scrapli generally changing to using semantic versioning, there are now actually two scrapli projects on PyPI -- <code>scrapli</code> and <code>scrapli2</code>. Both are the same codebase, with the only difference being the versioning scheme. <code>scrapli</code> is still released using calendar versioning. This ensures no change of behavior from the \"legacy\" scrapli things, and also keeps pip from losing its mind comparing calendar and semantic versions. If you prefer to just use semantic versioning you can install <code>scrapli2</code>.</p> <p>The simplest method of installing scrapli is simply to <code>pip</code> install it:</p> <pre><code>pip install scrapli\n</code></pre> <p>or</p> <pre><code>pip install scrapli2\n</code></pre> <p>You can install from main as well as follows:</p> <pre><code>pip install git+https://github.com/carlmontanari/scrapli\n</code></pre> <p>Or a specific commit hash or branch (respectively) like so:</p> <pre><code>pip install git+https://github.com/carlmontanari/scrapli.git@0d1e871\npip install git+https://github.com/carlmontanari/scrapli.git@some-feature#egg=scrapli2\n</code></pre> <p>Note: notice the <code>egg=scrapli2</code> part, that's important! Its needed because the pyproject.toml metadata in the repo has <code>scrapli2</code> (the semver version).</p> <p>You can of course also just install from source:</p> <pre><code>git clone https://github.com/carlmontanari/scrapli\ncd scrapli\npip install .\n</code></pre>"},{"location":"installation/#optional-extras","title":"Optional Extras","text":"<p>scrapli also has two optional extras -- textfsm/ntc-templates and genie. You can install those like:</p> <pre><code>pip install scrapli[textfsm]\npip install scrapli[genie]\n</code></pre> <p>Or alternatively the following to do both:</p> <pre><code>pip install scrapli[full]\n</code></pre>"},{"location":"installation/#go","title":"Go","text":"<p>Installation in a go project begins as you would expect. You can just use normal go toolchain things to include it in your project:</p> <pre><code>go get github.com/scrapli/scrapligo/v2\n</code></pre> <p>Or at a tag/commit:</p> <pre><code>go get github.com/scrapli/scrapligo/v2@v2.0.0\n</code></pre> <p>This gets you the source code, however it does not install libscrapli for you as there is no \"install\" step like we have with Python (via setuptools). You have a few options for how you can handle getting libscrapli when using scrapligo:</p> <ol> <li> <p>Do nothing</p> <p>If you elect to do nothing, the first time you run a program that is doing scrapligo things, libscrapli will be fetched and stored in a cache path. That path can be set via the <code>LIBSCRAPLI_CACHE_PATH</code> environment variable, or defaults to <code>XDG_CACHE_HOME</code> (if set) or <code>$HOME/.cache/scrapli</code> on linux systems, or <code>$HOME/Library/Caches/scrapli</code> on Darwin systems.</p> <p>libscrapli is fetched via HTTP whenever the libscrapli version (in <code>constants/versions.go</code>) of scrapligo is set to a tag. If you are using a development version that is pinned to a commit hash of libscrapli, you will need to have docker available as libscrapli will be fetched and built in a container.</p> <p>Do note that this does require the host to be able to access GitHub!</p> </li> <li> <p>Get it yourself</p> <p>You will likely want to use this option if you are building a container, don't want to wait for the things out lined in option one above to happen, or are needing to run things somewhere with no access to GitHub.</p> <p>If you've cloned the scrapligo project and have normal go tools available, you can use the helper program in the build dir to fetch libscrapli:</p> <pre><code>go run build/write_libscrapli_to_cache/main.go\n</code></pre> </li> </ol> <p>Alternatively you can fetch the libscrapli build for your specific platform (found in libscrapli releases), or of course you can build libscrapli yourself. Once you've got the compiled shared object, you simply need to place it at the appropriate cache path or set the override path as outlined above.</p>"},{"location":"installation/#zig","title":"Zig","text":"<p>Using libscrapli in zig is like using any other 0.16.0+ zig library, you can simply <code>zig fetch</code> and save it to your <code>build.zig.zon</code>:</p> <pre><code>zig fetch --save=libscrapli https://github.com/scrapli/libscrapli/archive/refs/tags/v0.0.1-rc.1.tar.gz\n</code></pre> <p>Then, in your <code>build.zig</code> you can use it as a dependency similar to this:</p> <pre><code>const std = @import(\"std\");\n\npub fn build(b: *std.Build) void {\n    const target = b.standardTargetOptions(.{});\n    const optimize = b.standardOptimizeOption(.{});\n\n    const main = b.step(\"main\", \"Build main.zig executable\");\n\n    const libscrapli = b.dependency(\n        \"libscrapli\",\n        .{\n            .target = target,\n            .optimize = optimize,\n        },\n    );\n\n    const exe_mod = b.createModule(\n        .{\n            .root_source_file = b.path(\"src/main.zig\"),\n            .target = target,\n            .optimize = optimize,\n        },\n    );\n\n    const main_exe = b.addExecutable(\n        .{\n            .name = \"libscrapli_usage_example\",\n            .root_module = exe_mod,\n        },\n    );\n\n    main_exe.root_module.addImport(\"scrapli\", libscrapli.module(\"scrapli\"));\n\n    const exe_target_output = b.addInstallArtifact(main_exe, .{});\n\n    main.dependOn(&amp;exe_target_output.step);\n}\n</code></pre> <p>Finally, in your program itself you can now import <code>scrapli</code>:</p> <pre><code>const scrapli = @import(\"scrapli\");\nconst cli = scrapli.cli;\n</code></pre> <p>And create a cli driver for example:</p> <pre><code>const d = try cli.Driver.init(allocator, host, .{})\n</code></pre>"},{"location":"migration/","title":"Legacy Migration","text":"<p>This page attempts to outline the changes from \"legacy\" scrapli to the newer libscrapli based libraries. Thankfully the surface area for the scrapli API is pretty small, so while the changes are dramatic, it shouldn't be too terribly difficult to migrate any existing code to the newer format.</p>"},{"location":"migration/#general-changes","title":"General Changes","text":"<ul> <li>All the smart stuff happens in Zig! Libscrapli is basically the core of everything now, Python and Go packages are thin, idiomatic wrappers around libscrapli.</li> <li>scrapli/scrapligo will not work without libscrapli -- please see the installation section for more info.</li> <li>No more generic vs network driver -- libscrapli dropped the idea of sending \"configurations\". There are now only inputs, you can send those inputs at any \"mode\" you would like (including of course \"configuration\" mode). With this change in mentality, there is no point in dividing things between generic and network, so that division does not exist anymore!</li> <li>scrapli community has been deprecated in favor of scrapli definitions -- this has been a long time coming, starting with scrapligo, where \"definitions\" were strictly YAML. This of course makes things more portable, at the expense of being less flexible (though it seems only FortiOS will have issues with this, see python changes below).</li> <li>You do not need to specify a platform anymore when using a Cli connection -- there is very generic default platform that will be auto selected if you do not provide one. You probably should still provide one to match your target device so you have proper pagination disabling and any other things like that.</li> <li>Privilege levels have been replaced with \"modes\" -- mostly this is a semantic change as you can still send inputs at a given mode/privilege level, and most definitions will try to acquire a sane default/initial mode upon connection.</li> <li>There is a lot more NETCONF support generally -- while not all RFC RPCs are supported, there is still a \"raw\" RPC method that should allow you to send whatever you need to your NETCONF server.</li> <li>The default <code>bin</code> transport now disables strict key checking by default -- this has historically been a pain point for folks using scrapli for the first time. You should enable this... but... up to you!</li> <li>The default <code>bin</code> transport no longer disables looking up default ssh config files (<code>-F /dev/null</code>) by default -- that means it will automatically honor any of your ssh config file settings by default.</li> <li>There is no longer any <code>auth_secondary</code> -- this has historically been used for \"enable\" passwords. This functionality has been replaced by lookups which is basically an array of lookup keys and the value to use for that lookup -- this is then referenced in a definition like: <code>__lookup::enable</code> which would use the lookup with the key \"enable\".</li> </ul>"},{"location":"migration/#python-changes","title":"Python Changes","text":"<ul> <li>No more paramiko, asyncssh, or ssh2-python -- all transport things happen in libscrapli/C dependencies now.</li> <li>TTP support has been removed -- TTP is great, it was just a little silly to retain extra API surface that was basically one line, you can easily handle this yourself!</li> <li>Everything but required args are forced to be keyword arguments (via <code>*</code>), this makes it easier to move args around without affecting user code.</li> <li>There is no longer a separate package for NETCONF, all NETCONF functionality lives in libscrapli and the scrapli package exposes that alongside the CLI functionality.</li> <li>Python 3.10+ only! At time of writing 3.10 is already only in security fixes anyway, so this should really not be a huge problem! That said, this should mostly work with only minor tweaks all the way back to 3.7ish if you really needed to make it work (type annotations being the big thing requiring 3.10).</li> <li>There is no longer any mixin shenanegins! This historically existed for us to have an async and sync version of everything w/ some common functionality -- now instead the same Cli/Netconf classes support methods in both async and sync flavors like: <code>get_config_async</code> and <code>get_config</code>.</li> <li>scrapli community has been deprecated -- this has some potential issues for a handful of platforms that had some \"extra\" things (looking at you FortiOS!). Supporting this will ultimately end up needing to be community/individually driven as retaining the type of customization that existed here (and AFAICT only here) is not easy to accomplish with the libscrapli backend.</li> <li>Python now supports handling NETCONF subscriptions -- this was not previously possible due to how the channel processed data. Please see the relevant example for how to set this up.</li> </ul>"},{"location":"migration/#go-changes","title":"Go Changes","text":"<ul> <li>Rejoice! There is no more timeout options, timeouts are instead now governed by contexts as you would expect in any reasonable go package!</li> <li>There is (currently?) no \"bring your own\" transport option.</li> <li>Please see the go installation section for details about getting libscrapli -- libscrapli is required and will be automatically fetched on initial execution, however you can handle this ahead of time if you'd prefer (or are doing things in a container for example).</li> <li>There is no more direct support for any kind of NETCONF subscription -- instead, please see the example section for this - there is support for fetching subscription/notification messages, you just need to set up the subscription a bit more on your own!</li> </ul>"},{"location":"examples/go/","title":"Go","text":"<p>This page contains a very simple example for using scrapli to connect to a CLI device (telnet/ssh) as well as a NETCONF server -- there are many more examples here, so check those out too.</p>"},{"location":"examples/go/#cli","title":"CLI","text":"<pre><code>package main\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"time\"\n\n    scrapligocli \"github.com/scrapli/scrapligo/v2/cli\" // (1)\n    scrapligooptions \"github.com/scrapli/scrapligo/v2/options\" // (2)\n)\n\nfunc main() {\n    ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second) // (3)\n    defer cancel()\n\n    opts := []scrapligooptions.Option{ // (4)\n        scrapligooptions.WithDefinitionFileOrName(scrapligocli.NokiaSrlinux),\n        scrapligooptions.WithUsername(\"scrapli\"),\n        scrapligooptions.WithPassword(\"verysecurepassword\"),\n    }\n\n    c, err := scrapligocli.NewCli( // (5)\n        \"myrouter\",\n        opts...,\n    )\n    if err != nil {\n        panic(fmt.Sprintf(\"failed creating cli object, error: %v\", err))\n    }\n\n    _, err = c.Open(ctx) // (6)\n    if err != nil {\n        panic(err)\n    }\n\n    defer c.Close(ctx) // (7)\n\n    r, err := c.SendInput(ctx, \"info\") // (8)\n    if err != nil {\n        panic(err)\n    }\n\n    fmt.Println(r.Result()) // (9)\n}\n</code></pre> <ol> <li>The <code>cli</code> package of course holds cli related things, including the <code>NewCli</code> function we'll use a bit later.</li> <li>We'll also import the <code>options</code> package -- this holds all the options we'll use when establishing our connection.</li> <li>Rejoice gophers! scrapligo uses context cancellation like you'd expect any go package to do (this was historically not the case).</li> <li>Here we create a slice of options to pass to the <code>NewCli</code> function -- in this example we are setting the definition to use the <code>NokiaSrlinux</code> definition, and setting a dummy username/password.</li> <li>And now we can create our <code>Cli</code> object with our given options to connect to \"myrouter\" in this case.</li> <li>Now we can open the connection using the appropriately named <code>Open</code> method.</li> <li>Always make sure to defer closing the connection -- this is especially important for daemons/long running programs as the <code>Close</code> method is where resources will be freed.</li> <li>We can use <code>SendInput</code> to... send an input to the device...</li> <li>Finally, we can access the full output from the result using the <code>Result()</code> method of the <code>Result</code> object that we got returned from <code>SendInput</code>.</li> </ol>"},{"location":"examples/go/#netconf","title":"NETCONF","text":"<pre><code>package main\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"time\"\n\n    scrapligonetconf \"github.com/scrapli/scrapligo/v2/netconf\" // (1)\n    scrapligooptions \"github.com/scrapli/scrapligo/v2/options\" // (2)\n)\n\nfunc main() {\n    ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second) // (3)\n    defer cancel()\n\n    opts := []scrapligooptions.Option{ // (4)\n        scrapligooptions.WithUsername(\"scrapli\"),\n        scrapligooptions.WithPassword(\"verysecurepassword\"),\n    }\n\n    n, err := scrapligonetconf.NewNetconf( // (5)\n        \"myrouter\",\n        opts...,\n    )\n    if err != nil {\n        panic(fmt.Sprintf(\"failed creating netconf object, error: %v\", err))\n    }\n\n    _, err = n.Open(ctx) // (6)\n    if err != nil {\n        panic(err)\n    }\n\n    defer n.Close(ctx) // (7)\n\n    r, err := n.GetConfig(ctx) // (8)\n    if err != nil {\n        panic(err)\n    }\n\n    fmt.Println(r.Result()) // (9)\n}\n</code></pre> <ol> <li>The <code>netconf</code> package of course holds NETCONF related things, including the <code>NewNetconf</code> function we'll use a bit later.</li> <li>We'll also import the <code>options</code> package -- this holds all the options we'll use when establishing our connection -- same as with the CLI example.</li> <li>Again, normal context things here.</li> <li>Here we create a slice of options to pass to the <code>NewNetconf</code> function -- in this example we are just setting a dummy username/password.</li> <li>And now we can create our <code>Netconf</code> object with our given options to connect to \"myrouter\" in this case.</li> <li>Now we can open the connection using the appropriately named <code>Open</code> method.</li> <li>Always make sure to defer closing the connection -- this is especially important for daemons/long running programs as the <code>Close</code> method is where resources will be freed.</li> <li>We can use <code>GetConfig</code> to... send a get-config rpc to the device...</li> <li>Finally, we can access the full output from the result using the <code>Result()</code> method of the <code>Result</code> object that we got returned from <code>GetConfig</code>.</li> </ol>"},{"location":"examples/python/","title":"Python","text":"<p>This page contains a very simple example for using scrapli to connect to a CLI device (telnet/ssh) as well as a NETCONF server -- there are many more examples here, so check those out too.</p>"},{"location":"examples/python/#cli","title":"CLI","text":"<pre><code>from scrapli import AuthOptions, Cli # (1)\n\n\ndef main(name):\n    cli = Cli( # (2)\n        definition_file_or_name=\"cisco_iosxe\",\n        host=\"myrouter\",\n        auth_options=AuthOptions(\n            username=\"scrapli\",\n            password=\"verysecurepassword\",\n        ),\n    )\n\n    with cli as c: # (3)\n        result = c.send_input(input_=\"show version\") # (4)\n        print(result.result) # (5)\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <ol> <li>Import the <code>Cli</code> and <code>AuthOptions</code> objects from scrapli, the <code>Cli</code> object is the class that represents our connection to some device via telnet/SSH, and <code>AuthOptions</code> is just a class that holds various authentication related things.</li> <li>Here we create our instance <code>cli</code> of the <code>Cli</code> class -- the only required argument is <code>host</code> -- as of course we must tell scrapli what host to connect to, but here we also provide a few other common things. <code>definition_file_or_name</code> refers to either a platform name or a local YAML file defining a platform. <code>auth_options</code> is of course options related to authentication.</li> <li>The <code>Cli</code> implements the context manager protocol, so you can use it like this in a <code>with</code> block, or simply call <code>open</code> and then <code>close</code> when you are done.</li> <li>Once we've got an opened connection we can use methods like <code>send_input</code> to interact with the device.</li> <li>All operations return a <code>Result</code> object, in this case we are printing the <code>result</code> field of that object which of course contains the output from our input.</li> </ol>"},{"location":"examples/python/#netconf","title":"NETCONF","text":"<pre><code>from scrapli import AuthOptions, Netconf # (1)\n\n\ndef main(name):\n    netconf = Netconf( # (2)\n        host=\"myrouter\",\n        auth_options=AuthOptions(\n            username=\"scrapli\",\n            password=\"verysecurepassword\",\n        ),\n    )\n\n    with cli as c: # (3)\n        result = c.get_config() # (4)\n        print(result.result) # (5)\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <ol> <li>Similar to the cli example we'll import <code>Netconf</code> here with our <code>AuthOptions</code>.</li> <li>When creating a <code>Netconf</code> connection we only need to provide the host and probably auth information.</li> <li>Again, using the context manager is a good idea, but not strictly required.</li> <li>Once we've got an opened connection we can use methods like <code>send_input</code> to interact with the device.</li> <li>All methods also return a <code>Result</code>, though this time it is a NETCONF flavor result, but the look and feel is pretty much the same!</li> </ol>"},{"location":"examples/zig/","title":"Zig","text":"<p>libscrapli the core zig library that really is scrapli, currently has the least amount of collateral about how to use it as it is expected that the vast majority of users will use the Python and Go wrappers. If you'd like to check out a few zig examples though, head here</p>"}]}